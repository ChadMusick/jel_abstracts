C81|Measuring Success: Clio and the Value of Database Creation|In a recent article Stefano Fenoaltea (2018) bemoaned the loss of respect and focus on the importance of creating databases, or “measurement” as he referred to it. Cliometrics has made and continues to make valuable contributions not just to the field of economic history, but economics in general. In particular, we focus on the contribution of cliometrics to the creation of datasets. We highlight several important cases in both the past and present, of recognized important contributions of new datasets to the economics discipline. We argue that Clio has continually focused on, and valued, the creation of new data sets and the clever and novel ways they have been exploited to further the frontiers of knowledge, and that these efforts are both appreciated and recognized.
C81|Lying and Shirking Under Oath|This study explores whether an oath to honesty can reduce both shirking and lying among crowd-sourced internet workers. Using a classic coin-ip experiment, we rst show that a substantial majority of Mechanical Turk workers both shirk and lie when reporting the number of heads ipped. We then demonstrate lying can be reduced by rst asking each worker to swear voluntarily on his or her honor to tell the truth in subsequent economic decisions. The oath, however, did not reduce shirking as measured by time- at-coin-ip-task, although it did increase the time they spent answering a demographic survey. Conditional on response, MTurk shirkers and liars were less likely to agree to an ex post honesty oath. Our results suggest oaths may help elicit more truthful behavior in on-line crowd-sourced environments.
C81|The survey of financial competences (ECF): description and methods of the 2016 wave|The Survey of Financial Competences (ECF) is a joint initiative of the Banco de España and the Comisión Nacional del Mercado de Valores (CNMV) aimed at measuring the financial competences of the adult population in Spain. Between 2016 and 2017, information has been collected for a large sample provided by the National Statistical Institute of randomly selected individuals, and representative of the whole Spanish population between 18 and 79 years of age and of each of its regions. This paper provides a detailed description of the most relevant methodological aspects in the design and implementation of the survey: the sample design, the questionnaire, the data collection process, the validation of the data, the computation of weights, and the imputation procedure.
C81|Measuring retail trade using card transactional data|In this paper we present a high-dimensionality Retail Trade Index (RTI) constructed to nowcast the retail trade sector economic performance in Spain, using Big Data sources and techniques. The data are the footprints of BBVA clients from their credit or debit card transactions at Spanish point of sale (PoS) terminals. The resulting indexes have been found to be robust when compared with the Spanish RTI, regional RTI (Spain’s autonomous regions), and RTI by retailer type (distribution classes) published by the National Statistics Institute (INE). We also went one step further, computing the monthly indexes for the provinces and sectors of activity and the daily general index, by obtaining timely, detailed information on retail sales. Finally, we analyzed the high-frequency consumption dynamics using BBVA retailer behavior and a structural time series model.
C81|Predicción de precios de vivienda: Aprendizaje estadístico con datos de oferta y transacciones para la ciudad de Montevideo|En este trabajo se presentan modelos predictivos para el precio de un activo de difícil valuación como la vivienda. Se utilizan dos fuentes de datos para la ciudad de Montevideo: una proveniente de sitios web (a través de web scraping) y otra de registros administrativos de transacciones. Se implementan tres modelos fácilmente replicables: modelo lineal, árbol de regresión y bosques aleatorios. Los resultados arrojan una mejor performance del modelo de bosques aleatorios respecto al modelo lineal hedónico, ampliamente difundido en la literatura. Se busca incorporar al análisis de predicción de precios una metodología aún escasamente difundida a nivel nacional, implementada en el software R y poner a disposición una nueva base de datos.
C81|Measuring inefficiency in international electricity trading|We show that established metrics used to monitor electricity trading inefficiency become increasingly inaccurate in several trading conditions. We devise the Unweighted and Price-Weighted Inefficient Interconnector Utilisation indices to address these deficiencies. These metrics are substantially more accurate than existing ones and perform equally well whether or not markets are coupled. Our results show a substantial decrease in inefficient trading between Great Britain and both France and the Netherlands after the European Union’s market coupling regulations were introduced in 2014. In view of Great Britain’s likely withdrawal from the European Union, the paper also evaluates how market uncoupling would affect cross-border trade. We find that uncoupling would lead to inefficiencies in trade, the electricity price differential between GB and France (Netherlands) rising by 3% (2%), net imports into GB decreasing by 26% (13%), congestion income decreasing by 10% (5%), and infra-marginal surplus decreasing by 1.6% (1.6%) of coupled congestion income. We also show that, should the EU decide to implement an equivalent carbon tax to GB’s Carbon Price Floor, uncoupling impacts would be slightly magnified due to electricity prices converging (by about 1% of coupled congestion income).
C81|Automating Response Evaluation for Franchising Questions on the 2017 Economic Census|Between the 2007 and 2012 Economic Censuses (EC), the count of franchise-affiliated establishments declined by 9.8%. One reason for this decline was a reduction in resources that the Census Bureau was able to dedicate to the manual evaluation of survey responses in the franchise section of the EC. Extensive manual evaluation in 2007 resulted in many establishments, whose survey forms indicated they were not franchise-affiliated, being recoded as franchise-affiliated. No such evaluation could be undertaken in 2012. In this paper, we examine the potential of using external data harvested from the web in combination with machine learning methods to automate the process of evaluating responses to the franchise section of the 2017 EC. Our method allows us to quickly and accurately identify and recode establishments have been mistakenly classified as not being franchise-affiliated, increasing the unweighted number of franchise-affiliated establishments in the 2017 EC by 22%-42%.<br><small>(This abstract was borrowed from another version of this item.)</small>
C81|Re-Engineering Key National Economic Indicators|Traditional methods of collecting data from businesses and households face increasing challenges. These include declining response rates to surveys, increasing costs to traditional modes of data collection, and the difficulty of keeping pace with rapid changes in the economy. The digitization of virtually all market transactions offers the potential for re-engineering key national economic indicators. The challenge for the statistical system is how to operate in this data-rich environment. This paper focuses on the opportunities for collecting item-level data at the source and constructing key indicators using measurement methods consistent with such a data infrastructure. Ubiquitous digitization of transactions allows price and quantity be collected or aggregated simultaneously at the source. This new architecture for economic statistics creates challenges arising from the rapid change in items sold. The paper explores some recently proposed techniques for estimating price and quantity indices in large scale item-level data. Although those methods display tremendous promise, substantially more research is necessary before they will be ready to serve as the basis for the official economic statistics. Finally, the paper addresses implications for building national statistics from transactions for data collection and for the capabilities and organization of the statistical agencies in the 21st century.<br><small>(This abstract was borrowed from another version of this item.)</small>
C81|Lying and Shirking Under Oath|This study explores whether an oath to honesty can reduce both shirking and lying among crowd-sourced internet workers. Using a classic coin-flip experiment, we first show that a substantial majority of Mechanical Turk workers both shirk and lie when reporting the number of heads flipped. We then demonstrate lying can be reduced by first asking each worker to swear voluntarily on his or her honor to tell the truth in subsequent economic decisions. The oath, however, did not reduce shirking as measured by time-at-coin-flip-task, although it did increase the time they spent answering a demographic survey. Conditional on response, MTurk shirkers and liars were less likely to agree to an ex post honesty oath. Our results suggest oaths may help elicit more truthful behavior in on-line crowd-sourced environments.
C81|Italian cooperatives: an analysis of their economic performances, employment characteristics and innovation processes based on combined used of official data|Researchers and policymakers have identified the need to accurately and quantitatively evaluate cooperatives and their economic, social and employment effects, as well as their evolution over time, in a way that is as reliable as possible and not subject to interpretation. This need was also manifested in the adoption by the 20th International Conference of Labour Statisticians of the Guidelines Concerning Statistics of Cooperatives, which aim to facilitate the development of a set of statistics on cooperatives that can be compared at the international level. This study provides informative insights and analyses based on a unified statistical representation of the structure, economic performance and profiles of cooperatives—including cooperative groups— within the Italian economy. Through the integration of several official statistical data sources released by the Italian National Institute of Statistics with the Cooperative Register managed by the Ministry of Economic Development, on the one hand, the paper highlights the peculiarities of cooperatives compared to other companies; on the other hand, it analyses in depth the composition of the cooperative sector with respect to both economic and structural variables.
C81|Networks of relations in Migori County (Kenya). Some findings on health and nutrition topics|Are Social Network Analysis (SNA) techniques useful to identify and map relations among key actors in development areas? In particular, is this technique able to disentangle the complexity of formal and informal actors involved in health and nutrition issues? Using this methodology we map relations among formal and informal actors living in Kenya, in Migori County. The analysis aims at detecting how different actors (i.e. institutions, community health workers and income generating activities groups) interact in order to share knowledge and information on health and nutrition projects. In this way we identify the main characteristics of the relations and understand how to enforce strengths and to reduce weaknesses, in order to enforce the projects implemented.
C81|‘Fear of the State’ in governance surveys? Empirical evidence from African countries|The need to collect data on governance-related issues has been growing since the 1990s. Demand gained momentum in 2015 with the adoption of SDG16 worldwide and Agenda 2063 in Africa. African countries played a key role in the adoption of SDG16 and are now leading the process of collecting harmonised household data on Governance, Peace and Security (GPS). Yet the possibility has recently been raised that sensitive survey data collected by government institutions are potentially biased due to self-censorship by respondents. This paper studies the potential bias in responses to what are seen as sensitive questions, here governance issues, in surveys conducted by public organisations. We compare Afrobarometer (AB) survey data, collected in eight African countries by self-professed independent institutions, with first-hand harmonised GPS survey data collected by National Statistics Offices (NSOs). We identify over 20 similarly worded questions on democracy, trust in institutions and perceived corruption. We first compare responses from AB survey respondents based on who they believe the survey sponsor to be. No systematic response bias is found between respondents who believe the government to be behind the AB survey and those who consider it to be conducted by an independent institution. The absence of a systematic self-censorship or attenuation bias is further evidenced by means of an experimental design, whereby responses from GPS surveys conducted by NSOs (the treatment) are compared with AB surveys sponsored by reportedly independent bodies. Our results provide evidence of the capacity and legitimacy of government-related organisations to collect data on governance as a matter of national interest and sovereignty.
C81|A Different Perspective on the Evolution of UK Income Inequality|This paper scrutinizes the conventional wisdom about trends in UK income inequality and also places contemporary inequality in a much longer historical perspective. We combine household survey and income tax data to provide better coverage of all income ranges from the bottom to the very top. We make a case for studying distributions of income between tax units (i.e. not assuming the full income sharing that goes with the use of the household as the unit of analysis) for reasons of principle as well as data harmonization. We present evidence that income inequality in the UK is as least as high today as it was just before the start of World War 2.
C81|Perspectives on poverty in Europe: following in Tony Atkinson’s footsteps|I address four topics: how our capacities to monitor poverty in Europe have improved substantially over recent decades; how progress on EU poverty reduction has been disappointing and why this has been; conceptual and measurement issues; and the future direction of EU-level anti-poverty actions. I follow in the footsteps of a giant – my perspectives are essentially elaborations of points made by Tony Atkinson.
C81|A Nonlinear Dynamic Factor Model of Health and Medical Treatment|Quantitative assessments of the relationship between health and medical treatment are of great importance to policy makers. However, simply looking at the raw correlation between health and medical care is unlikely to give the right answer because of endogeneity problems. We overcome these problems by formulating and estimating a tractable dynamic factor model of health and medical treatment where individual observed health outcomes are driven by the individual's latent health stock. The dynamics of latent health reflects both exogenous health depreciation and endogenous health investments. Our model allows us to investigate the effect of medical treatment on current health, as well as on future medical treatment and health outcomes. We estimate the model by maximum simulated likelihood and minimum distance methods using a rich longitudinal data set from Italy obtained by merging a number of administrative archives. These data contain detailed information on medical drug use, hospitalization, and mortality for a representative sample of elderly hypertensive patients. Our findings show that medical care consumption is highly correlated over time, and this relationship depends on both permanent and time-varying observed and unobserved heterogeneity. They also show that medical drug use significantly maintains future health levels and prevents transitions to worse health. These results suggest that policies aimed at increasing the awareness and the compliance of hypertensive patients help reduces cardiovascular risks and consequent hospitalization and mortality.
C81|Empirical foundation of valence using Aldrich-McKelvey scaling| This paper uses data from the 2004 pre-election survey of the American National Election Study to test empirically different ways of incorporating a valence parameter into a Downsian utility function. We call particular attention to the problem of interpersonal incomparability of responses to the liberal-conservative scale, and use the Aldrich-McKelvey’s pathbreaking method to obtain accurate distances between respondents and candidates, the key regressors. We find that the utility function the most supported by the empirical evidence, the intensity valence utility function, is the one which permits to make the better predictions for the 2004 presidential election. We also consider counterfactual analyses wherein we test if Bush, the candidate with the highest intensity valence, has dominant strategies which would have insured him to obtain a majority of the popular vote. According to the theory, it is known that the candidate with the highest intensity valence does not have such dominant strategies if the distribution of voters in the policy space is too heterogenous. Nevertheless, we show the distribution of voters in 2004 is sufficiently homogenous for Bush to have dominant strategies.
C81|Size, Internationalization, and University Rankings: Evaluating and Predicting Times Higher Education (THE) Data for Japan|International and domestic rankings of academics, academic departments, faculties, schools and colleges, institutions of higher learning, states, regions, and countries are of academic and practical interest and importance to students, parents, academics, and private and public institutions. International and domestic rankings are typically based on arbitrary methodologies and criteria. Evaluating how the rankings might be sensitive to different factors, as well as forecasting how they might change over time, requires a statistical analysis of the factors that affect the rankings. Accurate data on rankings and the associated factors are essential for a valid statistical analysis. In this respect, the Times Higher Education (THE) World University Rankings represent one of the three leading and most influential annual sources of international university rankings. Using recently released data for a single country, namely Japan, the paper evaluates the effects of size (specifically, the number of full-time-equivalent (FTE) students, or FTE (Size)) and internationalization (specifically, the percentage of international students, or IntStud) on academic rankings using THE data for 2017 and 2018 on 258 national, public (that is, prefectural or city), and private universities. The results show that both size and internationalization are statistically significant in explaining rankings for all universities, as well as separately for private and non-private (that is, national and public) universities, in Japan for 2017 and 2018.
C81|Internal Migration in the United States: A Comprehensive Comparative Assessment of the Consumer Credit Panel|We introduce and provide the first comprehensive comparative assessment of the Federal Reserve Bank of New York/Equifax Consumer Credit Panel (CCP) as a valuable and underutilized data set for studying internal migration within the United States. Relative to other data sources on US internal migration, the CCP permits highly detailed cross-sectional and longitudinal analyses of migration, both temporally and geographically. We compare cross-sectional and longitudinal estimates of migration from the CCP to similar estimates derived from the American Community Survey, the Current Population Survey, Internal Revenue Service data, the National Longitudinal Survey of Youth, the Panel Study of Income Dynamics, and the Survey of Income and Program Participation. Our results establish the comparative utility and illustrate some of the unique advantages of the CCP relative to other data sources on US internal migration. We conclude by identifying some profitable directions for future research on US internal migration using the CCP, as well as reminding readers of the strengths and limitations of these data. More broadly, this paper contributes to discussions and debates on improving the availability, quality, and comparability of migration data.
C81|Business Dynamics in the National Establishment Time Series (NETS)/Leland Crane, Ryan Decker|Business microdata have proven useful in a number of fields, but the main sources of comprehensive microdata are subject to significant confidentiality restrictions. A growing number of papers instead use a private data source seeking to cover the universe of U.S. business establishments, the National Establishment Time Series (NETS). Previous research documents the representativeness of NETS in terms of the distribution of employment and establishment counts across industry, geography, and establishment size. But there exists considerable need among researchers for microdata suitable for studying business dynamics---birth, growth, decline, and death. We evaluate NETS in terms of its ability to corroborate key insights from the business dynamics literature with a particular focus on the behavior of new and young firms. We find that NETS microdata exhibit patterns of business dynamics that are markedly different from official administrative sources, limiting the usefuln ess of NETS for studying these topics.
C81|Improving the Accuracy of Economic Measurement with Multiple Data Sources: The Case of Payroll Employment Data|"This paper combines information from two sources of U.S. private payroll employment to increase the accuracy of real-time measurement of the labor market. The sources are the Current Employment Statistics (CES) from BLS and microdata from the payroll processing firm ADP. We briefly describe the ADP-derived data series, compare it to the BLS data, and describe an exercise that benchmarks the data series to an employment census. The CES and the ADP employment data are each derived from roughly equal-sized samples. We argue that combining CES and ADP data series reduces the measurement error inherent in both data sources. In particular, we infer ""true"" unobserved payroll employment growth using a state-space model and find that the optimal predictor of the unobserved state puts approximately equal weight on the CES and ADP-derived series. Moreover, the estimated state contains information about future readings of payroll employment."
C81|Application of the economic theory of self-control to model energy conservation behavioral change in households|Smart meters and in-house displays hold a promise of energy conservation for those who invest in such technology. Research has shown that households only have a limited interest in such technology and information is thus often neglected, with rather limited energy savings. Surprisingly few empirical investigations have a theoretical foundation that may explain what is going on from a behavioral perspective. In this study the economic theory of self-control is used to model energy-eﬃcient behavior in middle-income households in Sweden. Our results show that diﬀerent levels of energy-eﬃcient behavior do not really have any impact on the actual consumption levels of electricity. Instead, diﬀerent beliefs exist of being energy-eﬃcient, but the households do not act accordingly. Our results suggest that the payment time period should be changed to stimulate the monitoring of bills and to introduce a gaming strategy to change incentives for energy conservation.
C81|Strikes and Lockouts in Sweden: Reconsidering Raphael’s List of Work Stoppages 1859-1902|This paper presents and discusses a recently digitized, dataset of strikes and lockouts in Sweden for the period 1859-1902. The dataset, which originally was collected by Axel Raphael by retrospectively browsing through newspapers, pre-dates the Swedish official statistics on work stoppages that began in 1903. Whereas Raphael’s data have been used to illustrate the long-run development of strikes, labour historians have been hesitant or completely dismissive towards the usefulness of his work. This paper reviews, and deepens previous assessments of Raphael’s data and compares his data with the official statistics for the period after 1903. This renewed assessment leads to three conclusions. Firstly, the coverage of the data is much better after 1885 than before. Trends and fluctuations in conflict frequency obtained from Raphael’s data for the later period are probably accurate. Secondly, there are also in the later period a lot of missing information in how conflicts are described, for example with regard to number of participants and outcomes. Thirdly, there are good opportunities to complement, and enhance, Raphael’s dataset by browsing through more newspapers or consulting other sources.
C81|On extreme perception bias|This preliminary note investigates perception bias: To what extent do individual opinions confound reality? We estimate the relative gap between self-declared estimates and real data. We asked a sample of Philippine respondents about the incidence of diabetes and smartphone usage in their country. We observed a trend of judgement miscalibration. Responses exhibit significant deviation from facts, e.g. inaccuracies can go as high as seven times the real value. Especially for estimates on smartphone ownership, bootstrapped quantile regression models show that perception bias is associated with age.
C81|Information Content Of The Russian Services Surveys|The paper explores the information content of surveys of the Russian services sector using the surveys’ results since 2012Q1 to 2018Q4. To summarise entrepreneurial opinions in a one-dimensional index the indicators of confidence and business climate are calculated. To examine the reaction of GDP to impulses in the business climate indicator and to forecast GDP growth by the end of 2019, the Vector Autoregression Model was used. The results of services surveys provide reliable information on the economic sentiment that is essential to measure recession and recovery development of the sector. Since 2013, the survey’s results demonstrate a stable five-year trend of ‘pessimism accumulation’ in the indicators dynamics. The slight increase in entrepreneurial optimism in 2016-2018 did not result in moving confidence to a positive zone. The business climate indicator (BCI) performs better than the traditional confidence indicator in terms of synchronous correlations with GDP growth. A longer observation period needs to draw conclusions about the BCI cyclic properties; however, it can be used now to analyze the development of the Russian services sector.
C81|Microeconometric Dynamic Panel Data Methods: Model Specification and Selection Issues|A motivated strategy is presented to find step by step an adequate model specification and a matching set of instrumental variables by applying the programming tools provided by the Stata package Xtabond2. The aim is to implement generalized method of moment techniques such that useful and reasonably accurate inferences are extracted from an observational panel data set on a single microeconometric structural presumably dynamic behavioral relationship. In the suggested specification search three comprehensive heavily interconnected goals are pursued, namely: (i) to include all the relevant appropriately transformed possibly lagged regressors, as well as any interactions between these if it is required to relax the otherwise very strict homogeneity restrictions on the dynamic impacts of the explanatories in standard linear panel data models; (ii) to correctly classify all regressors as either endogenous, predetermined or exogenous, as well as being either effect-stationary or effect-nonstationary, implying which internal variables could represent valid and relatively strong instruments; (iii) to enhance the accuracy of inference in finite samples by omitting irrelevant regressors and by profitably reducing the space spanned by the full set of available internal instruments. For the various tests which trigger the decisions to be made in the sequential selection process the relevant considerations are spelled out to interpret the magnitude of p-values. Also the complexities to establish and interpret the ultimately established dynamic impacts are explained. Finally the developed strategy is applied to a classic data set and is shown to yield new insights.
C81|Multi-Country Tasks Measures: Beyond US-based Data and a Focus on Migration|The US-based O*NET database is commonly used for multi-country studies on labor markets and migration by assuming invariant occupation technology, i.e. the quantitative assignment of tasks to occupations. We claim that the OECD dataset PIAAC (Programme for the International Assessment of Adult Competencies) could provide a valid alternative to obtain country-specific task measures. The US presence in both datasets allows us to compare the consistency of the two data sources along two dimensions. First, we compute the correlation coefficients between aggregate task indexes and they are very high (rarely less than 0.7). Secondly, we use the PIAAC database to replicate the empirical model in Peri and Sparber (2009) on US natives’ task upgrading after a migration shock, and the results are strikingly similar to the original O*NET-based estimates. The multi-country variability of PIAAC-based task indexes for European countries are non-negligible; hence, we recommend these PIAAC-based measures for future multi-country analysis.
C81|A nonlinear dynamic factor model of health and medical treatment|Quantitative assessments of the relationship between health and medical treatment are of great importance to policy makers.However, simply looking at the raw correlation between health and medical care is unlikely to give the right answer because of endogeneity problems. We overcome these problems by formulating and estimating a tractable dynamic factor model of health and medical treatment where individual observed health outcomes are driven by the individual’s latent health stock. The dynamics of latent health reflects both exogenous health depreciation and endogenous health investments. Our model allows us to investigate the effect of medical treatment on current health, as well as on future medical treatment and health outcomes. We estimate the model by maximum simulated likelihood and minimum distance methods using a rich longitudinal data set from Italy obtained by merging a number of administrative archives. These data contain detailed information on medical drug use, hospitalization, and mortality for a representative sample of elderly hypertensive patients. Our findings show that medical care consumption is highly correlated over time, and this relationship depends on both permanent and time-varying observed and unobserved heterogeneity. They also show that medical drug use significantly maintains future health levels and prevents transitions to worse health. These results suggest that policies aimed at increasing the awareness and the compliance of of hypertensive patients help reduce cardiovascular risks and consequent hospitalization and mortality.
C81|Using text mining in social science - tweet analysis of generation Y and Z|"Millennials are a generation of people born in the eighth and ninth decades of the twentieth century. They are also called the digital generation. Around this generation, as well as the previous age formation (eg baby boomers), many stereotypes have been created to give certain characteristics to a given population. Millennials are often referred to as the ""global village"", with a high level of self-confidence, caring for the quality of life and further development. Generaration Z is demographic cohort born after millennials, they have Internet even before they were born. Poster aims to present research in the area of ??text exploration analysis. There are 400 tweets in English, marked with hashtags: #millenials, #genY, #millenial, #genZ, #iGen, #postMillenial. An analysis of the mutual understanding of the phrases and phrases. Selected tweets have been published in January 2018. The obtained data are to serve as a confirmation or denial of the popularly generated stereotypes about both generations, and indicate the main areas of difficulty faced by representatives of this age groups."
C81|Challenges in predicting poverty trends using survey to survey imputation. Experiences from Malawi|Poverty in low-income countries is usually measured with large and infrequent household surveys. A challenge is to find methods to measure poverty more frequently. The objective of this study is to test a method for predicting poverty, based upon a statistical model utilizing consumption surveys and light annual surveys. A decade of poverty predictions and regular poverty estimates in Malawi provides us with a unique real-life experience to better understand the suitability of such approaches to monitor trends in poverty. The analysis from Malawi suggests that a modelling approach works per se, given that information on the household’s demographic composition is included in the model. The main challenge when predicting onto other surveys seems to be related to comparability between the surveys. Differences in implementation, questionnaire design and survey sample size are aspects that may contribute to incomparability of data collected between the surveys.
C81|Evaluating multilateral price indices in a dynamic item universe|Statistics Norway has a long history of using scanner data in the Consumer Price Index (CPI). The early research – in Norway as well as internationally – was focused on supermarket data which consists largely of stable items. The attention has since gradually shifted towards the parts of consumption market that are characterized by high item churn, where the methodology initially introduced for supermarket data is no longer adequate. Several National Statistical Institutes (NSIs) including Statistics Norway have been researching on a more generic scanner data methodology. The overall goal is to implement an approach that incorporates expenditure shares at the most detailed level without suffering from chain drift, and that works well across different commodity groups including those with high item churn. A variety of methods and index formulas are currently being tested and implemented for CPIs in different parts of the world. We propose a systematic approach to the investigation process, which has recently been developed at Statistics Norway. This consists mainly of two parts: a Total Effect Framework (TEF), and a set of generic diagnostics. The TEF is defined by the necessary choices required and the elements that affect these choices and we review, synthesize and develop a set of generic diagnostics. Most indices employed in such diagnostics are not genuine candidates for real production, but they are designed and introduced to generate useful empirical evidences, on which a plausible final choice of index method can be based. We shall illustrate the generic diagnostics using scanner datasets mainly from the markets of sport equipment which have high item churn. To this end we summarize our own experiences and put forward some preliminary conclusions of a generic scanner data price index methodology.
C81|Property rights, market access and crop cultivation in Southern Rhodesia: evidence from historical satellite data|Agriculture plays a central role in the efforts to fight poverty and achieve economic growth. This is especially relevant in sub-Saharan Africa (SSA) where the majority of the population lives in rural areas. A key issue that is generally believed to unlock agriculture potential is the recognition of property rights through land titling, yet there is no overwhelming empirical evidence to support this in the case of SSA (Udry, 2011). This paper investigates access to markets as an important pre-condition for land titles to result in agricultural growth. Using the case of Southern Rhodesia, we investigate whether land titles incentivised African large-scale holders in the Native Purchase Areas (NPAs) to put more of their available land under cultivation than their counterparts in the overcrowded Tribal Trust Areas (TTAs). We create a novel dataset by applying a Support Vector Machine (SVM) learning algorithm on Landsat imagery for the period 1972 to 1984 - the period during which the debate on the nexus between land rights and agricultural production intensified. Our results indicate that land titles are only beneficial when farmers are located closer to main cities, main roads and rail stations or sidings.
C81|Measuring the Services of Durables and Owner Occupied Housing|This paper provides an update to the chapter on the treatment of durables in the Consumer Price Index Manual (2004). The most important durable is housing, which typically accounts for approximately 20% of total consumption services. A large fraction of total housing services consists of the services of Owner Occupied Housing (OOH). The main approaches to measuring the services of OOH are (i) the acquisitions approach; (ii) the rental equivalence approach and (iii) the user cost approach. Two other approaches are sometimes used: (iv) the opportunity cost approach and (v) the payments approach. A main purpose of this paper is to present the main approaches to the treatment of OOH and to discuss the benefits and costs of the alternative approaches. The paper also discusses the problems associated with forming imputations for the services of â€œordinaryâ€ consumer durable goods.
C81|Quality Adjustment and Hedonics: A Unified Approach|The paper takes a consumer demand perspective to the problem of adjusting product prices for quality change. The various approaches to the problem of quality adjustment can be seen as special cases of the general framework. The special cases include the use of inflation adjusted carry forward and carry backward prices, the use of hedonic regressions and the estimation of Hicksian reservation prices.
C81|Estimating the Benefits of New Products: Some Approximations|A major challenge facing statistical agencies is the problem of adjusting price and quantity indexes for changes in the availability of commodities. This problem arises in the scanner data context as products in a commodity stratum appear and disappear in retail outlets. Hicks suggested a reservation price methodology for dealing with this problem in the context of the economic approach to index number theory. Feenstra and Hausman suggested specific methods for implementing the Hicksian approach. The present paper evaluates these approaches and suggests some alternative approaches to the estimation of reservation prices. The various approaches are implemented using some scanner data on frozen juice products that are available online.
C81|Measuring the Services of Durables and Owner Occupied Housing|This paper provides an update to the chapter on the treatment of durables in the Consumer Price Index Manual (2004). The most important durable is housing, which typically accounts for approximately 20% of total consumption services. A large fraction of total housing services consists of the services of Owner Occupied Housing (OOH). The main approaches to measuring the services of OOH are (i) the acquisitions approach; (ii) the rental equivalence approach and (iii) the user cost approach. Two other approaches are sometimes used: (iv) the opportunity cost approach and (v) the payments approach. A main purpose of this paper is to present the main approaches to the treatment of OOH and to discuss the benefits and costs of the alternative approaches. The paper also discusses the problems associated with forming imputations for the services of â€œordinaryâ€ consumer durable goods.
C81|Improving the representativeness of a simple random sample: an optimization model and its application to the Continuous Sample of Working Lives|This paper develops an optimization model for selecting a large subsample that improves the representativeness of a simple random sample previously obtained from a population larger than the population of interest. The problem formulation involves convex mixed-integer nonlinear programming (convex MINLP) and is therefore NP-hard. However, the solution is found by maximizing the “constant of proportionality” – in other words, maximizing the size of the subsample taken from a stratified random sample with proportional allocation – and restricting it to a p-value high enough to achieve a good fit to the population of interest using Pearson’s chi-square goodness-of-fit test. The beauty of the model is that it gives the user the freedom to choose between a larger subsample with a poorer fit and a smaller subsample with a better fit. The paper also applies the model to a real case: The Continuous Sample of Working Lives (CSWL), which is a set of anonymized microdata containing information on individuals from Spanish Social Security records. Several waves (2005-2017) are first examined without using the model and the conclusion is that they are not representative of the target population, which in this case is people receiving a pension income. The model is then applied and the results prove that it is possible to obtain a large dataset from the CSWL that (far) better represents the pensioner population for each of the waves analysed.
C81|What Time Use Surveys Can (And Cannot) Tell Us about Labor Supply|It has been widely acknowledged that the measurement of labor supply in the Current Population Survey (CPS) and other conventional microeconomic surveys has nonclassical measurement error, which will bias the estimates of crucial parameters in labor economics, such as labor supply elasticity. Time diary studies, such as the American Time Use Survey (ATUS), only have accurate measurement of hours worked on a single day, hence the weekly hours worked are unobserved. Despite the missing data problem, we provide several consistent estimators of the parameters in weekly labor supply equation using the information in the time use surveys. The consistency of our estimators does not require more conditions beyond those for a usual two stage least square (2SLS) estimator when the true weekly hours worked are observed. We also show that it is impossible to recover the weekly number of hours worked or its distribution function from time use surveys like the ATUS. In our empirical application we find considerable evidence of nonclassical measurement error in the hours worked in the CPS, and illustrate the consequences of using mismeasured weekly hours worked in empirical studies.
C81|Measuring Success: Clio and the Value of Database Creation|In a recent article Stefano Fenoaltea (2018) bemoaned the loss of respect and focus on the importance of creating databases, or “measurement” as he referred to it. Cliometrics has made and continues to make valuable contributions not just to the field of economic history, but economics in general. In particular, we focus on the contribution of cliometrics to the creation of datasets. We highlight several important cases in both the past and present, of recognized important contributions of new datasets to the economics discipline. We argue that Clio has continually focused on, and valued, the creation of new data sets and the clever and novel ways they have been exploited to further the frontiers of knowledge, and that these efforts are both appreciated and recognized.<br><small>(This abstract was borrowed from another version of this item.)</small>
C81|Un héritage des Annales, la cliométrie à Strasbourg|C’est par sa volonté de combiner la rigueur des modèles théoriques et mathématiques avec la prise en compte, de la façon la plus exhaustive possible, de la complexité de toutes les données (qualitatives et quantitatives) que l’Ecole cliométrique strasbourgeoise reste fidèle à l’esprit des Annales et prolonge le mouvement initié en 1929 par Marc Bloch et Lucien Febvre.
C81|Unemployment dynamics in Austria - The role of gender-specific worker-flows|There is a growing literature studying unemployment dynamics by means of worker flow data between labor market states. This paper contributes to this literature stream by analyzing the dynamics of the Austrian unemployment rate applying novel worker flow data for 2005-2016. Our main results can be summarized along two dimensions: First, we show that worker flows between unemployment and inactivity are major determinants of unemployment fluctuations in Austria. Second, we show for the working-age population that the contribution of male worker flows to the overall variation of the unemployment rate is higher, but that this relation turns when it comes to the youth cohort. The gender differences are probably related to the early occupational and educational segregation of young men and women in Austria. The paper concludes by stressing a strong need for further empirical and theoretical research which aims to link structural differences in an economy with different responses to the business cycle.
C81|How Polarized are Citizens? Measuring Ideology from the Ground-Up|Strong evidence has been emerging that major democracies have become more politically polarized, at least according to measures based on the ideological positions of political elites. We ask: have the general public (‘citizens’) followed the same pattern? Our approach is based on unsupervised machine learning models as applied to issueposition survey data. This approach ﬁrstly indicates that coherent, latent ideologies are strongly apparent in the data, with a number of major, stable types that we label as: Liberal Centrist, Conservative Centrist, Left Anarchist and Right Anarchist. Using this framework, and a resulting measure of ‘citizen slant’, we are then able to decompose the shift in ideological positions across the population over time. Speciﬁcally, we ﬁnd evidence of a ‘disappearing center’ in a range of countries with citizens shifting away from centrist ideologies into anti-establishment ‘anarchist’ ideologies over time. This trend is especially pronounced for the US.
C81|Arbeitsangebotsmodul zum IW-Mikrosimulationsmodell STATS: Dokumentation Version 1.0|Mit dem dargestellten Arbeitsangebotsmodul wird das Steuer-, Abgaben- und Transfer-Mikrosimulationsmodell des IW Köln um eine tragende Komponente erweitert, die die Simulation von Zweitrundeneffekten in Folge von Änderungen des deutschen Steuer- und Transfersystems auf unterschiedliche Zielgrößen ermöglicht. Am Beispiel einer (exogenen) Erhöhung der Bruttostundenlöhne von Männern und Frauen um jeweils 10 Prozent ließ sich zeigen, wie sich das Arbeitsangebot von unterschiedlichen Haushaltstypen anpasst. Die geschätzten unkompensierten Arbeitsangebotselastizitäten liegen dabei zwischen 0,02 und 0,08. Die Arbeitsangebotseffekte sind dabei für Single-Haushalte tendenziell größer als für Paarhaushalte und für Frauen größer als für Männer. Dabei sind dem Modell jedoch auch Grenzen gesetzt: So bezieht sich die Simulation von Arbeitsangebotseffekten ausschließlich auf abhängig Beschäftigte im erwerbsfähigen Alter zwischen 20 und 65 Jahren, die auf veränderte Arbeitsanreize auf dem Arbeitsmarkt reagieren können. Das Verhalten von Beamten, Rentnern oder Selbständigen wird aufgrund von andersartigen Arbeitsmarkt- und Beschäftigungsbedingungen in der derzeitigen Modellversion nicht abgebildet. Dies steht ebenfalls in Zusammenhang mit unterschiedlichen Präferenzen dieser Gruppen, die nicht oder nur schwer beobachtet werden können. Zudem unterliegt die Modellschätzung zum Teil strikten Annahme bezüglich des nutzenoptimalen Verhaltens der Haushalte und der darin lebenden Individuen: So kann beispielsweise die Annahme diskutiert werden, ob Paarhaushalte stets eine gemeinsame Nutzenfunktion maximieren - wie es angenommen wird - oder ob die Individuen nicht ihren eigenen Nutzen unter Berücksichtigung der Entscheidungen des Partners optimieren. Trotz dieser Einschränkungen stellen diskrete Arbeitsangebotsmodule bisweilen die beste und flexibelste Möglichkeit zur Modellierung von Arbeitsangebotsentscheidungen dar und sind ein wertvolles Instrument zur Evaluierung unterschiedlicher sozialpolitischer Reformvorhaben.
C81|Job loss expectations, durable consumption and household finances: Evidence from linked survey data|Job security is important for durable consumption and household savings. Using surveys, workers express a probability that they will lose their job in the next 12 months. In order to assess the empirical content of these probabilities, we link survey data to administrative data with labor market outcomes. Workers predict job loss quite well, in particular those whose job loss is followed by unemployment. Workers with higher job loss expectations acquire cheaper cars, and are less likely to buy new cars. In line with models of precautionary saving, higher job loss expectations are associated with more savings and less exposure to risky assets.
C81|Political Competition: How to Measure Party Strategy in Direct Voter Communication using Social Media Data?|Political competition, party strategy and communication in the era of social media are growing issues. Due to the increasing social media presence of parties and voters alike, direct communication is more important for party competition. This paper aims to improve the methodological approach used to analyze political competition and communication. The dataset includes over 30,000 Facebook status messages posted by seven German parties from January 2014 until February 2018. Topic modeling, which is commonly used in other fields, allows for evaluating party communication on a daily basis. The results show the high accuracy of calculating party-relevant issues. To determine the tone of the debate, a sentiment analysis was conducted. The prevalence of topics and sentiments over time allows for precise monitoring of the political debate.
C81|Predicting innovative firms using web mining and deep learning|Innovation is considered as a main driver of economic growth. Promoting the development of innovation through STI (science, technology and innovation) policies requires accurate indicators of innovation. Traditional indicators often lack coverage, granularity as well as timeliness and involve high data collection costs, especially when conducted at a large scale. In this paper, we propose a novel approach on how to create firm-level innovation indicators at the scale of millions of firms. We use traditional firm-level innovation indicators from the questionnaire-based Community Innovation Survey (CIS) survey to train an artificial neural network classification model on labelled (innovative/non-innovative) web texts of surveyed firms. Subsequently, we apply this classification model to the web texts of hundreds of thousands of firms in Germany to predict their innovation status. Our results show that this approach produces credible predictions and has the potential to be a valuable and highly cost-efficient addition to the existing set of innovation indicators, especially due to its coverage and regional granularity. The predicted firm-level probabilities can also directly be interpreted as a continuous measure of innovativeness, opening up additional advantages over traditional binary innovation indicators.
C81|“Who pollutes more? Gender differences in consumptions patterns”|Recent behavioral literature shows that we can identify differences between women and men in diverse domains in a general context, such as empathy, social preferences and reaction towards competitiveness, risk aversion, etc. Regarding the environment, recent studies propose that women have more knowledge and concern about the climate change than men. In this context, however, there is little evidence to what extend these behavioral differences between women and men have been translated into consumption actions more environmental friendly. Within this approach, this paper evaluates different environmental footprints of consumption patterns of women and men. As a case study, we examine Spain during the period 2008-2013. Using data from Spanish input-output tables, environmental air accounts, and household expenditure surveys for the same period, the study give evidence that gender differences take a relevant and significant position according to Weighted Least Square regression.
C81|On the use of Hedonic Regression Models to Measure the Effect of Energy Efficiency on Residential Property Transaction Prices: Evidence for Portugal and Selected Data Issues|Using a unique dataset containing information of around 256 thousand residential property sales, this paper discloses a clear sales premium for most energy efficient dwellings, which is more pronounced for apartments (13%) than for houses (5 to 6%). Cross-country comparisons support the finding that energy efficiency price premiums are higher in the Portuguese residential market than in central and northern European markets. Results emphasize the relevance of data issues in hedonic regression models. They illustrate how the use of appraisal prices, explanatory variables with measurement errors, and the omission of variables associated with the quality of the properties, may seriously bias energy efficiency partial effect estimates. These findings provide valuable information not only to policy-makers, but also to researchers interested in this area.
C81|An Empirical Total Survey Error Decomposition Using Data Combination|Survey error is known to be pervasive and to bias even simple, but important estimates of means, rates, and totals, such as poverty statistics and the unemployment rate. To summarize and analyze the extent, sources, and consequences of survey error, we define empirical counterparts of key components of the Total Survey Error Framework that can be estimated using data combination. Specifically, we estimate total survey error and decompose it into three high level sources of error: representation error, item non-response error and measurement error. We further decompose these sources into lower level sources such as a failure to report a positive amount and errors in amounts conditional on reporting a positive value. For error in dollars paid by two large government transfer programs, we use administrative records on the universe of program payments in New York State linked to three major household surveys to estimate the error components we define. We find that total survey error is large and varies in its size and composition, but measurement error is always by far the largest source of error. Our application shows that data combination makes it possible to routinely measure total survey error and its components. The results allow survey producers to assess error reduction strategies and survey users to mitigate the consequences of survey errors or gauge the reliability of their conclusions.
C81|Combining Administrative and Survey Data to Improve Income Measurement|We describe methods of combining administrative and survey data to improve the measurement of income. We begin by decomposing the total survey error in the mean of survey reports of dollars received from a government transfer program. We decompose this error into three parts, generalized coverage error (which combines coverage and unit non-response error and any error from weighting), item non-response or imputation error, and measurement error. We then discuss these three sources of error in turn and how linked administrative and survey data can assess and reduce each of these sources. We then illustrate the potential of linked data by showing how using linked administrative variables improves the measurement of income and poverty in the Current Population Survey, focusing on the substitution of administrative for survey data for three government transfer programs. Finally, we discuss how one can examine the accuracy of the underlying links used in the combined data.
C81|Missing Data in Imputed Highest Grade Completed in the 2015 -2018 NBER CPS Extracts|"In 2015, the Current Population Survey (CPS) eliminated three questions related to educational attainment. These questions are used by the NBER to calculate the variable, ""Imputed Highest Grade Completed"" (ihigrdc) in their Monthly Outgoing Rotation Group (MORG) extracts. Imputed Highest Grade Completed provides a convenient measure of years of education and is based on the credential oriented CPS variable that is coded from 31 to 46. Because the NBER continues to use coding that relies on these eliminated questions to calculate ihigrdc, this variable has a missing value for 27.5% of the observations in the 2015Ã¢â‚¬â€œ2018 extracts. These missing values, in turn, lead to an average Imputed Highest Grade Completed of about 1.2 fewer years after 2014 than would result from using the whole CPS. We informed the NBER of this issue in January 2019; however, because this variable with missing values remains on their website for download as of this writing (July 15, 2019), we are posting this working paper to inform users of these data so that they may address the issue appropriately in their own work."
C81|Is Positive Sentiment in Corporate Annual Reports Informative? Evidence from Deep Learning|We use a novel text classification approach from deep learning to more accurately measure sentiment in a large sample of 10-Ks. In contrast to most prior literature, we find that positive, and negative, sentiment predicts abnormal return and abnormal trading volume around 10-K filing date and future firm fundamentals and policies. Our results suggest that the qualitative information contained in corporate annual reports is richer than previously found. Both positive and negative sentiments are informative when measured accurately, but they do not have symmetric implications, suggesting that a net sentiment measure advocated by prior studies would be less informative.
C81|Age-Income Dynamics Over The Life Course: Cohort Transition Patterns In Relative Income Based On Canadian Tax Returns|This paper is concerned with patterns of cohort aging and income progression. We take a new approach to the characterization of relative income, explore the dynamics of age/income progression through the use of state transition matrices, consider alternative cohort definitions, and introduce an artificial cross-section cohort based on the transition matrices. Our applications make use of individual income records from the Statistics Canada Longitudinal Administrative Database. Relative income is defined by how an individual of a given age is positioned in the overall distribution of income in a given year. We derive the proportionate distribution of individuals in each decile group at each representative age, starting at 24, and the transition matrices then show the movements from the distribution at one age to the distribution five years later.
C81|Risk Aversion and Information Aggregation in Asset Markets|The paper investigates the relation between the risk preferences of traders and the information-aggregation properties of an experimental call market. We find evidence inconsistent with the prediction that market-clearing prices are closer to full revelation of the state when traders are more risk-averse. The observed pattern of prices is close to the risk-neutral benchmark, while individuals are risk averse both in a risk elicitation task and when estimating their risk aversion from their market activity. This purported conflict is explained by an attitude to exploit only part of the information possessed that we label operational conservatism. We show that operational conservatism represents an additional, although suboptimal, way to express one’s risk aversion. A remarkably consistent picture of measured risk preferences emerges then in our data. Independently-elicited risk attitudes retain the footprint of both the standard and the suboptimal facet of risk aversion estimated from subjects’ market activity.
C81|Calendar-based Graphics for Visualizing People's Daily Schedules|Calendars are broadly used in society to display temporal information and events. This paper describes a new calendar display for plotting data, that includes a layout algorithm with many options, and faceting functionality. The functions use modulus algebra on the date variable to restructure the data into a calendar format. The user can apply the grammar of graphics to create plots inside each calendar cell, and thus the displays synchronize neatly with ggplot2 graphics. The motivating application is studying pedestrian behavior in Melbourne, Australia, based on counts which are captured at hourly intervals by sensors scattered around the city. Faceting by the usual features such as day and month, is insufficient to examine the behavior. Making displays on a monthly calendar format helps to understand pedestrian patterns relative to events such as work days, weekends, holidays, and special events. The functions for the calendar algorithm are available in the R package sugrrants.
C81|A New Tidy Data Structure to Support Exploration and Modeling of Temporal Data|"Mining temporal data for information is often inhibited by a multitude of formats: irregular or multiple time intervals, point events that need aggregating, multiple observational units or repeated measurements on multiple individuals, and heterogeneous data types. On the other hand, the software supporting time series modeling and forecasting, makes strict assumptions on the data to be provided, typically requiring a matrix of numeric data with implicit time indexes. Going from raw data to model-ready data is painful. This work presents a cohesive and conceptual framework for organizing and manipulating temporal data, which in turn flows into visualization, modeling and forecasting routines. Tidy data principles are extended to temporal data by: (1) mapping the semantics of a dataset into its physical layout; (2) including an explicitly declared index variable representing time; (3) incorporating a ""key"" comprising single or multiple variables to uniquely identify units over time. This tidy data representation most naturally supports thinking of operations on the data as building blocks, forming part of a ""data pipeline"" in time-based contexts. A sound data pipeline facilitates a fluent workflow for analyzing temporal data. The infrastructure of tidy temporal data has been implemented in the R package tsibble."
C81|The economic importance of the Belgian ports : Flemish maritime ports, Liège port complex and the port of Brussels – Report 2017|This Working Paper analyses the economic importance of the Belgian ports largely based on annual accounts data for the year 2017. As the years prior to 2017 have been described in earlier papers in the same series, the emphasis lies on the ﬁgures for 2017 and the developments between 2016 and 2017 . After the stagnation in 2016, direct value added at the Belgian ports rose by 7.3% from € 18 052 million to € 19 368 million (current prices) or roughly 4.4% of Belgium’s GDP. All ports, with the exception of the Liège port complex, contributed to value added growth at the Belgian ports. The ports of Antwerp and Ghent were the most important players. The biggest contributing sectors to value added growth were the chemical industry and, to a lesser extent, cargo handling and the metalworking industry. In 2017, indirect value added was around 82% of direct value added. Direct value added increased significantly at the ports of Ghent, Brussels and Antwerp, by 13.4%, 16.0% and 6.1% respectively. The increase by more than 3% of direct value added at the ports of Zeebrugge and Ostend was also substantial. Direct value added fell by 2.4% at the Liège port complex. After the decline between 2012 and 2015, direct employment at the Belgian ports was up for the second year in a row. Between 2016 and 2017, the number of direct full-time equivalent jobs rose by 0.8%, from 115 401 to 116 311 or approximately 2.8% of Belgium’s total domestic employment. All ports, with the exception of Ostend and Brussels, contributed to employment growth at the Belgian ports. The ports of Antwerp and Ghent were the most important players. The biggest contributing sectors to employment growth were cargo handling and, to a lesser extent, the chemical industry. In 2017, indirect employment was around 120% of direct employment. Direct employment increased by around 1% at the ports of Antwerp, Ghent and Zeebrugge. Growth at the Liège port complex was more modest at 0.4%. The number of direct full-time equivalent jobs fell at the ports of Ostend and Brussels, by 1.2% and 4.2% respectively. The pattern of investment is closely linked to projects and is therefore highly volatile. After the decline between 2012 and 2014, direct investment at the Belgian ports was up for the third year in a row. Between 2016 and 2017, investment was up by 2.4%, from € 4 711 million to € 4 825 million. The port of Ghent and, to a lesser extent, the Liège port complex contributed to investment growth at the Belgian ports. The biggest contributing sectors to investment growth were the ‘port construction and dredging’ sector and, to a lesser extent, cargo handling, and the energy and chemical industries. Based on the figures of the traffic, the Flemish ports can be considered as real bridgeheads for trade with the UK. Developments regarding the modalities and consequences of the Brexit therefor should be followed with the greatest attention. Given the existing import and export volumes in terms of tonnage, it seems it will mostly be a challenge in Zeebrugge and to some extent for Antwerp. As a supplier to both China and the United States, Belgium is indirectly involved in trade between the two countries. If protectionism would close the United States off to exports from abroad, Belgian economy might get impacted one of the most in Europe.
C81|Food inflation nowcasting with web scraped data|In this paper we evaluate the ability of web scraped data to improve nowcasts of Polish food inflation. The nowcasting performance of online price indices is compared with aggregated and disaggregated benchmark models in a pseudo realtime experiment. We also explore product selection and classification problems, their importance in constructing web price indices and other limitations of online datasets. Therefore, we experiment not only with raw indices, but also with several approaches to include them into model-based forecasts. Our findings indicate that the optimal way to incorporate web scraped data into regular forecasting is to include them in simple distributed-lag models at the lowest aggregation level, combine the forecasts and aggregate them using statistical office methodology. We find this approach superior to other benchmark models which do not take online information into account.
C81|Tweet Sixteen and Pregnant: Missing Links in the Causal Chain from Reality TV to Fertility|We examine the relationship between social media activity, such as Google searches and tweets, related to teen pregnancy and the airing of the MTV program 16 and Pregnant. In contrast to Kearney and Levine's (2015) claim of a positive relationship, we find that the association is statistically insignificant or negative, when the analysis includes periods when new episodes of the program were not being broadcast. The results are also sensitive to using the total number of tweets, which were growing exponentially, as weights. Our results cast substantial doubt on social media as a link in the causal chain between reality television and fertility.
C81|Throwing the Baby out with the Drinking Water: Unintended Consequences of Arsenic Mitigation Efforts in Bangladesh|The 1994 discovery of arsenic in groundwater in Bangladesh prompted a massive public health campaign that led 20% of the population to switch from backyard wells to less convenient drinking water sources that had a higher risk of fecal contamination. We find evidence of unintended health consequences by comparing mortality trends between households in the same village that did and did not have an incentive to abandon shallow tubewells. Post-campaign, households encouraged to switch water sources have 46% higher rates of child mortality than those not encouraged to switch. Switching away from arsenic-contaminated wells also increased adult mortality.
C81|An Empirical Total Survey Error Decomposition Using Data Combination|Survey error is known to be pervasive and to bias even simple, but important estimates of means, rates, and totals, such as the poverty and the unemployment rate. To summarize and analyze the extent, sources, and consequences of survey error, we define empirical counterparts of key components of the Total Survey Error Framework that can be estimated using data combination. Specifically, we estimate total survey error and decompose it into three high level sources of error: generalized coverage error, item non-response error and measurement error. We further decompose these sources into lower level sources such as a failure to report a positive amount and errors in amounts conditional on reporting a positive value. For error in dollars paid by two large government transfer programs, we use administrative records on the universe of program payments in New York State linked to three major household surveys to estimate the error components we define. We find that total survey error is large and varies in its size and composition, but measurement error is always by far the largest source of error. Our application shows that data combination makes it possible to routinely measure total survey error and its components. The results allow survey producers to assess error reduction strategies and survey users to mitigate the consequences of survey errors or gauge the reliability of their conclusions.
C81|Combining Administrative and Survey Data to Improve Income Measurement|We describe methods of combining administrative and survey data to improve the measurement of income. We begin by decomposing the total survey error in the mean of survey reports of dollars received from a government transfer program. We decompose this error into three parts, generalized coverage error (which combines coverage and unit non-response error and any error from weighting), item non-response or imputation error, and measurement error. We then discuss these three sources of error in turn and how linked administrative and survey data can assess and reduce each of these sources. We then illustrate the potential of linked data by showing how using linked administrative variables improves the measurement of income and poverty in the Current Population Survey, focusing on the substitution of administrative for survey data for three government transfer programs. Finally, we discuss how one can examine the accuracy of the underlying links used in the combined data.
C81|Survival of the Fittest: The Impact of the Minimum Wage on Firm Exit|We study the impact of the minimum wage on firm exit in the restaurant industry, exploiting recent changes in the minimum wage at the city level. We find that the impact of the minimum wage depends on whether a restaurant was already close to the margin of exit. Restaurants with lower ratings are closer to the margin of exit on average, and are disproportionately driven out of business by increases to the minimum wage. Our point estimates suggest that a one dollar increase in the minimum wage leads to a 10 percent increase in the likelihood of exit for a 3.5-star restaurant (which is the median rating on Yelp), but has no discernible impact for a 5-star restaurant (on a 1 to 5 star scale). We expand the analysis to look at prices using data from delivery orders, and find that lower rated restaurants also increase prices in response to minimum wage increases. Our analysis also highlights how digital data can be used to shed new light on labor policy and the economy.
C81|Automated Linking of Historical Data|The recent digitization of complete count census data is an extraordinary opportunity for social scientists to create large longitudinal datasets by linking individuals from one census to another or from other sources to the census. We evaluate different automated methods for record linkage, performing a series of comparisons across methods and against hand linking. We have three main findings that lead us to conclude that automated methods perform well. First, a number of automated methods generate very low (less than 5%) false positive rates. The automated methods trace out a frontier illustrating the tradeoff between the false positive rate and the (true) match rate. Relative to more conservative automated algorithms, humans tend to link more observations but at a cost of higher rates of false positives. Second, when human linkers and algorithms have the same amount of information, there is relatively little disagreement between them. Third, across a number of plausible analyses, coefficient estimates and parameters of interest are very similar when using linked samples based on each of the different automated methods. We provide code and Stata commands to implement the various automated methods.
C81|The use and misuse of income data and extreme poverty in the United States|More than half of all misclassified households have incomes from the administrative data above the poverty line, and several of the largest misclassified groups appear to be at least middle class based on measures of material well-being. In contrast, the households kept from extreme poverty by in-kind transfers appear to be among the most materially deprived Americans.
C81|Secure Survey Design in Organizations: Theory and Experiments|We study the impact of secure survey designs ensuring plausible deniability on information transmission in organizations. We are interested in settings in which fear of retaliation makes potential informants reluctant to reveal the truth. Theory predicts that: (i) popular randomized-response designs fail to induce informative reports, because they are strategically equivalent to non-secure direct-elicitation designs; (ii) hard-garbling designs that exogenously distort survey responses improve information transmission; and (iii) unbiased estimates of the impact of survey design on information transmission can be obtained in equilibrium. Laboratory experiments qualify these predictions. While hard-garbling does improve information transmission over direct-elicitation, other predictions fail: randomized response performs much better than expected; and false accusations lead to a small but persistent bias in treatment effect estimates. We show that these deviations from equilibrium can be accounted for in an off-the-shelf model of boundedly rational play, and that this model of play makes specific predictions over the bias of treatment effect estimators. Additional experiments reveal that play converges to equilibrium if players can (socially) learn from cross-sectional data. These results suggest that randomized response cannot be used systematically in organizational settings, whereas hard garbling improves survey quality even under long-run equilibrium conditions.
C81|Estimating the Benefits of New Products|A major challenge facing statistical agencies is the problem of adjusting price and quantity indexes for changes in the availability of commodities. This problem arises in the scanner data context as products in a commodity stratum appear and disappear in retail outlets. Hicks suggested a reservation price methodology for dealing with this problem in the context of the economic approach to index number theory. Feenstra and Hausman suggested specific methods for implementing the Hicksian approach. The present paper evaluates these approaches and suggests some alternative approaches to the estimation of reservation prices. The various approaches are implemented using some scanner data on frozen juice products that are available online.<br><small>(This abstract was borrowed from another version of this item.)</small>
C81|Improving the Accuracy of Economic Measurement with Multiple Data Sources: The Case of Payroll Employment Data|This paper combines information from two sources of U.S. private payroll employment to increase the accuracy of real-time measurement of the labor market. The sources are the Current Employment Statistics (CES) from BLS and microdata from the payroll processing firm ADP. We briefly describe the ADP-derived data series, compare it to the BLS data, and describe an exercise that benchmarks the data series to an employment census. The CES and the ADP employment data are each derived from roughly equal-sized samples. We argue that combining CES and ADP data series reduces the measurement error inherent in both data sources. In particular, we infer “true” unobserved payroll employment growth using a state-space model and find that the optimal predictor of the unobserved state puts approximately equal weight on the CES and ADP-derived series. Moreover, the estimated state contains information about future readings of payroll employment.<br><small>(This abstract was borrowed from another version of this item.)</small>
C81|Combining Family History and Machine Learning to Link Historical Records|A key challenge for research on many questions in the social sciences is that it is difficult to link historical records in a way that allows investigators to observe people at different points in their life or across generations. In this paper, we develop a new approach that relies on millions of record links created by individual contributors to a large, public, wiki-style family tree. First, we use these “true” links to inform the decisions one needs to make when using traditional linking methods. Second, we use the links to construct a training data set for use in supervised machine learning methods. We describe the procedure we use and illustrate the potential of our approach by linking individuals across the 100% samples of the US decennial censuses from 1900, 1910, and 1920. We obtain an overall match rate of about 70 percent, with a false positive rate of about 12 percent. This combination of high match rate and accuracy represents a point beyond the current frontier for record linking methods.
C81|The Rich Underreport their Income: Assessing Bias in Inequality Estimates and Correction Methods using Linked Survey and Tax Data|Do survey respondents misreport their income? If so, how does misreporting correlate with income, how does this affect estimates of income inequality, and how well do existing methods correct for bias? We use a novel database in which a subsample of Uruguay's official household survey has been linked to tax records to document the extent and distribution of labor income underreporting and to assess the performance of various existing methods to correct inequality estimates. Individuals in the upper half of the income distribution tend to report less labor income in household surveys than those same individuals earn according to tax returns, and underreporting is increasing in income. Using simulations, we find that this leads to downward-biased inequality estimates. Correction methods that rely only on survey data barely affect the biased inequality estimates, while methods that combine survey and tax data can lead to over-correction and overestimation of inequality.
C81|Looking for the Missing Rich: Tracing the Top Tail of the Wealth Distribution|We analyze the top tail of the wealth distribution in Germany, France, and Spain based on the first and second wave of the Household Finance and Consumption Survey (HFCS). Since top wealth is likely to be underrepresented in household surveys, we integrate big fortunes from rich lists, estimate a Pareto distribution, and impute the missing rich. In addition to the Forbes list, we rely on national rich lists since they represent a broader base for the big fortunes in those countries. As a result, the top percentile share of household wealth in Germany jumps up from 24 percent to 31 percent in the first and from 24 to 33 percent in the second wave after top wealth imputation. For France and Spain, we find only a small effect of the imputation since rich households are better captured in the survey.
C81|Non-base wage components as a source of wage adaptability to shocks: evidence from European firms, 2010–2013|Abstract This paper provides evidence on the role of non-base wage components as a channel for firms to adjust labour costs in the event of adverse shocks. It uses data from a firm-level survey for 25 European countries that covers the period 2010–2013. We find that firms subject to nominal wage rigidities, which prevent them from adjusting base wages, are more likely to cut non-base wage components when they are hit by negative shocks. Firms thus use non-base wage components as a strategic margin to overcome base wage rigidity. We also show that while non-base wage components exhibit some degree of downward rigidity this is smaller than that observed for base wages.
C81|Estimating the Associations between SNAP and Food Insecurity, Obesity, and Food Purchases with Imperfect Administrative Measures of Participation|Administrative data are considered the “gold standard” when measuring program participation, but little evidence exists on their potential problems or implications for econometric estimates. We explore these issues using the FoodAPS, a unique data set containing two different administrative measures of Supplemental Nutrition Assistance Program (SNAP) participation and a survey‐based measure. We document substantial ambiguity in the two administrative measures and show that they disagree with each other almost as often as they disagree with self‐reported participation. Estimated participation and misreporting rates can be meaningfully sensitive to choices made to resolve this ambiguity and disagreement. We explore sensitivity in regression estimates of the associations between SNAP and food insecurity, obesity, and the healthy eating index. The signs are unchanged across the three measures, and the estimates are mostly not statistically different from each other. However, there are some meaningful differences in the magnitudes and levels of statistical significance of the estimates.
C81|A cautionary note on the reliability of the online survey data – the case of Wage Indicator|We investigate the reliability of data from the Wage Indicator (WI), the largest online survey on earnings and working conditions. Comparing WI to nationally representative data sources for 17 countries reveals that participants of WI are not likely to have been representatively drawn from the respective populations. Previous literature has proposed to utilize weights based on inverse propensity scores, but this procedure was shown to leave reweighted WI samples different from the benchmark nationally representative data. We propose a novel procedure, building on covariate balancing propensity score, which achieves complete reweighting of the WI data, making it able to replicate the structure of nationally representative samples on observable characteristics. While rebalancing assures the match between WI and representative benchmark data sources, we show that the wage schedules remain different for a large group of countries. Using the example of a Mincerian wage regression, we find that in more than a third of the cases, our proposed novel reweighting assures that estimates obtained on WI data are not biased relative to nationally representative data. However, in the remaining 60% of the analyzed 95 datasets systematic differences in the estimated coefficients of the Mincerian wage regression between WI and nationally representative data persists even after reweighting. We provide some intuition about the reasons behind these biases. Notably, objective factors such as access to the Internet or richness appear to matter, but self-selection (on unobservable characteristics) among WI participants appears to constitute an important source of bias
C81|Errors in Survey Reporting and Imputation and Their Effects on Estimates of Food Stamp Program Participation|Accurately measuring government benefit receipt in household surveys is necessary when studying disadvantaged populations and the programs that serve them. The Food Stamp Program is especially important given its size and recent growth. To validate survey reports, we use administrative data on participation in two states linked to the American Community Survey (ACS), the Current Population Survey (CPS), and the Survey of Income and Program Participation (SIPP). We find that 23 percent of true food stamp recipient households do not report receipt in the SIPP, 35 percent in the ACS, and fully 50 percent in the CPS. A substantial number of true non-recipients are also recorded as recipients, especially in the SIPP. We examine reasons for these errors including imputation, an important source of error. Both false negative and false positive reports vary with household characteristics, implying complicated biases in multivariate analyses, such as regressions. We then directly examine biases in common survey-based estimates of program receipt by comparing them to estimates from our combined administrative and survey data. We find that the survey estimates understate participation among single parents, non-whites, and low-income households, and also lead to errors in multiple program receipt, and time and age patterns of receipt.
C81|A method to estimate mean lying rates and their full distribution|Abstract Studying the likelihood that individuals cheat requires a valid statistical measure of dishonesty. We develop an easy empirical method to measure and compare lying behavior within and across studies to correct for sampling errors. This method estimates the full distribution of lying when agents privately observe the outcome of a random process (e.g., die roll) and can misreport what they observed. It provides a precise estimate of the mean and confidence interval (offering lower and upper bounds on the proportion of people lying) over the full distribution, allowing for a vast range of statistical inferences not generally available with the existing methods.
C81|The Elasticity of Taxable Income: A Meta-Regression Analysis|The elasticities of taxable and broad income are key parameters in tax policy analysis. To examine the large variation in estimates found in the literature, I conduct a comprehensive meta-regression analysis using information from 51 studies containing 1,448 estimates. Heterogeneity in reported estimates is driven by regression techniques, sample restrictions and variations across countries and time. Moreover, I provide descriptive evidence of the correlation between contextual factors and the magnitude of an elasticity estimate. Selective reporting bias is prevalent in the literature and the direction of reporting bias depends on whether or not deductions are included in the tax base.
C81|Perspectives on poverty in Europe|I address four topics: how our capacities to monitor poverty in Europe have improved substantially over recent decades; how progress on EU poverty reduction has been disappointing and why this has been; conceptual and measurement issues; and the future direction of EU-level anti-poverty actions. I follow in the footsteps of a giant – my perspectives are essentially elaborations of points made by Tony Atkinson
C81|Misreporting of Government Transfers: How Important Are Survey Design and Geography?|Recent studies linking household surveys to administrative records reveal high rates of misreporting of program receipt. We use the FoodAPS survey to examine whether the findings of these studies of general household surveys using one or two states generalize to a survey with a narrow focus and across many states. First, we study how reporting errors differ from other surveys. We find a lower rate of false negatives (failures to report true receipt) in FoodAPS, likely partly due to the shorter recall period of FoodAPS. Misreporting varies with household characteristics and between interviewers. Second, we examine geographic heterogeneity in survey error to assess whether we can extrapolate from linked data from a few states. We find systematic differences between states in unconditional error rates but no evidence of substantial differences conditional on common covariates. Thus, extrapolating error rates across states may yield more accurate receipt estimates than uncorrected survey estimates.
C81|Robust Inference in Risk Elicitation Tasks|Recent experimental evidence suggests that noisy behavior correlates strongly with cognitive ability. This puts previous studies that found a negative relation between cognitive ability and risk aversion into perspective and in particular raises the question of how to achieve robust inference in this domain. This paper shows that using structural estimation that models heterogeneity of noise in combination with a balanced design allows us to mitigate the bias problem. Our estimations show that cognitive ability is related to noisy behavior rather than risk preferences. We also find age and education to be strongly related to noise, but the personality characteristics obtained using the Big Five inventory, are less related to noise and more robustly correlated to risk preferences.
C81|Understanding Joint Retirement|Evidence from different sources shows that spouses' retirement decisions are correlated. Retirement policies affecting individuals in couples are therefore also likely to affect behavior of their spouses. It is therefore important to account for joint features in modeling retirement. This paper studies a structural collective model of labor supply and retirement of both partners in a couple with interdependent preferences, imperfect knowledge of preferences of the spouse, and subjective expectations about the future. We propose a novel method to estimate preferences and the intra-household bargaining process, which relies on stated preferences data collected in the Health and Retirement Study. Respondents were asked to choose between hypothetical retirement trajectories describing the retirement ages and replacement rates of both spouses from three perspectives: considering their own preferences only, the preferences of their spouse only, or the most likely decision for the household. With these data, all model parameters are identified and potential sources of joint retirement can be disentangled. We find that males misperceive their wives' preferences, overestimating their disutility of work. Our estimates correct for this bias. They suggest that correlation in unobserved heterogeneity components of the partners' marginal utility of leisure explains a large share of joint retirement decisions. We also find significant positive complementarities in leisure, but this explains a much smaller part of joint retirement.
C81|Measuring the Diffusion of Innovations with Paragraph Vector Topic Models|Measuring the diffusion of innovations from textual data sources besides patent data has not been studied extensively. However, early and accurate indicators of innovation and the recognition of trends in innovation are mandatory to successfully promote economic growth through technological progress via evidence-based policy making. In this study, we propose Paragraph Vector Topic Model (PVTM) and apply it on technology related news articles to analyze innovation related topics over time and gain insights regarding their diffusion process. PVTM represents documents in a semantic space, which has been shown to capture latent variables of the underlying documents, e.g. the latent topics. Clusters of documents in the semantic space can then be interpreted and transformed into meaningful topics by means of Gaussian mixture modeling. Using PVTM we identify innovation related topics from 170 thousand technology news articles published over a span of 20 years and gather insights about their diffusion state by measuring the topics importance in the corpus over time. Thereby, we find that PVTM diffusion indicators for certain topics are Granger causal to Google Trends indices with matching search terms. Further, our results suggest PVTM is well suited to discover latent topics in (technology related) news articles and that the diffusion of innovations could be assessed using topic importance measures derived from PVTM.
C81|Early-Stage Business Formation : An Analysis of Applications for Employer Identification Numbers|This paper reports on the development and analysis of a newly constructed dataset on the early stages of business formation. The data are based on applications for Employer Identification Numbers (EINs) submitted in the United States, known as IRS Form SS-4 filings. The goal of the research is to develop high-frequency indicators of business formation at the national, state, and local levels. The analysis indicates that EIN applications provide forward-looking and very timely information on business formation. The signal of business formation provided by counts of applications is improved by using the characteristics of the applications to model the likelihood that applicants become employer businesses. The results also suggest that EIN applications are related to economic activity at the local level. For example, application activity is higher in counties that experienced higher employment growth since the end of the Great Recession, and application counts grew more rapidly in counties engaged in shale oil and gas extraction. Finally, the paper provides a description of new public use dataset, the “Business Formation Statistics (BFS),” that contains new data series on business applications and formation. The initial release of the BFS shows that the number of business applications in the 3rd quarter of 2017 that have relatively high likelihood of becoming job creators is still far below pre-Great Recession levels.
C81|Tail and Center Rounding of Probabilistic Expectations in the Health and Retirement Study|A growing number of surveys elicit respondents’ expectations for future events on a 0-100 scale of percent chance. These data reveal substantial heaping at multiples of 10 and 5 percent, suggesting that respondents round their reports. This paper studies the nature of rounding by analyzing response patterns across expectations questions and waves of the Health and Retirement Study. We discover a tendency by about half of the respondents to provide more refined responses in the tails of the scale than the center. Only about five percent provide more refined responses in the center than the tails. We find that rounding varies across question domains, which range from personal health to personal finances to macroeconomic events. We develop a two-stage framework to characterize person-specific rounding. The first stage uses observed responses to infer respondents’ rounding practice in each question domain and scale segment. The second stage replaces each original point response with an interval, representing the range of possible values of the respondent’s true latent belief implied by the degree of rounding inferred in the first stage. We study how the inferred rounding types in the first stage vary with respondent characteristics, including age and cognitive abilities.
C81|The Poverty Reduction of Social Security and Means-Tested Transfers|Many studies examine the anti-poverty effects of social insurance and means-tested transfers, relying solely on survey data with substantial errors. We improve on past work by linking administrative data from Social Security and five large means-tested transfers (SSI, SNAP, Public Assistance, the EITC, and housing assistance) to 2008-2013 Survey of Income and Program Participation data. Using the linked data, we find that Social Security cuts the poverty rate by a third – more than twice the combined effect of the five means-tested transfers. Among means-tested transfers, the EITC and SNAP are most effective. All programs except for the EITC sharply reduce deep poverty (below 50% of the poverty line), while the impact of the EITC is more pronounced at 150% of the poverty line. For the elderly, Social Security single-handedly slashes poverty by 75%, more than 20 times the combined effect of the means-tested transfers. While single parent families benefit more from the EITC, SNAP, and housing assistance, they are still relatively underserved by the safety net, with the six programs together reducing their poverty rate by only 38%. SSI, Public Assistance, and housing assistance have the highest share of benefits going to the pre-transfer poor, while the EITC has the lowest. Finally, the survey data alone provide fairly accurate estimates for the overall population at the poverty line, although they understate the effects of Social Security, SNAP, and Public Assistance. However, there are more striking differences at other income cutoffs and for specific family types. For example, the survey data yield 1) effects of SNAP and Public Assistance on near poverty that are two-thirds and one-half what the administrative data generate and 2) poverty reduction effects of SSI, Social Security, and Public Assistance that are 34-44% of what the administrative data produce for single parent families.
C81|How Happy are Your Neighbours? Variation in Life Satisfaction among 1200 Canadian Neighbourhoods and Communities|This paper presents a new public-use dataset for community-level life satisfaction in Canada, based on more than 400,000 observations from the Canadian Community Health Surveys and the General Social Surveys. The country is divided into 1215 similarly sampled geographic regions, using natural, built, and administrative boundaries. A cross-validation exercise suggests that our choice of minimum sampling thresholds approximately maximizes the predictive power of our estimates. Our procedure reveals robust differences in life satisfaction between and across urban and rural communities. We then match the life satisfaction data with a range of key census variables to explore ways in which lives differ in the most and least happy communities. The data presented here are useful on their own to study community-level variation, and can also be used to provide contextual variables for multi-level modelling with individual life satisfaction data set in a community context.
C81|Expectations with Endogenous Information Acquisition: An Experimental Investigation|We use a survey experiment to generate direct evidence on how people acquire and process information. Participants can buy different information signals that could help them forecast the future median national home price. Participants put substantial value on their preferred signal and, when acquired, use the signal in the formation of their expectations. However, they disagree on which signal to buy. As a result, making information cheaper does not decrease the cross-sectional dispersion of expectations. We provide a model with costly acquisition and processing of information, and show that it can match almost all of our empirical results.
C81|Loss Attitudes in the U.S. Population: Evidence from Dynamically Optimized Sequential Experimentation (DOSE)|We introduce DOSE - Dynamically Optimized Sequential Experimentation - and use it to estimate individual-level loss aversion in a representative sample of the U.S. population (N = 2,000). DOSE elicitations are more accurate, more stable across time, and faster to administer than standard methods. We find that around 50% of the U.S. population is loss tolerant. This is counter to earlier findings, which mostly come from lab/student samples, that a strong majority of participants are loss averse. Loss attitudes are correlated with cognitive ability: loss aversion is more prevalent in people with high cognitive ability, and loss tolerance is more common in those with low cognitive ability. We also use DOSE to document facts about risk and time preferences, indicating a high potential for DOSE in future research.
C81|Measurement Error in Imputed Consumption|"Because of limitations in survey-based measures of household consumption, a growing literature uses an alternative measure of consumer expenditures commonly referred to as ""imputed consumption."" This approach typically utilizes annual snapshots of household income and wealth from administrative tax registries to calculate household spending as the residual of the household budget constraint. In this paper we use transaction-level retail investment data to assess the measurement error that can result in imputed consumption due to intra-year changes in asset values and composition. We show that substantial discrepancies between imputed and actual spending can arise due to trading costs, asset distributions, variable trade timing, and volatile asset prices between two annual snapshots. While these errors tend to be quantitatively small and centered around zero on average, we demonstrate that they vary across individuals of different types and income levels and are highly correlated with the business cycle. We end by suggesting ways to minimize the impact of these imputation errors in future research and we discuss which research questions are least likely to suffer from such errors."
C81|Errors in Survey Reporting and Imputation and Their Effects on Estimates of Food Stamp Program Participation|Benefit receipt in major household surveys is often underreported. This misreporting leads to biased estimates of the economic circumstances of disadvantaged populations, program takeup, and the distributional effects of government programs, and other program effects. We use administrative data on Food Stamp Program (FSP) participation matched to American Community Survey (ACS) and Current Population Survey (CPS) household data. We show that nearly thirty-five percent of true recipient households do not report receipt in the ACS and fifty percent do not report receipt in the CPS. Misreporting, both false negatives and false positives, varies with individual characteristics, leading to complicated biases in FSP analyses. We then directly examine the determinants of program receipt using our combined administrative and survey data. The combined data allow us to examine accurate participation using individual characteristics missing in administrative data. Our results differ from conventional estimates using only survey data, as such estimates understate participation by single parents, non-whites, low income households, and other groups. To evaluate the use of Census Bureau imputed ACS and CPS data, we also examine whether our estimates using survey data alone are closer to those using the accurate combined data when imputed survey observations are excluded. Interestingly, excluding the imputed observations leads to worse ACS estimates, but has less effect on the CPS estimates.
C81|Mechanics of replacing benefit systems with a basic income: comparative results from a microsimulation approach|Abstract Recent debates of basic income (BI) proposals shine a useful spotlight on the challenges that traditional forms of income support are increasingly facing, and highlight gaps in social provisions that largely depend on income or employment status. A universal “no questions asked” public transfer would be simple and have the advantage that no-one would be left without support. But an unconditional payment to everyone at meaningful but fiscally realistic levels would likely require tax rises as well as reductions in existing benefits. We develop a comprehensive BI scenario that facilitates an assessment of the resulting fiscal and distributional effects in a comparative context, undertake a microsimulation study to quantify them, and propose a simple decomposition to identify the mechanisms that drive effects in different country contexts. Results illustrate the challenges, but also the strengths, of existing social protection systems. A BI would fix benefit coverage gaps that exist in many countries, but would require very substantial tax rises if it were to be set at a meaningful level. As support would not be targeted on those most in need, it would not be a cost-effective way of directly reducing income poverty.
C81|Mechanics of replacing benefit systems with a basic income: comparative results from a microsimulation approach|Abstract Recent debates of basic income (BI) proposals shine a useful spotlight on the challenges that traditional forms of income support are increasingly facing, and highlight gaps in social provisions that largely depend on income or employment status. A universal “no questions asked” public transfer would be simple and have the advantage that no-one would be left without support. But an unconditional payment to everyone at meaningful but fiscally realistic levels would likely require tax rises as well as reductions in existing benefits. We develop a comprehensive BI scenario that facilitates an assessment of the resulting fiscal and distributional effects in a comparative context, undertake a microsimulation study to quantify them, and propose a simple decomposition to identify the mechanisms that drive effects in different country contexts. Results illustrate the challenges, but also the strengths, of existing social protection systems. A BI would fix benefit coverage gaps that exist in many countries, but would require very substantial tax rises if it were to be set at a meaningful level. As support would not be targeted on those most in need, it would not be a cost-effective way of directly reducing income poverty.
C81|Inequalities in household wealth across OECD countries: Evidence from the OECD Wealth Distribution Database|This paper describes how household wealth is distributed in 28 OECD countries, based on evidence from the second wave of the OECD Wealth Distribution Database. A number of general patterns emerge from these data. First, wealth concentration is twice the level of income inequality: across the 28 OECD countries covered, the wealthiest 10% of households hold, on average, 52% of total household wealth, while the 60% least wealthy households own little over 12%. Second, up to a quarter of all households report negative net worth (i.e. liabilities exceeding the value of their assets) in a number of countries. In addition, some countries feature large shares of households with high levels of debt relative to both their incomes and the assets that they hold; this potentially exposes such households to significant risks in the event of changes in asset prices or falls of their income. Third, more than one in three people are economically vulnerable, as they lack liquid financial assets to maintain a poverty-level living standard for at least three months. Fourth, one in three households has received some gift or bequest in their life, with this share being considerably larger among high income and high wealth households. The paper also describes changes in wealth distribution since the Great Recession among the sub-set of countries for which repeated observations are available in the OECD Wealth Distribution Database. Finally, the paper discusses a number of methodological challenges, notably on how to better account for the top end of the wealth distribution.
C81|Statistical quality by design: certification, rules and culture|To achieve and to communicate quality of official statistics, it is essential that national statistical institutes adopt some system of quality by design, i.e. formal quality certification, e.g. ISO or EFQM. International law, international regulations, national law, specific statistical regulations, Code of Practice, Privacy, ISO 27001 (Information security) and ISO 9001 (Quality management systems). These are some of the ‘rules’ that National Statistical Institutes have to work with. In this paper we look at the why and how of these rules: why should we follow these rules, how to manage these rules and how to transform them into practice. Even if an NSI complies with all principles of the Code of Practice for European Statistics, it is still necessary to have external proof of commitment to process and product quality as well as to privacy and security. We argue that to achieve and to communicate quality of official statistics, it is essential that national statistical institutes adopt some system of quality by design, i.e. formal quality certification, e.g. ISO or EFQM. Such an external proof is necessary in order to maintain public trust in statistics. But quality does not come by itself. The statistics that are actually produced, must have sufficient quality. So we also need a quality culture that provides a production and work environment in which quality is embedded. In essence, the quality culture should be based on the principles that the staff of NSIs are professionals and are responsible for the quality of their products. But their main task is to produce statistics, not to understand all those rules mentioned before. Therefore the only way to make them involved is to make them the real owners of quality; this should be our goal for the years to come. It requires embodiment of the quality culture in work processes, management, and guidelines, based on Total Quality Management and plan-do-check-act cycles.
C81|Amazon Mechanical Turk Workers Can Provide Consistent and Economically Meaningful Data|We explore the consistency of the characteristics of individuals who participate in studies posted on Amazon Mechanical Turk (AMT). The primary individuals analyzed in this study are subjects who participated in at least two of eleven experiments that were run on AMT between September of 2012 to January of 2018. We demonstrate subjects consistently report a series of demographic and personality characteristics. Further, subjective willingness to take risk is found to be significantly correlated with decisions made in a simple lottery experiment with real stakes - even when the subjective risk measure is reported months, sometimes years, in the past. This suggests the quality of data obtained via AMT is not significantly harmed by the lack of control over the conditions under which the responses are recorded.
C81|Quality management of methodology and process development for official statistics|"Methodology and process development are cornerstones of official statistics and belong to the major factors that contribute to their quality. This is reflected in the European Statistics Code of Practice, which mentions that ""Sound methodology underpins quality statistics"" and “Appropriate statistical procedures, implemented from data collection to data validation, underpin quality statistics”. However, methodology and processes are hard to explain to the average user, and so we must find other ways to ensure trust in statistical methodology and processes, and to convince users of the quality of official statistical methodology and processes. Important elements of such an approach are independence of the methodological and development units, transparency of methods and process designs, peer reviews, internal reviews and evaluations, and internal quality management. In this paper we look in particular at quality management. We show how quality management of methodological and development units may be based on the Code of Practice. We show how the various elements work together, and how the whole of these elements may lead to certification of the units, for example by EFQM or ISO. In 2017 the department for process development and methodology at Statistics Netherlands was certified according to ISO 9001. As an example, we discuss the various steps that have been taken to achieve this certification. In particular we focus on: the quality procedures for internal and external reports, recommendations and briefs; the quality assurance of statistical development projects in which methodologists and business analysts participate; the quality assurance of methodological courses taught to statisticians; the internal management of the department."
C81|Did recent reforms facilitate EU labour market adjustment? Firm level evidence|The paper analyses the effectiveness of the labour market reforms implemented in a number of EU countries during the recent crisis using qualitative data from a firm-level survey conducted in 2014-2015 in 25 EU countries. This data set contains information on firms’ perceptions on the easiness to adjust labour input and wages in 2013 compared to the prereform period together with firms’ and workers’ characteristics and information on the economic and institutional environment in which firms operate. We find that firms in countries that undertook wider labour markets reforms found it easier to adjust employment and wages, and they largely attribute this to the reforms in labour legislation. Consistent with the efficiency wage theory, we find that firms employing a higher share of skilled employees were less likely than those with relatively more unskilled workers to find it easier to adjust wages and lay off employees. Furthermore, firms applying firm-level agreements found it easier to adjust wages in 2013 than in 2010 suggesting that they benefited from the increased flexibility provided by these agreements.
C81|Non-base wage components as a source of wage adaptability to shocks: Evidence from European firms, 2010–2013|This paper provides evidence on the role of non-base wage components as a channel for firms to adjust labour costs in the event of adverse shocks. It uses data from a firm-level survey for 25 European countries that covers the period 2010–2013. We find that firms subject to nominal wage rigidities, which prevent them from adjusting base wages, are more likely to cut non-base wage components in order to adjust labour costs when needed. Firms thus use non-base wage components as a buffer to overcome base wage rigidity. We further show that while non-base wage components exhibit some degree of downward rigidity, they do so to a lesser extent than base wages.
C81|Volatility persistence and asymmetry under the microscope: the role of information demand for gold and oil|This study explores the relationship between Google search activity and the conditional volatility of oil and gold spot market returns. By aggregating the volume of queries related to the two commodity markets in the spirit of Da et al. (), we construct a weekly Searching Volume Index (SVI) for each market as proxy of households and investors information demand. We employ a rolling EGARCH framework to reveal how the significance of information demand has evolved through time. We find that higher information demand increases conditional volatility in gold and oil spot market returns. Information flows from Google SVI's reduce the proportion of the significant volatility asymmetry produced by negative shocks in both commodity markets. The latter is more profound in the gold market.
C81|Verification Of An Innovative Logistics-Based Costing Model For Agricultural Enterprises In A Process Approach|This paper presents the main assumptions and functionalities of an innovative logistics-based costing model dedicated to agricultural enterprises. The model was verified in purposefully selected farms of various acreage engaged in crop or livestock production. The use of an innovative logistics-based costing model allowed to determine the basic logistics cost ratios both at a general level and in a process-based approach (by stages and by basic logistics processes), taking total/actual process costs into account. In livestock farms, the ratio of logistics costs to total costs was twice as high as in crop farms, and ranged from 30.4% to 42.9% of total costs. In crop farms, the corresponding ratio varied from 15.8% to 23.6%. The analysis of logistics costs by basic logistics processes shows that the largest difference in ratios between the farms was observed for warehousing processes. In livestock farms, the relevant ratio was three times higher than in crop farms.
C81|Les liens entre taux d'épargne, revenu et incertitude. Une illustration sur données françaises|La compréhension des liens entre taux d’épargne et revenu des ménages est cruciale dans de nombreux débats de finances publiques (arbitrage entre taxation du travail ou de la consommation, progressivité de l’impôt sur le revenu, baisse de la taxation du capital,...). L’objectif de cet article est d’étudier, à partir des données de l’enquête Budget de famille 2010-2011 de l’INSEE, les liens entre le taux d’épargne des ménages français et leur revenu. Il s’agit d’abord de tester l’homogénéité des comportements en étudiant les liens entre taux d’épargne et revenu (courant et permanent) des ménages français. On met ensuite empiriquement en évidence l’existence d’un comportement d’épargne de précaution lié au risque sur le revenu, différencié selon le niveau de revenu. On montre d’abord que le taux d’épargne des ménages les plus riches croît avec le revenu permanent : ces derniers épargnent donc davantage sur le cycle de vie. En outre, l’étude empirique permet de mettre en évidence et de quantifier un motif de précaution lié au risque de chômage : le motif de précaution entraîne un surplus de flux d’épargne d’environ 7 % pour les ménages actifs. Par ailleurs, la part du patrimoine de précaution liée à l’incertitude sur le revenu futur se situe autour de 7 % de la richesse globale, ce qui confirme le résultat obtenu sur données françaises par d’autres auteurs (Arrondel et Calvo-Pardo, 2008). Enfin, l’importance du motif de précaution dépend du niveau de revenu selon une courbe en U inversé : il est deux fois plus fort pour les ménages aux revenus intermédiaires que pour les quintiles extrêmes de revenu..
C81|Patent-based Estimation Procedure of Private R&D: The Case of Climate Change and Mitigation Technologies in Europe|Information on R&D expenditure of the private sector is very limited, both in term of availability and data quality, especially when interest focuses on Climate Change Mitigation Technologies (CCMTs). This has an impact on the robustness of quantitative analyses, and, consequently, on the insights deriving from them. This paper proposes a methodology to estimate R&D expenditure in firms simultaneously active in multiple technology sectors, with the focus on those contributing to the development of CCMTs. The methodological approach is applied to measure how the private sector invests in R&D dedicated to CCMTs, and how this differentiates among European countries. Further the paper proposes metrics to analyse the geographical distribution of the R&D expenditures in Multinational Corporations (MNCs) across subsidiaries located in Europe. Early findings are formulated into useful insights for stakeholders and policy makers.
C81|Terrorist Attacks and Immigration Rhetoric: A Natural Experiment on British MPs|We study the effects of exogenous shocks on the rhetoric of British politicians on social media. In particular, we focus on the impact of terrorist attacks on the issue of immigration. For this purpose, we collect all the immigration-related Tweets from the active Twitter accounts of MPs using Web Scraping and Machine Learning techniques. Looking at the Manchester bombing of 2017 as our main Event Study, we detect a counterintuitive finding: a substantial decrease in the expected number of immigration-related Tweets occurred after the incident. We hypothesize that this “muting effect” results from risk-averse strategic behaviour of politicians during the election campaign. However, the MPs' response shows remarkable heterogeneity according to the socio-economic characteristics of their constituencies.
C81|Record Linkage in the Cape of Good Hope Panel|In this paper we describe the record linkage procedure to create a panel from Cape Colony census returns, or opgaafrolle, for 1787-1828, a dataset of 42,354 household-level observations. Based on a subset of manually linked records, we first evaluate statistical models and deterministic algorithms to best identify and match households over time. By using household-level characteristics in the linking process and near-annual data, we are able to create high-quality links for 84 percent of the dataset. We compare basic analyses on the linked panel dataset to the original cross-sectional data, evaluate the feasibility of the strategy when linking to supplementary sources, and discuss the scalability of our approach to the full Cape panel.
C81|Measuring the Distribution of Household Income, Consumption and Wealth: State of Play and Measurement Challenges|"This paper focuses on the data challenges encountered while measuring vertical economic inequality, i.e. inequality of income and consumption, and-whenever feasible-wealth, among households or individuals ranked by the level of their economic resources. The paper presents a critical assessment of international databases on inequality. Among the worrisome facts is that international databases not only show different levels of inequality but, for some countries (especially in Sub-Saharan Africa), diverging trends also. A key factor behind the limitations of existing databases is the quality of the underlying household surveys (microdata) used as inputs for their construction. Among the salient challenges is that household surveys suffer from undercoverage and underreporting of top incomes, i.e. the ""missing rich"". Missing the rich introduces a bias in the measured inequality indicators, a bias that could go in either direction. Another limitation in existing inequality indicators is that the typical welfare metrics are disposable income and/or consumption expenditures; these, however, take into account only part of the effect that taxes and transfers have on people's economic well-being. The paper suggests that a more comprehensive assessment needs to use an income variable that includes social transfers in-kind (especially education and health), and adds the effect of consumption taxes and subsidies as well."
C81|The Rich Underreport Their Income: Assessing Biases In Inequality Estimates And Correction Methods Using Linked Survey And Tax Data|Do survey respondents misreport their income? If so, how does misreporting correlate with income, how does this affect estimates of income inequality, and how well do existing methods correct for bias? We use a novel database in which a subsample of Uruguay’s official household survey has been linked to tax records to document the extent and distribution of labor income underreporting and to assess the performance of various existing methods to correct inequality estimates. Individuals in the upper half of the income distribution tend to report less labor income in household surveys than those same individuals earn according to tax returns, and underreporting is increasing in income. Using simulations, we find that this leads to downwardbiased inequality estimates. Correction methods that rely only on survey data barely affect the biased inequality estimates, while methods that combine survey and tax data can lead to overcorrection and overestimation of inequality.
C81|Scanner Data, Elementary Price Indexes and the Chain Drift Problem|Statistical agencies increasingly are able to collect detailed price and quantity information from retailers on sales of consumer products. Thus elementary price indexes (which are indexes constructed at the first stage of aggregation for closely related products) can now be constructed using this price and quantity information, whereas previously, statistical agencies had to construct elementary indexes using just retail outlet collected information on prices alone. Thus superlative indexes can now be constructed at the elementary level, which in theory, should lead to more accurate Consumer Price Indexes. However, retailers frequently sell products at heavily discounted prices, which lead to large increases in purchases of these products. This volatility in prices and quantities will generally lead to a chain drift problem; i.e., when prices return to their â€œnormalâ€ levels, quantities purchased are frequently below their â€œnormalâ€ levels and this leads to a downward drift in a superlative price index. The paper addresses this problem and looks at the likely bias in various index number formulae that are commonly used. The bias estimates are illustrated using some scanner data on the sales of frozen juice products that are available online.
C81|Estimating the Benefits and Costs of New and Disappearing Products|A major challenge facing statistical agencies is the problem of adjusting price and quantity indexes for changes in the availability of commodities. This problem arises in the scanner data context as products in a commodity stratum appear and disappear in retail outlets. Hicks suggested a reservation price methodology for dealing with this problem in the context of the economic approach to index number theory. Feenstra and Hausman suggested specific methods for implementing the Hicksian approach. The present paper evaluates these approaches and suggests some alternative approaches to the estimation of reservation prices. The various approaches are implemented using some scanner data on frozen juice products that are available online.
C81|Measuring Retail Trade Using Card Transactional Data|In this paper we present a high-dimensionality Retail Trade Index (RTI) constructed to nowcast the retail trade sector economic performance in Spain, using Big Data sources and techniques. The data are the footprints of BBVA clients from their credit or debit card transactions at Spanish point of sale (PoS) terminals.
C81|2017 Methods-of-Payment Survey: Sample Calibration and Variance Estimation|This technical report describes sampling, weighting and variance estimation for the Bank of Canada’s 2017 Methods-of-Payment Survey. Under quota sampling, a raking ratio method is implemented to generate weights with both post-stratification and nonparametric nonresponse weight adjustments. In the end, we estimate variances of weighted means and proportions using bootstrap replicate survey weights. Compared with probability sampling, we find that (i) strong assumptions are required to reduce bias when probabilities of selection are unknown, and (ii) multiple weight adjustments for bias reduction inflate variance. Therefore, it is important to focus more on bias than on variance in the context of nonprobability sampling.
C81|The Cross-border Household Finance and Consumption Survey: Results from the second wave|This report presents the methodology and main descriptive results of the second wave of the Cross-border Household Finance and Consumption Survey (XB-HFCS) conducted in 2014. The survey provides novel information on the economic and financial situation of households employed in Luxembourg but living in neighbouring countries (cross-border commuters), who contribute substantially to Luxembourg’s economy. We present results on the composition of their assets and liabilities, net wealth, income and consumption. Household net wealth of crossborder commuters is more equally distributed compared to that of employed households resident in Luxembourg. In addition, cross-border commuters have a higher median net wealth and gross income compared to those of the employed population in their country of residence. About 26% of their financial assets and 19% of their liabilities are located in Luxembourg. While the majority of the non-durable expenditures are done in the country of residence, cross-border commuters consume about 20% of their household income in Luxembourg.
C81|Evaluating the macro-representativeness of a firm-level database: an application for the Spanish economy|The availability of a firm-level database that represents the productive sector of an economy at the aggregate level is a necessary condition to undertake both reliable policy analysis and economic research in multiple areas. In this paper, we document the construction of a new representative firm-level dataset for Spain using detailed micro-level information provided by firms to the Spanish Commercial Registry and the Bank of Spain. A comparison with National Accounts figures serves to illustrate that the new micro-dataset is able to replicate the growth rates of output, employment and wage bill of the private sector. Using official statistics from the National Institute of Statistics (INE), we show that the resulting dataset covers more than 80% of firms registered in the census over the years 2000-2013 and, more importantly, the resulting dataset replicates the firm size distribution of the Spanish non-financial market economy. The same representativeness analysis is done for the manufacturing sector indicating that this sector is particularly well-represented in the dataset.
C81|The Spanish survey of household finances (EFF): Description and methods of the 2014 wave|The Spanish Survey of Household Finances 2014 (EFF2014) provides detailed information on the income, assets, debt and spending of Spanish households referring to end-2014. Together with the previous waves of 2002, 2005, 2008 and 2011, the EFF2014 enables the analysis of two complete phases of the economic cycle, which have had a strong impact on the fi nancial position of Spanish households. This paper provides a detailed description of the most relevant methodological aspects in the design and implementation of this fi fth edition: the sample design, the questionnaire, the data collection process, the validation of the data, the computation of weights and the imputation procedures. Important characteristics also present in this wave are the oversampling of wealthy households and the panel component of the sample.
C81|Mind the mode: lessons from a web survey on household finances|Surveys on household income and wealth are generally carried out through personal interviews. In recent years, however, the spread of surveys using the Internet as a means of data collection has increased, both for economic reasons and for the speed with which the collected data are available. However, there are no studies on the effects of using this tool in surveys on household income and wealth. This paper contributes to fill this gap by illustrating the results of an experimental survey conducted in 2016 by the Bank of Italy in collaboration with the Italian national statistical institute (ISTAT). The quality of the information collected is assessed by comparison with tax statistics and with the aggregate evidence inferable from the interim survey conducted through personal interviews. The paper focuses on coverage, non-response and measurement errors. Overall, the results show that the web-based mode can be a valid alternative means of collecting qualitative data and of gathering information on less sensitive sources of income (such as employment and retirement income). In order to reduce the bias associated with the use of this instrument, it is essential, however, to have auxiliary information on the entire selected sample.
C81|The potential of big housing data: an application to the Italian real-estate market|We present a new dataset of housing sales advertisements (ads) taken from Immobiliare.it, a popular online portal for real estate services in Italy. This dataset fills a big gap in Italian housing market statistics, namely the absence of detailed physical characteristics for houses sold. The granularity of online data also makes possible timely analyses at a very detailed geographical level. We first address the main problem of the dataset, i.e. the mismatch between ads and actual housing units - agencies have incentives for posting multiple ads for the same unit. We correct this distortion by using machine learning tools and provide evidence about its quantitative relevance. We then show that the information from this dataset is consistent with existing official statistical sources. Finally, we present some unique applications for these data. For example, we provide first evidence at the Italian level that online interest in a particular area is a leading indicator of prices. Our work is a concrete example of the potential of large user-generated online databases for institutional applications.
C81|Adjustment of the Regional Indicator of Income in Retail Trade|INEGI publishes, on a monthly basis, national indexes for sector, subsector and industry group of wholesale and retail trade, and state indexes for commerce sector based on information from the Monthly Survey of Commercial Establishments, EMEC. Although the sample design of this survey is representative at the national level and by industry group of economic activity of the commerce sector, the aggregation of state indexes at industry group level, necessary to construct regional indicators, requires an adjustment in the weighting of the observations. This document presents an aggregation methodology to build regional indexes based on retail trade state income data calculated from the information of EMEC databases. Moreover, a measure of the relative size of real income by region is proposed, it identifies those subsectors of retail trade with greatest contribution to the growth of regional income.
C81|Landscape Change and Trade in Ancient Greece: Evidence from Pollen Data|In this paper we use pollen data from a number of sites in southern Greece and Macedonia to study long-term vegetation change in these regions from 1000 BCE to 600 CE. Based on insights from environmental history, we interpret our estimated trends in the regional presence of cereal, olive, and vine pollen as proxies for structural changes in agricultural production. We present evidence that there was a market economy in ancient Greece and a major trade expansion several centuries before the Roman conquest. Our results are consistent with auxiliary data on settlement dynamics, shipwrecks, and ancient oil and wine presses.
C81|Expenditure imputation and microsimulation of VAT|In this paper, we document the development process of the microsimulation model for the analysis of the indirect value-added tax liabilities of households in Slovakia. This simulation module can be directly integrated into the framework of SIMTASK, the Slovak microsimulation model of income taxes, health and social security contributions and transfers. In the first step, a combined micro-level dataset that integrates information on disposable income and expenditures of Slovak households has been created. Households’ expenditures reported in HBS dataset have been imputed to SK-SILC dataset by estimating parametric Engel curves. Validation of the imputation procedure of households’ consumption and simulation of VAT has been discussed.
C81|Un Nuevo Sistema de Correspondencia CIIU 3.0-CAES 2000|El presente trabajo introduce una Tabla de Correspondencia Directa entre la Clasificación Internacional Industrial Uniforme 3.0 (CIIU 3.0) y la Clasificación de Actividades Económicas para Encuestas Sociodemográficas del Mercosur (CAES 2000). Se detallan las inconsistencias del proceso formal de correspondencia preexistente a esta tabla (esto es, utilizar las Tablas de Correspondencia de ONU y Mercosur), las decisiones adoptadas durante el proceso de su elaboración y la forma en que la nueva tabla soluciona las inconsistencias.
C81|An Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices|Statistical agencies face a dual mandate to publish accurate statistics while protecting respondent privacy. Increasing privacy protection requires decreased accuracy. Recognizing this as a resource allocation problem, we propose an economic solution: operate where the marginal cost of increasing privacy equals the marginal benefit. Our model of production, from computer science, assumes data are published using an efficient differentially private algorithm. Optimal choice weighs the demand for accurate statistics against the demand for privacy. Examples from U.S. statistical programs show how our framework can guide decision-making. Further progress requires a better understanding of willingness-to-pay for privacy and statistical accuracy.
C81|Loss Attitudes in the U.S. Population: Evidence from Dynamically Optimized Sequential Experimentation (DOSE)|We introduce DOSE - Dynamically Optimized Sequential Experimentation - and use it to estimate individual-level loss aversion in a representative sample of the U.S. population (N=2,000). DOSE elicitations are more accurate, more stable across time, and faster to administer than standard methods. We find that around 50% of the U.S. population is loss tolerant. This is counter to earlier findings, which mostly come from lab/student samples, that a strong majority of participants are loss averse. Loss attitudes are correlated with cognitive ability: loss aversion is more prevalent in people with high cognitive ability, and loss tolerance is more common in those with low cognitive ability. We also use DOSE to document facts about risk and time preferences, indicating a high potential for DOSE in future research.
C81|Harmonization and Interpretation of the ifo Business Survey's Micro Data|Every month, the ifo Business Survey (IBS) asks a representative set of 9000 German firms about their current and expected economic conditions. Thus, the micro data of the IBS are ideally suited to study various aspects of firm behavior. However, methodological heterogeneities between different subsets of the IBS have prevented joint analyses of firms in all main sectors of the economy. This paper expands the scope for economic research based on the IBS by presenting a harmonization procedure that overcomes these heterogeneities and that improves the possibility to merge firms to administrative industry-specific data at disaggregate levels. Moreover, the paper exploits the harmonized dataset to shed light on the interpretation of the most widely recognized variables in the IBS: firms' current business conditions and their expectations for the next six months. The results show that firms' assessments are strongly related to current and future levels in revenues and speak in favor of interpreting both questions as referring to the similar dimension of the same latent variable.
C81|Understanding Joint Retirement|Evidence from different sources shows that spouses' retirement decisions are correlated. Retirement policies affecting individuals in couples are therefore also likely to affect behavior of their spouses. It is therefore important to account for joint features in modeling retirement. This paper studies a structural collective model of labor supply and retirement of both partners in a couple with interdependent preferences, imperfect knowledge of preferences of the spouse, and subjective expectations about the future. We propose a novel method to estimate preferences and the intra-household bargaining process, which relies on stated preferences data collected in the Health and Retirement Study. Respondents were asked to choose between hypothetical retirement trajectories describing the retirement ages and replacement rates of both spouses from three perspectives: considering their own preferences only, the preferences of their spouse only, or the most likely decision for the household. With these data, all model parameters are identified and potential sources of joint retirement can be disentangled. We find that males misperceive their wives' preferences, overestimating their disutility of work. Our estimates correct for this bias. They suggest that correlation in unobserved heterogeneity components of the partners' marginal utility of leisure explains a large share of joint retirement decisions. We also find significant positive complementarities in leisure, but this explains a much smaller part of joint retirement.
C81|SDG 16 on Governance and its measurement: Africa in the Lead|(english) This article provides some elements for reflection on an apparent paradox. On the one hand, Africa appears to be the continent most riddled by problems related to governance and conflict; on the other hand, it is at the forefront in both promoting the issue of governance at the international level and in implementing its statistical measurement, an observation that has gone largely unnoticed until now. Will Africa manage to maintain its lead following the adoption by all countries of Sustainable Development Goal 16 on governance, peace and security, to which the continent contributed greatly?_________________________________ (français) Cet article se propose d’apporter des éléments de réflexion sur un apparent paradoxe : alors que l’Afrique apparaît comme le continent où les questions de gouvernance et de conflits sont les plus problématiques, c’est également celui qui se montre le plus en pointe, à la fois dans la promotion de cette thématique au niveau international et dans la mise en oeuvre de sa mesure statistique, un constat passé largement inaperçu jusqu’ici. Cette avance pourra-t-elle se maintenir avec l’adoption par tous les pays de l’Objectif de Développement Durable 16 sur la gouvernance, la paix et la sécurité, auquel le continent a largement contribué ?e la société malgache. La faible organisation, tant du côté d’élites fragmentées que d’une population atomisée géographiquement et socialement, n’est pas propice à l’émergence de violences politiques. Mais c’est surtout la prégnance d’une violence symbolique systémique qui permet le maintien de l’ordre établi et freine l’émergence de mobilisations susceptibles de remettre en cause l’équilibre de la société. Faiblesse organisationnelle, normes sociales et violence symbolique se conjuguent pour une apparente paix sociale. Celle-ci reflète moins une solidité institutionnelle que la domination symbolique de la classe élitaire.
C81|AI meets labor market: exploring the link between automation and skills|This paper develops a set of innovative tools for labor market intelligence by applying machine learning techniques to web vacancies on the Italian labor market. Our approach allows to calculate, for each occupation, the different types of skills required by the market alongside a set of relevant variables such as region, sector, education and level of experience. We construct a taxonomy for skills and map it into the recently developed ESCO classification system. We subsequently develop measures of the relevance of soft and hard skills and we analyze their detailed composition. We apply the dataset constructed to the debate on computerization of work. We show that soft and digital skills are related to the probability of automation of a given occupation and we shed some light on the complementarity/substitutability of hard and soft skills.
C81|Looking for the missing rich: Tracing the top tail of the wealth distribution|We analyze the top tail of the wealth distribution in Germany, France, and Spain based on the first and second wave of the Household Finance and Consumption Survey (HFCS). Since top wealth is likely to be underrepresented in household surveys, we integrate big fortunes from rich lists, estimate a Pareto distribution, and impute the missing rich. In addition to the Forbes list, we rely on national rich lists since they represent a broader base for the big fortunes in those countries. As a result, the top percentile share of household wealth in Germany jumps up from 24 percent to 31 percent in the first and from 24 to 33 percent in the second wave after top wealth imputation. For France and Spain, we find only a small effect of the imputation since rich households are better captured in the survey.
C81|A methodology for automised outlier detection in high-dimensional datasets: an application to euro area banks' supervisory data|Outlier detection in high-dimensional datasets poses new challenges that have not been investigated in the literature. In this paper, we present an integrated methodology for the identification of outliers which is suitable for datasets with higher number of variables than observations. Our method aims to utilise the entire relevant information present in a dataset to detect outliers in an automatized way, a feature that renders the method suitable for application in large dimensional datasets. Our proposed five-step procedure for regression outlier detection entails a robust selection stage of the most explicative variables, the estimation of a robust regression model based on the selected variables, and a criterion to identify outliers based on robust measures of the residuals' dispersion. The proposed procedure deals also with data redundancy and missing observations which may inhibit the statistical processing of the data due to the ill-conditioning of the covariance matrix. The method is validated in a simulation study and an application to actual supervisory data on banks’ total assets. JEL Classification: C18, C81, G21
C81|Perspectives on Poverty in Europe|I address four topics: how our capacities to monitor poverty in Europe have improved substantially over recent decades; how progress on EU poverty reduction has been disappointing and why this has been; conceptual and measurement issues; and the future direction of EU-level anti-poverty actions. I follow in the footsteps of a giant – my perspectives are essentially elaborations of points made by Tony Atkinson.
C81|Expanding access to administrative data: the case of tax authorities in Finland and the UK|Abstract We discuss typical issues in getting access to and using high-quality administrative tax data for research purposes. We discuss research involving both quasi- and field experiments implemented together with the tax authority. We reflect on practical solutions that promote co-creation of knowledge and reduce information asymmetries between researchers and practitioners, based on our experiences of working with the tax authorities in Finland and the UK. We provide examples of how to improve the overall research environment focusing on two successful case studies: the HMRC Datalab in the UK and the remote access to data from Statistics Finland. We propose two key arguments to persuade policymakers elsewhere to follow similar practices: improved data security and equality of access across researchers.
C81|Sample selection biases and the historical growth pattern of children|Bodenhorn et al. (2017) have recently sparked considerable controversy by arguing that the fall in adult stature observed in military samples in the United States and Britain during industrialisation was a figment of sample selection bias. While subsequent papers have questioned the extent of the bias (Komlos and A’Hearn 2016; Zimran 2017), there is renewed concern about selection bias in historical anthropometric datasets. This paper extends Bodenhorn et al.’s discussion of selection bias on unobservables to sources of children’s growth, specifically focussing on biases that could distort the age pattern of growth. Understanding how the growth pattern of children has changed is important since these changes underpinned the secular increase in adult stature and are related to child stunting observed in developing countries today. However, there is potential for selection on unobservables in historical datasets containing children’s and adolescents’ height, so scholars must be aware of these biases before analysing these sources. This paper highlights, among others, three common sources of bias: 1) positive selection of children into secondary school in the late nineteenth and early twentieth centuries; 2) distorted height by age profiles created by age thresholds for enlistment in the military; and 3) changing institutional ecology which determines to which institutions children are sent. Accounting for these biases weakens the evidence of a strong pubertal growth spurt in the nineteenth century and raises doubts on some long run analyses of changes in children’s growth, especially for Japan.
C81|Size, Internationalization and University Rankings: Evaluating Times Higher Education (THE) Data for Japan|International and domestic rankings of academics, academic departments, faculties, schools and colleges, institutions of higher learning, states, regions and countries, are of academic and practical interest and importance to students, parents, academics, and private and public institutions. International and domestic rankings are typically based on arbitrary methodologies and criteria. Evaluating how the rankings might be sensitive to different factors, as well as forecasting how they might change over time, requires a statistical analysis of the factors that affect the rankings. Accurate data on rankings and the associated factors is essential for a valid statistical analysis. In this respect, the Times Higher Education (THE) World University Rankings is one of the three leading and most influential annual sources of international university rankings. Using recently released data for a single country, namely Japan, the paper evaluates the effects of size (specifically, the number of Full-Time Equivalent (FTE) students, or FTE(Size)) and internationalization (specifically, the percentage of international students, or IntStud) on academic rankings using THE data for 2017 and 2018 on 258 national, public (that is, prefectural or city), and private universities. The results show that both size and internationalization are statistically significant in explaining rankings for all universities, as well as separately for private and non-private (that is, national and public) universities, in Japan for each of 2017 and 2018.
C81|Quality Assessment of Microsimulation Models The Case of EUROMOD|Assessing the quality of microsimulation models is an important contributing factor for motivating their use in both academic and policy environments. This is particularly relevant for EUROMOD, the tax-benefit microsimulation model for the European Union, because it is intended to be widely used. This paper explains how the quality of EUROMOD is assessed. It focusses on the validity and scope of results as particularly important dimensions of quality, and on the transparency with which this assessment is done. It also provides evidence on the extent and breadth of the use of EUROMOD. Some of the key trade-offs between different aspects of quality are identified and the paper concludes with a view on the appropriate division of responsibility for quality assessment, between model developers and users.
C81|Distributional analysis of the role of breadth and persistence of multiple deprivation in the health gradient measured by biomarkers|This paper analyses the relationship between health and socioeconomic status accounting for the role of breadth and persistence of multiple deprivation. Adopting a holistic approach to multidimensional deprivation, we construct measures of absolute and relative deprivation and use these measures along with a range of nurse measured and blood-based biomarkers for a distributional analysis of the relationship between socioeconomic status and health. Using data from the British Household Panel Survey and Understanding Society, our analysis finds the presence of systematic multidimensional deprivation gradient across the distribution of most of our biomarkers (BMI, waist circumference, heart rate, C-reactive protein and HbA1c) beyond income, with the size of this gradient to be substantially larger at higher tails of the biomarker distribution. Decomposition analysis of the contribution of components of deprivation to health suggests breadth of deprivation to dominate the contribution over persistence. Health policy prioritising health of people enduring deprivation across multiple domains, i.e., people who experience dual burden of deprivation across several domains and poor health, may be particularly effective at reducing the risk of falling into a health-deprivation trap.
C81|Les liens entre taux d'épargne, revenu et incertitude. Une illustration sur données françaises|La compréhension des liens entre taux d’épargne et revenu des ménages est cruciale dans de nombreux débats de finances publiques (arbitrage entre taxation du travail ou de la consommation, progressivité de l’impôt sur le revenu, baisse de la taxation du capital,...). L’objectif de cet article est d’étudier, à partir des données de l’enquête Budget de famille 2010-2011 de l’INSEE, les liens entre le taux d’épargne des ménages français et leur revenu. Il s’agit d’abord de tester l’homogénéité des comportements en étudiant les liens entre taux d’épargne et revenu (courant et permanent) des ménages français. On met ensuite empiriquement en évidence l’existence d’un comportement d’épargne de précaution lié au risque sur le revenu, différencié selon le niveau de revenu. On montre d’abord que le taux d’épargne des ménages les plus riches croît avec le revenu permanent : ces derniers épargnent donc davantage sur le cycle de vie. En outre, l’étude empirique permet de mettre en évidence et de quantifier un motif de précaution lié au risque de chômage : le motif de précaution entraîne un surplus de flux d’épargne d’environ 7 % pour les ménages actifs. Par ailleurs, la part du patrimoine de précaution liée à l’incertitude sur le revenu futur se situe autour de 7 % de la richesse globale, ce qui confirme le résultat obtenu sur données françaises par d’autres auteurs (Arrondel et Calvo-Pardo, 2008). Enfin, l’importance du motif de précaution dépend du niveau de revenu selon une courbe en U inversé : il est deux fois plus fort pour les ménages aux revenus intermédiaires que pour les quintiles extrêmes de revenu..
C81|Internal Migration in the United States: A Comparative Assessment of the Utility of the Consumer Credit Panel|This paper demonstrates that credit bureau data, such as the Federal Reserve Bank of New York Consumer Credit Panel/Equifax (CCP), can be used to study internal migration in the United States. It is comparable to, and in some ways superior to, the standard data used to study migration, including the American Community Survey (ACS), the Current Population Survey (CPS), and the Internal Revenue Service (IRS) county-to-county migration data. CCP-based estimates of migration intensity, connectivity, and spatial focusing are similar to estimates derived from the ACS, CPS, and IRS data. The CCP can measure block-to-block migration and it is available at quarterly rather than annual frequencies. Migrants’ precise origins are not available in public versions of the ACS, CPS, or IRS data. We report measures of migration from the CCP data at finer geographies and time intervals. Finally, we disaggregate migration flows into first-, second-, and higher-order moves. Individual-level panels in the CCP make this possible, giving the CCP an additional advantage over the ACS, CPS, or publicly available IRS data.
C81|Using Payroll Processor Microdata to Measure Aggregate Labor Market Activity|We show that high-frequency private payroll microdata can help forecast labor market conditions. Payroll employment is perhaps the most reliable real-time indicator of the business cycle and is therefore closely followed by policymakers, academia, and financial markets. Government statistical agencies have long served as the primary suppliers of information on the labor market and will continue to do so for the foreseeable future. That said, sources of “big data” are becoming increasingly available through collaborations with private businesses engaged in commercial activities that record economic activity on a granular, frequent, and timely basis. One such data source is generated by the firm ADP, which processes payrolls for about one fifth of the U.S. private sector workforce. We evaluate the efficacy of these data to create new statistics that complement existing measures. In particular, we develop a set of weekly aggregate employment indexes from 2000 to 2017, which allows us to measure employment at a higher frequency than is currently possible. The extensive coverage of the ADP data—similar in terms of private employment to the BLS CES sample—implies potentially high information value of these data, and our results confirm this conjecture. Indeed, the timeliness and frequency of the ADP payroll microdata substantially improves forecast accuracy for both current-month employment and revisions to the BLS CES data.
C81|Oil, equities, and the zero lower bound|Since 2008, oil and equity returns have moved together much more than they did previously. In addition, we show that both oil and equity returns have become more responsive to macroeconomic news. Before 2008, there is little evidence that oil returns were responsive to macroeconomic news. We argue that these results are consistent with a new-Keynesian model that includes oil and incorporates the zero lower bound on nominal interest rates. Our empirical findings lend support the model's implication that different rules apply at the zero lower bound.
C81|Reaching the Hard to Reach with Intermediaries: The Kansas City Fed’s LMI Survey|Reaching hard-to-reach individuals is a common problem in survey research. The low- and moderate-income (LMI) population, for example, is generally hard to reach. The Kansas City Fed’s Low- and Moderate-Income Survey addresses this problem by sampling a database of organizations to serve as proxies for the LMI population. In this paper, I describe why the LMI population can be hard to reach. I then explore potential problems with using a nonrandom survey sample and address the empirical validity of the Kansas City Fed’s LMI Survey. I compare results from the survey using the standard sample to results from the survey using a random sample. I find that the results of the surveys using the standard and random samples are not significantly different and conclude that the use of a nonrandom sample is not a significant problem for the LMI Survey. I find that the series of responses from the LMI Survey are correlated with the things they should be correlated with, suggesting that the survey is empirically valid and does a good job of measuring economic conditions in LMI communities.
C81|Working Paper 03-18 - The PEACH2AIR database of air pollution associated with household consumption in Belgium in 2014 - Methodological description for the SUSPENS research project funded by the Federal Science Policy Office<BR>[Working Paper 03-18 - La base de données PEACH2AIR sur la pollution atmosphérique liée à la consommation des ménages en Belgique en 2014 - Description méthodologique dans le cadre du projet de recherche SUSPENS financé par BELSPO]|The database PEACH2AIR links emissions of greenhouse and acidifying gases, of gases contributing to tropospheric ozone formation and particulate matter to consumer expenditures in Belgium in 2014. It relies on standardized air pollution data (including air emissions accounts), input-output tables and the Household Budget Survey. Analyses for 2014 show that energy products as well as food and non-alcoholic beverages are the most air polluting expenditure categories.
C81|Organic Food Retailing and the Conventionalisation Debate|We propose an empirical study of French sales in conventional food retailing and in specialised organic stores for 2012. We examine the plant or animal origin of food products, as an indicator of the environmental and health impacts of sales, and their degree of processing, as an indicator of their health impact. The results indicate that sales of organic food products are more plant-based and less processed in specialised organic stores than in conventional retail stores, two criteria for a better health and environmental impact. In conventional stores, organic sales are more plant-based and less processed than conventional sales. Organic sales in conventional stores show some specificity, having the highest share of particular product ranges lacking a clear health or environmental impact, such as processed culinary ingredients or unprocessed or minimally processed animal products. Building a typology of buyers in conventional stores, we find that even purchases by buyers with the highest organic purchase intensity in conventional stores are less plant-based and more processed than average purchases in specialised organic stores. Our results characterise to what extent some of the holistic environmental and health impacts of organic agriculture are lower in conventional retail stores than in specialised organic stores in France in 2012.
C81|Impact sur l’emploi de la participation aux projets de R&D des pôles de compétitivité. Méthode et résultats|?Since their creation in 2005, competitiveness clusters have been defined as a structuring instrument of French industrial policy. From the implementation of an evaluation model that is well-identified in the literature, this work proposes a quantified estimation of the clusters? effects on employment for the companies taking part in R&D projects labeled by the clusters. This observation was carried out on the basis of the construction of an original database and the mobilization of a double difference evaluation method. This article highlights the positive and significant effect of French competitiveness clusters on employment.?
C81|Do people stand by their commitments? Evidence from a classroom experiment|We test the fulfilment of commitments in terms of chosen effort that students intend to exert under an incentive contract in the absence of strategic interactions. We designed classroom experiments whereby students had to decide on whether to commit to their ex ante level of effort despite that they have no interest to do so ex post. The experiment consisted of three within-subject treatments that define different institutional contexts regarding information disclosure, evoking different levels of social visibility and commitment. In contrast to the theoretical predictions, a significant percentage of students tend to stand by their ex ante commitments regardless of the manipulation of the social context. Our findings corroborate the existence of a freezing effect by showing that promise keeping is sensitive to our manipulation of social visibility and self-commitment, with a stronger effect for public disclosure of the average level of effort than for public self-announcement of private choices. Our data also allows us to shed light on promise making behaviour. Contrary to promise keeping, there are order effects. However, the number of observations is too small to identify a difference between the baseline treatment and the one implying public self-announcement of level of effort.
C81|When social goals meet economic goals: the double dividend of extending free access to healthcare in Uganda|In recent years, the need for a better access to health services has become a social objective in many sub-Saharan African countries that seek to achieve the Millennium Goals for Development. Yet such pursuits raise questions about the appropriate balance between the social goals and economic objectives of poverty reduction policies, such that measures promoting agricultural growth might appear as a more effective strategies. This article explores how an improvement of health subsidies policy in Uganda experiment might meet both these social and economic goals. Focusing on the relationship between farmers’ health and agricultural productivity, we use a computable general equilibrium model and a non-parametric micro-simulation model to predict the effect of this policy. The results show that it is likely to increase both households’ access to health care and growth processes. They also show that in a context marked by scarce budgetary resources, it is possible to maximise the impact of this policy by reallocating subsidies toward the categories of health care with the greatest impacts on workers’ productivity or toward rural households.
C81|Mindfulness and Stress - a Randomised Experiment|We conduct a randomised controlled trial of an online course in mindfulness. Previous research has found evidence that mindfulness reduces stress; however, few studies have been carried out on non-clinical populations that have not self-selected into or paid for treatment. Our sample consists of 139 students with no pre-existing medical conditions and no prior information on the experiment and treatments. Half of them are asked to follow a four-week mindfulness training, while the other half are asked to watch a four-week series of historical documentaries. We follow participants for five consecutive weeks, with an additional post-intervention session five months later. We evaluate the effects of the mindfulness program on measures of chronic stress, and on the response to stressful situations, measured by cortisol and self-reports. We find strong evidence that mindfulness training reduces perceived stress, as measured by the Perceived Stress Scale. However, the physiological responses to an acutely stressful situation do not differ significantly between the treatment and control groups.
C81|Record linkage in the Cape of Good Hope Panel|In this paper we describe the record linkage procedure to create a panel from Cape Colony census returns, or opgaafrolle, for 1787--1828, a dataset of 42,354 household-level observations. Based on a subset of manually linked records, we first evaluate statistical models and deterministic algorithms to best identify and match households over time. By using household-level characteristics in the linking process and near-annual data, we are able to create high-quality links for 84 percent of the dataset. We compare basic analyses on the linked panel dataset to the original cross-sectional data, evaluate the feasibility of the strategy when linking to supplementary sources, and discuss the scalability of our approach to the full Cape panel.
C81|A Multidimensional Classification For The Information Technology Market|This paper expands the existing informational and analytical opportunities of application of the results of business tendency surveys which solve the problem of the loss of valuable statistical information in its traditional aggregation into simple and composite indicators. Based on methods of multidimensional classification, an algorithm of statistical analysis significantly raises the analytical opportunities for the more wide measurement of trajectories of development and short-term fluctuations of branch of the information technology (IT) is developed and discussed. This allows the construction of behavioral models of business tendency data which improve the understanding of the business cycle in more detail. Furthermore the empirical results confirm the possibility of receiving various information which increases the analytical potential of business tendency surveys
C81|A cautionary note on the reliability of the online survey data - the case of Wage Indicator|We investigate the reliability of data from the Wage Indicator (WI), the largest online survey on earnings and working conditions. Comparing WI to nationally representative data sources for 17 countries reveals that participants of WI are not likely to have been representatively drawn from the respective populations. Previous literature has proposed to utilize weights based on inverse propensity scores, but this procedure was shown to leave reweighted WI samples different from the benchmark nationally representative data. We propose a novel procedure, building on covariate balancing propensity score, which achieves complete reweighting of the WI data, making it able to replicate the structure of nationally representative samples on observable characteristics. While rebalancing assures the match between WI and representative benchmark data sources, we show that the wage schedules remain different for a large group of countries. Using the example of a Mincerian wage regression, we find that in more than a third of the cases, our proposed novel reweighting assures that estimates obtained on WI data are not biased relative to nationally representative data. However, in the remaining 60% of the analyzed 95 datasets systematic differences in the estimated coefficients of the Mincerian wage regression between WI and nationally representative data persists even after reweighting. We provide some intuition about the reasons behind these biases. Notably, objective factors such as access to the Internet or richness appear to matter, but self-selection (on unobservable characteristics) among WI participants appears to constitute an important source of bias.
C81|Distributional analysis of the role of breadth and persistence of multiple deprivation in the health gradient measured by biomarkers|This paper analyses the relationship between health and socioeconomic status ac- counting for the role of breadth and persistence of multiple deprivation. Adopting a holistic approach to multidimensional deprivation, we construct measures of absolute and relative deprivation and use these measures along with a range of nurse measured and blood-based biomarkers for a distributional analysis of the relationship between so- cioeconomic status and health. Using data from the British Household Panel Survey and Understanding Society, our analysis finds the presence of systematic multidimensional deprivation gradient across the distribution of most of our biomarkers (BMI, waist cir- cumference, heart rate, C-reactive protein and HbA1c) beyond income, with the size of this gradient to be substantially larger at higher tails of the biomarker distribution. De- composition analysis of the contribution of components of deprivation to health suggests breadth of deprivation to dominate the contribution over persistence. Health policy pri- oritising health of people enduring deprivation across multiple domains, i.e., people who experience dual burden of deprivation across several domains and poor health, may be particularly effective at reducing the risk of falling into a health-deprivation trap.
C81|Das Experteninterview als Datenerhebungsmethode in Prüfungsarbeiten|No abstract is available for this item.
C81|Die Patentleistung der deutschen KFZ-Unternehmen: Eine Analyse der Patentanmeldungen beim deutschen Patent- und Markenamt unter Berücksichtigung von branchen- und technologiespezifischen Schwerpunkten|Megatrends wie die zunehmende Elektrifizierung des Antriebsstrangs und das autonome Fahren führen zu einem gravierenden Strukturwandel im Fahrzeugbau. Die vorliegende Studie analysiert, wie gut die deutschen KFZ-Unternehmen auf diesen Strukturwandel vorbereitet sind. Hierzu werden die Patentanmeldungen der deutschen Hersteller, Zulieferer und Entwicklungsdienstleister des aktuellsten verfügbaren Jahres analysiert und folgende Fragen beantwortet: Welcher Anteil aller deutschen Patentanmeldungen entfällt aktuell auf den KFZ-Bereich? Leisten dabei Hersteller oder Zulieferer einen höheren Beitrag zum Innovationsgeschehen? In welchen Technologiebereichen sind die deutschen KFZ-Unternehmen mit Bezug auf die Internationale Patentklassifikation (IPC) besonders forschungsaktiv und welche Bedeutung nimmt dabei der konventionelle Antriebsstrang ein, der durch den Strukturwandel an relativer Bedeutung verlieren wird? Die Ergebnisse beziehen sich auf die Patentanmeldungen des aktuellsten verfügbaren Jahres und zeigen, dass die deutschen KFZ-Unternehmen bereits heute viel besser und zukunftssicherer aufgestellt sind, als von der öffentlichen Meinung kolportiert wird. [...]
C81|Web mining of firm websites: A framework for web scraping and a pilot study for Germany|Nowadays, almost all (relevant) firms have their own websites which they use to publish information about their products and services. Using the example of innovation in firms, we outline a framework for extracting information from firm websites using web scraping and data mining. For this purpose, we present an easy and free-to-use web scraping tool for large-scale data retrieval from firm websites. We apply this tool in a large-scale pilot study to provide information on the data source (i.e. the population of firm websites in Germany), which has as yet not been studied rigorously in terms of its qualitative and quantitative properties. We find, inter alia, that the use of websites and websites' characteristics (number of subpages and hyperlinks, text volume, language used) differs according to firm size, age, location, and sector. Web-based studies also have to contend with distinct outliers and the fact that low broadband availability appears to prevent firms from operating a website. Finally, we propose two approaches based on neural network language models and social network analysis to derive firm-level information from the extracted web data.
C81|An Integrated Micro Data Base for Tax Analysis in Germany|This paper documents methodology underlying the construction of the integrated data base for our study on “Wer trägt die Steuerlast in Deutschland? – Verteilungswirkungen des deutschen Steuer- und Transfersystems” (Who bears the tax burden in Germany? – Distributional Analyses of the German tax and transfer system). Financial support from the Hans Böckler Stiftung for the project is gratefully acknowledged. The paper greatly benefited from comments by the members of the scientific advisory council of the project.
C81|A replication recipe: List your ingredients before you start cooking|"The author argues that researchers should do replications using preanalysis plans. These plans should specify at least three characteristics: (1) how much flowtime the researchers will spend, (2) how much money and effort (working hours) the researchers will spend, and (3) the intended results and the precision of the replication necessary for ""success"". A researcher's replication will be ""successful"" according to context-specific criteria in the preanalysis plan. The author also argues that the two biggest drawbacks of preanalysis plans-(1) that they discount unexpected but extraordinary findings and (2) that they make it difficult for researchers to prespecify all possible actions in their decision trees-are less relevant for replications compared with new research. The author concludes with describing a preanalysis plan for replicating a paper on housing demand and household formation."
C81|Does a spouse's health shock influence the partner's risk attitudes?|The purpose of this study is to investigate the effect of a spouse's health shock on own risk attitudes. A spouse's health shock (i.e., the occurrence of a severe disease) can influence own expectations about the probability of falling ill. Moreover, an indisposition of the spouse, which may disrupt the ability and efficiency in sharing the everyday responsibilities, can increase mental and financial pressure, and thus would lead to a reduction of own risk willingness. On the other hand, a health shock may act as a wake-up call to enjoy life and may increase risk willingness. Using German Socio Economic Panel data, this study reveals that a health shock suffered by the spouse decreases own risk willingness. The effect is more pronounced the more serious the health shock is. The findings have implications for health insurance decisions and policy evaluations.
C81|Inventor mobility index: A method to disambiguate inventor careers|Usually patent data does not contain any unique identifiers for the patenting assignees or the inventors, as the main tasks of patent authorities is the examination of applications and the administration of the patent documents as public contracts and not the support of the empirical analysis of their data. An inventor in a patent document is identified by his or her name. Depending on the patent authority the full address or parts of it may be included to further identify this inventor. The goal is to define an inventor mobility index that traces the career of an inventor as an individual with all the job switches and relocations approximated by the patents as potential milestones. The inventor name is the main criteria for this identifier. The inventor address information on the other hand is only of limited use for the definition of a mobility index. The name alone can work for exotic name variants, but for more common names the problem of namesakes gets in the way of identifying individuals. The solution discussed here consists in the construction of a relationship network between inventors with the same name. This network will be created by using all the other information available in the patent data. These could be simple connections like the same applicant or just the same home address, up to more complex connections that are created by the overlapping of colleagues and co-inventors, similar technology fields or shared citations. Traversal of these heuristically weighted networks by using methods of the graph theory leads to clusters representing a person. The applied methodology will give uncommon names a higher degree of freedom regarding the heuristic limitations than the more common names will get.
C81|The elasticity of taxable income: A meta-regression analysis|The elasticities of taxable (ETI) and broad income (EBI) are key parameters in optimal tax and welfare analysis. To examine the large variation in estimates found in the literature, I conduct a comprehensive meta-regression analysis of elasticities that measure behavioral responses to income taxation using information from 51 different studies containing 1,420 estimates. I find that heterogeneity in reported estimates is driven by regression techniques, sample restrictions and variations across countries and time. Moreover, I provide descriptive evidence of the correlation between contextual factors and the magnitude of an elasticity estimate. Overall, the study confirms the fact that the ETI itself is endogenous to the underlying tax system. I also document that selective reporting bias is prevalent in the literature. The direction of reporting bias depends on whether or not deductions are included in the tax base.
C81|The Power of Big Data : Historical Time Series on German Education|Numerous primary investigators collected and processed long-termed time series on German educational statistics in the context of their studies. As a result, there are a multitude of quantitative empirical studies. On the one hand, there is the project group on German Educational Statistics. 1 Its projects were targeted at describing and analyzing the long-term structural changes of the German educational system on a broad empirical and statistical basis. On the other hand, there are comprehensive data compilations of individual research projects, focusing on a wide variety of special educational research topics. The online database “histat” provides central digital access to these datasets on German educational history. Currently, it offers more than 120,000 long-term time series on the German educational system for a period of 200 years. The striking size of the database shows its key importance for researchers in the field of education. Thus, this paper aims to provide useful insights into the background of the database, the special characteristics of the data compilations and their analytical potential. Additionally, examples are given of how the data have already been used by researchers.
C81|Interval Based Composite Indicators|Composite indicators are increasingly important in country comparisons and in policy making. At the same time, the robustness of the results obtained and in particular of the rankings and the conclusions obtained from the analysis it is usually accepted with doubts. In this sense our proposal is to use interval data in order to measure the uncertainty related to the different composite indicators based on the different assumptions used as input. In this sense where composite indicators can be considered as models, for this reason it could be necessary to assess the uncertainties related to the different choices in the construction. The uncertainty can be represented by the interval data. The intervals keep the information related to the initial value of the composite indicator, but at the same time give information on the range of the results.
C81|A Spatial Econometric Analysis of Within-field Crop Yield Variability Using Yield Monitor Data from a Mississippi Farm| It is widely observed that the crop yields vary significantly within the field, primarily because of the intra-field variations in soil, landscape, water, and nutrient conditions. That variability forms the foundation for site-specific management in precision agriculture. However, thus far the studies about the within-field yield variability are mostly based on one or several sample fields, while the variability distribution for a real world farm or a larger region have received less investigations. In addition, due to the small number of sample fields, the determining factors of yield variability have not been fully examined. This study fill this research gap by collecting and analyzing high resolution yield monitor data of over a hundred fields from a large size farm in the Mississippi Delta. It quantitatively describes the extent of the within-field yield variability over a large scale area, and empirically examines the relationship between the yield variability and factors such as soil types, landscapes, weather conditions, management inputs, etc. A spatial econometric model is utilized to account for other unobserved but spatially correlated yield-impacting soil properties. This study contributes to exploring the method of analyzing GIS data from farming and turning the data into site-specific management decisions.
C81|FOI as a data collection tool for economists|This paper sets out a method of generating a unique data set that has been underused by economists – a Freedom of Information (FOI) request. The FOI Act came into force in 2005 in the UK and allows the public to make requests of publicly held data. We explain how they can be made and provide suggestions on how to make effective data driven requests, those most frequently made by economists. Finally, we document the determinants of one particular FOI request. We applied for crime data from all police forces in the UK and examine the determinants of that request. In general, we find that observable characteristics of the local area or the police force neither determine whether the request was fulfilled, nor the speed at which it was responded to.
C81|Applications For Businesses That Uses Relational Databases:|The paper presents a database production model designed as a warehouse star that contain dimensions like deposits, raw materials, stocks, products, producer, locations, time and a fact table with foreign keys and measures. This model optimize the activity of a business based on a production activity in the way that it can store large amount of data in a historical way that can be the base for future scenarios with key values changed by the decision maker. The decision maker analyses a large spectrum of reports and choose what indicators to observe and what measures to display and so it’s easy to decide based on large amount of data and trends. Database applications for business improve the efficiency in managing large quantity of data in the sense for storage, updates, queries, interaction with the users and also getting answers through reports. The schema specific to a database is very flexible and permits adding or removing columns and also adding and removing entities. This feature is very useful when the relational database schema is transformed in a data warehouse shaped as a star with dimensions and a fact table. This model permits advanced queries and the usage of rollup and drill down objects specific to the business intelligence tools that offer quick responses to the complex answers. To a production business the choice of a database application designed and implemented as data warehouse star model, bennefits from all the advantage of storage and also a superior and complex tool for building queries.
C81|What’s Up with Unit Non-Response in the Bank of Canada’s Business Outlook Survey? The Effect of Staff Tenure|Since 1997, the Bank of Canada’s regional offices have been conducting the Business Outlook Survey (BOS), a quarterly survey of business conditions. Survey responses are gathered through face-to-face, confidential consultations with a sample of private sector firms representative of the various sectors, firm sizes and regions across Canada. Participation is voluntary and although efforts are made to encourage participation, some firms either do not respond to the Bank’s contact attempts or refuse to or cannot participate for various reasons, resulting in unit non-response. Using data for all firms contacted between 2009 and 2016, this paper analyzes the determinants of unit non-response including the impact of the tenure of the Bank’s survey booking teams. Difference-in-differences estimates suggest that new survey booking teams increase the probability of unit non-response. Building on previous findings, regression results also provide further support that some firm characteristics are associated with non-response, including firm size, ownership status, sector and participation history. There is little evidence to conclude that the effect linked to new booking teams differs significantly for new versus repeat firms. Finally, we find no statistically significant relationship between firms’ credit scores and unit non-response, and no obvious upward trend in the BOS non-response rate once other relevant factors have been taken into account.
C81|The Bank of Canada 2015 Retailer Survey on the Cost of Payment Methods: Nonresponse|Nonresponse is a considerable challenge in the Retailer Survey on the Cost of Payment Methods conducted by the Bank of Canada in 2015. There are two types of nonresponse in this survey: unit nonresponse, in which a business does not reply to the entire survey, and item nonresponse, in which a business does not respond to particular questions within the survey. Both types may create a bias when computing statistics such as means and weighted totals for different variables. This technical report analyzes solutions to fix the problem of nonresponse in the survey data. Unit nonresponse is addressed through response probability adjustment, in which response probabilities are modelled using logistic regression (a clustering approach for the unit response probabilities is also considered) and are used in the construction of a set of survey weights. Item nonresponse is addressed through imputation, in which the gradient boosting machine (GBM) and extreme gradient boosting (XGBoost) algorithms are used to predict missing values for variables of interest.
C81|The Bank of Canada 2015 Retailer Survey on the Cost of Payment Methods: Sampling|In 2015, the Bank of Canada undertook the large-scale Retailer Survey on the Cost of Payment Methods. This paper describes and discusses the sampling methodology used in this survey, with a focus on the challenges of voluntary business surveys. Recommendations for sampling strategies in future retailer surveys are offered.
C81|The Bank of Canada 2015 Retailer Survey on the Cost of Payment Methods: Calibration for Single-Location Retailers|Calibrated weights are created to (a) reduce the nonresponse bias; (b) reduce the coverage error; and (c) make the weighted estimates from the sample consistent with the target population in terms of certain key variables. This technical report details our calibration analysis of singlelocation retailers for the Retailer Survey on the Cost of Payment Methods. We first compare two types of calibration approaches, consisting of (1) traditional calibration, in which calibration is implemented after explicit nonresponse modelling, and (2) nonresponse-embedded calibration, where the nonresponse correction is automatically built in (Särndal and Lundström, 2005). After carefully selecting auxiliary variables, we find minor differences between these two methods. We also examine the effects of trimming, sample size, smoothing and influential units on the calibrated weights, and show that our calibration is robust in view of these considerations.
C81|The Luxembourg Household Finance and Consumption Survey: Results from the 2nd wave|This report presents the main results and the underlying methodology of the 2nd wave of the Luxembourg Household Finance and Consumption Survey (LU-HFCS) and compares them to those obtained in the 1st wave in 2010. This survey is conducted among private households resident in Luxembourg and is part of the Eurosystem Household Finance and Consumption Survey, which provides detailed individual and household data on assets, liabilities, income and consumption. This individual-level information on households provides a view on the distribution of assets and liabilities that complements the aggregate data on the household sector in the financial accounts.
C81|Microsimulation tools for the evaluation of fiscal policy reforms at the Banco de España|This paper presents the microsimulation models developed at the Banco de España for the study of fiscal reforms, describing the tool used to evaluate changes in the Spanish personal income tax and also the one for the value added tax and excise duties. In both cases the structure, data and output of the model are detailed and its capabilities are illustrated using simple examples of hypothetical tax reforms, presented only to illustrate the use of these simulation tools.
C81|Text Mining-based Economic Activity Estimates|This paper outlines the methodology for calculating a high-frequency indicator of economic activity in Russia. News articles taken from Internet resources are used as data sources. The news articles are analysed using text mining and machine learning methods, which, although developed relatively recently, have quickly found wide application in scientific research, including economic studies. This is because news is not only a key source of information but a way to gauge the sentiment of journalists and survey respondents about the current situation and convert it into quantitative data.
C81|Building a firm level dataset for the analysis of industrial dynamics and demography|"This paper illustrates the building procedure of a firm-level panel dataset that merges several sources of information concerning the various activities of business firms. The aim of this work is to achieve a detailed dataset able to shed light on firm demographics, in terms of survival, entry and exit processes, distinguishing between “voluntary"" and “involuntary"" exits. Moreover, the derived dataset allows to monitor the innovation activities of the firms and also to capture complementarities between two instruments of intellectual property rights (IPRs), namely granted patents and registered trademarks. We assess the validity of the proposed procedures resorting to the virtual universe of Italian limited liability companies as provided by Bureau van Dijk (BvD). The dataset covers more than 1 million companies operating in both manufacturing and service sectors and contain financial and economic information, as well as, among the others, the ownership structure and administrative procedures undergone by the firms, which may lead to firm exit. The main purpose of the paper is to provide a unified set of procedures to help the researcher dealing with the vast amount of information available on corporate firms and of ever increasing size. This will also facilitate the replication of empirical analyses, across researchers working on dataset with similar characteristics, although from different countries or data providers."
C81|An Evaluation of Using Linked Survey and Administrative Data to Impute Nonfilers to the Population of Tax Return Filers: Working Paper 2017-06|Administrative tax return data are increasingly used for policy analysis and economic research. A potential weakness of that data source is that not everyone is required to file a tax return, even though information on the characteristics of those nonfilers is desirable for the analysis of various tax policies and tax administration. In this paper, I use data from the Census Bureauâ€™s Current Population Survey (CPS) linked to administrative tax return data to obtain demographic and income characteristics of filers and nonfilers. Those linked data are also used to model an
C81|CBO's New Framework for Analyzing the Effects of Means-Tested Transfers and Federal Taxes on the Distribution of Income: Working Paper 2017-09|This paper describes CBOâ€™s new framework for analyzing the distribution of household income and how means-tested transfers and federal taxes affect that distribution. The new framework will use a new measure of incomeâ€”income before transfers and taxesâ€”to rank households and calculate average means-tested transfer rates and average federal tax rates.
C81|Random expected utility and certainty equivalents: mimicry of probability weighting functions|Abstract For simple prospects routinely used for certainty equivalent elicitation, random expected utility preferences imply a conditional expectation function that can mimic deterministic rank-dependent preferences. That is, a subject with random expected utility preferences can have expected certainty equivalents exactly like those predicted by rank-dependent probability weighting functions of the inverse-s shape discussed by Quiggin (J Econ Behav Organ 3:323–343, 1982) and advocated by Tversky and Kahneman (J Risk Uncertainty 5:297–323, 1992), Prelec (Econometrica 66:497–527, 1998) and other scholars. Certainty equivalents may not nonparametrically identify preferences: Their conditional expectation (and critically, their interpretation) depends on assumptions concerning the source of their variability.
C81|Financial inclusion of the poor and money laundering indicators: empirical evidence for Colombia|Taking advantage of the largest financial inclusion program in Colombia, we estimate how increasing the access to such services for the poor impacts money laundering indicators in the country. We find that eventhough, on average, government’s indicators of money laundering activities in Colombia decreased, complex and heterogeneous impacts across the country and in time are observed. While money laundering indicators decreased in areas with high historic values of this crime, indicators in areas with medium historic levels increased. The evidence suggests that after the bancarization process a fragmentation and expansion of money laundering indicators across municipalities in Colombia took place, diminishing the accuracy of the alerts that the financial institutions provide to the government in order to fight this crime.
C81|Updating USAGE: Baseline and Illustrative Application|USAGE is a dynamic, CGE model of the U.S. economy created at CoPS in collaboration with the U.S. International Trade Commission (USITC). The model has been used by and on behalf of: the USITC; the U.S. Departments of Commerce, Agriculture, Energy, Transportation and Homeland Security; private sector organizations such as the Cato Institute and the Mitre Corporation; and the Canadian Embassy in Washington DC. To keep the model relevant for policy analysis, it must be updated periodically. This paper describes a major update of USAGE undertaken for the USITC. In accordance with the CoPS contract with the USITC, the update task was to: 1. build a NAICS-based database at the 400-industry level for USAGE using the 2007 BEA benchmark input-output tables; 2. update this database to 2014; 3. create a baseline projection starting from the base year of 2014 and proceeding at 5 year intervals to 2024; and 4. conduct an illustrative USAGE policy simulation around the baseline. At the completion of this work in August 2016, the ITC requested a fifth task: 5. update from 2007 to 2015 rather than 2014 and create a baseline from 2015 to 2020. This paper describes how we undertook the five tasks.
C81|Attrition in randomized control trials: Using tracking information to correct bias|This paper starts from a review of RCT studies in development economics, and documents many studies largely ignore attrition once attrition rates are found balanced between treatment arms. The paper analyzes the implications of attrition for the internal and external validity of the results of a randomized experiment with balanced attrition rates, and proposes a new method to correct for attrition bias. We rely on a 10-years longitudinal data set with a nal attrition rate of 10 percent, obtained after intensive tracking of migrants, and document the sensitivity of ITT estimates for schooling gains and labour market outcomes for a social program in Nicaragua. We nd that not including those found during the intensive tracking leads to an overestimate of the ITT effects for the target population by more than 35 percent, and that selection into attrition is driven by observable baseline characteristics. We propose to correct for attrition using inverse probability weighting with estimates of weights that exploit the similarities between missing individuals and those found during an intensive tracking phase. We compare these estimates with alternative strategies using regression adjustment, standard weights, bounds or proxy information. JEL codes:
C81|Violence exposure and deprivation: Evidence from the Burundi civil war|We investigate the relationship between exposure to con ict and household deprivation, using original three-wave household-level panel data for Burundi which report local-level violence exposure. First, the data reveal that aggregate poverty has not changed between 1998 and 2012, while food poverty has increased and we observe multiple household-level transitions into and out of poverty. Second, households living in localities exposed to the war since 1993 subsequently exhibit a signi cantly higher level of deprivation than non-exposed households, this di erence being persistent years after the con ict termination. Moreover, the correlation between violence and household deprivation is robust to within-household estimations. Third, the analysis of the household-level poverty dynamics following the most recent period of violence reveals that the likelihood to pull through of poor households is hampered by exposure to high-intensity violence, while the risk to fall into poverty of non-poor households is ampli ed by exposure to low-intensity violence. We discuss a mechanism based on the nature of violence which could explain this result, and derive some policy implications regarding poverty alleviation in the aftermath of civil wars.
C81|Counting What Counts: Africa’s Seminal Effort to Produce Harmonized Official Statistics on Governance, Peace and Security|(english) The paper documents the practical experience of eleven African national statistical offices that tested and eventually institutionalized a methodology for producing official harmonized statistics in the area of governance, peace and security statistics between 2012 and 2017. This took place whilst the rest of the world was still debating the rationale for including this new domain in the next global development agenda. It situates Africa’s successful GPS-SHaSA experiment in the context of the continent’s long-standing commitment to “achieve political sovereignty through data autonomy”. The paper also presents some strategic advantages of the GPS-SHaSA methodology, provides illustrations using selected targets of Africa’s Agenda 2063 and Sustainable Development Goal (SDG) 16 on how the four types of data generated by the methodology can inform policymaking. It finally concludes by identifying a number of methodological, institutional, financial and communicational investments necessary for GPS statistical production by NSOs to be sustainable, in Africa and beyond. _________________________________ (français) Cet article présente l’expérience concrète des instituts nationaux de la statistique (INS) de onze pays africains qui ont testé en pratique et institutionnalisé une méthodologie harmonisée pour produire des statistiques officielles dans le champ de la gouvernance, la paix et la sécurité (GPS) entre 2012 et 2017. Cette expérience s’est déroulée alors que le reste du monde était encore en train de débattre de la pertinence d’inclure ce nouveau champ thématique comme une composante à part entière de l’agenda global du développement post 2015. Le papier montre comment le succès de l’expérience GPS-SHaSA s’inscrit dans un engagement de longue date de l’Afrique pour « atteindre sa souveraineté politique à travers l’autonomie des données ». Il décrit également les avantages stratégiques de la méthodologie GPS-SHaSA, et offre quelques illustrations tirées de cibles particulières de l’Agenda 2063 de l’Afrique et de l’Objectif du Développement Durable (ODD) 16 pour montrer comment les quatre types de données produites par le projet peuvent informer les politiques publiques et le processus de décision. Il conclut en identifiant un certain nombre de défis méthodologiques, institutionnels, financiers et en termes de communication à relever pour que la production de données GPS par les INS puisse être durable, en Afrique et au-delà.
C81|Dimensions of Quality of Life in Germany: Measured by Plain Text Responses in a Representative Survey (SOEP)|"This paper demonstrates how quality of life can be measured by plain text in a representative survey, the German Socio Economic Panel Study (SOEP). Furthermore, the paper shows that problems that are difficult to monitor, especially problems like the state of the European Union, long-term climate change but also the national debt or problems with the quality of consumer goods (like food) and services (like medical treatment), are not issues of particular importance to the majority of people. Developments and risks that are difficult to monitor and only have long-term effects should be left primarily to the discourse conducted by experts and the politically-minded ""elites"", the avant garde. And in representative democracies it is ultimately the parliamentarians who must decide. Parliamentarians are likely able to make somewhat better decisions using modern representative surveys and national dialogues than they would be without these instruments of civic participation. Nevertheless, improved civic participation cannot replace parliaments."
C81|An integrated approach for top-corrected Ginis|Household survey data provide a rich information set on income, household context and demographic variables, but tend to under-report incomes at the very top of the distribution. Tax record data offer more precise information on top incomes at the expense of household context details and incomes of non-fillers at the bottom of the distribution. We combine the benefits of the two data sources to improve survey-based Gini coefficients in two ways. First, we incorporate top income share estimates based on tax records with survey-based Ginis for the rest of the population following Atkinson (2007) and Alvaredo (2011). Second, we impute top fractile's income in EU-SILC survey data with the Pareto distribution coefficients obtained from tax records and then calculate the Gini coefficient. We find that both approaches produce rather similar results. The gap between unadjusted and top-corrected Ginis is highest in countries that rely exclusively on survey data as compared to purely register or partly register countries.
C81|Worries across Time and Age in Germany: Bringing Together Open- and Close-Ended Questions|We investigate how worries in Germany change across time and age, drawing on both closed-ended questions (which typically list a number of worry items) and open-ended questions answered in text format. We find that relevant world events influence worries. For example, worries about peace peaked in 2003, the year of the Iraq War, with a considerable number of respondents also referring to the Iraq war in their text responses. Furthermore, we found that – controlling for these historical effects – worries about various topics such as health and the general economic situation increase with age. With increasing age, respondents also became more likely to answer the open-ended question. This suggests that the age increases in worries we found are not merely a result of an age-biased choice of worry items, but instead also hold for worries self-generated by the respondents.
C81|Worries across Time and Age in Germany: Bringing Together Open- and Close-Ended Questions|We investigate how worries in Germany change across time and age, drawing on both closed-ended questions (which typically list a number of worry items) and open-ended questions answered in text format. We find that relevant world events influence worries. For example, worries about peace peaked in 2003, the year of the Iraq War, with a considerable number of respondents also referring to the Iraq war in their text responses. Furthermore, we found that – controlling for these historical effects – worries about various topics such as health and the general economic situation increase with age. With increasing age, respondents also became more likely to answer the open-ended question. This suggests that the age increases in worries we found are not merely a result of an age-biased choice of worry items, but instead also hold for worries self-generated by the respondents.
C81|Survey shortcuts? Evidence from a payment diary survey|In this paper we examine the presence of panel conditioning in a payment diary survey studying the payment behavior of Dutch consumers. We analyze whether the reporting behavior of frequent participants in the payment survey systematically differs from that of less-frequent survey participants. We introduce refreshment groups that allow us to compare the reporting behavior of 'trained' and 'fresh' respondents, where the differences between reported values are used as a proxy for the panel conditioning effect. We find no consistent significant differences for the number and value of cash and debit card payments between trained and fresh respondents, for any demographic group, sector or transaction size. Likewise we find no consistent significant differences for the value of cash withdrawals between trained and fresh respondents. However we do find some signs of panel conditioning in the reported number of cash withdrawals
C81|The elasticity of taxable income: A meta-regression analysis|The elasticities of taxable (ETI) and broad income (EBI) are key parameters in optimal tax and welfare analysis. To examine the large variation in estimates found in the literature, I conduct a comprehensive meta-regression analysis of elasticities that measure behavioral responses to income taxation using information from 51 different studies containing 1,420 estimates. I find that heterogeneity in reported estimates is driven by regression techniques, sample restrictions and variations across countries and time. Moreover, I provide descriptive evidence of the correlation between contextual factors and the magnitude of an elasticity estimate. Overall, the study confirms the fact that the ETI itself is endogenous to the underlying tax system. I also document that selective reporting bias is prevalent in the literature. The direction of reporting bias depends on whether or not deductions are included in the tax base.
C81|Optimal Data Collection for Randomized Control Trials|In a randomized control trial, the precision of an average treatment effect estimator can be improved either by collecting data on additional individuals, or by collecting additional covariates that predict the outcome variable. We propose the use of pre-experimental data such as a census, or a household survey, to inform the choice of both the sample size and the covariates to be collected. Our procedure seeks to minimize the resulting average treatment effect estimator's mean squared error, subject to the researcher's budget constraint. We rely on a modification of an orthogonal greedy algorithm that is conceptually simple and easy to implement in the presence of a large number of potential covariates, and does not require any tuning parameters. In two empirical applications, we show that our procedure can lead to substantial gains of up to 58%, measured either in terms of reductions in data collection costs or in terms of improvements in the precision of the treatment effect estimator.
C81|Knowledge spillovers and patent citations: trends in geographic localization, 1976-2015|" This paper examines the trends in geographic localization of knowledge spillovers via patent citations, considering US patents from the period of 1976-2015. Despite accelerating globalization and widespread perception of the ""death of distance,"" our multi-cohort ""matched-sample"" study reveals signi cant and growing localization effects of knowledge spillovers at both intra- and international levels after the 1980s. We also develop a novel network index based on the notion of ""farness,"" which an instrumental variable estimation shows to be a signifi cant and sizable determinant of the observed trends at the state-sector level."
C81|Correcting Measurement Errors in Transition Models Based on Retrospective Panel Data|We propose in this paper a dynamic n-state transition model to correct for measurement error, that could arise for example from recall and/or design bias, in retrospective panels. Our model allows the correction of measurement errors, when very little auxiliary information is available, over a long period of time taking into consideration the conjuncture fluctuations. The technique suggested shows that it is sufficient to have population moments (for at least one point in time) to correct over- or under-reporting biases. Using a Simulated Method of Moments, one can estimate a transition- and time-specific correction matrix for the labor market flows in a biased retrospective panel. Using retrospective and contemporaneous data from Egypt, we estimate the model and show the significance and robustness of our correction. We show through a reform evaluation that neglecting measurement error in the data would have produced significantly different and misleading results.
C81|Dimensions of Quality of Life in Germany: Measured by Plain Text Responses in a Representative Survey (SOEP)|This paper demonstrates how quality of life can be measured by plain text in a representative survey, the German Socio Economic Panel study (SOEP). Furthermore, the paper shows that problems that are difficult to monitor, especially problems like the state of the European Union, long-term climate change but also the national debt or problems with the quality of consumer goods (like food) and services (like medical treatment), are not issues of particular importance to the majority of people. Developments and risks that are difficult to monitor and only have long-term effects should be left primarily to the discourse conducted by experts and the politically-minded “elites”, the avant garde. And in representative democracies it is ultimately the parliamentarians who must decide. Parliamentarians are likely able to make somewhat better decisions using modern representative surveys and national dialogues than they would be without these instruments of civic participation. Nevertheless, improved civic participation cannot replace parliaments. In diesem Beitrag wird gezeigt, dass es heutzutage gut möglich ist, die Wichtigkeitgesellschaftlicher Ziele und dem Stand der Lebensqualität in der Bevölkerung mit Hilfe einesrepräsentativen Surveys (hier: dem Sozio-oekonomischen Panel, SOEP) mit offenen Fragenund Klartextantworten zu erheben und sinnvoll auszuwerten. Dabei zeigt sich, dasslangfristig wichtige, aber zugleich aktuell wenig spürbare Themen wie Klimawandel,Staatsverschuldung oder die Europäische Unionkaum genannt werden. Wir ziehen dieSchlussfolgerung, dass langfristig wirkende Entwicklungen und Gefahren auch weiterhinvorwiegend dem Diskurs der Fachleute und der politisch denkenden „Avantgarde“zugewiesen werden sollten. Undam Ende müssen in einer repräsentativen Demokratie dieParlamente entscheiden. Auf Basis von modernen repräsentativen Erhebungen undBürgerdialogen können Parlamente vermutlich etwas besser entscheiden als ohne dieseInstrumente der Bürgerbeteiligung. Aber auch eine noch so effektive Bürgerbeteiligung kannParlamente nicht ersetzen.
C81|Competition and subsequent risk-taking behaviour: Heterogeneity across gender and outcomes|This paper studies if competition affects subsequent risk-taking behaviour by means of a laboratory experiment that manipulates the degree of competitiveness of the environment under equivalent monetary incentives. We find that competition increases risk aversion, especially for males, but not in a significant manner. When conditioning on the outcome, we find that males become significantly more risk averse after losing the tournament than after randomly earning the same low payoff. In contrast, males do not become more risk-seeking after winning the tournament, while females’ average risk-taking behaviour is unaffected by tournament participation and outcomes. Our findings can be rationalized using the results of the literature on self-serving attribution.
C81|Safe options induce gender differences in risk attitudes|Gender differences in risk attitudes are frequently observed, although recent literature has shown that they are context dependent rather than ubiquitous. In this paper we try to rationalize the heterogeneity of results investigating experimentally whether the presence of a safe option among the set of alternatives explains why females are more risk averse than males. We manipulate three widely used risk elicitation methods finding that the availability of a safe option causally affects risk attitudes. The presence of a riskless alternative does not entirely explain the gender gap but it has a significant effect in triggering or magnifying (when already present) such differences. Despite the pronounced instability that usually characterizes the measurement of risk preferences, we show, estimating a structural model, that the effect of a safe option is remarkably stable accross tasks. This paper constitutes the first successful attempt to shed light on the determinants of gender differences in risk attitudes.
C81|Survey Under-Coverage of Top Incomes and Estimation of Inequality: What is the Role of the UK’s SPI Adjustment?|Survey under-coverage of top incomes leads to bias in survey-based estimates of overall income inequality. Using income tax record data in combination with survey data is a potential approach to address the problem; we consider here the UK’s pioneering ‘SPI adjustment’ method that implements this idea. Since 1992, the principal income distribution series (reported annually in Households Below Average Income) has been based on household survey data in which the incomes of a small number of ‘very rich’ individuals are adjusted using information from ‘very rich’ individuals in personal income tax return data. We explain what the procedure involves, reveal the extent to which it addresses survey under-coverage of top incomes, and show how it affects estimates of overall income inequality. More generally, we assess whether the SPI adjustment is fit for purpose and consider whether variants of it could be employed by other countries.
C81|Using Linked Survey and Administrative Data to Better Measure Income: Implications for Poverty, Program Effectiveness and Holes in the Safety Net|We examine the consequences of underreporting of transfer programs in household survey data for several prototypical analyses of low-income populations. We focus on the Current Population Survey (CPS), the source of official poverty and inequality statistics. We link administrative data for food stamps, TANF, General Assistance, and subsidized housing from New York State to the CPS at the household level. Program receipt in the CPS is missed for over one-third of housing assistance recipients, over 40 percent of food stamp recipients and over 60 percent of TANF and General Assistance recipients. Dollars of benefits are also undercounted for reporting recipients, particularly for TANF, General Assistance and housing benefits. We find that the survey sharply understates the income of poor households. Underreporting in the survey data also greatly understates the effects of anti-poverty programs and changes our understanding of program targeting, often making it seem that welfare programs are less targeted to both the very poorest and middle-income households than they are. Using the combined data rather than survey data alone, the poverty reducing effect of all programs together is nearly doubled while the effect of housing assistance is tripled. We also re-examine the coverage of the safety net, specifically the share of people without work or program receipt. Using the administrative measures of program receipt rather than the survey ones often reduces the share of single mothers falling through the safety net by one-half or more.
C81|Comparing retrospective and panel data collection methods to assess labor market dynamics|Abstract There is potential for measurement problems in both retrospective and panel microdata. In this paper, we compare results on basic indicators related to labor markets and their dynamics from retrospective and panel survey data in Egypt, in order to determine the conditions under which results are similar or different. Specifically, we (1) assess the consistency of reporting of time-invariant characteristics in different waves of the panel, (2) compare the retrospective and panel data results on past labor market statuses, (3) assess the consistency of estimates of labor market transition rates across two specific dates by comparing panel and retrospective data, (4) assess the consistency of estimates of the level and trends of annual labor market transition rates across retrospective data from different waves of the survey, and (5) assess whether retrospective data can provide accurate trends of labor market aggregates, such as unemployment rates. We find that it is possible to garner useful information on labor market dynamics from retrospective data, but one must be cautious about which information to trust and at what level of detail. We conclude with a discussion of implications for future research as well as future survey design. JEL Classification: C83, C81, J01, J62, J64
C81|Microdata for Social Sciences and Policy Evaluation as a Public Good|The balance between the right to privacy and the right to freedom of information is altered when scientific research comes into play, because of its inherent needs and societal function. This paper argues that, for research purposes, microdata should be characterised as a public good. The evolution of the rules and practices in the European Union (EU) for protecting confidentiality while allowing access to microdata for research purposes is reviewed. Two key directions are identified for further improvement: remote access to confidential data and the enlargement of the notion of 'European statistics' to include microdata produced for evaluating interventions (co)financed by the EU.
C81|Do the rich save more in Latin America?|Abstract This paper reports evidence that the savings rate of the rich is higher than that of the poor in Brazil, Chile, Costa Rica, Ecuador, Honduras, Mexico, Panama, Paraguay and Peru. On average, the difference between the fifth and fourth income quintile groups is 7 percentage points. No differences between income groups are found in Uruguay and the results for Argentina and Colombia are not robust to estimation alternatives. The key methodological step is to construct a measure of lifetime income. Current income is not a good proxy since it is affected by phases of the life cycle and transitory shocks. We implement a two-stage procedure based on the education level of the household head and the education level of his/her partner. Several robustness exercises are reported for different age groups, inclusion/exclusion of outliers and for a wealth index based on homeownership, home appliances and other household owned assets.
C81|Do the rich save more in Latin America?|Abstract This paper reports evidence that the savings rate of the rich is higher than that of the poor in Brazil, Chile, Costa Rica, Ecuador, Honduras, Mexico, Panama, Paraguay and Peru. On average, the difference between the fifth and fourth income quintile groups is 7 percentage points. No differences between income groups are found in Uruguay and the results for Argentina and Colombia are not robust to estimation alternatives. The key methodological step is to construct a measure of lifetime income. Current income is not a good proxy since it is affected by phases of the life cycle and transitory shocks. We implement a two-stage procedure based on the education level of the household head and the education level of his/her partner. Several robustness exercises are reported for different age groups, inclusion/exclusion of outliers and for a wealth index based on homeownership, home appliances and other household owned assets.
C81|What do firms know? What do they produce? A new look at the relationship between patenting profiles and patterns of product diversification|Abstract In this work, we analyze the relationship between the patterns of firm diversification, if any, across product lines and across bodies of innovative knowledge, proxied by the patent classes where the firm is present. Putting it more emphatically, we investigate the relationship between “what a firm does” and “what a firm knows.” Using a newly developed dataset matching information on patents and products at the firm level, we provide evidence concerning firms’ technological and product scope, their relationships, the size-scaling and coherence properties of diversification itself. Our analysis shows that typically firms are much more diversified in terms of products than in terms of technologies, with their main products more related to the exploitation of their innovative knowledge. The scaling properties show that the number of products and technologies increases log-linearly with firm size. And the directions of diversification themselves display coherence between neighboring activities also at relatively high degrees of diversification. These findings are well in tune with a capability-based theory of the firm.
