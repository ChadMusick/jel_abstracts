C80|Cross-sectional noise reduction and more efficient estimation of Integrated Variance|In this paper we propose a straightforward approach to obtain a more efficient estimate of the integrated variance of an asset through a cross-sectional combination with a futures contract written on it. Our method constructs a variance-preserving series with reduced noise size as a linear combination of the underlying asset and the futures and base measurement of the integrated variance on this new series. We first illustrate how a theoretically but infeasible optimal series can be obtained and then suggest a feasible procedure to attain noise reduction. In a simulation study we verify how prevalent estimators of integrated variance applied to such noise-reduced series outperform estimators applied directly to the asset price. Finally, we apply the method to an empirical data set and, through the stabilized signature plot, we show how the noise reduced series provides consistent integrated variance estimates using naive realized measures at very high frequencies.
C80|Online Job Seekers in Canada: What Can We Learn from Bing Job Queries?|Labour markets in Canada and around the world are evolving rapidly with the digital economy. Traditional data are adapting gradually but are not yet able to provide timely information on this evolution.
C80|Mitigating misleading implications for policy: Treatment of outliers in a difference-indifferences framework|Applications of the difference-in-differences estimator in economics, banking and finance, and management commonly treat outliers using the winsorize method. However, failure to winsorize outliers in both the treatment and controls groups introduces volatility in estimated coefficients, significance levels, and standard errors. A faulty process can lead to an exogenous event realising a significant effect that proper process would fail to detect. In demonstration, we randomly generate placebo interventions in bank-level data and discuss how to detect and limit the problem.
C80|Text Mining for Economic Analysis (in Korean)|We provide detailed description of how text data analysis is done and review series of studies done through text mining. Natural language can be characterized with ambiguity and obscurity compared to structured data. It is hard to retrieve useful information from text data as it carries natural language itself. Text mining or natural language processing is a multi-discipline area of modern technic in which we can distill and obtain just what we need from text. With the development of AI and machine learning, text mining is becoming one of the high-end technology in various fields of research even in economics. We expect there will be more demand for text data analysis as it will be complementary to traditional structured data and also as a new source of information.
C80|Spillovers and Exports: A Meta-Analysis|This study uses meta-analysis to analyze the empirical literature on spillovers and exports. It collects 3,291 estimated spillover effects from 99 studies. The estimated spillover effects in the literature span a large number of types and measures of both exports and spillovers. As a result, we transform estimates to partial correlation coefficients (PCCs). We analyze these transformed effects using four different versions of Weighted Least Squares estimators, incorporating both meta-analytic “Fixed Effects” and “Random Effects”. Our analysis produces three main findings. First, while we estimate a mean overall effect of spillovers on exports that is statistically significant, the size of the effect is economically negligible. Second, we find evidence of positive publication bias using conventional Funnel Asymmetry Tests. However, the size of the estimated publication bias is small, and disappears in some regressions when other explanatory variables are included in the analysis. Third, using both Bayesian Model Averaging and frequentist WLS estimation, we find that some data, estimation, and study characteristics are significant in some regressions. However, only a few of the characteristics are robust, and none are large in size.
C80|Why the Economics Profession Must Actively Participate in the Privacy Protection Debate|When Google or the US Census Bureau publishes detailed statistics on browsing habits or neighborhood characteristics, some privacy is lost for everybody while supplying public information. To date, economists have not focused on the privacy loss inherent in data publication. In their stead, these issues have been advanced almost exclusively by computer scientists who are primarily interested in technical problems associated with protecting privacy. Economists should join the discussion, first to determine where to balance privacy protection against data quality—a social choice problem. Furthermore, economists must ensure new privacy models preserve the validity of public data for economic research.
C80|Policy Uncertainty and Information Flows: Evidence from Pension Reform Expectations|Subjective expectations about future policy play an important role in individuals’ welfare. We examine how workers’ expectations about pension reform vary with proximity to reforms, information cost, and aggregate information acquisition. We construct a new pan-European dataset of reform implementations and government announcements, and combine it with individual-level representative survey data on expectations about future reforms and country-level data on online search. We find: (1) Expectations are revised upward by about 10 percentage points in the year leading up to a reform, from a median of 50%, regardless of whether the reform is announced; (2) Aggregate online search increases after announcements, when the cost of information is lower; (3) Reform announcements and online information gathering are substitutes in the formation of expectations; (4) Expectations do not converge as a result of announcements or implementations; (5) The effect of information on expectations varies substantially across workers and systematically with observed characteristics that proxy cognitive ability and information value. These findings, interpreted using a model of rational inattention, reveal substantial informational rigidities, with welfare costs that run into trillions of Euros.
C80|Partage de la rente et progressivité des régimes fiscaux dans le secteur minier : une analyse sur 21 pays africains producteurs d’or|Dans le secteur minier, les Etats doivent être en mesure de concilier deux objectifs : attirer les investissements directs étrangers pour exploiter la ressource et capter une part suffisante de la rente minière pour financer le développement. Cette problématique est connue depuis longtemps et pose certes la question de la répartition de la rente minière entre les acteurs mais devrait aussi mettre en évidence l’importance de la progressivité des régimes fiscaux. Une fiscalité progressive est un, sinon le critère principal qui pourrait rassurer de façon durable les investisseurs et garantir à l’Etat de capter une part « juste » de la rente générée par le secteur. Alors que plusieurs études différencient les instruments fiscaux selon leurs effets économiques, aucune ne cherchent à évaluer la capacité des régimes miniers africains à adapter la charge fiscale supportée par l’investisseur à la rentabilité des projets. La base de données fiscales mise à disposition par la Ferdi[1], en partenariat avec le CERDI et l’ICTD, recense les 12 principaux impôts, droits et taxes qui s’appliquent selon la législation aux entreprises industrielles dans le secteur de l’or de 1980 à nos jours dans 21 pays africains. Appliquer aux données économiques de mines représentatives africaines, cette base de données donne les moyens aux chercheurs et analystes de construire des indicateurs permettant d’identifier les régimes fiscaux les plus à même de réconcilier les acteurs du secteur, tout en tenant compte de leur complexité. Les résultats de notre analyse montrent 1) que la part de la rente minière perçue par les Etats est très hétérogène entre les pays, et 2) que les « innovations » en termes de conception de l’impôt, n’ont fait qu’atténuer, dans le meilleur des cas, la régressivité des régimes fiscaux. [1] https://fiscalite-miniere.ferdi.fr.
C80|Partage de la rente et progressivité des régimes fiscaux dans le secteur minier : une analyse sur 21 pays africains producteurs d’or|Dans le secteur minier, les Etats doivent être en mesure de concilier deux objectifs : attirer les investissements directs étrangers pour exploiter la ressource et capter une part suffisante de la rente minière pour financer le développement. Cette problématique est connue depuis longtemps et pose certes la question de la répartition de la rente minière entre les acteurs mais devrait aussi mettre en évidence l’importance de la progressivité des régimes fiscaux. Une fiscalité progressive est un, sinon le critère principal qui pourrait rassurer de façon durable les investisseurs et garantir à l’Etat de capter une part « juste » de la rente générée par le secteur. Alors que plusieurs études différencient les instruments fiscaux selon leurs effets économiques, aucune ne cherchent à évaluer la capacité des régimes miniers africains à adapter la charge fiscale supportée par l’investisseur à la rentabilité des projets. La base de données fiscales mise à disposition par la Ferdi[1], en partenariat avec le CERDI et l’ICTD, recense les 12 principaux impôts, droits et taxes qui s’appliquent selon la législation aux entreprises industrielles dans le secteur de l’or de 1980 à nos jours dans 21 pays africains. Appliquer aux données économiques de mines représentatives africaines, cette base de données donne les moyens aux chercheurs et analystes de construire des indicateurs permettant d’identifier les régimes fiscaux les plus à même de réconcilier les acteurs du secteur, tout en tenant compte de leur complexité. Les résultats de notre analyse montrent 1) que la part de la rente minière perçue par les Etats est très hétérogène entre les pays, et 2) que les « innovations » en termes de conception de l’impôt, n’ont fait qu’atténuer, dans le meilleur des cas, la régressivité des régimes fiscaux. [1] https://fiscalite-miniere.ferdi.fr.
C80|Speaking for Herself: Changing Gender Roles in Survey Response|Among married and cohabiting couples, the percentage of female respondents has increased substantially in the PSID (Panel Study of Income Dynamics) from 9% in 1968 to 60% in 2015. This shift in gender composition has taken place despite a formal policy that historically designated male heads of household as respondents. We use this shift as a case study to explore which characteristics are associated with women responding to the PSID and how different respondent gender compositions may affect data quality. First, we find that women are increasingly less likely to respond as their husband’s income increases or if their husband is highly educated. Women are more likely to respond if they are more educated than their husband. {{p}} Second, we find that male respondents tend to report incomes about $5,000 higher than female respondents. Had the gender composition of respondents been closer to 50/50, average household income would have been reduced by as much as $2,500. Our research provides important insights into the quality of survey data and the changing role of women in households.
C80|Sources and Types of Big Data for Macroeconomic Forecasting|This chapter considers the types of Big Data that have proven useful for macroeconomic forecasting. It first presents the various definitions of Big Data, proposing one we believe is most useful for forecasting. The literature on both the opportunities and challenges of Big Data are presented. It then proposes a taxonomy of the types of Big Data: 1) Financial Market Data; 2) E-Commerce and Credit Cards; 3) Mobile Phones; 4) Search; 5) Social Media Data; 6) Textual Data; 7) Sensors, and The Internet of Things; 8) Transportation Data; 9) Other Administrative Data. Noteworthy studies are described throughout.
C80|Towards an Institutional Interpretation of TFP Changes in China|This research note reiterates the productivity theory in the Solow growth accounting framework to explore an institutional interpretation of changes in total factor productivity. In theory, total factor productivity or TFP growth is a costless gain in output, which captures the effect of positive externalities caused by spillovers of technological and organizational changes in a perfect market system. This provides a yardstick to gauge institutional effect on output in an imperfect market system if all inputs are properly measured. Using the Chinese case, I show that an integrated approach a la Jorgenson and Griliches (1967) that ensures a consistency between theory, methodology and measurement can facilitate empirical exercises even with data problems, and a so-constructed TFP index for China can satisfactorily reproduce China's post-reform productivity path with institutional interpretations.
C80|The 2011 Break in the Part-Time Indicator and the Evolution of Wage Inequality in Germany|German social security records involve an indicator for part-time or full-time work. In 2011, the reporting procedure was changed suggesting that a fraction of worker recorded to be working full-time before the change were in fact part-time workers. This study develops a correction based on estimating the probability of being a part-time worker before and after the break. Using the correction, the paper confirms that the rise in wage inequality among full-time workers in West Germany until 2010 is not a spurious consequence of the misreporting of working time.
C80|Earth Observation in a Cost-Benefit Analysis Perspective: Cosmo SkyMed Satellites of the Italian Space Agency|Over the past decade, an increasing number of high-resolution satellite images have become available to public administration, policymakers and scientists, boosting the amount of information they can obtain to manage and analyse different issues. Satellites allow observing different natural and socio-economic phenomena that would be very hard and costly to monitor from the ground with the same optimal coverage, accuracy and consistency, providing valuable information both to the private and public sector. These phenomena include global societal challenges, such as climate change and air pollution, as well as local ones such as precision farming, urbanisation and transport infrastructures monitoring. This working paper aims at paving the way to a comprehensive assessment of the socio-economic impact of the Italian Space Agency (ASI) concerning the creation of innovative products and services generated by the Earth Observation (EO). Although the wide range of potential applications of EO satellite data, little is known about the effective use of Cosmo SkyMed (CSK) data so far. Most of the benefits related to their availability remain potential, unexpressed and undervalued. The analysis also intends to identify the institutional and organisational barriers that limit their full exploitation and formulate sounds policy recommendations to release the untapped potential of the Italian space downstream sector.
C80|Classifying small (TL3) regions based on metropolitan population, low density and remoteness|This paper provides a method to classify TL3regions across OECD countries based on their level of access to metropolitan areas. TL3 regions are classified as ‘metropolitan’ if more than half of their population lives in one or more functional urban area (FUA) of at least 250 thousand inhabitants and as ‘non-metropolitan’ otherwise. The method sub-classifies metropolitan regions into ‘large metro’ or ‘metro’ regions based on the population size of the FUAs located within those regions. Non-metropolitan TL3 regions are sub-classified into: with accessto a metro, with access to a small/medium city, or remote based on their level of access to a FUA with population above a predetermined threshold. The method relies on publicly available grid-level population data and localised information on driving conditions.
C80|Resolutions to flip-over credit risk and beyond|Abstract Given a risk outcome y over a rating system {R_i }_(i=1)^k for a portfolio, we show in this paper that the maximum likelihood estimates with monotonic constraints, when y is binary (the Bernoulli likelihood) or takes values in the interval 0≤y≤1 (the quasi-Bernoulli likelihood), are each given by the average of the observed outcomes for some consecutive rating indexes. These estimates are in average equal to the sample average risk over the portfolio and coincide with the estimates by least squares with the same monotonic constraints. These results are the exact solution of the corresponding constrained optimization. A non-parametric algorithm for the exact solution is proposed. For the least squares estimates, this algorithm is compared with “pool adjacent violators” algorithm for isotonic regression. The proposed approaches provide a resolution to flip-over credit risk and a tool to determine the fair risk scales over a rating system.
C80|FDI Statistics and International Production: Towards (Re-) Conciliation?|"In a highly complex global production landscape, the quest for sound statistics to measure the international activity of multinational enterprises (MNEs) has become ever more pressing, and challenging at the same time. Rationales for the use of FDI statistics from Balance of Payments, traditionally the main indicators of international production, seem to have weakened as boundaries between ""real"" and financial investment are becoming increasingly blurry. The purpose of this paper is to critically revisit the main objections to the use of FDI statistics to describe international production, and the possible counter-arguments and mitigating factors. Such balanced approach is aimed at providing concrete indications on the best analytical use of FDI statistics to measure international production."
C80|Adaptive Analytical Approach to Lean and Green Operations|Recent problems faced by industrial players commonly relates to global warming and depletion of resources. This situation highlights the importance of improvement solutions for industrial operations and environmental performances. Based on interviews and literature studies, manpower, machine, material, money and environment are known as the foundation resources to fulfil the facility's operation. The most critical and common challenge that is being faced by the industrialists is to perform continuous improvement effectively. The needs to develop a systematic framework to assist and guide the industrialist to achieve lean and green is growing rapidly. In this paper, a novel development of an adaptive analytic model for lean and green operation and processing is presented. The development of lean and green index will act as a benchmarking tool for the industrialist. This work uses the analytic hierarchy process to obtain experts opinion in determining the priority of the lean and green components and indicators. The application of backpropagation optimisation method will further enhance the lean and green model in guiding the industrialist for continuous improvement. An actual industry case study (combine heat and power plant) will be presented with the proposed lean and green model. The model is expected to enhance processing plant performance in a systematic lean and green manner.
C80|Women’s Asset Ownership: Evidence from Georgia; Mongolia; and Cavite, Philippines|Since the implementation of the Millennium Development Goals, significant global progress has been achieved in promoting gender equality in education and health. However, progress has not been as remarkable in advancing women’s rights on asset ownership and control, which is critical for securing gender equity in economic participation and opportunity, and delivering on the Sustainable Development Goals. Part of the problem comes from the lack of standards on collecting sexdisaggregated data on the topic. The Evidence and Data for Gender Equality (EDGE) initiative aims to develop standardized methods and guidelines for collecting sex-disaggregated data on asset ownership. This paper provides rich inputs to the methodological guidelines being developed by the United Nations and development partners by drawing on the key findings from the pilot surveys conducted in Georgia; Mongolia; and Cavite, Philippines. Furthermore, survey results suggest substantive gender gaps in ownership across different types of assets and countries. These variations confirm the importance of understanding the social norms governing gender roles in society and legislation that can facilitate or impede women’s asset ownership.
C80|Estimation and Forecasting of Industrial Production Index|It is essential for policy makers to timely consider the cyclical changes in output. Monthly industrial production is one of the most important and commonly used macroeconomic indicators for this purpose. In Pakistan monthly estimates of industrial production are not available. Alternatively, policy makers rely on Large Scale Manufacturing (LSM) index which accounts for only 10% of the GDP. Another limitation of LSM is that it mainly accounts for private sector industry thus leaving out direct public sector presence in industrial production. LSM is relied upon heavily by economic policy makers to gauge economic activity in Pakistan. In this paper, we present a new Industrial Production Index (IPI), which covers whole of industrial sector in Pakistan. The advantage of this IPI index is that it provides additional information that LSM misses out. Post estimation, we built seven econometrics models reflecting conditions in real, financial and external sectors to estimate YoY changes in the proposed Instrial Production Index (IPI). Our results show that the root mean square error of the ARDL model reflecting financial conditions is lowest across all horizons
C80|Improving interoperability in Healthcare using Hl7 FHIR|Data sharing within patients, hospitals and medical centers and the diversity of healthcare data still remain one of the main challenges in Albania. Exchanging health information is crucial because it can improve treatment, health care and decision-making process. FHIR (Fast Healthcare Interoperability Resources) is used as a standard for exchanging healthcare information in HL7 (Health Level 7). FHIR is based on the RESTful principles, so the resources can be accessed using HTTP and displayed in XML or JSON format. The aim of this paper is to analyse the use of FHIR standard in improving interoperability and integration of patient?s data between different hospital services and radiology service in Albania.
C80|Quantification of feedback effects in FX options markets|We model the feedback effect of delta hedging for the spot market volatility of the forex market (dollar-yen and dollar-euro) using an economy of two types of traders, an option market maker (OMM) and an option market taker (OMT), whose exposures reflect the total outstanding positions of all option traders in the market. A different hedge ratio of the OMM and OMT leads to a net delta hedge activity that introduces market friction and feedback effects. This friction is represented by a simple linear permanent impact model for the net delta hedge volumes that are executed in the spot market. This approach allows us to derive the dependence of the spot market volatility on the gamma exposure of the trader that hedges a larger share of her delta exposure and on the market impact of the delta hedge transactions. We reconstruct the aggregated OMM's gamma exposure by using publicly available DTCC trade repository data and find that it is negative, as expected: the OMT usually buys options with either a view on the spot price or with the desire to hedge other positions and, thus, is net long on options. As the OMM provides liquidity as a service to the market, their position is reversed compared with the OMT. Our regressions show a high goodness of fit, a highly significant parameter for the gamma exposure of the OMM and, as expected, that the volatility is increased by the OMM's short gamma exposure. Quantitatively, a negative gamma exposure of the OMM of approximately -1000 billion USD (which is around what we observe from our reconstructed OMM data) leads to an absolute increase in volatility of 0.7% in EURUSD and 0.9% in USDJPY. If we assume that the hedge ratios in the two markets are the same, the difference can be directly explained by the higher market impact of a transaction in the USDJPY spot market compared to the EURUSD spot market, as the liquidity of the EURUSD spot market is higher than that of the USDJPY spot market. Our results are in line with and empirically confirm previous theoretical work on the feedback effect of delta hedging strategies on spot market volatility.
C80|Sustainability and Wellbeing: A Text Analysis of New Zealand Parliamentary Debates, Official Yearbooks and Ministerial Documents|Recent advances in natural language processing and semantic analysis methods are enabling scholars to analyse text extensively. These techniques have not only minimized the margins of error arising from missing data from a traditionally conducted discourse analysis but also permitted reproducibility of research results. In this paper, we use several text analysis methods to analyse the evolution of the terms ‘sustainability’ and ‘wellbeing’ (SaW) from parliamentary debates (Hansard), New Zealand Official Yearbooks (NZOYBs) and ministerial documents over 125 years. The term ‘welfare’ has existed in the NZOYBs and Hansard text since the start of our analysis (1893), with a steadily increasing trend until the mid-1980s. The term ‘wellbeing’ gained momentum in mid-1930s and has been linked strongly with ‘sustainability’ in the following decades. Our analysis re-emphasizes the importance of the Brundtland Report (‘Our Common Future’) which acted as a catalyst to the sustainable movement in late 1980s. ‘Sustainability’ and ‘wellbeing’ then began to appear in conjunction. Our analysis includes the finding that SaW differ significantly when political parties are considered.
C80|Predicting free-riding in a public goods game: Analysis of content and dynamic facial expressions in face-to-face communication|This paper illustrates how audio-visual data from pre-play face-to-face communication can be used to identify groups which contain free-riders in a public goods experiment. It focuses on two channels over which face-to-face communication influences contributions to a public good. Firstly, the contents of the face-to-face communication are investigated by categorising specific strategic information and using simple meta-data. Secondly, a machine-learning approach to analyse facial expressions of the subjects during their communications is implemented. These approaches constitute the first of their kind, analysing content and facial expressions in face-to-face communication aiming to predict the behaviour of the subjects in a public goods game. The analysis shows that verbally mentioning to fully contribute to the public good until the very end and communicating through facial clues reduce the commonly observed end-game behaviour. The length of the face-to-face communication quantified in number of words is further a good measure to predict cooperation behaviour towards the end of the game. The obtained findings provide first insights how a priori available information can be utilised to predict free-riding behaviour in public goods games.
C80|The 2011 break in the part-time indicator and the evolution of wage inequality in Germany|German social security records involve an indicator for part-time or full-time work. In 2011, the reporting procedure was changed suggesting that a fraction of worker recorded to be working full-time before the change were in fact part-time workers. This study develops a correction based on estimating the probability of being a part-time worker before and after the break. Using the correction, the paper confirms that the rise in wage inequality among full-time workers in West Germany until 2010 is not a spurious consequence of the misreporting of working time.
C80|Econometric Perspectives on Economic Measurement|It turns out that price index functions share a basic interpretation; practically all of them measure a change in some average of quality-adjusted prices. The different options are distinguished by their choice of average, their definition of quality, and their stance on what I label 'equal interest'. This new perspective updates the so-called stochastic approach to choosing index functions. It also offers new avenues to understand and tackle measurement problems. I discuss three examples.
C80|Improve Naïve Bayesian Classifier by Using Genetic Algorithm for Arabic Document|Automatic text categorization (TC) has become one of the most interesting fields for researchers in data mining, information retrieval, web text mining, as well as natural language processing paradigms due to the vast number of new documents being retrieved for various information retrieval systems. This paper proposes a new TC technique, which classifies Arabic language text documents using the naïve Bayesian classifier attached to a genetic algorithm, model; this algorithm classifies documents by generating a random sample of chromosomes that represent documents in the corpus. The developed model aims to enhance the work of naïve Bayesian classifier through applying the genetic algorithm model. Experiment results show that the precision and recall are increased when testing higher number of documents; the precision was ranged from 0.8 to 0.97 for different testing environment; the number of genes that is placed in every chromosome is also tested and experiments show that the best value for the number of genes is 50 genes
C80|Methods and Algorithms of Speech Signals Processing and Compression and Their Implementation in Computer Systems|The review and comparative analysis of the methods of compression and recognition of speech signals is carried out. The result of the carried out analysis of the existing recognition methods indicates, that all of them are based on the use of ?inflexible? algorithms, which are badly adapted to the characteristic features of speech signals, thus degrading the efficiency of the operation of the whole recognition system. The necessity of the use of algorithms for determination of recognition features along with the use of the wavelet packet analysis as one of the advanced directions of the creation of the effective methods and principles of the development of the speech signals recognition systems is substantiated.Analysis of the compression methods with the use of the orthogonal transformations at the complete exception of minimal decomposition factors is conducted; a maximal possible compression degree is defined. In this compression method the orthogonal transformation of the signal segment with the subsequent exception of the set of the smallest modulo decomposition factors, irrespective of the order of their distribution, is conducted. Therefore the additional transfer of the information on the factors distribution is required. As a result, two information streams appear, the first one corresponds to the information stream on the decomposition factors, and the second stream transfers information on the distribution of these factors.Method of the determination of the speech signals recognition features and the algorithm for nonlinear time normalization is proposed and proved.Wavelet-packet transformation is adaptive, i.e. it allows adapting to the signal features more accurately by means of the choice of the proper tree of the optimal decomposition form, which provides the minimal number of wavelet factors at the prescribed accuracy of signal reconstruction, thus eliminating the information-surplus and unnecessary details of the signals.
C80|A Bibliometric Analysis of the Energy and Fuel Research Field Based on Science Mapping|This article investigates the conceptual evolution of qualitative research in the field of energy and fuel focus on oil and gas research from 1990 to 2018 identifying the main topics and practical applications which it has been used. The automatic approach was based on a co-word analysis and combines performance analysis and science mapping. The considerable number of studies published according to the journals in energy and fuel field focus on oil and gas research indexed in ISI Web of Science makes it possible to undertake a conceptual analysis of how the field has evolved. To observe the conceptual evolution of energy and fuel, we define three consecutive periods: 1990-2000, 2001-2008, 2009-2018. The results show that energy and fuel focus on oil and gas research are distributed in ten main theoretical areas: VEGETABLE-OILS, BIO-OIL, OIL, DIESEL-FUEL, PERFORMANCE, BIO-DIESEL, BIOMASS, CRUDE-OIL, RENEWABLE-ENERGY, SHALE. The research output could be used by the scientific community to identify thematic areas and to know the evolution of the energy and fuel field.
C80|Breaking Audio Captchas for IRCTC Booking Automization|CAPTCHAs are computer generated tests in the form of images, audios and object recognition that world can communicate easily and computer systems cannot. Internet sites present users with captchas to set apart human users from false computer programs, often referred to as bots. Their purpose is to obstruct attackers from performing automatic registration, online polling and other such actions. IRCTC, being the website to reserve tickets for Indian railways, one of the biggest railway network, has also employed both image and audio captchas for security purposes. However, the audio captchas used on the website are not effective in distinguishing between humans and bots. Most of the visual CAPTCHAs and some audio CAPTCHAs on different websites have been cracked using various methods of machine learning and we propound an identical idea to examine the security of audio CAPTCHAs on IRCTC website. In this paper, we show that our bot is able to break the IRCTC audio captchas with a success rate of 98%, 96.04% and 80.3% using three different models. Along with breaking the captcha, another python script written by us was able to automate the process of ticket booking. Thus, combining all of it into a single package could result in a system which would login and reserve tickets only by a single click. Travel brokers can easily use such a system for easy and fast booking of tatkal tickets which would lead to commercializing this activity for deriving huge profit from needy travelers.
C80|Classifying Firms with Text Mining|Statistics on the births, deaths and survival rates of firms are crucial pieces of information, as they enter as an input in the computation of GDP, the identification of each sectorâ€™s contribution to the economy, and the assessment of gross job creation and destruction rates. Official statistics on firm demography are made available only several months after data collection and storage, however. Furthermore, unprocessed and untimely administrative data can lead to a misrepresentation of the life-cycle stage of a firm. In this paper we implement an automated version of Eurostatâ€™s algorithm aimed at distinguishing true startup endeavors from the resurrection of pre-existing but apparently defunct firms. The potential gains from combining machine learning, natural language processing and econometric tools for pre- processing and analyzing granular data are exposed, and a machine learning method predicting reactivations of deceptively dead firms is proposed.
C80|Decomposing the Redistributive Effect of Taxation to Reveal Axiom Violations|"In this paper we propose two alternative strategies in order to decompose the redistributive effect of the personal income tax in the portion due to deductions, marginal tax rates and tax credits. The first one, inspired by the analysis by Lambert (2001), Pfahler (1990) and Onrubia et al. (2014), is a stepwise or ""ex ante"" decomposition, whilst the second strategy, inspired by the works by Podder (1993a,b) and Podder and Chatterjee (2002), is an overall and simultaneous or ""ex post"" decomposition. The value added of our approaches is twofold: they are very simple and intuitive, and, moreover, both of them allow to quantify the Axiom violations, as proposed by Kakwani and Lambert (1998), for each part in which the redistributive effect can be decomposed. We take Italy as a case study."
C80|Cliometrics|"Cliometrics has been defined and summarized in numerous scholarly articles. They all pretty much start with the obvious, that cliometrics is the application of economic theory and quantitative techniques to study history; and then move on to the origin of the name, the joining of Clio (the muse of history), with metrics (""to measure,"" or ""the art of measurement""), allegedly coined by economist Stanley Reiter while collaborating with economic historians Lance Davis and Jonathan Hughes.<br><small>(This abstract was borrowed from another version of this item.)</small>"
C80|Learning outside the factory: the impact of technological change on the rise of adult education in nineteenth-century France|The paper provides an empirical examination of the effect of the use of steam engine technology on the development of adult education in nineteenth-century France. In particular, we exploit exogenous regional variations in the distribution of steam engines across France to evidence that technological change significantly contributed to the development of lifelong training during the 1850-1881 period. Our research shows that steam technology adoption in France was not deskilling. We argue that this process raised the demand for new skills adapted to the development of French industries.<br><small>(This abstract was borrowed from another version of this item.)</small>
C80|Coexistence of Symmetry Properties for Bayesian Confirmation Measures|"Many Bayesian Confirmation Measures have been proposed so far. They are used to assess the degree to which an evidence (or premise) E supports or contradicts an hypothesis (or conclusion) H, making use of prior probability P(H), posterior probability P(H|E) and of probability of evidence P(E). Many kinds of comparisons of those measures have already been made. Here we focus on symmetry properties of confirmation measures, which are partly inspired by classical geometric symmetries. We define symmetries relating them to the dihedral group of symmetries of the square, determining the symmetries that can coexist and reconsidering desirable/undesirable symmetry properties for a Bayesian Confirmation Measure."
C80|Testing for the Conditional Geometric Mixture Distribution|This study examines the mixture hypothesis of conditional geometric distributions using a likelihood ratio (LR) test statistic based on that used for unconditional geometric distributions. As such, we derive the null limit distribution of the LR test statistic and examine its power performance. In addition, we examine the interrelationship between the LR test statistics used to test the geometric and exponential mixture hypotheses. We also examine the performance of the LR test statistics under various conditions and confirm the main claims of the study using Monte Carlo simulations.
C80|Theory and Practice of Testing for a Single Structural Break in Stata|The major objective of this paper is to demonstrate, theoretically and empirically, the test of a single structural break/change. Failure to address a structural break can lead to forecasting errors and the general unreliability of a model. Three approaches of testing for structural change are discussed using data from Johnston et al. (1997, p.130) on Stata 14 software. The first approach assesses whether there is a structural break in parameters (slope and intercept) while the second and third assess whether there is a break in slope and intercept respectively. The Residual Sum of Squares (RSS) for the restricted and unrestricted models are established to necessitate the use of an F-test in making inferences. According to the first approach, a structural break exists at 5% level of significance. This result is confirmed by the Chow test. The second and third approaches establish that the structural break is from the intercept and not the slope. These results are also affirmed by the Chow test. Furthermore, all these results, from the first to the third approach, are confirmed by an alternative approach which relies on the knowledge that . Therefore, the dependent variable is not affected by the policy change on the explanatory variable but it is mainly affected by the basic unobserved qualitative characteristics of the two sub-periods. For further analysis, it is recommended that a unit root test be conducted using the Zivot-Andrews test. This test has been established as the panacea for the interplay between unit root and structural changes.
C80|Mögliche Auswirkungen eines harten oder weichen Brexit auf die deutsche Landwirtschaft - Update| The United Kingdom (UK) is an important destination for German agri-food products. This becomes especially apparent when looking at the German-UK trade balance of agricultural products, where Germany had a surplus of 3.1 Billion € in 2016. Furthermore, the UK is the trade partner where Germany exhibits the largest trade surplus. Those facts already suggest that Germany is likely to be affected by a changing trade environment following Brexit. In this working paper we are considering a soft Brexit scenario where we assume a deep and comprehensive free trade agreement and a more protective hard Brexit scenario with reciprocal imposition of MFN tariffs between EU and UK. The model results suggest that the decline in production value of German agri-food products amounts 400 Million € in the soft Brexit scenario and is three times larger in the hard Brexit scenario.
C80|Some (Maybe) Unpleasant Arithmetic in Minimum Wage Evaluations: The Role of Power, Significance and Sample Size|In this paper, we discuss the importance of sample size in the evaluation of minimum wage effects. We first show which sample sizes are necessary to make reliable statements about the effects of minimum wages on binary outcomes, and second how to determine these sample sizes. This is particularly important when interpreting statistically insignificant effects, which could be due to (i) the absence of a true effect or (ii) lack of statistical power, which makes it impossible to detect an effect even though it exists. We illustrate this for the analysis of labour market transitions using two data sets which are particularly important in the minimum wage research for Germany, the Integrated Labour Market Biographies (IEB) and the Socio-Economic Panel (SOEP).
C80|Cliometrics|"Cliometrics has been defined and summarized in numerous scholarly articles. They all pretty much start with the obvious, that cliometrics is the application of economic theory and quantitative techniques to study history; and then move on to the origin of the name, the joining of Clio (the muse of history), with metrics (""to measure,"" or ""the art of measurement""), allegedly coined by economist Stanley Reiter while collaborating with economic historians Lance Davis and Jonathan Hughes."
C80|Learning outside the factory: the impact of technological change on the rise of adult education in nineteenth-century France|The paper provides an empirical examination of the effect of the use of steam engine technology on the development of adult education in nineteenth-century France. In particular, we exploit exogenous regional variations in the distribution of steam engines across France to evidence that technological change significantly contributed to the development of lifelong training during the 1850-1881 period. Our research shows that steam technology adoption in France was not deskilling. We argue that this process raised the demand for new skills adapted to the development of French industries.
C80|Mögliche Auswirkungen eines harten oder weichen Brexit auf die deutsche Landwirtschaft - Update|Das Vereinigte Königreich (VK) stellt einen bedeutsamen Abnehmer für deutsche Agrarprodukte dar. Dies wird auch durch die hohen deutschen Nettoagrarexporte von 3,1 Mrd. € in 2016 deutlich. Damit ist das VK der Handelspartner, mit welchem Deutschland den mit Abstand größten Agrarhandelsüberschuss aufweist. Allein diese Fakten verdeutlichen bereits, dass die mit einem Brexit verbundene Einführung von wie auch immer gearteten Handelsbarrieren einen potenziell starken Einfluss auf die deutschen Agrarmärkte haben kann. In der folgenden Analyse werden mit einem 'weichen' und einem 'harten' Brexit zwei Szenarien mit unterschiedlich stark ausgeprägten Handelshemmnissen untersucht. Das 'weiche' Brexit Szenario beinhaltet ein tiefgreifendes Freihandelsabkommen zwischen der EU und dem VK, während das 'harte' Brexit Szenario mit der Einführung von MFN Zöllen eine stärker protektionistische Politik unterstellt. Die Modellergebnisse zeigen, dass bei einem 'weichen' Brexit mit einem Rückgang der deutschen Agrarproduktion in Höhe von 400 Mio. € zu rechnen ist. Dieser wertmäßige Rückgang würde bei einem 'harten' Brexit dreimal höher ausfallen.
C80|The Government of Canada Debt Securities Data Set|We present the daily time series of the outstanding amounts of all Government of Canada marketable debt securities from July 2001 to June 2017. The data set is accompanied by a matching data set describing the most relevant events for each bond on each day: auction, repurchase, benchmark status and maturity. This previously unavailable data set is designed with academic researchers and market participants in mind and could be regularly updated in the future. We discuss the construction of the data set and potential uses for empirical asset pricing and related studies.
C80|Testing the Waters: Behavior across Participant Pools|We leverage a large-scale incentivized survey eliciting behaviors from (almost) an entire university student population, a representative sample of the U.S. population, and Amazon Mechanical Turk (MTurk) to address concerns about the external validity of experiments with student participants. Behavior in the student population offers bounds on behaviors in other populations, and correlations between behaviors are largely similar across samples. Furthermore, non-student samples exhibit higher measurement error. Adding historical lab participation data, we find a small set of attributes over which lab participants differ from non-lab participants. Using an additional set of lab experiments, we see no evidence of observer effects.
C80|Testing the Waters: Behavior across Participant Pools|We leverage a large-scale incentivized survey eliciting behaviors from (almost) an entire university student population, a representative sample of the U.S. population, and Amazon Mechanical Turk (MTurk) to address concerns about the external validity of experiments with student participants. Behavior in the student population offers bounds on behaviors in other populations, and correlations between behaviors are largely similar across samples. Furthermore, non-student samples exhibit higher measurement error. Adding historical lab participation data, we find a small set of attributes over which lab participants differ from non-lab participants. Using an additional set of lab experiments, we see no evidence of observer effects.
C80|Best practices for the risk based approach assessment of the anti-money laundering program within a financial institutionBest practices for the risk based approach assessment of the anti-money laundering program within a financial institution|The Anti-Money Laundering („AML”) internal controls of financial institutions are no longer implemented to satisfy the supervision authorities, but precisely to prevent risks from materializing, risks which are much higher than just a fine, such as legal, reputational or substantial financial risks. Thus, we are welcoming institutional changes on the mentality and organizational culture, with the purpose of preventing the use of the financial institutions as means for money laundering, terrorist financing or other fraud schemes.This paper will firstly approach the „need” evolution with respect to AML measures, continuing by detailing the trends for assessing these measures. Basically, we would like to highlight that the Compliance function, especially from the AML point of view,should represent a business actual support and not an encumbrance. In this way, compliance and business should go in the same direction, whichis business development in a safe and legal environment.
C80|What Drives Bitcoin Volatility?|We look at the link between the volatility in the Bitcoin market and the volatility in other related traditional markets, i.e. the gold, currency and stock market. We also try to answer if the volatility in the Bitcoin market can be explained by retail investor-driven internet search volumes or, perhaps, by the general level of risk in the financial system, as measured by two market-wide risk indicators. We use daily, weekly as well as monthly data covering the period 2011 to 2017. Correlations and regressions reveal a weak but positive contemporaneous link between changes in the Bitcoin volatility and changes in the volatility of the trade weighted USD currency index. A stronger positive link is found between Bitcoin volatility and search pressures on Bitcoin-related words on Google, particularly for the word “bitcoin”. To further assess what drives Bitcoin volatility we turn to a VAR-analysis and impulse response functions which point at Google searches for the word “bitcoin”, and to some extent the USD currency index volatility, being the only determinants of future Bitcoin volatility. We then use our findings to make improved predictions of Bitcoin volatility based on Google search activity. Interestingly, the significant link that we find between Google search volumes and market volatility points at retail investors, rather than large institutions, being the most important drivers of Bitcoin volatility. We believe that we contribute to the literature in several ways and that our results could be of significant practical importance if the Bitcoin market continues to grow at the current speed.
C80|Some (maybe) unpleasant arithmetic in minimum wage evaluations: The role of power, significance and sample size|In this paper, we discuss the importance of sample size in the evaluation of minimum wage effects. We first show which sample sizes are necessary to make reliable statements about the effects of minimum wages on binary outcomes, and second how to determine these sample sizes. This is particularly important when interpreting statistically insignificant effects, which could be due to (i) the absence of a true effect or (ii) lack of statistical power, which makes it impossible to detect an effect even though it exists. We illustrate this for the analysis of labour market transitions using two data sets which are particularly important in the minimum wage research for Germany, the Integrated Labour Market Biographies (IEB) and the Socio-Economic Panel (SOEP).
C80|Rising Mean Incomes for Whom?|Not everybody is benefiting equally from rising mean incomes. We discuss the mean-income population share (MPS), defined as the population share earning less than the mean income, as an indicator of how representative the mean income is for the mass of the population. This measure is both analytically tractable and simple to interpret to inform the public debate. We discuss its properties and estimation using micro-level and grouped income data. Our empirical application finds that MPS has risen in 13 out of 16 high- and middle-income countries in the last decades, indicating that growth has mostly not been inclusive. MPS shows a mixed correlation structure with the Gini coefficient.
C80|The economic importance of the Belgian ports : Flemish maritime ports, Liège port complex and the port of Brussels – Report 2016|This Working Paper analyses the economic importance of the Belgian ports based largely on the annual accounts data for the year 2016. As the years prior to 2016 have been described in earlier papers in the same series, we mainly focus on the figures for 2016 and developments between 2015 and 2016. On the back of strong growth, direct value added in the Belgian ports remained more or less stable in 2016 at around € 18 000 million (current prices) or roughly 4.3% of Belgium’s GDP. Direct value added declined in the Flemish seaports, mainly in the port of Antwerp. Ghent and Zeebrugge could only partly compensate for the fall in Antwerp’s value added, while Ostend showed a small decline itself. The inland ports as a whole grew over the period 2015-2016; the port of Brussels registered a decline and the Liège port complex an increase. Indirect value added is around 82% of the direct figure. After declining from 2012, direct employment in the Belgian ports was more or less stable in 2016 at around 115 000 FTE or approximately 2.8% of Belgium’s total domestic employment. Direct employment in the Flemish seaports increased, mainly in the ports of Zeebrugge, Ghent and Antwerp. Ostend showed a decline in employment. The inland ports recorded lower employment; the port of Brussels registered a decline, as did the Liège port complex. Indirect employment is around 1.2 times the direct figure. Delving deeper into the data and trying to explain the above trends in terms of the structural composition of the Belgian ports shows that all ports are concentrated on a few sectors, and within those sectors often on just a handful of companies. Based on the figures of the traffic, the Flemish ports can be considered as real bridgeheads for trade with the UK. Developments regarding the modalities and consequences of the Brexit therefor should be followed with the greatest attention. Given the existing import and export volumes in terms of tonnage, it seems it will mostly be a challenge in Zeebrugge and to some extent for Antwerp.
C80|Testing the Waters: Behavior across Participant Pools|We leverage a large-scale incentivized survey eliciting behaviors from (almost) an entire university student population, a representative sample of the U.S. population, and Amazon Mechanical Turk (MTurk) to address concerns about the external validity of experiments with student participants. Behavior in the student population offers bounds on behaviors in other populations, and correlations between behaviors are largely similar across samples. Furthermore, non-student samples exhibit higher measurement error. Adding historical lab participation data, we find a small set of attributes over which lab participants differ from non-lab participants. Using an additional set of lab experiments, we see no evidence of observer effects.
C80|Leave No One Behind: How are Development Assistance Committee members answering the pledge of the 2030 Agenda for Sustainable Development?|In 2015, UN Member States and the international community more broadly endorsed the 2030 Agenda for Sustainable Development and the Agenda’s commitment to achieve the Sustainable Development Goals for everyone to leave no one behind. This working paper presents and analyses the findings of a survey circulated to members of the OECD’s Development Assistance Committee (DAC) between April and May 2018. The survey investigated the level and extent of commitment to leave no one behind in development co-operation policies, strategies and programming. It also gathered views and evidence from DAC members about the comparative advantage, opportunities, challenges and strategies for answering this pledge of the 2030 Agenda for Sustainable Development. The findings presented in this paper inform the analysis of the 2018 Development Co-operation Report: Joining Forces to Leave No One Behind.
C80|Diversity statistics in the OECD: How do OECD countries collect data on ethnic, racial and indigenous identity?|Data on ethnic, racial and indigenous identity can help render certain minorities statistically visible, and expose potential discrimination and inequalities. This paper systematically reviews diversity data collection practices in OECD countries and selected key partners and identifies three common challenges: the legal treatment of ‘sensitive’ data and concerns around privacy; the use of different data sources for different policy purposes; and issues of comparability over time since identities are dynamic and multiple constructs. When relevant, recommendations and best practices to improve diversity data are put forward. These include: expanding the collection of data on ethnic and racial identities where legal frameworks permit; ensuring the representation of hard-to-reach populations such as indigenous communities; developing national diversity statistical standards to standardise information and allow linking data across sources; raising the timeliness and policy relevance of diversity data by including questions in both regular sample surveys and population censuses; and involving communities in the data collection process.
C80|Chinaâ€™s Increasing Inequality of Wealth: Piketty with Chinese Characteristics?|John Knight, LI Shi and WAN Haiyuan The inequality of wealth in China has increased rapidly in recent years. China presents a fascinating case study of how inequality of household wealth increases as economic reform takes place, marketisation occurs, and capital accumulates. Wealth inequality and its growth are measured and decomposed using data from two national sample surveys of the China Household Income Project (CHIP) relating to 2002 and 2013. An attempt is made to explain the rising wealth inequality in terms of the relationships between income and wealth, differential saving, house price inflation, and income from wealth. This last relationship is stressed by Thomas Piketty in his 2014 book. In China the evidence for it is weak, but there is support for a reformulation that includes real capital gain as part of income. Pikettyâ€™s mechanism is relevant, but only â€˜with Chinese characteristicsâ€™.
C80|Economics of big data: review of best papers for January 2018|Hundreds of new papers on big data are released every month and at times it is difficult to distinguish between them in terms of quality and practical use. The purpose of this monthly review is to highlight the findings in the most relevant papers in Economics of big data to help readers identify the most important new developments in the field. The review for January 2018 includes a study of social networks in truancy, a paper on consumer privacy and data collection and three NBER papers on applications of Artificial Intelligence in Economics.
C80|A cliometric counterfactual: what if there had been neither Fogel nor North?|Abstract 1993 Nobel laureates Robert Fogel and Douglass North were pioneers in the “new” economic history, or cliometrics. Their impact on the economic history discipline is great, though not without its critics. In this essay, we use both the “old” narrative form of economic history, and the “new” cliometric form to analyze the impact each had on the evolution of economic history.
C80|FOI as a data collection tool for economists|This paper sets out a method of generating a unique data set that has been underused by economists – a Freedom of Information (FOI) request. The FOI Act came into force in 2005 in the UK and allows the public to make requests of publicly held data. We explain how they can be made and provide suggestions on how to make effective data driven requests, those most frequently made by economists. Finally, we document the determinants of one particular FOI request. We applied for crime data from all police forces in the UK and examine the determinants of that request. In general, we find that observable characteristics of the local area or the police force neither determine whether the request was fulfilled, nor the speed at which it was responded to.
C80|Variance Estimator in Complex Surveys using Linear Regression with Expansion Factor as Independent Variable|In probability sampling, variance estimation of an estimated mean or total requires developing a mathematical expression that depends on the design used to extract a sample. These formulae can be difficult to build and sometimes involve computation of joint inclusion probabilities of selection, which can be hard to obtain. For some sampling designs it is not possible to obtain an unbiased estimator of the variance. These designs include the selection of one element or one large primary sampling unit within some strata, or systematic selection of units or primary sampling units within strata. The problem of variance estimation may also arise from an analytical perspective, while estimating means or totals in unplanned domains, it is possible to arrive at only one unit or cluster within some strata. In this article, we propose a linear regression variance estimator which is very simple to compute and gives a solution to the aforementioned problems. Some examples using different designs are given.
C80|Sending firm messages: text mining letters from PRA supervisors to banks and building societies they regulate|Our paper analyses confidential letters sent from the Bank of England’s Prudential Regulation Authority (PRA) to banks and building societies it supervises. These letters are a ‘report card’ written to firms annually, and are arguably the most important, regularly recurring written communication sent from the PRA to firms it supervises. Using a mix of methods, including a machine learning algorithm called random forests, we explore whether the letters vary depending on the riskiness of the firm to whom the PRA is writing. We find that they do. We also look across the letters as a whole to draw out key topical trends and confirm that topics important on the post-crisis regulatory agenda such as liquidity and resolution appear frequently. And we look at how PRA letters differ from the letters written by the PRA’s predecessor, the Financial Services Authority. We find evidence that PRA letters are different, with a greater abundance of forward-looking language and directiveness, reflecting the shift in supervisory approach that has occurred in the United Kingdom following the financial crisis of 2007–09.
C80|A Primer on the “Reproducibility Crisis” and Ways to Fix It|This article uses the framework of Ioannidis (2005) to organize a discussion of issues related to the “reproducibility crisis.” It then goes on to use that framework to evaluate various proposals to fix the problem. Of particular interest is the “post-study probability”, the probability that a reported research finding represents a true relationship. This probability is inherently unknowable. However, a number of insightful results emerge if we are willing to make some conjectures about reasonable parameter values. Among other things, this analysis demonstrates the important role that replication can play in improving the signal value of empirical research.
C80|Mining taxation in Africa: the gold mining industry in 14 countries from 1980 to 2015|The lack of information about the sharing of mining resource rent between governments and investors is an easy statement to make for Africa. The existing datasets are often insufficient for a deep analysis of African tax law as applied to the natural resource sectors, which has limited the academic and operational approaches. This paper describes the first legal and tax database which specifies the tax regime applied to industrial gold mining companies in 14 African gold-producing countries from 1980 to 2015. The database has three major innovations: (i) an inventory of taxes and duties (rate, base and exemptions) payable during the prospecting phase and mining phase of a gold project; (ii) a new detailed historical record covering 1980 to 2015; (iii) the link between each piece of tax information and its legal source. This database is used to make a first analysis of mining tax regimes and rent sharing in the main gold-producing countries. The first results highlight the heterogeneity of tax regimes between English-speaking and French-speaking countries. There has been a convergence of the average effective tax rates across most of the countries, the effective tax rate has increased in most countries following the tax reforms undertaken since 2010.The database is downloadable following the link : http://www.ferdi.fr/en/indicator/minining-tax-database-africa.Keywords: Mining sector, Gold, Taxation of natural resources, DatabaseJEL: Q38, K34, C80
C80|Willingness to Pay and Willingness to Accept are Probably Less Correlated Than You Think|An enormous literature documents that willingness to pay (WTP) is less than willingness to accept (WTA) a monetary amount for an object, a phenomenon called the endowment effect. Using data from an incentivized survey of a representative sample of 3,000 U.S. adults, we add one (probably) surprising additional finding: WTA and WTP for a lottery are, at best, slightly correlated. Across all respondents, the correlation is slightly negative. A meta-study of published experiments with university students shows a correlation of around 0.15--0.2, consistent with the correlation in our data for high-IQ respondents. While poorly related to each other, WTA and WTP are closely related to different measures of risk aversion, and relatively stable across time. We show that the endowment effect is not related to individual-level measures of loss aversion, counter to Prospect Theory or Stochastic Reference Dependence.
C80|Omnimetrics and Awards|The digital revolution has led to a quantification of ever more areas of human life and society. At the same time, there is an explosion of the number of awards , which by their very nature are based on non- quantified performance. Will quantification take over completely, leading to “omnimetrics”? The paper argues that this will not be the case. An economic explanation for the paradoxical existence of two totally different developments is offered: The value of awards is the higher, the stronger is the effort to quantify. The two developments depend on each other. The more digitalized the world is, the more non-quantified and non-quantifiable aspects of life are cherished. The quantification mania not only raises the value of awards but also the importance of personal relationships, of friendship, love and admiration. While digitalization will proceed and will determine increasingly larger parts of our lives, it is hypothesized that the non-quantified aspects of life will not disappear but flourish.
C80|Reactivity in Economic Science|There is a fundamental difference between the natural and the social sciences due to reactivity. This difference remains even in the age of Artificially Intelligent Learning Machines and Big Data. Many academic economists take it as a matter of course that economics should become a natural science. Such a characterization misses an essential aspect of a social science, namely reactivity, i.e. human beings systematically respond to economic data, and in particular to interventions by economic policy, in a foreseeable way. To illustrate this finding, I use three examples from quite different fields: Happiness policy, World Heritage policy, and Science policy.
C80|Explaining Differences In Efficiency: The Case Of Local Government Literature|One learns two main lessons from the efficiency literature on local governments. The first lesson regards the heterogeneity in the efficiency scores reported in primary papers. The second lesson is that there is no quantitative evidence on the role played by the features of each paper (i.e. estimation method, sample size, dimension, returns to scale) in explaining the differences in results. In order to fill this gap, we review the related empirical literature and perform a Meta Regression Analysis (MRA) by examining 360 efficiency scores retrieved from 54 papers published from 1993 to 2016. The meta-regression is based on a random effect model estimated with the Random Effects Maximum Likelihood (REML) technique, because it controls for within- and between-study heterogeneity. We also run a fixed effect unrestricted Weighted Least Squares (WLS) regression. Due to its main research focus, that is measuring the impact of potential sources of heterogeneity on local government efficiency, the paper contributes to the debate in two ways. One of this concerns the role of methodological choices made by researchers when performing an efficiency study. The second regards the role of deregulation in local government, which is a policy-issue in a number of countries. Results show that efficiency scores are highly heterogeneous. To be precise, significant differences in means are found when grouping efficiency by different criteria. The meta-regression estimates indicate that studies focusing on technical efficiency provide higher efficiency scores than works evaluating cost efficiency. Using panel data in primary studies allows researchers to obtain higher efficiency of local government than papers using cross-section data. Interestingly, FDH studies yield, on average, higher efficiency scores than DEA papers, thereby suggesting that in this literature the convexity hypothesis of the production set is a matter. Furthermore, we find that primary papers evaluating the efficiency of European municipalities provide lower efficiency scores than studies focusing on other countries (USA, Africa, Asia and Latina America). We also provide evidence that the estimated efficiency scores in primary papers focusing on the municipalities of a region are, one average, lower than those retrieved from studies addressing the efficiency of the national system of local government.
C80|Measuring the Market Size for Cannabis: A New Approach Using Forensic Economics|Quantifying the market size for cannabis is important given vigorous policy debates about how to intervene in this market. We develop a new approach to measuring the size of the cannabis market using forensic economics. The key insight is that cannabis consumption often requires the use of complementary legal inputs: roll-your-own tobacco and rolling papers. The forensic approach specifies how legal and illegal inputs are combined in the production of hand-rolled cigarettes and cannabis joints. These input relationships, along with market adding-up conditions, can then be used to infer the size of the cannabis market. We prove proof-of-concept that this approach can be readily calibrated using: (i) point-of-sales data on the legal inputs of roll-your-own tobacco and rolling papers; (ii) input parameter estimates drawn from a wide-ranging interdisciplinary evidence base. We then implement the approach using data from 2008-9. For those years, the forensic estimates for the UK cannabis market are near double those derived from standard demand-side approaches. We make precise what drives the measurement gap between methods by establishing: (i) the parameter adjustments needed in demand-side approaches to match the forensic measure; (ii) the changes in methodology to the forensic approach needed to match the demand-side estimate. Our analysis develops an agenda on measurement and data collection that allows for credible cost-benefit analysis of policy interventions in illicit drug markets.
C80|Omnimetrics and Awards|The digital revolution has led to a quantification of ever more areas of human life and society. At the same time, there is an explosion of the number of awards, which by their very nature are based on non-quantified performance. Will quantification take over completely, leading to “omnimetrics”? The paper argues that this will not be the case. An economic explanation for the paradoxical existence of two totally different developments is offered: The value of awards is the higher, the stronger is the effort to quantify. The two developments depend on each other. The more digitalized the world is, the more non-quantified and non-quantifiable aspects of life are cherished. The quantification mania not only raises the value of awards but also the importance of personal relationships, of friendship, love and admiration. While digitalization will proceed and will determine increasingly larger parts of our lives, it is hypothesized that the non-quantified aspects of life will not disappear but flourish.
C80|Reactivity in Economic Science|There is a fundamental difference between the natural and the social sciences due to reactivity. This difference remains even in the age of Artificially Intelligent Learning Machines and Big Data. Many academic economists take it as a matter of course that economics should become a natural science. Such a characterization misses an essential aspect of a social science, namely reactivity, i.e. human beings systematically respond to economic data, and in particular to interventions by economic policy, in a foreseeable way. To illustrate this finding, I use three examples from quite different fields: Happiness policy, World Heritage policy, and Science policy.
C80|Inference from high-frequency data: A subsampling approach|In this paper, we show how to estimate the asymptotic (conditional) covariance matrix, which appears in central limit theorems in high-frequency estimation of asset return volatility. We provide a recipe for the estimation of this matrix by subsampling; an approach that computes rescaled copies of the original statistic based on local stretches of high-frequency data, and then it studies the sampling variation of these. We show that our estimator is consistent both in frictionless markets and models with additive microstructure noise. We derive a rate of convergence for it and are also able to determine an optimal rate for its tuning parameters (e.g., the number of subsamples). Subsampling does not require an extra set of estimators to do inference, which renders it trivial to implement. As a variance–covariance matrix estimator, it has the attractive feature that it is positive semi-definite by construction. Moreover, the subsampler is to some extent automatic, as it does not exploit explicit knowledge about the structure of the asymptotic covariance. It therefore tends to adapt to the problem at hand and be robust against misspecification of the noise process. As such, this paper facilitates assessment of the sampling errors inherent in high-frequency estimation of volatility. We highlight the finite sample properties of the subsampler in a Monte Carlo study, while some initial empirical work demonstrates its use to draw feasible inference about volatility in financial markets.
C80|An alternative single parameter functional form for Lorenz curve|This paper proposes a single parameter functional form for the Lorenz curve and compares its performance with the existing single parameter functional forms using Australian income data for 10 years. The proposed parametric functional form performs better than the existing Lorenz functional forms. The Gini based on the proposed functional form is closest to true Gini each year.
C80|Mining taxation in Africa: The gold mining industry in 14 countries from 1980 to 2015|The lack of information about the sharing of mining resource rent between governments and investors is an easy statement to make for Africa. The existing datasets are often insufficient for a deep analysis of African tax law as applied to the natural resource sectors, which has limited the academic and operational approaches. This paper describes the first legal and tax database which specifies the tax regime applied to industrial gold mining companies in 14 African gold-producing countries from 1980 to 2015. The database has three major innovations: (i) an inventory of taxes and duties (rate, base and exemptions) payable during the prospecting phase and mining phase of a gold project; (ii) a new detailed historical record covering 1980 to 2015; (iii) the link between each piece of tax information and its legal source. This database is used to make a first analysis of mining tax regimes and rent sharing in the main gold-producing countries. The first results highlight the heterogeneity of tax regimes between English-speaking and French-speaking countries. There has been a convergence of the average effective tax rates across most of the countries, the effective tax rate has increased in most countries following the tax reforms undertaken since 2010.The database is downloadable following the link :http://www.ferdi.fr/en/node/3198.
C80|Longevity, age-structure, and optimal schooling|The mechanism stating that longer life implies larger investment in human capital, is premised on the view that individual decision-making governs the relationship between longevity and education. This relationship is revisited here from the perspective of optimal period school life expectancy, obtained from the utility maximization of the whole population characterized by its age structure and its age-specific fertility and mortality. Realistic life tables such as model life tables are mandatory, because the age distribution of mortality matters, notably at infant and juvenile ages. Optimal period school life expectancy varies with life expectancy and fertility. The application to French historical data from 1806 to nowadays shows that the population age structure has indeed modified the relationship between longevity and optimal schooling.
C80|Reducing the gap between stated and real behavior in transportation studies: The use of an oath script|We investigate whether taking an oath in a survey situation affects respondent behavior in choice experiments with a focus on travel time, comfort, and cost. We conduct two studies in Beijing: one with car commuters and one with public transport commuters. Overall, we find little difference in behavior between responses with and without an oath. In fact, the only difference is that responses are more internally consistent in the version with an oath script: the respondents trade off money in terms of a fuel cost and in terms of a congestion charge in the same way. However, there is no statistically significant effect on marginal willingness to pay for any of the attributes.
C80|The Economics of Natural Disasters: an Overview of the Current Research Issues and Methods|In the last decades, we have observed a dramatic increase in the number of reported natural disasters and of their widespread human, economic, and environmental losses. This paper presents an overview of the current status of economic research on natural disasters. Firstly, it discusses key issues related to disaster definition, available datasets, and cost assessment. Then, it presents the main methodological approaches for estimating impacts and effects of natural disasters on the economy. Finally, it proposes a number of possible future research directions.
C80|A Comparison of Russian Practices in Industrial Statistics with Un Recommendations: Similarities and Differences in Classifications, Data Items and Indicators|This study compares Russian state information systems of industry with UN international recommendations. The harmonization of the Russian information system with successful international practices is necessary for measuring the main industrial indicator levels and dynamics in comparison with the information analogues of both cross-border and strategically important countries. This allows the estimation of the efficiency and competitiveness of Russian industry and the best decisions to be made at all levels of governance in Russia including in the technology and innovation policy sphere. The study shows that a significant number of annual, quarterly, monthly and weekly reporting forms within the Russian statistical system in the absence of a single questionnaire for obtaining comprehensive information from an enterprise and unified methodological recommendations do not solve the information gap problem. The available disaggregated information is not sufficient to analyse the quality and effectiveness of industrial policy, especially in comparison with global levels and tendencies of re-industrialization. The state statistical system needs modernization to reduce the reporting burden on enterprises and improve information transparency and comparability at the detailed level.
C80|Swiss Household Energy Demand Survey (SHEDS): Objectives, design, and implementation|The Swiss Household Energy Demand Survey (SHEDS) has been developed as part of the research agenda of the Competence Center for Research in Energy, Society, and Transition (SCCER CREST). It is designed to collect a comprehensive description of the Swiss households' energy-related behaviors, their longitudinal changes and the existing potentials for future energy demand reduction. The survey has been planned in five annual waves thus generating a rolling panel dataset of 5,000 respondents per wave. The first two waves of SHEDS were fielded in April 2016 and April-May 2017. This paper elaborates on SHEDS's general objectives, design, and implementation. It also reports a series of practical examples of how the datasets are being used in empirical analyses.
C80|Hedonic Recommendations: An Econometric Application on Big Data|This work will demonstrate how economic theory can be applied to big data analysis. To do this, I propose two layers of machine learning that use econometric models introduced into a recommender system. The reason for doing so is to challenge traditional recommendation approaches. These approaches are inherently biased due to the fact that they ignore the final preference order for each individual and under-specify the interaction between the socio-economic characteristics of the participants and the characteristics of the commodities in question. In this respect, our hedonic recommendation approach proposes to first correct the internal preferences with respect to the tastes of each individual under the characteristics of given products. In the second layer, the relative preferences across participants are predicted by socio-economic characteristics. The robustness of the model is tested with the MovieLens (100k data consists of 943 users over 1682 movies) run by GroupLens. Our methodology shows the importance and the necessity of correcting the data set by using economic theory. This methodology can be applied for all recommender systems using ratings based on consumer decisions
C80|Willingness-To-Pay and Willingness-To-Accept are Probably Less Correlated than You Think|Willingness to pay (WTP) and willingness to accept (WTA) a monetary amount for a lottery should be closely related. In data from an incentivized survey of a representative sample of 3,000 U.S. adults, we find that WTA and WTP for a lottery are, at best, weakly correlated. Across all respondents, the correlation is slightly negative. For the subgroups that we examine, the correlation is almost always small, typically statistically insignificant, and often negative. The exception is respondents who score highly on a within-study IQ test, where the correlation is around 0.2. A meta-study of similar lab experiments with university students also shows a correlation of around 0.15-0.2. While poorly related to each other, our measures of WTA and WTP are strongly related to different measures of risk aversion, and relatively stable across time. These various patterns allow us to show that this lack of relationship between WTA and WTP is compatible with existing theories, such as Prospect Theory and Stochastic Reference Dependence, only under very specific, and unlikely, correlational structures between parameters. We suggest a simpler formalization.
C80|Impure Altruism and Other Donor Attraction Factors: A Study Based on a Database of Non-Government Organizations (NGOs) in the Philippines|"This study uses panel data on a sample of non-government organizations (NGOs) to estimate the factors that motivate donors to contribute to them. The results of empirical estimation suggest that a mix of conventional and tax factors influence donors. The results are consistent with the hypothesis that donors are not totally altruistic and are motivated by private benefits from donating. There is strong evidence that the private benefits come more from tax concessions from the act of donating. Hence, tax planning and arbitrage motives, more than ""warm glow"" factors influence donor contributions."
C80|Information Technology Project System Model|This research aimed to study and design information technology project model for learning and teaching. It was a case study. The sample group was 10 students who studied the special problem course and 30 users were used to evaluate the systems. The methods of data collection were questionnaire and information technology systems. The key performance indicators in this study included 10 information technology systems, usability of system, the accuracy and completeness of system. The instruments used in this study were: time to develop information system and evaluate users? document. The data were analyzed by percentage and mean. The results of this research found that 10 information technology systems could be delivered in time and information technology project system model included 5 components: analysis module, logical design module, physical design module, implementation module and testing module. The students and users in this study expressed positive attitudes towards instruments of learning and information technology systems.
C80|Crowdfunding success prediction: An emprical study on Indiegogo platform|Crowdfunding is an appealing financing method to enterpreneurs with financial difficulties in realizing their project ideas. This practice is an endeavour to raise funds for a project or a business venture from a large population where the enterpreneurs make an open call through the internet and try to persuade individuals to support their innovative ideas. Within four different types of crowdfunding and hundreds of websites emerged, this study focuses on reward and donation based crowdfunding in one of the most prominent platforms, Indiegogo. The study introduces a decision tree model that classifies the submitted projects at Indiegogo as successful or not and underlines the key success features for entrepreneurs who are to make an online call for fundraising.
C80|Jump-robust estimation of volatility with simultaneous presence of microstructure noise and multiple observations|Abstract In this paper, we develop the multipower estimators for the integrated volatility in (Barndorff-Nielsen and Shephard in J. Financ. Econom. 2:1–37, 2004); these estimators allow the presence of jumps in the underlying driving process and the simultaneous presence of microstructure noise and multiple records of observations. By multiple records we mean more than one observation recorded on a single time stamp, as often seen in stock markets, in particular, for heavily traded securities, for a data set with even millisecond frequency. We establish the consistency and asymptotic normality of the estimators for both noise-free and noise-present cases. Simulation studies confirm our theoretical results. We apply the estimators to a real high-frequency data set.
C80|Disciplinarity and interdisciplinarity in citation and reference dimensions: knowledge importation and exportation taxonomy of journals|Abstract This work proposes an entropy-based disciplinarity indicator (EBDI) which allows the classification of scientific journals in four classes: knowledge importer, knowledge exporter, disciplinary and interdisciplinary with regards to the discipline(s) in which they are classified. Assuming that the set references in the papers published in a journal represent a significant part of their knowledge basis, the diversity (measured with Shannon’s entropy) and ratio between internal and external (to the discipline in which the journal is classified) references can provide a measure of the disciplinarity/interdisciplinarity of the journal in the reference dimension. The homologous analysis can be applied to the set of citations received by the papers published in the journal. In this article, an entropy-based indicator for the measurement of the disciplinarity of scientific journals is developed, applied (to the cited and citing dimensions) and discussed. The indicator can take finite values and it is found to be theoretically consistent when tested against two definitions for bibliometric indicators. The combinations of disciplinarity values in the citing and cited dimensions permits the classification of journals according to their knowledge importing/exporting profile (separately, with regards to the social sciences or the sciences), providing a taxonomy of the role of journals according to their importing, exporting, interdisciplinary or specialized profile with regards to the subject category in which they are classified. The indicator, EBDI and the resulting taxonomy is proposed and tested for the set of journals in LIS subject category in JCR 2013 and for the sets of journals in Andrology and Legal Medicine in JCR 2015. Evidence of concurrent validity with journal co-classification patterns is found in the three sets of journals.
C80|Combining SAO semantic analysis and morphology analysis to identify technology opportunities|Abstract Increasingly complex competitive environments drive corporations in almost all industries to conduct omnibearing innovation activities to enhance their technological innovation capability and international competitiveness. Against this background, we propose subject–action–object (SAO) based morphological analysis to identify technology opportunities by detecting prioritized combinations within the morphology matrix. SAO structures emphasize the key concepts with provision of diverse technology information based on semantic relationships. The combination of SAO semantic structures can support the establishment of matrix, which consists of two dimensions: compositions and properties of technology. Later, novel indicators are used to evaluate the subsequent technological feasibility of each new configuration under a customized analysis and prior combinations aided by a high score can be identified. We apply this method to the case of dye-sensitized solar cells (DSSCs) in patents documents. The approach holds promise to strengthen information support systems for commercial enterprises in technical innovation and market innovation activities. We believe the analysis can be adapted well to fit other technologies, especially in their emerging stage.
C80|The Changing Structure of Africa’s Economies|Using data from the Groningen Growth and Development Center’s Africa Sector Database and the Demographic and Health Surveys, we show that much of Africa’s recent growth and poverty reduction has been associated with a substantive decline in the share of the labor force engaged in agriculture. This decline is most pronounced for rural females over the age of 25 who have a primary education; it has been accompanied by a systematic increase in the productivity of the labor force, as it has moved from low productivity agriculture to higher productivity services and manufacturing. We also show that, although the employment share in manufacturing is not expanding rapidly, in most of the low-income African countries the employment share in manufacturing has not peaked and is still expanding, albeit from very low levels. More work is needed to understand the implications of these shifts in employment shares for future growth and development in Africa south of the Sahara.
C80|Online Annex – Economic Challenges of Lagging Regions: Annex II – Econometric Analysis and Supplemental Tables|This report is an annex to wiiw Research Report 423, ‘Economic Challenges of Lagging Regions III Recent Investment Trends and Needs’. Based on spatial econometric methods, it provides estimates and simulations of the investment effects on economic development in the EU lagging regions. It also provides additional data related to the analysis in wiiw Research Report 423.
C80|A replication recipe: List your ingredients before you start cooking|"The author argues that researchers should do replications using preanalysis plans. These plans should specify at least three characteristics: (1) how much flowtime the researchers will spend, (2) how much money and effort (working hours) the researchers will spend, and (3) the intended results and the precision of the replication necessary for ""success"". A researcher's replication will be ""successful"" according to context-specific criteria in the preanalysis plan. The author also argues that the two biggest drawbacks of preanalysis plans-(1) that they discount unexpected but extraordinary findings and (2) that they make it difficult for researchers to prespecify all possible actions in their decision trees-are less relevant for replications compared with new research. The author concludes with describing a preanalysis plan for replicating a paper on housing demand and household formation."
C80|Trees And Semi-Lattices: Analysing Space Configuration Of Two Urban Systems In Lisbon Region|This study examines patterns of order and structure in street networks and its relationships with spatial life of two urban neighborhoods (housing estates). It explores the concepts of “tree” and “semi-lattice” as two different ways of looking and thinking about the structure of cities, each one generating a different form of life and community place (Alexander, 1965). The authors propose a configurational analysis of street networks of two urban plans designed according to different city ideologies and historical background. Based on space syntax methodology the street network was represented both as convex spaces and axial lines as nodes of a graph. The network was then analyzed in terms of the mathematical properties of the graph. The objective was to address a comparative study of structural properties of the urban street networks in order to speculate some implications on social life of each neighborhood. Syntactic measures have shown that conceptual designs have different spatial and social patterns both at global and local scales. It was corroborated that the difference between the characteristics of topological properties which reflects the mathematical principle of tree and semi-lattice is responsible for the different character of public life we found in each urban area.
C80|Statistical Data Processing with R – Metadata Driven Approach|In recent years the Statistical Office of the Republic of Slovenia has put a lot of effort into re-designing its statistical process. We replaced the classical stove-pipe oriented production system with general software solutions, based on the metadata driven approach. This means that one general program code, which is parametrized with process metadata, is used for data processing for a particular survey. Currently, the general program code is entirely based on SAS macros, but in the future we would like to explore how successfully statistical software R can be used for this approach.Paper describes the metadata driven principle for data validation, generic software solution and main issues connected with the use of statistical software R for this approach.
C80|Two Decades of Research Collaboration: A Keyword Scopus Evaluation|One issue that has become more important over the years is to evaluate the capability for worldwide research networks on different areas of research, especially in the areas that are identified as being worldwide significant. The study investigated the research output, citations impact and collaborations on publications listed in Scopus authored by researchers all over the world, research published between 1999-2014, selected by a group of keywords identified by authors. The results of the analysis identified an increasing trend in scientific publications starting with 2006, especially on three of the analyzed keywords. We also found differences in the citations patterns for the Black Sea and Danube Delta keywords in the contributing countries. The results of this study revealed a steady increase of the collaboration output and an increasing trend in the collaboration behavior, both at the European and national level. Additionally, at the national level the study identified the collaboration network between Romanian institutions per counties.
C80|Research Parasites Are Beneficial for the Organism as a Whole: Competition between Researchers Creates a Symbiotic Relationship|"In the New England Journal of Medicine, Longo and Drazen critically assessed the concept of data sharing. Their main concern is that a ""new class of research person will emerge"" that uses data, which were gathered by other researchers, for their own original research questions. The authors referred to this class of researcher as ""research parasites"". Longo and Drazen are right when they note that scientific data sharing deserves more recognition. However, they indicate that the most adequate form of recognition for data sharing is coauthorship. They suggest to work ""symbiotically, rather than parasitically, with the investigators holding the data, moving the field forward in a way that neither group could have done on its own."" Although this is true in particular cases, co-authorship as the sole instrument of credit will unnecessarily restrict the potential of data sharing. More suitable instruments for giving credit where credit is due would be a much greater appreciation of data sharing by research communities by introducing citations of data sets, bestowing awards for good datasets, and considering data ""production"" when assessing scientists' career prospects, funding applications, and research outputs."
C80|Parentsâ€™ Choice Function for Wardsâ€™ School Continuation in Rural India: A Case Study in West Bengal|In this article, we present a choice function of a rural household relating to her/his wardâ€™s schooling. It makes an empirical evaluation on the basis of a simple theoretical framework using a primary data set surveyed from two backward districts of West Bengal. It explores the underlying causes of wardsâ€™ discontinuation of school by examining the choice function of the parents using ordered probit analysis. The likelihood of dropout is higher at the primary level for low-income households and significantly depends on parentsâ€™ attributes, which are mostly endogenous in an educational production function, and other exogenous difficulties in accessing school. It is also triggered by a lack of expectation about the future impact of education on a childâ€™s life. JEL Classification: C25, C80, D19, I21, I25
C80|Social and Business Innovations: Are Common Measurement Approaches Possible?|This article reviews various approaches to measuring business innovation with the aim of drawing lessons for measuring social innovations, and offers several methodological and policy conclusions. First, Innovation Union Scoreboard (IUS) indicators, in principle, could be useful in settings where the dominant mode of innovation is based on R&D activities. In practice, however, both R&D and non-R&D-based modes of innovation are important. IUS, therefore, only provides a partial picture. Social innovations can essentially rely on R&D-based technological innovations; their essence, however, tends to be essentially organizational, managerial, and behavioural modifications. The IUS indicators do not capture these types of changes. Second, an assessment of the 81 indicators used to compile the Global Innovation Index reveals that it would not be fruitful to rely on such indicators to capture social innovations. Third, given the diversity among innovation systems, a poor performance signalled by a composite indicator does not automatically identify the area(s) necessitating the most urgent policy actions; only tailored, thorough comparative analyses can do so. Finally, analysts and policy makers need to be aware of the differences between measuring (i) social innovation activities (or efforts); (ii) the framework for social innovations (pre-requisites, available inputs, skills, norms, values, behavioural patterns, etc.); and (iii) the economic, societal, and environmental impacts of social innovations.
C80|Social and Business Innovations: Are Common Measurement Approaches Possible?|This article reviews various approaches to measuring business innovation with the aim of drawing lessons for measuring social innovations, and offers several methodological and policy conclusions. First, Innovation Union Scoreboard (IUS) indicators, in principle, could be useful in settings where the dominant mode of innovation is based on R&D activities. In practice, however, both R&D and non-R&D-based modes of innovation are important. IUS, therefore, only provides a partial picture. Social innovations can rely on R&D-based technological innovations; their essence, however, tends to be organizational, managerial, and behavioural changes. The IUS indicators do not capture these types of changes. Second, an assessment of the 81 indicators used to compile the Global Innovation Index reveals that it would not be fruitful to rely on such indicators to capture social innovations. Third, given the diversity among innovation systems, a poor performance signalled by a composite indicator does not automatically identify the area(s) necessitating the most urgent policy actions; only tailored, thorough comparative analyses can do so. Finally, analysts and policy makers need to be aware of the differences between measuring (i) social innovation activities (or efforts); (ii) the framework for social innovations (pre-requisites, available inputs, skills, norms, values, behavioural patterns, etc.); and (iii) the economic, societal, and environmental impacts of social innovations.
C80|Poor-quality data and cohort life tables|Data for cohort life tables and its quality is very important information and good data is the basic assumption to construct any model. For cohort life tables information about mortality for 100 years is needed. As is known many regions have problem with some short time periods with weak or no information about mortality patterns in detailed structure. Aim of the paper is to describe possible way how to solve the problem with short periods with low quality data and to evaluate impact of this to the total cohort mortality. Information about cohort mortality is very important for many institutions as pension funds, government and others.
C80|Control Strategy To Trade Cryptocurrencies|The paper deals with the cryptocurrencies. First, a general introduction to crypto-currencies is given from the programmer?s point of view. It describes some basic strategies for automated trading. Also explained is the algorithm Floyd-Warshall and its modifications for automation arbitrage. An illustrative example is given and a trading algorithm is listed. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
C80|Using the Methods in the Area of HRM: Capabilities and Limitations (Metody badawcze stosowane w obszarze ZZL: mozliwosci i ograniczenia)|The existence of many methods and approaches allows their appropriate selection depending on the subject and purpose of the study. However, it makes it more difficult to take a decision. Basic knowledge of methodology of the research process and the possibilities and limitations of the various methods and techniques allows not only for achieving research objectives but also for their attainment in a proper and reliable way. The aim of this research is to determine the possibilities and limits of the use of different types of research methods in the field of human resource management in organizations. The study presents the used methods and techniques according to their reliability and shows limitations to the research process. The article presents the most popular research methods and techniques of human resources management in the commercial and public sectors on the basis of two journals – Personnel Management and Human Resources Management Journal.
C80|Big Data is a big deal but how much data do we need?<BR>[Big Data gut und schön. Aber wie viel Data brauchen wir?]|Abstract Those with a more conservative disposition might believe that Big Data is a short-lived fad and they may in fact be partially right. Others by contrast – especially those who dispassionately note that digitization is only now beginning to deliver its payload – may beg to differ. I argue that all things considered, Big Data will likely cease to exist, not so much because it is a fad but quite likely because all data will eventually be Big Data. In this essay, with the law of diminishing returns in the back of my mind, I use diverse examples, in an effort to shed some light on the question of “how much data do we really need”. My intend is not to exhaustively explore the answers so much as it is to provoke thought among the reader. I argue that depending on the use case both a data deficit and an abundance thereof may be counterproductive and that the various stakeholders, from lay persons and data experts to firms and the society at large, are probably faced with different, and possibly conflicting, optimization problems, whereby nothing will free us from having to continuously ponder on how much data is enough data. Finally the greatest challenges that data-intensive societies are likely to face might include positive reinforcement, feedback mechanisms and data endogeneity.
C80|Exponential GARCH Modeling With Realized Measures of Volatility| We introduce the realized exponential GARCH model that can use multiple realized volatility measures for the modeling of a return series. The model specifies the dynamic properties of both returns and realized measures, and is characterized by a flexible modeling of the dependence between returns and volatility. We apply the model to 27 stocks and an exchange traded fund that tracks the S&P 500 index and find specifications with multiple realized measures that dominate those that rely on a single realized measure. The empirical analysis suggests some convenient simplifications and highlights the advantages of the new specification.
C80|La banca dati dei progetti di ricerca dei docenti del DEM afferenti all|The purpose of the paper is to illustrate both the main methodological-procedural aspects and the most significant results achieved within the first phase of an investigation, which aims to setup a database of research projects, started and not yet completed - namely still being developed by teachers and researchers who belong to the DEM - in order to increase the projects accountability and to contribute to build social responsibility. The main features of this Database should be the easy manageability and the free access by all those willing or requiring to use the scientific knowledge and expertise, available on this research framework, as a representative sample of projects of other Departments belonging to UNIFE.
C80|Micro- and Macrodata: a Comparison of the Household Finance and Consumption Survey with Financial Accounts in Austria|This article compares the results of Austria’s Household Finance and Consumption Survey (HFCS) on savings deposits and estimates on total financial assets with administrative records from the national accounts for the household sector. The microdata that are newly generated through the HFCS and the detailed (internally available) breakdown of savings deposits in the existing macrodata (financial accounts) lend themselves to a more in-depth analysis of the similarities and differences in these two sources. Comparing the data shows that the HFCSbased aggregate estimates are lower than the financial accounts data, which is in line with evidence from the literature. The article also shows, however, that the survey adequately captures the underlying patterns at the microlevel in terms of the overall financial portfolio allocation and the distribution of savings deposits over detailed breakdowns. Moreover, a simulation based on the HFCS data demonstrates the effect that the inclusion of savings deposits in the most affluent tail of the distribution has on common statistics. Undercoverage above all of the upper deposit ranges suggests an underestimation or bias in the statistics. This underestimation, however, can be shown to be relatively minor, particularly in the case of robust statistical measures, such as the median or percentile ratios.
C80|On a way to overcome strategic overbidding in open-ended stated preference surveys: A recoding approach|Stated preference (SP) surveys often use open-ended questions to elicit individuals’ willingness-to-pay values for goods, services, or policy projects. However, an open-ended format may encourage strategic overbidding, and so lead to biased value estimates. We propose a new approach, based on economic theory, to limit strategic overbidding in open-ended SP surveys: prior to the valuation question, respondents are told that their insincere responses will be (unfavourably) recoded as zeros. We develop a theoretical model and verify its predictions in a field SP study. We find that the approach works: respondents aware of subsequent unfavourable recoding of their insincere answers state significantly lower willingness-to-pay values.
C80|Can Business Owners Form Accurate Counterfactuals? Eliciting Treatment and Control Beliefs about Their Outcomes in the Alternative Treatment Status|A survey of participants in a large-scale business plan competition experiment, in which winners received an average of US$50,000 each, is used to elicit beliefs about what the outcomes would have been in the alternative treatment status. Participants are asked the percent chance they would be operating a firm, and the number of employees and monthly sales they would have, had their treatment status been reversed. The study finds the control group to have reasonably accurate expectations of the large treatment effect they would experience on the likelihood of operating a firm, although this may reflect the treatment effect being close to an upper bound. The control group dramatically overestimates how much winning would help them grow the size of their firm. The treatment group overestimates how much winning helps their chance of running a business, and also overestimates how much winning helps them grow their firms. In addition, these counterfactual expectations appear unable to generate accurate relative rankings of which groups of participants benefit most from treatment.
C80|IT-basiertes Wissensmanagement|Ausgehend von einer Diskussion der Begriffe Wissensmanagement und Wissen wird im Beitrag der Stand des Einsatzes von Informationstechnologie für das Wissensmanagement diskutiert. Im Mittelpunkt stehen Ansätze, die eine (semi-)formale Darstellung von Wissen ermöglichen und damit die Grundlage schaffen, dass der Computer selbst Wissen verarbeiten und somit auch neues Wissen generieren kann. Dieses führt einerseits zu flexibleren betriebswirtschaftlichen Anwendungen, in denen Entscheidungen unter Nutzung von regelbasiertem Wissen (semi-)automatisch getroffen werden können. Andererseits führt eine vernetzte Darstellung von Wissen im Computer dazu, Wissen schnell und im richtigen Zusammenhang aufzufinden. Die hierzu eingesetztem Techniken, Wissensrepräsentation mittels Regeln oder in Netzen, sind seit langem bekannt, wurde diese doch im Rahmen der Arbeiten zur Künstlichen Intelligenz bereits vor einigen Jahrzehnten entwickelt. Die Untersuchung konzentriert sich auf die Arbeiten seit 2011. Die Forschungen zu den Techniken der Wissensdarstellung befassen sich in diesen Jahren mit folgenden Themen: Aufbau einer Wissensbasis; Behandlung von unvollständigen oder widersprüchlichen Wissen; Einsatz von Analysetechniken (auch Data Mining) zum Erkennen von Begriffen für Ontologien; Verknüpfung von Ontologien mit regelbasierter Wissensdarstellung. Der Einsatz dieser Techniken im Wissensmanagement ist noch nicht so lange Gegenstand der Betrachtungen. Das Ziel eines IT-basierten Wissensmanagements wird von Studer (2010) als Vision formuliert, die auch weiterhin als eine Vision zu betrachten ist ...
C80|Informations- und Datenquellen zu den Finanzierungsstrukturen mittelständischer Unternehmen|Bei der Diskussion um die Finanzierung bzw. Eigenkapitalausstattung mittelständischer Unternehmen rücken gegenwärtig die Möglichkeiten zur Fremdkapitalaufnahme, neue Finanzierungsformen und damit die sich verändernden Rahmenbedingungen bei der Kreditvergabe an kleine und mittlere Unternehmen in den Vordergrund. Verschiedenste Institutionen veröffentlichen in diesem Zusammenhang, teilweise regelmäßig, entsprechende Studienergebnisse und Kennzahlen(-berichte). Der vorliegende Beitrag gibt daher einen kurzen Überblick über die Informations- und Datenquellen, die in den letzten Jahren häufig zur Erklärung des Finanzierungsverhaltens bzw. der Finanzierungsstrukturen mittelständischer Unternehmen herangezogen wurden.
C80|Refugees welcome? Introducing a new dataset on anti-refugee violence in Germany, 2014-2015|The recent rise of xenophobic attacks against refugees in Germany has sparked both political and scholarly debates on the drivers, dynamics, and consequences of right-wing violence. Thus far, a lack of systematic data collection and data processing has inhibited the quantitative analysis to help explain this social phenomenon. This paper introduces a new georeferenced event dataset on anti-refugee violence and social unrest in Germany in 2014 and 2015 based on a public chronicle. Our dataset includes information of 1645 events of four different types of right-wing violence and social unrest: demonstrations, assault, arson attacks, and miscellaneous attacks against refugee housing. After discussing how the dataset was constructed, we offer a descriptive analysis of patterns of right-wing violence and unrest in Germany in 2014 and 2015. We conclude by outlining preliminary ideas on how the dataset can be used in future research.
C80|Estimating Fixed Effects Logit Models with Large Panel Data|For the parametric estimation of logit models with individual time-invariant effects the conditional and unconditional fixed effects maximum likelihood estimators exist. The conditional fixed effects logit (CL) estimator is consistent but it has the drawback that it does not deliver estimates of the fixed effects or marginal effects. It is also computationally costly if the number of observations per individual T is large. The unconditional fixed effects logit estimator (UCL) can be estimated by including a dummy variable for each individual (DVL). It suffers from the incidental parameters problem which causes severe biases for small T. Another problem is that with a large number of individuals N, the computational costs of the DVL estimator can be prohibitive. We suggest a pseudo-demeaning algorithm in spirit of Greene (2004) and Chamberlain (1980) that delivers the identical results as the DVL estimator without its computational burden for large N. We also discuss how to correct for the incidental parameters bias of parameters and marginal effects. Monte-Carlo evidence suggests that the bias-corrected estimator has similar properties as the CL estimator in terms of parameter estimation. Its computational burden is much lower than the CL or the DVL estimators, especially with large N and/or T.
C80|Testing for heteroscedasticity in jumpy and noisy high-frequency data: A resampling approach|In this paper, we propose a new way to measure and test the presence of time-varying volatility in a discretely sampled jump-diffusion process that is contaminated by microstructure noise. We use the concept of pre-averaged truncated bipower variation to construct our t-statistic, which diverges in the presence of a heteroscedastic volatility term (and has a standard normal distribution otherwise). The test is inspected in a general Monte Carlo simulation setting, where we note that in finite samples the asymptotic theory is severely distorted by infinite-activity price jumps. To improve inference, we suggest a bootstrap approach to test the null of homoscedasticity. We prove the first-order validity of this procedure, while in simulations the bootstrap leads to almost correctly sized tests. As an illustration, we apply the bootstrapped version of our t-statistic to a large cross-section of equity high-frequency data. We document the importance of jump-robustness, when measuring heteroscedasticity in practice. We also find that a large fraction of variation in intraday volatility is accounted for by seasonality. This suggests that, once we control for jumps and deate asset returns by a non-parametric estimate of the conventional U-shaped diurnality profile, the variance of the rescaled return series is often close to constant within the day.
C80|International Data on Measuring Management Practices|"We examine methods used to survey firms on their management and organizational practices. We contrast the strengths and weaknesses of ""open ended questions"" (like the World Management Survey) with ""closed questions"" (like the MOPS). For this type of data, open ended questions give higher quality responses, but are more costly than closed question-based surveys."
C80|Modernizing Federal Economic Statistics|Official statistical data on the structure, evolution and performance of the U.S. economy are produced by a variety federal, state and local agencies. Much of the methodology, policy frameworks and infrastructure for U.S. economic measurement have been in place for decades. There are growing concerns that the economy is evolving more rapidly than are the economic statistics we use to monitor it. We discuss both the challenges and opportunities to modernizing federal economic statistics. We describe an incremental approach that federal statistics agencies can follow to build a 21st century economic measurement system.
C80|The View from Above: Applications of Satellite Data in Economics|The past decade or so has seen a dramatic change in the way that economists can learn by watching our planet from above. A revolution has taken place in remote sensing and allied fields such as computer science, engineering, and geography. Petabytes of satellite imagery have become publicly accessible at increasing resolution, many algorithms for extracting meaningful social science information from these images are now routine, and modern cloud-based processing power allows these algorithms to be run at global scale. This paper seeks to introduce economists to the science of remotely sensed data, and to give a flavor of how this new source of data has been used by economists so far and what might be done in the future.
C80|What Do People Want From Their Jobs? A Dual Factor Analysis Based On Gender Differences Drain|The objective of this paper is to offer a better understanding of the situation on emigration, with a focus on the emigration of the university-educated individuals, from 6 different Eastern European countries, namely Bulgaria, the Czech Republic, Hungary, Poland, Romania and the Slovak Republic. The main purpose of the paper is to identify what employees want from their jobs from the perspective of Herzberg’s’ two factor theory. The study wants to determine empirically the motivator-hygiene factors that have a significant impact on the overall level of Romanian employee job satisfaction using stepwise regression models, as well as to compare the existence of differences in the key dimensions of satisfaction according to workers' gender. The factor “work itself” was the most motivating aspect for Romanian employees while the least motivating aspect was “salary”. All of the job motivator and hygiene factors were moderately or substantially related to overall job satisfaction. The factors “working conditions,” “salary” and “achievement” explained the variability among Romanian employees’ overall level of job satisfaction. Furthermore, a gender analysis was conducted in order to identify if there are significant differences between men and women regarding the overall job satisfaction and the job factors resulted from the regression analysis. The empirical results of Mann-Whitney tests revealed that the gender characteristics were negligibly related to overall job satisfaction and also there are statistically significant differences between males and females about salary as one of factors that motivate employees
C80|What Piketty said in Capital in the Twenty-first Century and how economists reacted|This work rehearses the main themes of Piketty.s book and summarizes the debate it triggered. The paper dwells on the rise in the ratio of household wealth to GDP in the rich countries since the 1980s and the role played by the build-up of saving and variations in house and financial asset prices; on the various justifications put forward for the increasing income and wealth inequality that has accompanied the rise in the wealth/income ratio, especially in the US and Britain; on the relationship between the rate of return on capital and the economic growth rate; on the ties between rising income inequality and the financial crisis of 2007-08; on the feasibility of Piketty.s proposals for higher taxation of top incomes and a progressive global tax on net household wealth; and on the progress that has been made in the US and Europe in exchanging information on citizens. income and foreign assets.
C80|Resampling-ratio estimation in stratified sampling|In stratified sampling there are designs with one unit selected per stratum or when one is willing to make estimations on unplanned domains with one unit in some strata. In these cases the variance is generally estimated by the collapsed strata method, which requires identification of the strata to be collapsed previous to variance estimation. This can be quite complex in surveys with a lot of strata or variables to estimate. In this article we propose an alternative method by means of two ratio estimators based on strata means obtained from jackknife subsamples, which are easy to compute without collapsing strata. The estimators are biased and we build the expressions for them, together with their sample estimators. Some examples are given, among them, estimations with data from the Mexican employment survey and poverty measures.
C80|A Simple Improvement of the IV-estimator for the Classical Errors-in-Variables Problem|Two measures of an error-ridden explanatory variable make it possible to solve the classical errors-in-variable problem by using one measure as an instrument for the other. It is well known that a second IV estimate can be obtained by reversing the roles of the two measures. We explore a simple estimator that is the linear combination of these two estimates, that minimizes the asymptotic mean squared error. In a Monte Carlo study we show that the gain in precision is significant compared to using only one of the original IV estimates. The proposed estimator also compares well with full information maximum likelihood under normality.<br><small>(This abstract was borrowed from another version of this item.)</small>
C80|Managing the Workload: an Experiment on Individual Decision Making and Performance|The present research investigates individual decision making regarding jobs scheduling, by means of a laboratory experiment based on the “Admission Test” of the University of Bologna, in which students have to allocate effort among several tasks in a limited timespan. The experiment includes three treatments that differ in the way the test is administered to participants: either with a fixed sequence of questions, or with a fixed time per task, or with no constraints. Results show large and significant heterogeneity in treatment effects. Constraints on the answering sequence or on the time allocation for each task improved the performance of those subjects who failed to efficiently allocate their effort among the tasks, whereas negative effects were found for students who were already good in self-organizing. The study has relevant policy implications for the organization of the workload in the labor force, when different types of workers are employed. Furthermore, important intuitions on the design of the university student-selection mechanisms are also discussed.
C80|The Global Consumption and Income Project (GCIP): An Overview|We introduce two separate datasets [The Global Consumption Dataset (GCD) and The Global Income Dataset (GID)] making possible an unprecedented portrait of consumption and income of persons over time, within and across countries, around the world. The current benchmark version of the dataset presents estimates of monthly real consumption and income for every percentile of the population (a “consumption/income profile”) for more than 160 countries and more than half a century (1960–2015). We describe the construction of the datasets and demonstrate possible uses by presenting some sample results concerning the distribution of consumption, poverty and inequality in the world.
C80|La fiscalité minière en Afrique : un état des lieux du secteur de l’or dans 14 pays de 1980 à 2015|The lack of information about the mining resource rent sharing between governments and investors is an easy statement in Africa. Existing public databases are often insufficient for a deep analysis of the African tax law applied to natural resource sectors, which limits the academic and operational work. The FERDI publishes the first tax and legal database which specifies the tax regime applied to industrial gold mining companies in 14 African countries from the 1980s to 2015. The database featuring three major innovations: (i) an inventory of taxes and duties (rate, base and exemptions) payable during the prospecting phase and mining phase of a gold mining project; (ii) an entirely new level of historical depth; (iii) the link between each piece of tax information and its legal source. This database is used to make a first analysis of tax regimes and rent sharing in gold producer countries. The first results emphasize heterogeneity of tax regimes between English-speaking and French-speaking countries with a convergence of the average effective tax rates that increase in most countries following the tax reforms undertaken since 2010.
C80|Extended Yule–Walker identification of VARMA models with single- or mixed-frequency data|Chen and Zadrozny (1998) developed the linear extended Yule–Walker (XYW) method for determining the parameters of a vector autoregressive (VAR) model with available covariances of mixed-frequency observations on the variables of the model. If the parameters are determined uniquely for available population covariances, then, the VAR model is identified. The present paper extends the original XYW method to an extended XYW method for determining all ARMA parameters of a vector autoregressive moving-average (VARMA) model with available covariances of single- or mixed-frequency observations on the variables of the model. The paper proves that under conditions of stationarity, regularity, miniphaseness, controllability, observability, and diagonalizability on the parameters of the model, the parameters are determined uniquely with available population covariances of single- or mixed-frequency observations on the variables of the model, so that the VARMA model is identified with the single- or mixed-frequency covariances.
C80|On The Sources Of Heterogeneity In Banking Efficiency Literature|This study reviews the empirical literature on banking efficiency by conducting a metaâ€ regression analysis. The metaâ€ dataset consists of 1661 observations retrieved from 120 papers published over the period 2000â€“2014. While the role of study design and methodâ€ specific characteristics of primary studies is evaluated, the focus concerns regulation in banking. The results are fourfold. First, parametric methods always yield lower levels of banking efficiency than nonâ€ parametric studies. Second, banking efficiency is higher in studies using the valueâ€ added approach rather than the intermediation method. Third, efficiency scores also depend on the journal's ranking and on the number of observations and variables used in the primary papers. Finally, regulation matters: primary papers focusing on countries with a liberalized banking industry provide higher values for efficiency scores.
C80|Can business owners form accurate counterfactuals ? eliciting treatment and control beliefs about their outcomes in the alternative treatment status|A survey of participants in a large-scale business plan competition experiment, in which winners received an average of US$50,000 each, is used to elicit beliefs about what the outcomes would have been in the alternative treatment status. Participants are asked the percent chance they would be operating a firm, and the number of employees and monthly sales they would have, had their treatment status been reversed. The study finds the control group to have reasonably accurate expectations of the large treatment effect they would experience on the likelihood of operating a firm, although this may reflect the treatment effect being close to an upper bound. The control group dramatically overestimates how much winning would help them grow the size of their firm. The treatment group overestimates how much winning helps their chance of running a business, and also overestimates how much winning helps them grow their firms. In addition, these counterfactual expectations appear unable to generate accurate relative rankings of which groups of participants benefit most from treatment.
C80|Can War Foster Cooperation?|"In the past decade, nearly 20 studies have found a strong, persistent pattern in surveys and behavioral experiments from over 40 countries: individual exposure to war violence tends to increase social cooperation at the local level, including community participation and prosocial behavior. Thus while war has many negative legacies for individuals and societies, it appears to leave a positive legacy in terms of local cooperation and civic engagement. We discuss, synthesize, and reanalyze the emerging body of evidence and weigh alternative explanations. There is some indication that war violence enhances in-group or ""parochial"" norms and preferences especially, a finding that, if true, suggests that the rising social cohesion we document need not promote broader peace."
C80|Perceptions and Practices of Replication by Social and Behavioral Scientists: Making Replications a Mandatory Element of Curricula Would Be Useful|We live in a time of increasing publication rates and specialization of scientific disciplines. More and more, the research community is facing the challenge of assuring the quality of research and maintaining trust in the scientific enterprise. Replication studies are necessary to detect erroneous research. Thus, the replicability of research is considered a hallmark of good scientific practice and it has lately become a key concern for research communities and science policy makers alike. In this case study we analyze perceptions and practices regarding replication studies in the social and behavioral sciences. Our analyses are based on a survey of almost 300 researchers that use data from the German Socio-Economic Panel Study (SOEP), a multidisciplinary longitudinal multicohort study. We find that more than two thirds of respondents disagree with the statement that replications are not worthwhile, because major mistakes will be found at some point anyway. Nevertheless, most respondents are not willing to spend their time to conduct replication studies. This situation can be characterized as a “tragedy of the commons”: everybody knows that replications are useful, but almost everybody counts on others to conduct them. Our most important finding concerning practical consequences is that among the few replications that are reported, a large majority is conducted in the context of teaching. In our view, this is a promising detail: in order to foster replicability, one avenue may be to make replication studies a mandatory part of curricula as well as of doctoral theses. Furthermore, we argue that replication studies need to be more attractive for researchers. For example, successful replications could be listed in the publication lists of replicated authors. Vice versa, data sharing needs to receive more recognition, for example by considering data production and subsequent data sharing as scientific output.
C80|Stochastic approach to computation of purchasing power parities in the International Comparison Program (ICP)|The paper presents a stochastic approach based on the country-product-dummy (CPD) method for the computation of purchasing power parities (PPPs) in the International Comparison Program. The approach develops estimation strategies in conjunction with the country-product-dummy method to derive a range of multilateral index number methods for the compilation of PPPs at the basic heading level as well as at higher levels of aggregation. At the basic heading level our approach generates Jevons geometric index, arithmetic and harmonic indexes as well as the Dutot index. At higher levels of aggregation, a weighted stochastic model with alternative stochastic specifications and the method of moments (MOM) are used to derive the Geary–Khamis, Iklé, Rao and other multilateral index number methods employed in international comparisons. Expressions for computing standard errors for PPPs based on these formulae are also derived. Existence of solutions to the estimating equations derived from the weighted method of moments or the maximum weighted likelihood is also discussed. A numerical illustration based on ICP 2005 data is presented.
C80|Language, culture and institutions: Evidence from a new linguistic dataset|Kashima and Kashima's (1998) linguistic dataset has played a prominent role in the economics of culture, providing the instrumental variables used in two seminal works to identify the causal effect of culture on institutional quality. However, for economists, this dataset has a number of weaknesses, including poor overlap with a key cultural dataset and reliance on sources of linguistic information of uneven quality. We address these issues by constructing a new linguistic dataset based on an authoritative source of linguistic information, the World Atlas of Language Structures. The resulting dataset has greater overlap with key sources of cultural information, is arguably less subject to selection bias, and provides more refined information regarding key dimensions of linguistic variation. We show that the variables in this dataset are significantly correlated with commonly used measures of individualism and egalitarianism. In addition, we reexamine the key results from the literature on culture and institutions, showing the causal relationship between culture and institutions is robust to the use of the new linguistic instruments.
C80|R&D and productivity in OECD firms and industries: A hierarchical meta-regression analysis|The relationship between R&D investment and firm/industry productivity has been investigated widely following seminal contributions by Zvi Griliches and others from late 1970s onwards. We aim to provide a systematic synthesis of the evidence, using 1253 estimates from 65 primary studies that adopt the so-called primal approach. In line with prior reviews, we report that the average elasticity and rate-of-return estimates are positive. In contrast to prior reviews, however, we report that: (i) the estimates are smaller and more heterogeneous than what has been reported before; (ii) residual heterogeneity remains high among firm-level estimates even after controlling for moderating factors; (iii) firm-level rates of return and within-industry social returns to R&D are small and do not differ significantly despite theoretical predictions of higher social returns; and (iv) the informational content of both elasticity and rate-of-return estimates needs to be interpreted cautiously. We conclude by highlighting the implications of these findings for future research and evidence-based policy.
C80|Confirmation: What's in the evidence?|The difference between accommodated evidence (i.e., when evidence is known first and then a hypothesis is proposed to explain and fit the observations) and predicted evidence (i.e., when evidence verifies the prediction of a hypothesis formulated before observing the evidence) is investigated in this article. According to the purely logical approach of Bayesian confirmation theory, accommodated and predicted evidence constitute equally strong confirmation. Using a survey experiment on a sample of students, however, it is shown that predicted evidence is perceived to constitute stronger confirmation than accommodated evidence. The results show that predictions work as a signal about the scientists’ (the proposer of the hypothesis) knowledge which in turn provides stronger confirmation.
C80|La adopción de la estrategia de servitización: estudio Delphi para incrementar el conocimiento sobre la transformación del sector manufacturero|The research study described in this article seeks to bring to light the main evidence found concerning the adoption of the strategy of servitisation. The Delphi Method was used to collect statements and opinions from 33 high-ranking executives at 28 organisations of different sizes which represent an interesting cross section of the fabric of production in Britain. The findings focus on five main areas: (1) servitisation and advanced services; (2) the process of transformation: stimuli, incentives and organisational change; (3) impact on customers and manufacturers; (4) facilitators and inhibitors; and (5) the potential for businesses and for the economy. As a result, eight key points are presented here that together help to extend our knowledge of the strategic process adopted by manufacturing firms to compete on services.
C80|Fondi strutturali: un’analisi della concentrazione degli interventi su base regionale|Questo studio propone un’analisi comparativa condotta a livello regionale, del grado di concentrazione della spesa co-finanziata con i fondi strutturali, nel periodo di programmazione 2007/2013. Per le principali tipologie di spesa, si valuta attraverso l’indice di concentrazione di Herfindahl-Hirschman il livello di frammentazione degli interventi. Parte della letteratura ritiene, infatti, che la concentrazione degli investimenti in determinati settori o aree geografiche sia un aspetto sostanziale delle politiche di sviluppo. Le analisi vengono svolte sia dal punto di vista territoriale che per tipologia di spesa. Dal lavoro emerge che il finanziamento medio è maggiore nel Mezzogiorno rispetto al Centro-Nord.
C80|La fiscalité minière en Afrique : Un état des lieux sur le secteur de l’or dans 14 pays de 1980 à 2015|Le manque d’information concernant le partage de la rente minière entre les Etats et les investisseurs est un constat aisé en Afrique. Les bases de données existantes sont souvent insuffisantes pour mener une analyse détaillée des règles constituant les systèmes d’imposition africains appliqués aux secteurs des ressources naturelles ce qui limite les travaux académiques et opérationnels. Cet article présente la première base de données juridiques et fiscales qui précise le régime fiscal s’appliquant aux mines industrielles d’or dans 14 pays africains producteurs des années 1980 à 2015. La base de données présente trois innovations majeures : (i) un recensement par pays des impôts, droits et taxes (taux, assiette, exonérations) dus en phase de recherche et en phase d’exploitation d’un projet aurifère ; (ii) une profondeur historique inédite 1980 à 2015 ; (iii) l’association de chaque information fiscale à sa source juridique. Cette base de données est utilisée pour formuler une première analyse des régimes d’imposition des entreprises minières et du partage de la rente qui en découle dans les principaux pays producteur d’or. Les premiers résultats soulignent une hétérogénéité des régimes fiscaux entre pays anglophones et pays francophones, avec toutefois une convergence des taux effectifs moyens d’imposition, qui augmentent dans la plupart des pays suite aux réformes fiscales engagées depuis 2010. (La base de données est téléchargeable ici)Mots clés : Secteur minier, Or, Fiscalité des ressources naturelles, Base de données
C80|Anchoring Bias in Recall Data: Evidence from Central America|Self-reported retrospective survey data is widely used in empirical work but may be subject to cognitive biases, even over relatively short recall periods. This paper examines the role of anchoring bias in self-reports of objective and subjective outcomes under recall. We use a unique panel-survey dataset of smallholder farmers from four countries in Central America collected over a period of three years. We exploit differences between recalled and concurrent responses to quantify the degree of mental anchoring in survey recall data. We assess whether respondents use their reported value for the most recent period as a cognitive heuristic when recalling the value from a previous period, while controlling for the value they reported earlier. The results show strong evidence of sizeable anchoring bias in self-reported retrospective indicators for both objective measures (income, wages, and working hours) and subjective measures (reports of happiness, health, stress, and well-being). We also generally observe a larger bias in response to negative changes for objective indicators and a larger bias in response to positive changes for subjective indicators.
C80|Technological innovation and employment in derived labour demand models: A hierarchical meta-regression analysis|The effect of technological innovation on employment is of major concern for workers and their unions, policy-makers and academic researchers. We aim to provide a quantitative synthesis of the evidence base and the extent of heterogeneity therein. Analysing 567 estimates from 35 primary studies that estimate a derived labour demand model we report the following findings: (i) the effect on employment is positive but small and highly heterogeneous; (ii) publication selection bias reflects a tendency to support the twin hypotheses that process innovation is associated with job destruction whereas product innovation is associated with job creation; (iii) the effects of process and product innovations do not conform to theoretical predictions or narrative review findings after selection bias is controlled for; (iv) only a small part of the residual heterogeneity is explained by moderating factors; (v) country-specific effect-size estimates are related to labour-market and product-market regulation in six OECD countries in a U-shaped fashion; and (vi) OLS estimates reflect upward bias whereas those based on time-differenced or within estimators reflect a downward bias. Our findings bridge the evidence gap in the research field and point out to data quality and modeling issues that should be considered in future research.
C80|La fiscalité minière en Afrique : un état des lieux du secteur de l’or dans 14 pays de 1980 à 2015|The lack of information about the mining resource rent sharing between governments and investors is an easy statement in Africa. Existing public databases are often insufficient for a deep analysis of the African tax law applied to natural resource sectors, which limits the academic and operational work. The FERDI publishes the first tax and legal database which specifies the tax regime applied to industrial gold mining companies in 14 African countries from the 1980s to 2015. The database featuring three major innovations: (i) an inventory of taxes and duties (rate, base and exemptions) payable during the prospecting phase and mining phase of a gold mining project; (ii) an entirely new level of historical depth; (iii) the link between each piece of tax information and its legal source. This database is used to make a first analysis of tax regimes and rent sharing in gold producer countries. The first results emphasize heterogeneity of tax regimes between English-speaking and French-speaking countries with a convergence of the average effective tax rates that increase in most countries following the tax reforms undertaken since 2010.
C80|Approaches to Defining and Measuring Russia’S Internet Economy|Our study object is the Russian Internet economy, i.e. economic activities of companies relying on the Russian-language segment of the World Wide Web. The purpose of this study is to classify businesses engaged in the national Internet economy and measure its size (as a share of GDP) using official statistics. The analysis of international approaches used for such studies allowed us to classify these according to the following criteria: the direct impact of the Internet on the economy, indirect economic impact of the Internet, and its indirect impact on the social sphere. To assess the size of the Russian Internet economy we used the approaches applied by international organizations (OECD, BCG, McKinsey) for the analysis of the direct impact of the Internet on the economy [BCG (2014), McKinsey (2011), OECD (2014), etc.]. The authors singled out three sectors within the Internet economy: the sector of ICT infrastructure and its maintenance; the sector of companies doing business purely on the Internet, and the sector of companies combining an online and offline business. To assess the share of the Internet economy in GDP using the production approach we first defined the above sectors in accordance with All-Russian Classification of Economic Activities (OKVED) Rev. 1.1 and subsequently calculated gross value added (GVA) for each sector. For this purpose, the GVA data calculated by Federal Service of State Statistics (Rosstat) was disaggregated while the share of the GVA contributed by the third sector companies (i.e. combining an online and offline business) was assessed using the results of special surveys and Rosstat data. To measure the size of the Internet economy using the expenditure approach we focused on consumer spending on goods bought through the Internet, ICT equipment and Internet access as well as institutions’ expenditure for ICT equipment, fixed capital investment of enterprises engaged in Internet activities, public sector ICT spending, net exports of ICT goods and services. According to our estimates obtained by two methods such as the production approach and expenditure approach, the share of the Internet economy in GDP in 2014 amounted to 2.7 and 2.6%, respectively. Future studies would require a more detailed definition and description of the Internet-related economic activities on the basis of OKVED2 with subsequent calculation of GVA for appropriate companies as well as development of statistical tools for collecting data on household spending
C80|A Practical Approach to Testing Calibration Strategies|Abstract A calibration strategy tries to match target moments using a model’s parameters. We propose tests for determining whether this is possible. The tests use moments at random parameter draws to assess whether the target moments are similar to the computed ones (evidence of existence) or appear to be outliers (evidence of non-existence). Our experiments show the tests are effective at detecting both existence and non-existence in a non-linear model. Multiple calibration strategies can be quickly tested using just one set of simulated data. Applying our approach to indirect inference allows for the testing of many auxiliary model specifications simultaneously. Code is provided.
C80|Research parasites are beneficial for the organism as a whole: competition between researchers creates a symbiotic relationship|"In the New England Journal of Medicine, Longo and Drazen critically assessed the concept of data sharing. Their main concern is that a ""new class of research person will emerge"" that uses data, which were gathered by other researchers, for their own original research questions. The authors referred to this class of researcher as ""research parasites"". Longo and Drazen are right when they note that scientific data sharing deserves more recognition. However, they indicate that the most adequate form of recognition for data sharing is coauthorship. They suggest to work ""symbiotically, rather than parasitically, with the investigators holding the data, moving the field forward in a way that neither group could have done on its own."" Although this is true in particular cases, co-authorship as the sole instrument of credit will unnecessarily restrict the potential of data sharing. More suitable instruments for giving credit where credit is due would be a much greater appreciation of data sharing by research communities by introducing citations of data sets, bestowing awards for good datasets, and considering data ""production"" when assessing scientists' career prospects, funding applications, and research outputs.<br><small>(This abstract was borrowed from another version of this item.)</small>"
C80|Factors Influencing Female Labor Force Participation in Egypt and Germany: A Comparative Study|This paper aims to identify the major factors influencing female labor force participation (FLFP) in Egypt and Germany. On a narrow scope and given the unclear relationship between educational attainment and Egyptian FLFP, this paper seeks to examine the effect of educational attainment on the Egyptian FLFP while considering other personal and household factors. On a broader scope, the literature on FLFP illustrates that certain personal and household characteristics determine FLFP. However, the question remains, to what extent these determinants differ between Egypt and Germany. This paper attempts to shed light on understanding if and how specific demographic factors affect the Egyptian FLFP in comparison with the German FLFP. Limited dependent variable technique; Probit model is utilized to determine which factors influence FLFP in both countries. The cross sectional analysis is conducted through the use of the 2012 Egyptian Labor Market Panel Survey (ELMPS) in collaboration with Egypt’s Central Agency for Public Mobilization and Statistics (CAPMAS) and the 2012 German Socio-Economic Panel (SOEP). Findings indicate that indeed higher educational attainment increases the Egyptian female’s predicted probability of participating in the labor market. Additionally, the comparative study showed that number of factors affect FLFP in both countries, some of which has a positive influence as years of schooling and age while others with a negative impact as being a married women, living in urban areas and number of children. On the other hand some other variables impact each country differently as wealth. Additionally, it was evident that years of schooling has a higher marginal impact on Egyptian FLFP yet, age, being married and number of children have a higher marginal effect on German FLFP.
C80|The Effectiveness of Fiscal Rules - The Case of Switzerland|This paper aims to measure the effectiveness of fiscal rules. Fiscal rules are constraints on fiscal policy that limit budgetary outcomes. Some studies in the literature have examined their effectiveness using a stringency index. Arguing this index possesses some arbitrariness, this study measured the effectiveness of fiscal rules using cluster analysis. This cluster analysis resulted in dividing the data into two clusters. Using panel data of 26 Swiss cantons plus the Swiss federation over the period 1990 - 2012, a Least Squares Dummy Variable econometric model was conducted. The findings indicate that fiscal rules have a favorable effect. It was found that the frameworks of cantons in cluster 1 are more effective in decreasing cantonal deficits than those of cluster 2. Furthermore, it was found that cantons in cluster 1 have lower debt levels in comparison to cantons in cluster 2.
C80|Material flow analysis of the forest-wood supply chain: a consequential approach for log export policies in France|In the context of national policies for climate mitigation and energy transition, the forestwood sector is drawing increasing attention, not only for energy wood but also for longer-life timber products. At the same time, part of the French timber transformation industry suffers from difficulties to adapt to recent changes on global markets, which translates into net exports of raw wood and imports of transformed products, detrimental to both the trade balance and the local creation of wealth. This article first aims at objectifying this situation by undertaking the first material flow analysis of the French forest-wood supply chain. We then evaluate the potential consequences of various scenarios of raw wood exports reduction policies, namely subsidies for consumption or transformation and taxation of exports, on both economic outcomes for the different actors and material flows. We thus provide an example of coupling material flow analysis with economic modeling in an attempt to move from the diagnostic phase to the assessment of possible actions within a decision-making perspective.
C80|Measuring short and rare activities – Time diaries in criminology|Motivated by recent time use studies in criminology, this study examined whether time diaries are suitable for measuring short and rare activities such as offending. The study compared time diary data collected among 843 adolescents from the conurbation of The Hague (the Netherlands) with stylized questionnaire data from the same respondents, and with stylized questionnaire data from another sample that is representative for Dutch adolescents (N = 1849). Based on the reported offenses in the diaries (N = 101), findings indicate that time diaries may underestimate population offense rates and may not capture offenses committed by low-frequent offenders. On the other hand, time diaries seem able to measure changes in individuals’ involvement in offending over time and to capture most of the situational conditions under which offenses occur. The study concludes with suggestions for dealing with the problems associated with measuring short and rare activities.
C80|The Global Consumption and Income Project (GCIP): An Overview|We introduce two separate datasets (The Global Consumption Dataset (GCD) and The Global Income Dataset (GID)) making possible an unprecedented portrait of consumption and income of persons over time, within and across countries, around the world. The current benchmark version of the dataset presents estimates of monthly real consumption and income for every percentile of the population (a ‘consumption/income profile’) for more than 160 countries and more than half a century (1960-2015). We describe the construction of the datasets and demonstrate possible uses by presenting some sample results concerning the distribution of consumption, poverty and inequality in the world
C80|A Rough Guide to New Zealand's Longitudinal Business Database (2nd edition)|New Zealand's Longitudinal Business Database is a rich resource for understanding the behaviour of New Zealand firms. This paper provides an introductory guide to the content and structure of the data aimed at new and prospective users. Where relevant, it references other publications which provide greater detail on particular aspects of the data. It also briefly describes access protocols for researchers, and processes for updating and expanding the database.
C80|Imputation in U.S. Manufacturing Data and Its Implications for Productivity Dispersion|In the U.S. Census Bureau’s 2002 and 2007 Censuses of Manufactures, 79% and 73% of observations, respectively, have imputed data for at least one variable used to compute total factor productivity (TFP). The bureau primarily imputes for missing values using mean-imputation methods, which can reduce the underlying variance of the imputed variables. For five variables entering TFP, we show that dispersion is significantly smaller in the Census mean-imputed versus the nonimputed data. We use classification and regression trees (CART) to produce multiple imputations with observed data for similar plants. For 90% of the 473 industries in 2002 and 84% of the 471 industries in 2007, we find that TFP dispersion increases as we move from Census mean-imputed data to nonimputed data to the CART-imputed data.
C80|The Increasing Inequality of Wealth in China, 2002-2013|The inequality of wealth in China has increased rapidly in recent years. Prior to 1978 all Chinese households possessed negligible wealth. China therefore presents a fascinating case study of how inequality of household wealth increases as economic reform takes place, marketisation occurs, and capital accumulates. Wealth inequality and its growth are measured and decomposed using data from two national sample surveys of the China Household Income Project (CHIP) relating to 2002 and 2013. Techniques are devised and applied to measure the sensitivity of wealth inequality to plausible assumptions about under-representation of and under-reporting by the wealthy. An attempt is made to explain the rising wealth inequality in terms of the relationships between income and wealth, house price inflation, differential saving, and income from wealth.
C80|Възможности За Използване На Протокол Http/2 За Намаляване На Лага При Зареждане На Уеб Приложения<BR>[Opportunities for Using the Protocol HTTP/2 to Reduce Lag When Loading Web Applications]|This article examines the evolution of the protocol HTTP - from version 0.9 through 1.0, and 1.1 to version 2. The factors affecting latency and lag when loading web pages are discussed in details. The research concludes that nowadays network bandwidth plays an increasingly small role about the lag. The results of empirical research how much the lag is reduced when using HTTP/2 while loading an average by volume and by content web page are presented. In the tests are used different versions of the protocol HTTP - HTTP/1.0, HTTP/1.1, HTTPS/1.1 and HTTPS/2. An experimental software is created and an external program to simulate network latency is used.
C80|Proof-of-Sovereignty (PoSv) as a Method to Achieve Distributed Consensus in Crypto-Currency Networks|In this paper, a method to implement K-Y protocol using Distributed Consensus is discussed. Firstly, the various available methods are discussed. Then, Proof - Of - Sovereignty (PoSv) is proposed. Its mechanism is deliberated and its advantages are described vis-a-vis other methods of distributed consensus. Finally a summary of all the procedures involved in 'NationCoin Mining' is explained.
C80|A Markov Chain Estimator of Multivariate Volatility from High Frequency Data|We introduce a multivariate estimator of financial volatility that is based on the theory of Markov chains. The Markov chain framework takes advantage of the discreteness of high-frequency returns. We study the finite sample properties of the estimation in a simulation study and apply it to highfrequency commodity prices.
C80|Testing for Level Shifts in Fractionally Integrated Processes: a State Space Approach|Short memory models contaminated by level shifts have similar long-memory features as fractionally integrated processes. This makes hard to verify whether the true data generating process is a pure fractionally integrated process when employing standard estimation methods based on the autocorrelation function or the periodogram. In this paper, we propose a robust testing procedure, based on an encompassing parametric specification that allows to disentangle the level shifts from the fractionally integrated component. The estimation is carried out on the basis of a state-space methodology and it leads to a robust estimate of the fractional integration parameter also in presence of level shifts. Once the memory parameter is correctly estimated, we use the KPSS test for presence of level shift. The Monte Carlo simulations show how this approach produces unbiased estimates of the memory parameter when shifts in the mean, or other slowly varying trends, are present in the data. Therefore, the subsequent robust version of the KPSS test for the presence of level shifts has proper size and by far the highest power compared to other existing tests. Finally, we illustrate the usefulness of the proposed approach on financial data, such as daily bipower variation and turnover.
C80|Easier said than done: the divergence between soft and hard data|Between the first half of 2013 and the summer of 2014, survey data pointed to a gradual recovery of economic activity, while the hard data continued to show persistent weakness. After providing statistical evidence to support the hypothesis that, during the sovereign debt crisis, the relationship between soft and hard variables for the Italian economy has weakened, the paper evaluates some possible explanations for this gap. The micro data for the quarterly survey conducted by the Bank of Italy – Il Sole 24 Ore on growth and inflation expectations tend to rule out the hypothesis that the gap between the qualitative and quantitative indicators comes from selection effects due to the progressive exclusion from the sample of economically distressed firms. Furthermore, the prolonged recession seems to have modified firms’ expectations, leading to a downward revision of production plans and the setting of a “new normal” situation. Therefore, firms may still have expressed favorable expectations for the economic outlook in spite of cyclically slack activity.
C80|La situation financière des entreprises – Synthèse du colloque organisé par la Banque de France le 21 novembre 2014|Le récent changement de base de la comptabilité nationale, et la persistance de la très faible croissance de l’activité en France ont rendu nécessaire une mise au point sur la situation financière des entreprises en France et dans certains pays de l’OCDE. Cette évaluation de la situation des entreprises a été effectuée sous trois angles d’attaque : le premier consiste à revisiter les données en nouvelle base de la comptabilité nationale en insistant sur les changements induits pour les entreprises par le changement de base ; le deuxième tente de tirer des faits stylisés de la structure de financement des entreprises françaises à l’aide de données individuelles fines issues de deux échantillons spécifiques ; le troisième angle d’analyse permet de faire un zoom sur les comportements des entreprises en termes de financements externes en prenant appui sur diverses données recueillies au cours des mois les plus récents. Pour chacune de ces approches, les discussions sont introduites par deux experts issus des directions générales de la Banque et des institutions externes compétentes pour garantir la pluralité des points de vue et ouvrir le débat à d’autres secteurs que celui d’une banque centrale. Les débats ont conduit au constat selon lequel la situation financière des entreprises n’est pas aussi dégradée que ne le laissaient penser les données en ancienne base. Par ailleurs, la cartographie de la structure de financement et celle de l’endettement des entreprises ne sont pas homogènes ; elles dépendent notamment de la taille des entreprises. Enfin, l’analyse des sources externes de financement sur la période récente montre l’importance accrue des financements de marché et la forte diversité des sources de ces financements.
C80|The state of corporate finances: Summary of the symposium held by the Banque de France on 21 November 2014|While governments are deploying substantial resources to lower the cost of labour (tax credits for competitiveness and jobs, Responsibility Pact, etc.) and help to improve the financial position of companies, it is useful to characterise this situation using reliable metrics from different sources (national accounts, new base year, surveys, individual data, etc.).
C80|La fiscalité minière en Afrique : le secteur de l’or dans 14 pays de 1980 à 2015|The lack of information about the mining resource rent sharing between governments and investors is an easy statement in Africa. Existing public databases are often insufficient for a deep analysis of the African tax law applied to natural resource sectors, which limits the academic and operational work. The FERDI publishes the first tax and legal database which specifies the tax regime applied to industrial gold mining companies in 14 African countries from the 1980s to 2015. The database featuring three major innovations: (i) an inventory of taxes and duties (rate, base and exemptions) payable during the prospecting phase and mining phase of a gold mining project; (ii) an entirely new level of historical depth; (iii) the link between each piece of tax information and its legal source. This database is used to make a first analysis of tax regimes and rent sharing in gold producer countries. The first results emphasize heterogeneity of tax regimes between English-speaking and French-speaking countries with a convergence of the average effective tax rates that increase in most countries following the tax reforms undertaken since 2010. Codes JEL : Q38, K34, C80.
C80|The Meaning of Failed Replications: A Review and Proposal - Working Paper 399|Economists are increasingly using publicly shared data and code to check each other’s work, an exercise often called ‘replication’ testing. But this much-needed trend has not been accompanied by a consensus about what ‘replication’ means. If a follow-up study does not ‘replicate’ an original result, according to current usage of the term, this can mean anything from an unremarkable disagreement over methods to scientific incompetence or misconduct. This paper proposes an unambiguous definition of replication. Many social scientists already use the term in the way suggested here, but many more do not. The paper contrasts this definition with decades of unsuccessful attempts to standardize terminology, and argues that many prominent results described as replication tests should not be described as such. It argues that professional associations should formally adopt this definition, thereby improving incentives for researchers to conduct more and better replication tests.
C80|Big Data And The Internet Of Things|Nowadays, technology is on an evolution wave both in terms of software (complexes and complete business package software solutions) and hardware (increasing processing power for mobile devices, large consume of Internet world wide). The speed with which humans interact with the Internet, use social media and interconnect their devices with other devices is rapidly growing. This desire to stay connected is translated as an exponential growth of volumes of data. Therefore all data that is generated represents the main engine for innovation both in terms of business and technology. Based on unprecedented connectivity among objects and to collect massive amounts of data, Internet of Things (IoT) is ready to provide significant business benefits. Organizations are interested to adopt IoT as a business strategy and they must be prepared to address a number of technical and administrative challenges. The purpose of this article is to define the IoT , looking at Big Data.
C80|Generational Economics and the National Transfer Accounts|This article provides a comprehensive picture of the National Transfer Accounts (NTA), a project that aims at measuring how people produce, consume, save, and share economic resources at every age. It stands today with a unique dataset that includes 47 countries from around the world, permitting a comparative understanding of economic flows within and between generations and over time.
C80|Der Einsatz quantitativer Methoden zur Messung der Wirkung von Kunst auf junge Menschen am Beispiel einer Skulptur von Katharina Grosse<BR>[The Use of Quantitative Methods to Measure the Effect of Art on Young People Taking a Sculpture of Katharina Grosse as an Example]|"The Lionsclub Düsseldorf-Hösel participated in the acquisition of the elliptical-shaped sculpture by Katharina Grosse, art professor in Düsseldorf. This colourful work of art measures 11 x 8 meters (H x W) and was handed over on September 17, 2014 in a public ceremony. It can be found in the Ehrenhof of the Museum Kunstpalast in front of the library. The aim of the study was to find out whether this work of art has an effect on young people: This was to be done by measuring the psychological feelings by means of a semantic differential towards the location before and after the mounting of the artwork while also attempting to determine the effect by means of an open-ended question. The results are quite meaningful: In the six closed-ended questions asked the values improved significantly on the 0.1 % level in five features. In the characteristic ""fits to Düsseldorf"" a significance level of 2 % was achieved. In the open-ended question, 80 young people judged the future location very negatively: A total of 84 % negative and only 16 % positive statements. After the mounting of the artwork a further 80 young people were asked who then made 70 % positive and only 30 % negative statements. This difference is also statistically highly significant. The results of the experiment are interpreted psychologically and discussed in the light of the philosophy of science and epistemology. Finally, attention is drawn to the everyday impact assessment in corporate practice and the appropriate use of ""real"" artists in corporate and brand management is discussed."
C80|Big Data And Big Cities: The Promises And Limitations Of Improved Measures Of Urban Life|New, “big data” sources allow measurement of city characteristics and outcome variables at higher collection frequencies and more granular geographic scales than ever before. However, big data will not solve large urban social science questions on its own. Big urban data has the most value for the study of cities when it allows measurement of the previously opaque, or when it can be coupled with exogenous shocks to people or place. We describe a number of new urban data sources and illustrate how they can be used to improve the study and function of cities. We first show how Google Street View images can be used to predict income in New York City, suggesting that similar imagery data can be used to map wealth and poverty in previously unmeasured areas of the developing world. We then discuss how survey techniques can be improved to better measure willingness to pay for urban amenities. Finally, we explain how Internet data is being used to improve the quality of city services. (JEL R1, C8, C18)
C80|A piecewise method for estimating the Lorenz curve|We propose a piecewise method to estimate the Lorenz curve for grouped income data. Our illustrative application shows that the method can produce more plausible density when the income distribution data has multiple peaks and the Lorenz curve cannot be modeled satisfactorily over the entire interval with a single Lorenz curve model.
C80|A hybrid method for creating Lorenz curves|We first suggest a bi-parametric Lorenz curve and then analyze the curvature structure of the function. We then build a series of single-parameter Lorenz curves with varied curvatures, which are special cases of the rational function. A hybrid method is then introduced for creating efficient functional models for the Lorenz curve from the single-parameter functional forms. Using grouped income distribution data for the United States, we find that our proposed models perform well.
C80|About the hyperbolic Lorenz curve|In a recent paper in this journal, Wang and Smyth (2015) propose a new bi-parametric functional form for the Lorenz curve and use it to derive new parametric forms. In this paper, we demonstrate that the new bi-parametric model is a reparameterization of the hyperbolic Lorenz curve proposed by Arnold (1986). We obtain new and important properties not previously considered.
C80|Short-term uncertainty in long-term energy system models — A case study of wind power in Denmark|When wind power constitutes a larger share of the electricity production mix, credible and reliable modelling of its operation in long-term investment models becomes increasingly important. In this paper the intermittent characteristics of wind power are modelled as a stochastic parameter in a long-term TIMES model of the Danish heat and electricity sector. To our knowledge, this is not a common approach in long-term investment models, and has not been done previously in TIMES, where the short-term uncertainty of wind power is normally taken into account by a deterministic constraint that ensures excess back-up capacity. In our model, the stochasticity gives lower total energy system costs, significant lower investments in wind power, less expected electricity export and higher expected biomass consumption compared to using the traditional deterministic approach. Also, the deterministic investment strategy can be insufficient in periods with poor wind conditions. Based on our findings, we recommend using a stochastic representation of intermittent renewables in long-term investment models to provide more solid results for decision makers.
C80|Does data frequency matter for the impact of forward premium on spot exchange rate?|In this paper we take the forward premium and exchange rate literature forward by asking whether data frequency matters in that relationship. We use four frequencies of data, namely, quarterly, monthly, weekly and daily. We find that data frequencies matter both statistically and economically. More specifically, we document that investors prefer the forward premium model over a constant returns model in most countries when models are estimated using daily, weekly, and quarterly data, but not when using monthly data.
C80|Bibliometric evaluation vs. informed peer review: Evidence from Italy|A relevant question for the organization of large-scale research assessments is whether bibliometric evaluation and informed peer review yield similar results. In this paper, we draw on the experience of the panel that evaluated Italian research in Economics, Management and Statistics during the national assessment exercise (VQR) relative to the period 2004–2010. We exploit the unique opportunity of studying a sample of 590 journal articles randomly drawn from a population of 5681 journal articles (out of nearly 12,000 journal and non-journal publications), which the panel evaluated both by bibliometric analysis and by informed peer review. In the total sample we find fair to good agreement between informed peer review and bibliometric analysis and absence of statistical bias between the two. We then discuss the nature, implications, and limitations of this correlation.
C80|The internet as a data source for advancement in social sciences|Purpose - – The purpose of this paper is to recommend the use of internet data for social sciences with a special focus on human resources issues. It discusses the potentials and challenges of internet data for social sciences. The authors present a selection of the relevant literature to establish the wide spectrum of topics, which can be reached with this type of data, and link them to the papers in this Design/methodology/approach - – Internet data are increasingly representing a large part of everyday life, which cannot be measured otherwise. The information is timely, perhaps even daily following the factual process. It typically involves large numbers of observations and allows for flexible conceptual forms and experimental settings. Findings - – Internet data can successfully be applied to a very wide range of human resource issues including forecasting (e.g. of unemployment, consumption goods, tourism, festival winners and the like), nowcasting (obtaining relevant information much earlier than through traditional data collection techniques), detecting health issues and well-being (e.g. flu, malaise and ill-being during economic crises), documenting the matching process in various parts of individual life (e.g. jobs, partnership, shopping), and measuring complex processes where traditional data have known deficits (e.g. international migration, collective bargaining agreements in developing countries). Major problems in data analysis are still unsolved and more research on data reliability is needed. Research limitations/implications - – The data in the reviewed literature are unexplored and underused and the methods available are confronted with known and new challenges. Current research is highly original but also exploratory and premature. Originality/value - – The paper reviews the current attempts in the literature to incorporate internet data into the mainstream of scholarly empirical research and guides the reader through this Special Issue. The authors provide some insights and a brief overview of the current state of research.
C80|Measurement Error In Macroeconomic Data And Economics Research: Data Revisions, Gross Domestic Product, And Gross Domestic Income|We use a preanalysis plan to analyze the effect of measurement error on economics research using the fact that the Bureau of Economic Analysis both revises its gross domestic product (GDP) data and also publishes a second, theoretically identical estimate of U.S. output that only differs from GDP due to measurement error: gross domestic income (GDI). Using a sample of 23 models published in top economics journals, we find that reestimating models using revised GDP always gives the same qualitative result as the original publication. Estimating models using GDI instead of GDP gives a different qualitative result for three of 23 models (13%). (JEL C80, C82, E01)
C80|Heterogeneity in Economic Shocks and Household Spending|Large swings in aggregate household-sector spending, especially for big ticket items such as cars and housing, have been a dominant feature of the macroeconomic landscape in the past two decades. Income and wealth inequality increased over the same period, leading some to suggest the two phenomena are interconnected. Indeed, there is supporting evidence for the idea that heterogeneity in economic shocks and spending are connected, most notably in studies using local-area geography as the unit of analysis. The Survey of Consumer Finances (SCF) provides a household-level perspective on changes in wealth, income, and spending across different types of families. The SCF confirms that inequality is indeed increasing in recent decades, and the data provide support for the proposition that shocks to income and wealth are indeed related to large swings in spending across and within birth cohorts. However, the economic shocks associated with the Great Recession and changes in spending and debt to income ratios are widespread, and inconsistent with a narrow focus on the experiences and changes in behavior of particular (especially low- and modest-income) households.
C80|"Is Economics Research Replicable? Sixty Published Papers from Thirteen Journals Say ""Usually Not"""|No abstract is available for this item.
C80|Weather-adjusting employment data|First version: December 18, 2014. This version: January 12, 2015. This paper proposes and implements a statistical methodology for adjusting employment data for the effects of deviation in weather from seasonal norms. This is distinct from seasonal adjustment, which only controls for the normal variation in weather across the year. Unusual weather can distort both the data and the seasonal factors. We control for both of these effects by integrating a weather adjustment step in the seasonal adjustment process. We use several indicators of weather, including temperature, snowfall and hurricanes. Weather effects can be very important, shifting the monthly payrolls change number by more than 100,000 in either direction. The effects are largest in the winter and early spring months and in the construction sector.
C80|How Do Different Time Spans Affect The Prediction Accuracy Of Business Failure?|The prediction of business failure has been widely studied by many authors. Most of the studies focused on improve the results by applying new methodologies or by using more suitable financial information. This study aims to analyze the impact of the input data timeframe on the prediction accuracy of business failure. Using an artificial neural network, the self-organizing maps (SOM), we compare the results obtained by using 9, 6 and 3 years of input data. We concluded that the 3-year case provides a better global results despite of the 6-year case presents the lowest error type I.
C80|On the size of sheepskin effects: A meta-analysis|We use information gathered from 122 studies on the effects of high school degrees on wages in different countries worldwide to carry out a meta-analysis that shows high school degrees have a statistically significant effect on wages of nearly 8%. This effect varies either when the review is made in countries away from the tropics or when factors such as sex, race, and continent are taken into account. Our results also reveal the existence of a publication bias that tends to increase the magnitude of the sheepskin effect. Nevertheless, when the former is included into the analysis the later remains statistically significant.
C80|Los ciclos económicos departamentales en Colombia, 1960-2011|En este trabajo se estima el ciclo del PIB nacional y de algunos departamentos entre 1960 y 2011 usando el modelo de tendencia lineal local de Nelson y Plosser, así como el coeficiente de correlación entre el componente cíclico de las series del PIB departamental y nacional para clasificar sus co-movimientos. El estudio revela una diversidad de comportamientos de las fluctuaciones económicas departamentales con respecto a la nacional y, además, que las economías departamentales fuertemente procíclicas son las más diversificadas y más ricas.
C80|An exploratory analysis of disabled people accessibility to urban public transport: the use of Geographical Information Systems|The potential information available in administrative records managed by Public Administrations is vast for its value in improving the social and economic research and its utility to evaluate, judge and plan the public policies. An advance in the standardization and coordination of the information records and systems would reduce the marginal cost of operations and would update data in order to avoid the fraud and improve the transparency. Thus, the aim of this paper is merging three independent public databases that they refer to people with disabilities, their location and their accessibility to urban transport. To do this, a new and unique database is built using a Geographic Information System (GIS). It is the ability of GIS to reconcile spatial data from different sources that allows the creation of new data sets. This framework may improve the availability of needed data, promote integration of technology and encourage collaboration among firms and the public sector what would allow Public Administrations’ decision making taking into account the economic and social characteristics of the registered disabled people.
C80|Open access to research data: Strategic delay and the ambiguous welfare effects of mandatory data disclosure|Mandatory disclosure of research data is an essential feature for credible empirical work but comes at a cost: First, authors might invest less in data generation if they are not the full residual claimants of their data after the first journal publication. Second, authors might “strategically delay” the time of submission of papers in order to fully exploit their data in subsequent research. We analyze a three-stage model of publication and data disclosure. We find that the welfare effects of universal mandatory data disclosure are ambiguous. The mere implementation of mandatory data disclosure policies may be welfare-reducing, unless accompanied by appropriate incentives which deter strategic delay.
C80|Automatic Generation of Association Thesaurus Based on Domain-Specific Text Collection|The given work examines distributive approach for automatic generation of the associative thesauri of a definite domain. Distributive approach is based on assumption that presence of associative link among terms of the domain is defined by the statistics of their co-occurence in thematically related discources. The advantage of distributive approach is defined by the fact that it uses raw basic material (for example collection of documents of the domain) and it does not use additional knowledge about the domain. Distributive approach is supported only by mathematical apparatus of statistics and does not take into account neither lexical nor semantic information, that is why this approach let cover extensive lexical space of terms. However it leads to the main shortcoming of the approach, i.e. it produces excessive amount of ?unnecessary? links among words which are less informative from utilitarian point of view. For solving set problems in the given work it is suggested to use special approach represented by combination of methods of distributive statistics, latent semantic analysis and graph theory.
C80|Konut Sektöründe Kapitalizasyon Oranlarını Belirleyen Faktörler: Türkiye İçin Bir Mikro-Veri Analizi|The capitalization rate is important in demand for houses either for dwelling or for an alternative financial investment. A portfolio holder may buy a house to live in or to maintain the value of his/her financial saving. On the other hand, one may prefer a mortgage loan to buy a house to live in, instead of paying rent. A rationale for such behaviors is the capitalization rate. In this study, we utilize a set of micro-data collected from the various advertising sources open to public, and compute capitalization rates, and then estimate those rates on a set of variables related to house characteristics. Our findings show that the capitalization rates are higher for second hand houses, probably because of higher maintenance expenses. Also the size, the distance to city center, and some other factors seem to significantly affect the capitalization rates.
C80|Coevolution of finite automata with errors|We use a genetic algorithm to simulate the evolution of error-prone finite automata in the repeated Prisoner’s Dilemma game. In particular, the automata are subjected to implementation and perception errors. The computational experiments examine whether and how the distribution of outcomes and genotypes of the coevolved automata change with different levels of errors. We find that the complexity of the automata is decreasing in the probability of errors. Furthermore, the prevailing structures tend to exhibit low reciprocal cooperation and low tolerance to defections as the probability of errors increases. In addition, by varying the error level, the study identifies a threshold. Below the threshold, the prevailing structures are closed-loop (history-dependent) and diverse, which impedes any inferential projections on the superiority of a particular automaton. However, at and above the threshold, the prevailing structures converge to the open-loop (history-independent) automaton Always-Defect (ALLD). Finally, we find that perception errors are more detrimental than implementation errors to the fitness of the automata. These resultsshow that the evolution of cooperative automata is considerably weaker than expected. Copyright Springer-Verlag Berlin Heidelberg 2014
C80|Teaching Replication in Quantitative Empirical Economics|In empirical economics, a twofold lack of incentives leads to chronic problems with replicability: For authors of empirical studies providing replicable material is not awarded in the same way as publishing new irreplicable studies is. Neither is authoring replication studies. We offer a strategy to set incentives for replicability and replication. By integrating replication studies in the education of young scholars, we raise the awareness for the importance of replicability among the next generation of researchers and ensure that a big number of scientists get incentives to write replication studies: credit points and the prospect of publications at least of working papers already during their time as students. By raising the number of researchers involved in replication and by providing an infrastructure for sharing their information, on the one hand we help to lower the amount of work researchers need to put into making their studies replicable. On the other hand, we facilitate the dissemination of insights derived from replication studies. This as a side effect imposes a significant threat of detection of irreplicable research, following the cases of recently introduced wiki projects for the revelation of plagiarism. In contrast to previous efforts like the report on the American Economic Review Data Availability Compliance Project, with our project we build the basis for the first replicable review paper on reblicability as we give account of which studies were tested and which results were found in each case. After exploring several dozen studies published in highly ranked journals, we have not yet determined a single case where we see replicability is fully ensured. We identified two main problems: First, not all published results can be obtained from the replication material provided. Second, information about how the used data were obtained from the raw data is hardly ever sufficient. For our investigation, we gave seminars at several faculties. We set up a wiki project for documenting the results of our replications as well as those found in the literature. In our database, we provide information about more than 1800 empirical studies, especially with regards to the availability of material for their replication. We invite for discussion to develop standards for how to make research replicable and how to write replication studies. For this we provide information about existing projects that facilitate the sharing of material for empirical econometric research.
C80|An analysis on economic opportunity| Although economic opportunity is considered as a latent variable, it can serve as another factor in promoting growth and development. Through the construction of an economic opportunity index, this article identifies the extensity and intensity channels through which economic opportunity is created. Data on 24 variables for 184 world economies for the period 2000 to 2010 are collected for the empirical analysis. The methodology involves the use of principal component analysis in constructing three indices for the parametric and nonparametric regression analyses. The country sample is divided into OECD and non-OECD economies so as to examine their different performances. Extensity seems to be the more important channel to all economies, but for non-OECD economies, a higher performance in intensity can enrich the effect of extensity on economic opportunity.
C80|Estimation of Long Memory in Integrated Variance| A stylized fact is that realized variance has long memory. We show that, when the instantaneous volatility is a long memory process of order d , the integrated variance is characterized by the same long-range dependence. We prove that the spectral density of realized variance is given by the sum of the spectral density of the integrated variance plus that of a measurement error, due to the sparse sampling and market microstructure noise. Hence, the realized volatility has the same degree of long memory as the integrated variance. The additional term in the spectral density induces a finite-sample bias in the semiparametric estimates of the long memory. A Monte Carlo simulation provides evidence that the corrected local Whittle estimator of Hurvich et al. (2005) is much less biased than the standard local Whittle estimator and the empirical application shows that it is robust to the choice of the sampling frequency used to compute the realized variance. Finally, the empirical results suggest that the volatility series are more likely to be generated by a nonstationary fractional process.
C80|Are Household Surveys Like Tax Forms? Evidence from Income Underreporting of the Self-Employed| A large literature shows that the self-employed underreport their income to tax authorities. In this paper, we quantify the extent to which the self-employed also systematically underreport their income in U.S. household surveys. We use the Engel curve describing the relationship between income and expenditures of wage and salary workers to infer the actual income, and thus the reporting gap, of the self-employed based on their reported expenditures. On average, the self-employed underreport their income by about 25%. We show that failing to account for such income underreporting leads to biased conclusions in a variety of settings. © No rights reserved. This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 U.S.C. 105, no copyright protection is available for such works under U.S. law.
C80|The Data Revolution and Economic Analysis|"Many believe that ""big data"" will transform business, government, and other aspects of the economy. In this article we discuss how new data may impact economic policy and economic research. Large-scale administrative data sets and proprietary private sector data can greatly improve the way we measure, track, and describe economic activity. They can also enable novel research designs that allow researchers to trace the consequences of different events or policies. We outline some of the challenges in accessing and making use of these data. We also consider whether the big data predictive modeling tools that have emerged in statistics and computer science may prove useful in economics."
C80|The Data Revolution and Economic Analysis|"Many believe that ""big data"" will transform business, government, and other aspects of the economy. In this article we discuss how new data may impact economic policy and economic research. Large-scale administrative data sets and proprietary private sector data can greatly improve the way we measure, track, and describe economic activity. They can also enable novel research designs that allow researchers to trace the consequences of different events or policies. We outline some of the challenges in accessing and making use of these data. We also consider whether the big data predictive modeling tools that have emerged in statistics and computer science may prove useful in economics.<br><small>(This abstract was borrowed from another version of this item.)</small>"
C80|Forecasting With the Standardized Self‐Perturbed Kalman Filter|We propose and study the finite‐sample properties of a modified version of the self‐perturbed Kalman filter of Park and Jun (Electronics Letters 1992; 28: 558–559) for the online estimation of models subject to parameter instability. The perturbation term in the updating equation of the state covariance matrix is weighted by the estimate of the measurement error variance. This avoids the calibration of a design parameter as the perturbation term is scaled by the amount of uncertainty in the data. It is shown by Monte Carlo simulations that this perturbation method is associated with a good tracking of the dynamics of the parameters compared to other online algorithms and to classical and Bayesian methods. The standardized self‐perturbed Kalman filter is adopted to forecast the equity premium on the S&P 500 index under several model specifications, and determines the extent to which realized variance can be used to predict excess returns. Copyright © 2016 John Wiley & Sons, Ltd.
C80|A comparative study of the forecasting performance of three international organizations|This article evaluates and compares the forecasting performance of three international organizations: the United Nations, the International Monetary Fund and the World Bank. The annual forecasts made by the United Nations in the period of 1981-2011 are found to be fairly robust, in terms of bias and efficiency. In comparison, the forecasting performance of the United Nations is found to be marginally better than the other two organizations during the period of 2000-2012. However, the forecasts of all these organizations missed the Great Recession of 2009 by a large margin.
C80|Sensitivity and simmetry of Confirmation Measures|Bayesian Confirmation Measures can be used in ranking inductive rules obtained as an output when using Association Rules in database mining. Many measures of this kind have been defined and the choice of the right one can be considered as a further challenge to be faced. In this paper we try to classify them observing their sensitivity and simmetry properties.
C80|Economic Freedom Research: Some Comments and Suggestions|The Economic Freedom of the World (EFW) index is extensively used in academic research to show how economic freedom relates to a wide array of economic and social outcomes. Given this, it is important that researchers understand the goal of the index and how to properly utilize this index in their research. There seem to be several common misconceptions about the EFW index resulting from a simple misunderstanding of the index itself. This paper discusses each of these misconceptions in turn and makes suggestions for future research. This paper aims to significantly improve the quality of research using the EFW index, and possibly the EFW index itself through the development of new datasets and weighting schemes.
C80|Die Eignung des Taxpayer-Panels zur Identifizierung von Selbstständigen und Gründungen|Auf der Basis der Einkommensteuerdaten lassen sich Angaben zu Selbstständigen sowie zu Gründungen nach Tätigkeitsarten ermitteln. Bis zum Jahr 2007 ist die Anzahl der Personen mit selbstständigen Tätigkeiten auf 6,8 Millionen gestiegen. Davon entfallen rund eine Million auf Rentner/Pensionäre (Zuerwerb) und 2 Millionen auf Nebenerwerbsselbstständige. 1,6 Millionen Selbstständige üben Freie Berufe aus, davon 57 % im Haupterwerb. Das Panel kann zur Erstellung einer aktuellen Gründungsstatistik beitragen, da es Hinweise zur Struktur der Gründungen z. B. mit Informationen zum Erwerbsstatus und zur Einkunftslage der Per-sonen sowie zur Beständigkeit der Gründung gibt.
C80|Analysing Party Preferences Using Google Trends|The formation of party preferences is a complex and not yet fully understood process based on a number of factors. This process, which is of great interest for both social and political science, is usually studied using questionnaire data which has proven to be a very reliable yet often costly and limited approach. Advances in technology and the rise of the internet as a primary information source for many people have created a new approach to keep track of people s interests. The major gateways to the internet s information are the so-called search engines, and Google, arguably the most commonly used search engine, allows scientists to tap the vast source of information generated by its users search queries. In this paper we describe how this data source can be used to estimate the effect of different issues on party preferences using German voters and the German party system as an example. We find that using data provided by Google Trends can lead to a variety of interesting and occasionally counterintuitive insights into peoples party preferences.
C80|Dissatisfied with Life or with Being Interviewed? Happiness and Motivation to Participate in a Survey|Information on the number of interviewer contacts allows insights into how people's responses to questions on happiness are connected to the difficulty of reaching potential participants. Using the paradata of the German Socio-Economic Panel Study (SOEP), this paper continues such research by revealing a strong link between respondent motivation and reported happiness. Analyses of responses by future non-respondents substantiate this finding and shed light on a key question for empirical research on subjective well-being, which is whether the unhappy tend to avoid survey participation or whether the unwilling might respond more negatively when being asked about their satisfaction with life.
C80|Modeling and Forecasting the Distribution of Energy Forward Returns - Evidence from the Nordic Power Exchange|We explore intraday transaction records from NASDAQ OMX Commodities Europe from January 2006 to October 2013. We analyze empirical results for a selection of existing realized measures of volatility and incorporate them in a Realized GARCH framework for the joint modeling of returns and realized measures of volatility. An influential bias in these measures is documented, which motivates the use of a flexible and robust methodology such as the Realized GARCH. Within this framework, forecasting of the full density for long horizons is feasible, which we pursue. We document variability in conditional variances over time, which stresses the importance of careful modeling and forecasting of volatility. We show that improved model fit can be obtained in-sample by utilizing high-frequency data compared to standard models that use only daily observations. Additionally, we show that the intraday sampling frequency and method have significant implications for model fit in-sample. Finally, we consider an extensive out-of-sample exercise to forecast the conditional return distribution. The out-of-sample results for the Realized GARCH forecasts suggest a limited added value from using “traditional” realized volatility measures. For the conditional variance, a small gain is found, but for densities the opposite is the case. We conclude that realized measures of volatility developed in recent years must be used with caution in this market, and importantly that the use of high-frequency financial data in this market leaves much room for future research.
C80|A Review of Peter Temin's The Roman Market Economy|"Herein, I review Peter Temin's book, ""The Roman Market Economy"", and take the occasion to alert economists to the exciting work that is being done and could be done in the economic history of the ancient world. (JEL C80, N01, N13, N73)"
C80|An Economist's Guide to Visualizing Data|Once upon a time, a picture was worth a thousand words. But with online news, blogs, and social media, a good picture can now be worth so much more. Economists who want to disseminate their research, both inside and outside the seminar room, should invest some time in thinking about how to construct compelling and effective graphics.
C80|On the size of sheepskin effects: A meta-analysis|The authours use information gathered from 122 studies on the effects of high school diplomas on wages in different countries worldwide to carry out a meta-analysis that shows high school diplomas have a statistically significant effect on wages of nearly 8%. This effect varies whether the country is away from the tropics or whether factors such as gender, race, and continent are taken into account. The results also reveal the existence of a publication bias that tends to increase the magnitude of the sheepskin effect. Nevertheless, when the former is factored into the analysis the latter remains statistically significant.
C80|Innovation adoption and productivity growth: evidence for Europe|This paper provides an empirical verification of the relationship between innovation adoption and productivity growth. After a brief revision of the literature about the concept and main determinants of innovation adoption/diffusion, the paper provides empirical evidence of the above-mentioned relationship through means of descriptive statistics and subsequently, we study the impact that innovation adoption may have on productivity growth through a regression analysis. The analysis is made with the statistical information provided by the Community Innovation Survey in its third and fourth reports, which concern innovative activities carried out between 1998 and 2000 and between 2002 and 2004 respectively. The countries covered are the 25 EU Member States plus Iceland and Norway as well as Turkey.
C80|Bounds for the variance, design effect and coefficient of variation of proportions in two-stage cluster sampling with equal sizes|In the estimation of proportions using simple random sampling, the maximum value of the variance can be used to compute the sample size when there is no information of the variable of interest. We extend this result to the estimation of proportions under two-stage cluster sampling with equal sizes, showing the expression for the maximum variance. As a by-product it is immediate to obtain bounds for the design effect and the coefficient of variation of the proportion estimator. Some examples are given related to the computation of the bounds.
C80|Le comportement des entreprises durant la crise : quelles leçons peut-on tirer des données microéconomiques ? - Synthèse de la conférence organisée par la Banque de France les 28 et 29 novembre 2013|La conférence a mis en évidence la diversité des domaines où les données individuelles et les études économétriques peuvent contribuer à mieux cerner des mécanismes d’ajustement en période de crise : démographie des entreprises, ajustements du marché du travail, investissement, financement et positionnement des entreprises sur les marchés d’exportation.
C80|Statistical Power of Within and Between-Subjects Designs in Economic Experiments|This paper discusses the choice of the number of participants for within-subjects (WS) designs and between-subjects (BS) designs based on simulations of statistical power allowing for different numbers of experimental periods. We illustrate the usefulness of the approach in the context of field experiments on gift exchange. Our results suggest that a BS design requires between 4 to 8 times more subjects than a WS design to reach an acceptable level of statistical power. Moreover, the predicted minimal sample sizes required to correctly detect a treatment effect with a probability of 80% greatly exceed sizes currently used in the literature. Our results suggest that adding experimental periods in an experiment can substantially increase the statistical power of a WS design, but have very little effect on the statistical power of the BS design. Finally, we discuss issues relating to numerical computation and present the powerBBK package programmed for STATA. This package allows users to conduct their own analysis of power for the different designs (WS and BS), conditional on user specified experimental parameters (true effect size, sample size, number of periods, noise levels for control and treatment, error distributions), statistical tests (parametric and nonparametric), and estimation methods (linear regression, binary choice models (probit and logit), censored regression models (tobit)).
C80|Distribution Model of Manufactured Products|In this paper we presented a model for distribution of products manufactured so that the total cost of transport is minimized. The model can be applied to a number of F units that carry goods from distribution centers Cj. The plan allows for the development of transport depending on the parameter Cj.
C80|New Trends in Competitiveness through Concentration and Specialization of Industrial Sectors. Case: Nord West Region of Romania|The key factor in determining economic growth, for the entry in a market full of strong competitive forces, is economic competitiveness. In addition, the development of competitive economic advantages must be a constant process, which takes into account European trends, and the process of globalization as a whole. The paper provides an analysis of competitiveness through concentration and specialization patterns in NW Region of Romania, and by data processing reveals the most important industrial sectors in this region .Conclusions point out that the increase in competitiveness should not be seen as a process of exploiting short-term advantages but as a process of building an economic structure based on capital investment and research -development-innovation processes. In other words, a medium and long term perspective should consider a knowledge-based development of economy. Sustainable economic growth and improving living standards of the population are determined by the development of economic competitiveness in the context of global challenges (globalization of the economy, opening of international markets, rapid technological change), challenges that must be turned into opportunities for the Romanian economy.
