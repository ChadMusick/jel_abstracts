C69|A General Derivation of Axiomatizations for Allocation Rules: Duality and Anti-Duality Approach|"We offer a general derivation of axiomatizations for allocation rules, referred to as ""duality"" and ""anti-duality"" approach. We show basic properties of duality and antiduality approach. Using these properties, we can derive axiomatizations of allocation rules by taking (anti-)dual of axioms involved in axiomatizations of their self-(anti-)dual rules. As an illustration, we derive a new axiomatization of the Shapley value for bidding ring problems from using the notion of duality and axioms involved in axiomatizations of the Shapley value for airport problems. As another illustration, we derive a new axiomatization of the nucleolus for bidding ring problems from using the notion of antiduality and axioms involved in axiomatizations of the nucleolus for airport problems."
C69|Analysis of long-term challenges for agricultural markets|The Long-term Agricultural Outlook model (LAO) is a long-run partial equilibrium trade model developed by the OECD as a complementary modelling tool to AGLINK-COSIMO, a more detailed partial equilibrium model used to develop ten-year projections for agricultural markets, as reported in the annual OECD-FAO Agriculture Outlook publication. LAO describes the drivers of structural changes in global supply and demand, provides a baseline of real agricultural prices, and can be used to situate short and medium term price projections in a longer-term context. The model is also suitable for performing scenario analysis of long-term issues concerning agriculture, such as the links between food security and climate change. The model structure is similar to that of AGLINK-COSIMO, which enhances comparability, but much simpler, with highly aggregated commodity and regional groupings. The simplified structure makes it possible to make use of data on productivity growth in a way not possible in more complex models, and to investigate the role of long term drivers of productivity growth, in particular research spending. It also facilitates a focus on key macro-economic drivers of agricultural market developments. This report details the motivation, structure, and development of the model, alongside initial outputs. The baseline results indicate a lowering of real agricultural prices in the long run, as growth in global supply outpaces growth in global demand.
C69|Bilinear form test statistics for extremum estimation|This paper develops a set of test statistics based on bilinear forms in the context of the extremum estimation framework. We show that the proposed statistic converges to a conventional chi-square limit. A Monte Carlo experiment suggests that the test statistic works well in ?nite samples
C69|Simulateur pédagogique des effets de répartition des soutiens de la PAC au niveau nation|[texte en français] The latest reform of the Common Agricultural Policy (CAP), which was decided by the Member States of the European Union in 2013, has again modified some of the modalities with which the different types of direct payments are allocated to farmers. The reform concerns first Pillar « decoupled » payments as well as « coupled » payments, and leaves Member States with a great flexibility in how to implement the various policy measures inside a common framework. In this paper, we present a tool (which was developed with Excel and is compatible with the LibreOffice package) which allows to simulate the implementation of the main aspects of the reform, and to assess their impacts both in terms of payment distribution across farms and in terms of income. Being an educational tool, it is neither an academic effort which would precisely model the impact of the latest reform, nor a device which would permit to estimate the exact amount of support a specific farmer could claim in practice. It is based on the French strand of the Farm Accounting Data Network (FADN) and allows to analyse the choices made by France in 2013, shedding light on the underlying rationale which may have motivated the decisions. Because its initial purpose was the lifelong training of agricultural yet non-CAP or non-economics specialist professionals, the proposed simulation tool comes with a user-friendly interface and has also already been used for the initial training of Agrocampus Ouest students and with an even larger audience during the INRA’s 70th birthday Open Days in Rennes in 2016. Building on these experiences, we are currently incorporating this simulation tool inside an Agreenium-IAVFF MOOC dedicated to the economics of the European agricultural policy.
C69|Geographic Environmental Kuznets Curves: The Optimal Growth Linear-Quadratic Case|We solve a linear-quadratic model of a spatio-temporal economy using a polluting one-input technology. Space is continuous and heterogenous: locations differ in productivity, nature self-cleaning technology and environmental awareness. The unique link between locations is transboundary pollution which is modelled as a PDE diffusion equation. The spatio-temporal functional is quadratic in local consumption and linear in pollution. Using a dynamic programming method adapted to our infinite dimensional setting, we solve the associated optimal control problem in closed-form and identify the asymptotic (optimal) spatial distribution of pollution. We show that optimal emissions will decrease at given location if and only if local productivity is larger than a threshold which depends both on the local pollution absorption capacity and environmental awareness. Furthermore, we numerically explore the relationship between the spatial optimal distributions of production and (asymptotic) pollution in order to uncover possible (geographic) Environmental Kuznets Curve cases.
C69|Approximate super-resolution and truncated moment problems in all dimensions|We study the problem of reconstructing a discrete measure on a compact set K subset Rn from a finite set of moments (possibly known only approximately) via convex optimization. We give new uniqueness results, new quantitative estimates for approximate recovery and a new sum-of-squares based hierarchy for approximate super-resolution on compact semi-algebraic sets.
C69|Shock Diffusion in Large Regular Networks: The Role of Transitive Cycles|We study how the presence of transitive cycles in the interbank network affects the extent of financial contagion. In a regular network setting, where the same pattern of links repeats for each node, we allow an external shock to propagate losses through the system of linkages (interbank network). The extent of contagion (contagiousness) of the network is measured by the limit of the losses when the initial shock is diffused into an infinitely large network. This measure indicates how a network may or may not facilitate shock diffusion in spite of other external factors.\r\nOur analysis provides two main results. First, contagiousness decreases as the length of the minimal transitive cycle increases, keeping the degree of connectivity (density) constant. Secondly, as density increases the extent of contagion can decrease or increase, because the addition of new links might decrease the length of the minimal transitive cycle. Our results provide new insights to better understand systemic risk and could be used to build complementary indicators for financial regulation.
C69|Duality and Anti-duality for Allocation Rules in Economic Problems I: An Axiomatic Analysis|We develop the notions of duality and anti-duality for axiomatic analysis of allocation rules. First, we show basic properties of duality and anti-duality for allocation rules. Next, using the notion of duality and axioms involved in axiomatizations of the Shapley rule for airport problems, we axiomatize the Shapley rule for bidding ring problems. Finally, using the notion of anti- duality and axioms involved in axiomatizations of the nucleolus for airport problems, we axiomatize the nucleolus rule for bidding ring problems. From the approach proposed, we may derive appropriate interpretations of axioms involved in axiomatizations of economic rules.
C69|Shock Diffusion in Regular Networks: The Role of Transitive Cycles|We study how the presence of transitive cycles in the interbank network affects the extent of financial contagion. In a regular network setting, where the same pattern of links repeats for each node, we allow an external shock to propagate losses through the system of linkages (interbank network). The extent of contagion (contagiousness) of the network is measured by the limit of the losses when the initial shock is diffused into an infinitely large network. This measure indicates how a network may or may not facilitate shock diffusion in spite of other external factors. Our analysis highlights two main results. First, contagiousness decreases as the length of the minimal transitive cycle increases, keeping the degree of connectivity (density) constant. Second, as density increases the extent of contagion can decrease or increase, because the addition of new links might decrease the length of the minimal transitive cycle. Our results provide new insights to better understand systemic risk and could be used to build complementary indicators for financial regulation.
C69|Financialization and Endogenous Technological Change: a Post-Kaleckian Perspective|In post-Keynesian literature, Hein (2012a) was the first to incorporate financialization as an influential positive determinant of the rate of technological change. However, financialization is more like a two-edged sword which can affect technological progress negatively as well. We capture both the positive as well as the negative effect of financialization on technological progress which encapsulates the possibility of multiple equilibria. In analyzing the long run of the model we endogenize the financialization parameter as well. We then show how two subsystems (technological progress and financialization dynamics) when interact with each other, can produce instability and cycles for the whole system. We show that under certain circumstances, higher speed of diffusion of technological innovation, more regulated financial markets, and higher intra-class competition among firms are desirable for stabilizing the economy. Finally, we provide some policy prescriptions for the same.
C69|Simulateur pédagogique des effets de répartition des soutiens de la PAC au niveau national| The latest reform of the Common Agricultural Policy (CAP), which was decided by the Member States of the European Union in 2013, has again modified some of the modalities with which the different types of direct payments are allocated to farmers. The reform concerns first Pillar « decoupled » payments as well as « coupled » payments, and leaves Member States with a great flexibility in how to implement the various policy measures inside a common framework. In this paper, we present a tool (which was developed with Excel and is compatible with the LibreOffice package) which allows to simulate the implementation of the main aspects of the reform, and to assess their impacts both in terms of payment distribution across farms and in terms of income. Being an educational tool, it is neither an academic effort which would precisely model the impact of the latest reform, nor a device which would permit to estimate the exact amount of support a specific farmer could claim in practice. It is based on the French strand of the Farm Accounting Data Network (FADN) and allows to analyse the choices made by France in 2013, shedding light on the underlying rationale which may have motivated the decisions. Because its initial purpose was the lifelong training of agricultural yet non-CAP or non-economics specialist professionals, the proposed simulation tool comes with a user-friendly interface and has also already been used for the initial training of Agrocampus Ouest students and with an even larger audience during the INRA’s 70th birthday Open Days in Rennes in 2016. Building on these experiences, we are currently incorporating this simulation tool inside an Agreenium-IAVFF MOOC dedicated to the economics of the European agricultural policy.
C69|Farkaseva lema: elementarni dokaz i ekonomske primjene|U ovom radu donosimo elementarni dokaz Farkaseve leme. U matematici je Farkaseva lema vrlo bitna činjenica koja se koristi u teoriji optimizacije, primjerice u izvođenju Karush-Khun-Tuckerovih uvjeta optimalnosti u slučaju ograničenja u obliku nejednakosti kod nelinearnog programiranja, te u dokazivanju dualnih teorema za linearno programiranje. Iako je Farkasevu lemu vrlo jednostavno iskazati, njezin dokaz nije trivijalan (većina dokaza se temelji na netrivijalnim rezultatima iz područja optimizacije i (linearne) algebre), o čemu govori i podatak da su ju mnogi na različite načine dokazivali još od 1972. (pa i ranije) sve do danas, nadmećući se pritom tko će ponuditi jednostavniji dokaz. U ovom radu Farkasevu lemu dokazujemo na elementaran način koristeći matematičku indukciju. Dokaz ove leme matematičkom indukcijom je poznat u stranoj, ali ne i u domaćoj literaturi. Stoga je cilj ovog rada revidirati taj dokaz, ispraviti postojeće nedostatke i pogreške, te detaljno objasniti svaku stavku dokaza, nekoristeći pritom složene termine i činjenice iz područja optimizacije i algebre. Osim samog dokaza Farkaseve leme, navodimo i njezine dvije primjene u ekonomiji, čime želimo, s jedne strane, približiti i objasniti Farkasevu lemu na razumljiv način čitateljima koji po svom zvanju nisu matematičari, ali ju koriste u svom radu, te s druge strane doprinijeti razumijevanju samog iskaza Farkaseve leme kroz konkretne primjere.
C69|The Development And The Current Status Of The Capital Market Hypotheses: A Few Benchmarks|The capital markets are in continuous development and change, which raises the question whether the market hypotheses are still relevant and statistically valid in the present times. Thus, this paper presents an analysis of the development and the current status of the capital market hypotheses. Moreover, the paper presents a summary of the tests used to assess form efficiency in a developing market, and of the research methods used to detect chaos in a financial time series.
C69|Optimal targeting strategies in a network under complementarities|The paper analyzes the optimal targeting strategies of a planner (a governmental agency, a firm) who aims to increase the aggregate action of a population. The agents interact through a social network and react to their exposure to neighbors' actions. The reaction function describes, for example, the best response in a strategic game, a mechanical influence in a contagion disease or a mimetic behavior. The reaction is assumed to be increasing in exposure, resulting in complementarity in actions. When it is linear, the optimal planner's strategies are explicit, characterized by well-known centralities indices computed on the bilateral impacts. When the reaction function is concave or convex, the optimal strategies depend not only on the impacts but also on the pattern of agents' attentions. The value of information on the interaction structure is shown to be (almost always) positive and related to some form of heterogeneity between agents.
C69|Saver types: An evolutionary-adaptive approach|"We set up an agent-based macromodel focusing on consumption-saving without the assumption of utility maximization, but preserving certain ""rational"" aspects of human choice based on the idea of ecological rationality Todd et al. (2012). In this framework we address the classical problem of the efficiency of long-run capital accumulation. Three qualitatively different saving strategies are defined: 1. buffer stock saving (prudent and forward looking), 2. permanent income saving (forward looking without prudence), and 3. myopic saving (caring only about immediate consumption, and saving accidentally). In the model these types (that have subtypes depending on continuous parameters) may coexist, and we explore their respective survival chances by conducting simulations. It is found that prudent saving behavior becomes prevalent when the selection pressure is very high, but an economy comprising only prudent households tends to accumulate capital in excess of what is implied by the Golden Rule. As selecion pressure is reduced, myopic consumers appear, and under very low selection pressure the distribution of the main saver types becomes almost random. A seemingly puzzling fact emerges: the economy gets close to the Golden Rule of capital accumulation via endogenous selection of subtypes in a way that can be interpreted as ""perverse exploitation"", i.e. the exploitation of the rich by the poor. In other words, lowering the intensity of evolutionary forces, that results in more diversity in saver types, may be socially beneficial. Crickets may be useful for society as a whole, including prudent and cautious ants."
C69|Matrix representation of TU-games for Linear Efficient and Symmetric values|The aim of this article is to present a new tool for assessing TU-game based on a matrix representation. We focus on TU-games with coalition structures and provide a general matrix form of TU-game. We shed light on some useful properties of the matrix representation of TU-game and the general form obtained is applied to describe the representation for some classical TU-game. The facilities provided by such a representation are used to characterize subclasses of Linear Efficient and Symmetric (LES) values.
C69|On the relationship between GHGs and Global Temperature Anomalies: Multi-level rolling analysis and Copula calibration|The relationship between GHG emissions and global warming is studied through multi-level rolling analysis to assess whether or not there are increasing rates in global change as a result of higher levels of anthropogenic emissions, as we move forward in time. Furthermore, in order to assess whether we observe tail-dependence, representing simultaneous occurrence of extreme events, we employ copula methods. Our main findings do not support views of increasing rates in global climate change as a result of higher levels of emissions. On the contrary, they suggest a constant or even a decreasing effect of emissions on temperature anomalies especially from 2005 onward. At the same time, our copula calibration shows that the Frank copula achieves the best fit. Since the Frank copula is a copula that assigns a low probability to joint extreme events, our analysis does not show tail dependence.
C69|Measuring the influence of energy prices within the price formation mechanism| Environmental economics has proposed the taxation on energy as an effective way to mitigate the pollution caused by the production and use of energy based on fossil fuels. From a practical point of view, however, taxes on energy are thought to have a detrimental impact on the economy that reduce competitiveness and diminish economic welfare, especially if the tax burden is (completely or partially) translated to final prices. This paper provides a method to analyse by how much energy prices influence the price formation mechanism of an economy. The model used, which captures the general equilibrium channels existing among energy activities, the rest of the production system and households, is based on the accounting identities reflected in a Social Accounting Matrix (SAM). The SAM price model allows to identify the role of energy prices into the cost transmission and the price definition process. The empirical application, which is for the Catalan economy, shows a considerable influence of energy prices on both production and final prices. The results also show that the different forms of energy exert asymmetric impacts on the costs of sectors and consumers. Keywords: energy prices, cost linkages, price transmission, social accounting matrix. JEL Classification: C69. D58. Q41.
C69|Beyond wishful thinking: Explorative Qualitative Modeling (EQM) as a tool for achieving the Sustainable Development Goals (SDGs)|The UN's Sustainable Development Goals in their generalized form need to be further reflected in order to identify synergies and trade-offs between their (sub-)targets, and to apply them to concrete nations and regions. Explorative, qualitative cause and effect modeling could serve as a tool for adding crucial factors and enabling a better understanding of the interrelations between the goals, eventually leading to more informed concrete measures better able to cope with their inherent obstacles. This work provides and describes a model that could serve as a template for concrete application. The generalized model already points to some potential ambivalences as well as synergies that can be reflected on using some of the latest theories and concepts from economics and transition research, among other fields. Its first analyses cautiously raise doubts that some possible assumptions behind the original Sustainable Development Goals might overlook some systemic boundaries. For example, an undifferentiated increase of productivity contradicts a lessened environmental impact and need for resources in light of potential planetary boundaries.
C69|A Model of the International Steam Coal Market (COALMOD-World)|Coal is at the core of the debate about climate change mitigation policies, yet the internationalmarket for it is not well represented in most energy models. This paper presents the COALMODframework which is a model of the international steam coal market that can be readily used toexplore implications of climate policies, but also to analyze market structure or to investigate issue ofsupply security. It features a detailed representation of both domestic and international steam coalsupply, based on endogenously calculated Cost, Insurance, Fright (CIF) costs, and prices that take intoaccount additional rents. It features endogenous investment into production, land transport, andexport capacity, as well as an endogenous mechanism assessing production cost increase due toresource depletion. We provide a detailed model and data description and illustrate the features ofthe model by analyzing to scenarios derived from the IEA World Energy Outlook (New Policies and450ppm scenario), highlighting the functionalities of the model.
C69|Fast convergence in evolutionary models: A Lyapunov approach|Evolutionary models in which N players are repeatedly matched to play a game have “fast convergence” to a set A if the models both reach A quickly and leave A slowly, where “quickly” and “slowly” refer to whether the expected hitting and exit times remain bounded when N tends to infinity. We provide simple and general Lyapunov criteria which are sufficient for reaching quickly and leaving slowly. We use these criteria to determine aspects of learning models that promote fast convergence.
C69|Effects of the German Renewable Energy Act on structural change in agriculture – The case of biogas|The strong political support for biogas production in Germany over the past decade has greatly affected agricultural production, farms and land markets. This paper analyzes the effects of Germany's biogas policies on agricultural development by using the agent-based simulation model AgriPoliS. Particular focus is placed on the effects of the previous German Renewable Energy Act (REA, German “EEG”) of 2012, as well as the latest amendments, which were added in 2014. Our results show that under the previous REA and its predecessors, biogas production provided an attractive investment opportunity, especially for large farms, which led to a boost in biogas production. However, this policy also caused distortions within the agricultural sector, including increasing land rental prices. These effects particularly threatened farms that were not able to invest in biogas, as well as smaller biogas farms. On average, biogas farms could not increase their profitability. The main reason for this effect can be seen in the fact that a significant share of the value added is transferred via increased rental prices to land owners. The amendment of the REA in 2014, which reduced support levels substantially, partly attenuates some of these effects, though the previous policy will cast a long shadow.
C69|Effects of the German Renewable Energy Act on structural change in agriculture – The case of biogas|The strong political support for biogas production in Germany over the past decade has greatly affected agricultural production, farms and land markets. This paper analyzes the effects of Germany's biogas policies on agricultural development by using the agent-based simulation model AgriPoliS. Particular focus is placed on the effects of the previous German Renewable Energy Act (REA, German “EEG”) of 2012, as well as the latest amendments, which were added in 2014. Our results show that under the previous REA and its predecessors, biogas production provided an attractive investment opportunity, especially for large farms, which led to a boost in biogas production. However, this policy also caused distortions within the agricultural sector, including increasing land rental prices. These effects particularly threatened farms that were not able to invest in biogas, as well as smaller biogas farms. On average, biogas farms could not increase their profitability. The main reason for this effect can be seen in the fact that a significant share of the value added is transferred via increased rental prices to land owners. The amendment of the REA in 2014, which reduced support levels substantially, partly attenuates some of these effects, though the previous policy will cast a long shadow.
C69|Cuantificación de los efectos de la disminución de remesas internacionales dirigidas a las regiones urbanas y rurales de México en 2002 mediante el uso de una matriz de contabilidad social|En este artículo, se estiman los efectos multisectoriales de una reducción de las remesas internacionales que recibieron los hogares mexicanos en 2002. Para ello, se usa una matriz de contabilidad social correspondiente a 1996 en la que se desglosan las regiones rurales de México, actualizada a 2002 y balanceada con el método de entropía. Los resultados muestran que los efectos fueron mayores en la producción sectorial de agriculturaganadería, manufactura alimentaria, comercio, servicios y transporte. Además, el factor productivo más afectado globalmente es el trabajo urbano ligado a los sectores comercio y transporte, otros servicios y servicios profesionales. Con una baja de 10% en las remesas, el PIB se reduce 1%. La mayor parte de la afectación total corresponde a la región urbana (0.27%) y marginalmente a las rurales (0.01%).
C69|No bullying! A playful proof of Brouwer's fixed-point theorem|We give an elementary proof of Brouwer's fixed-point theorem. The only mathematical prerequisite is a version of the Bolzano-Weierstrass theorem: a sequence in a compact subset of n-dimensional Euclidean space has a convergent subsequence with a limit in that set. Our main tool is a `no-bullying' lemma for agents with preferences over indivisible goods. What does this lemma claim? Consider a finite number of children, each with a single indivisible good (a toy) and preferences over those toys. Let's say that a group of children, possibly after exchanging toys, could bully some poor kid if all group members find their own current toy better than the toy of this victim. The no-bullying lemma asserts that some group S of children can redistribute their toys among themselves in such a way that all members of S get their favorite toy from S, but they cannot bully anyone.
C69|Cohesion and Competition of Europe: Innovation Policy from the Perspective of Networks and Entropy|This study analyzes the innovation performance of the European Union in the context of the European Research Area (ERA). Literature related to the Systems of Innovation, network studies, Framework Programs and the European Research Area will be used to establish a theoretical framework for policy analysis. It forms a database from three different resources to establish a European Research and Innovation Network, which appears as a result of policy and program implementation at the European level. The evaluation of the European Union’s innovation performance is discussed for developing policy recommendations, which are derived from theoretical arguments as well as analytical studies, based on network analysis and the notion of entropy. The implementation of a relatively simple rule by the European Commission, in addition to policies focusing on the development of countries’ diversity and absorptive capacity, which are structural holes, may make an important contribution to improving cohesion and competition within the European Research Area, as well innovation in the European Union.
C69|Cohesion and Competition of Europe: Innovation Policy from the Perspective of Networks and Entropy|This study analyzes the innovative potential of the European Union in the context of the European Research Area (ERA). Literature related to the Systems of Innovation, network studies, Framework Programs and the European Research Area will be used to establish a theoretical framework for policy analysis. It forms a database from three different resources to establish a European Research and Innovation Network, which appears as a result of policy and program implementation at the European level. The evaluation of the European Union’s innovative potential is discussed for developing policy recommendations, which are derived from theoretical arguments as well as analytical studies, based on network analysis and the notion of entropy. The implementation of a relatively simple rule by the European Commission, in addition to policies focusing on the development of countries’ diversity and absorptive capacity, which are structural breakdowns, may make an important contribution to improving cohesion and competition within the European Research Area, as well innovation in the European Union.
C69|Decision Making And Saint Petersburg Paradox: Focusing On Heuristic Parameters, Considering The Non-Ergodic Context And The Gambling Risks|The Saint Petersburg Paradox is still a contemporary issue because of the great impact on the probabilistic theory and decision-making. This article proposes some hints on avoiding the trap of the infinite expected value (EV). The highly stochastic mechanism and its EV have always to be contextualized in the limited period where we take our choices taking into account all possible limitations deriving from the theory (including the non-ergodic features and some inappropriate consequences we may attribute to the EV). This contextualisation is one of the most important factors to consider especially when we deal with infinite quantity coming from models that may misrepresent our field of application and therefore generate paradoxes.
C69|A magyarországi távhő-szabályozás modellezése. A megújuló energiára alapozott hőtermelés<BR>[Modelling policy options in the district heating sector, with a focus on renewable consumption]|Cikkünkben a magyarországi távhőszektor jövőbeli fejlődési lehetőségeit vizsgáljuk, amely a teljes hőfogyasztás 15 százalékát adja. Mind a hazai, mind az uniós dokumentumok kiemelten hangsúlyozzák a fenntartható, megfizethető és biztonságos energiaellátást. Ezt az elvet szem előtt tartva a magyarországi táv hő szek tor elemzésére kifejlesztettünk egy tökéletes versenyzői viselkedést feltételező alulról felfelé építkező, szektorális modellt. Ennek segítségével a különböző szabályozóeszközök hatását vizsgáltuk a hőtermelés költségére és a megújuló energia alkalmazására. Eredményeink alapján a beruházási és működési támogatások hatékony eszköznek bizonyulhatnak a szektor piaci részesedésének fenntartásához/növeléséhez, ezzel szemben a távhő végfelhasználói árának támogatása, illetve a kapcsolt támogatás nem vezet optimális eredményhez, a távhő részesedése a hőpiacból jelentősen csökkenhet. A jelenlegi magyarországi távhő-szabályozási rendszerről elmondható, hogy a távhő kedvezményes forgalmi adója és a kapcsolt erőművek támogatása pontosan ez utóbbi eszközt alkalmazza, míg a megújuló energiára alapozott távhőtermelés beruházási támogatása csak kismértékben jelenik meg, a hőtermeléshez kapcsolódó működési támogatások pedig szinte teljesen hiányoznak a hazai támogatási palettáról. Journal of Economic Literature (JEL) kód: C69, Q42, Q48.
C69|The Principle of Social Scaling|This paper motivates the content and analytical significance of processes of “social scaling” in competitive economic settings, postulating a general Principle that describes the regulations they impose on the functioning of certain economic systems. Economic competition often defines behavioral relationships between individual measures of certain variables and average or social measures of themselves. These relationships ensure a number of behaviorally significant economic variables are socially scaled measures. Individual values of such variables are subject to systemic interdependences, which may take the form of aggregate first-moment constraints on their distributions. The paper shows how processes of social scaling in capital and labor markets can help account for the observed frequency distributions of wage income and Tobin’s q, suggesting such processes may be a pervasive in economic systems. Finally, the paper’s discussion illustrates and motivates the distinctive usefulness of statistical-mechanical methods in Economics, both in defining new conceptualizations of the relationship between individual agencies and aggregate regulations in economic systems, and in the development of logically robust observational methods in economic analysis.
C69|Analysis of average value of a Fourier series using z-transform: comparison with Hodrick-Prescott filter|This paper develops a method of analyzing average value of a complex-valued function that can be represented as a Fourier series satisfying a few realistic restrictions. This method may be useful when Discrete Fourier transform is highly inefficient, and comparison with Hodrick-Prescott filter is made.
C69|A three-pole filter understanding of the average value of a Fourier series|This paper extends the idea in ``Analysis of average value of a Fourier series using z-transform'' by the author. The main difference is that a three-pole filter is used instead of a two-pole filter. This paper reaches qualitatively the same conclusion.
C69|Revize monetárního modelu Marca Lavoieho endogenizací parametru gama|Revision of Marc Lavoie’s Monetary Model by the Endogenization of the Parameter γ This paper tries to point out a fallacy in Lavoie’s (2006) conclusion that incorporation of deep endogeneity of parameters into the PKA model suffices to bring about irreversibility of such a system. The arguments of the authors are supported by Setterfield’s (1998a, 2008) concept of hysteresis as path-dependence in the long-run outcome of systems with direct shocks. The paper shows that extension of Lavoie’s PKA model by deep endogeneity of the parameter γ causes the fulfillment of the necessary condition of hysteresis - Setterfi eld’s condition (a) ensuring deep endogeneity of the alleged exogenous parameter and, by means of this, path dependence in the long-run output - but not the fulfi llment of the sufficient condition of hysteresis - condition (c) ensuring the presence of adjustment asymmetry and, by means of this, irreversibility. Thus, deependogenisation of the parameter γ does not bring about Setterfi eld’s hysteresis and, in effect, does not cause irreversibility.
C69|Об одном подходе к оценке эффективности инновационного территориального кластера в сырьевом регионе. An approach to the evaluation of the effectiveness of innovative territorial cluster in the feed region|Рассматривается концептуальная совокупность экономико-математических задач, решение которых позволяет оценивать оптимизированную предполагаемую эффективность инновационного территориального кластера объединяющего добывающие и перерабатывающие сырье производства, в трех ее проявлениях – для региональной экономики, для самого кластера как интеграционной структуры, создающей системный и синергетический эффект для его участников; для каждого из участников кластера, ожидающих проявление эффекта от диверсификации их деятельности. Иначе говоря, речь идет о триединой эффективности создаваемого или действующего кластера. В качестве примера рассматривается пилотный инновационный территориальный кластер «Комплексная переработка угля и техногенных отходов» в Кемеровской области. The article discusses the conceptual set of economic-mathematical problems, the solution of which allows to evaluate the optimized estimated efficiency of innovative regional clusters bringing together mining and processing raw materials production, in its three forms – for the regional economy, for the cluster itself as an integration structure that creates a systematic and synergetic effect for its participants; for each of the cluster members, pending the manifestation of the effect of the diversification of their activities, that is, in an article talking about the triune efficiency created or existing cluster. As an example, the article is considered a pilot innovative territorial clusters «Complex processing of coal and industrial waste» in Kemerovo region.
C69|A Decision Making Method Obtained By Reducing Soft Matrices|Soft matrices was firstly defined by Ça?man and Engino?lu [3]. These are representations of soft sets, introduced by Molodtsov [1], for modelling vagueness and uncertainties inherent in the problems of engineering, physical science, biological science, economics, social science, medical science, etc. Ça?man and Engino?lu [3], presented a decision making method, called soft max-min decision making method, by using the concept of soft matrix. In this study, firstly, we define two new soft matrix operations and obtain some of their properties. Secondly, we construct a new decision making method by using soft matrices. The soft decision making we constructed in this study is more practical among the other decision making methods and can be successfully applied to many problems that contain uncertainties. Finally, two applications of decision making problems in which it is necessary to use these new soft matrix operations, are presented. Since this decision making method constructed on soft matrices, then it can be easily transferred to a computer.
C69|Soft Topology Derived By Soft Points And Fixed Point Functions|Abstract: Soft set theory was proposed by Molodtsov [1], for modeling vague ness and uncertainties inherent in the problems of engineering, physical science, biological science, economics, social science, medical science, etc. Recently, studies on soft set theory are progressing rapidly. Then topological structures of soft set and fuzzy soft set have been studied by many authors recently.The notion of soft topology was introduced by Ça?man [3].In the later years soft topological structures and their properties have been studied commonly. In this study, we introduce a new approach to soft topology. We construct anew structure by giving the notion of soft points and the fixed point functions. This definition enables us to define soft usual topology. So we can study on soft path-connectedness by this way.
C69|Bijective Soft Matrix Theory And Its Applications|Soft set theory was firstly introduced by Molodtsov [1].In the papers[1,2,3], the soft set theory was succesfully applied in several directions, such as smoothness of functions, gametheory, operations research, riemann integration, Perron integration, probability, theory of measurement and so on.Gong et al.[4] presented bijective soft set theory. Since it is easy to store and manipulate matrices, transferring of bijective soft sets to soft matrices is very useful. Soft matrices which are representations of soft sets was firstly defined by Ça?man and Engino?lu[5]. In this study, we construct bijective soft matrix theory and investigate some properties of bijective soft matrices, in detail. We demonstrate some matrix operations are preserved for bijective soft matrices, such as AND product.Finally, we indicate that can use the bijective soft matrices in decision making problems.
C69|Second order multiscale stochastic volatility asymptotics: stochastic terminal layer analysis and calibration|Abstract Multiscale stochastic volatility models have been developed as an efficient way to capture the principal effects on derivative pricing and portfolio optimization of randomly varying volatility. The recent book by Fouque et al. (Multiscale Stochastic Volatility for Equity, Interest-Rate and Credit Derivatives, 2011) analyzes models in which the volatility of the underlying is driven by two diffusions – one fast mean-reverting and one slowly varying – and provides a first order approximation for European option prices and for the implied volatility surface, which is calibrated to market data. Here, we present the full second order asymptotics, which are considerably more complicated due to a terminal layer near the option expiration time. We find that to second order, the implied volatility approximation depends quadratically on log-moneyness, capturing the convexity of the implied volatility curve seen in data. We introduce a new probabilistic approach to the terminal layer analysis needed for the derivation of the second order singular perturbation term, and calibrate to S&P 500 options data.
C69|The algebraic approach to some ranking problems|The problem of ranking a set of elements, namely giving a “rank” to the elements of the set, may arise in very different contexts and may be handled in some possible different ways, depending on the ways these elements are set in competition the ones against the others. For example there are contexts in which we deal with an even paired competition, in the sense the pairings are evenly matched: if we think for example of a national soccer championship, each team is paired with every other team the same number of times. Sometimes we may deal with an uneven paired competition: think for example of the UEFA Champions League, in which the pairings are not fully covered, but just some pairings are set, by means of a random selection process for example. Mathematically based ranking schemes can be used and may show interesting connections between the ranking problems and classical theoretical results. In this working paper we first show how a linear scheme in the ranking process directly takes to some fundamental Linear Algebra concepts and results, mainly the eigenvalues and eigenvectors of linear transformations and Perron–Frobenius theorem. We apply also the linear ranking model to a numerical simulation taking the data from the Italian soccer championship 2015-2016. We finally point out some interesting differences in the final ranking by comparing the actual placements of the teams at the end of the contest with the mathematical scores provided to teams by the theoretical model.
C69|Job placement agencies in an agent-based model of the local labor market with the long-term unemployed and on-the-job flows|In this paper, an agent-based search model of the labor market with heterogeneous agents and an on-the-job search is developed, i.e. the long-term unemployed and other job seekers compete for vacancies which differ in skills demands and in the sector of the economy. Job placement agencies help both types of unemployed persons find the proper vacant job by improving their search effectiveness and by sharing leveraged job advertisements. The agents' interactions take place in an artificial world drawn from labor market search theory. Six global model parameters were calibrated with the Latin hypercube sampling technique for one of the largest urban areas in Poland. To investigate the impact of parameters on model output, two global sensitivity analysis methods were used, i.e. Morris screening and Sobol indices. The results show that both programs considerably influence unemployment and long-term unemployment ratios as well as the level of wages, duration of unemployment, skills demand and worker turnover. Moreover, strong cross-effects were detected: programs aimed at one group of job seekers affect other job seekers and the whole economy. This impact is sometimes positive and sometimes it is negative.
C69|Job placement agencies in an artificial labor market|In this paper, an agent-based search and matching (ABSAM) model of a local labor market with heterogeneous agents and an on-the-job search is developed, i.e. job seekers who vary in unemployment duration, skills levels and preferences compete for vacancies which differ for skills demands and the sector of the economy. Job placement agencies help unemployed persons find appropriate job vacancies by improving their search effectiveness and by sharing job advertisements. These agents cooperate in an artificial labor market where the key economic conditions are imposed. The interactions between the participants are drawn directly from labor market search theory. The main research task was to measure the direct and indirect impacts of labor market policies on labor market outcomes. The global parameters of the ABSAM model were calibrated with the Latin hypercube sampling technique for one of the largest urban areas in Poland. To study the impact of parameters on model output, two global sensitivity analysis methods were used, i.e. Morris screening and Sobol indices. The results show that the job placement agencies' services, as well as minimum wage and unemployment benefits, considerably interact with and influence unemployment and long-term unemployment ratios, wage levels, duration of periods of unemployment, skills demand, and worker turnover. Moreover, strong indirect effects were detected, e.g. programs aimed at one group of job seekers affected other job seekers and the whole economy. This impacts are sometimes positive and sometimes negative.
C69|Effects of the Renewable Energy Act on structural change in Agriculture- The case of biogas| Biogas production affected agricultural and land markets significantly. This paper provides insights in effects of biogas production on farms and farm structures for the period 2012-2026 in two German regions by using the agent-based simulation model AgriPoliS. We compare the agricultural development in both regions under alternative policy scenarios in order to analyze the effects of biogas production and the impact of the latest amendment in the REA in 2014. Our results show that biogas production provides especially for large farms a profitable income opportunity. However, it implies an increasing dependency of these farms on biogas production and their whole production structures change. Due to an increased competition among farms, rental prices rise. This effect threatens particularly smaller biogas farms. The last amendment of the REA in 2014 with a substantial reduction of the support level attenuates partly some of these effects.
C69|Nitrogen Trading in Lake Taupo: An Analysis and Evaluation of an Innovative Water Management Policy|This paper provides an overview and early evaluation of the Lake Taupo nitrogen cap and trade programme, established as part of Waikato Regional Council’s 2011 Regional Plan Variation Five. The policy establishes a catchment-wide cap on nitrogen losses by allocating farmers individual nitrogen discharge allowances and allowing those farmers flexibility to trade allowances amongst themselves and to sell allowances to a public fund while remaining within the overall catchment cap. The Taupo trading scheme is the world’s first agricultural non-point-source water-quality cap and trade scheme. This paper explains the structure and evolution of the nitrogen trading market, and analyses its impact thus far. Research drawn from written material and descriptive quantitative data provides the basis for analysing the policy, while interviews with relevant stakeholders provide insight into the successful, surprising and contentious issues that arose throughout its development and implementation.
C69|The Squared Coefficient of Variation as an Inequality Index: A Social Evaluation Characterization|The squared coefficient of variation (C2) is a well-known index of relative inequality. However, the existing economic theory of inequality does not contain a characterization of this index in terms of the properties of the underlying social evaluation function. It is well-known that if the Atkinson-Kolm-Sen (AKS) index of relative inequality derived from a social evaluation relation defined on a space of distributions is C2, it is necessary that the relation satisfies a ¡®transfer neutrality¡¯ condition. This paper obtains a complete characterization of the index by proving the converse. It is shown that, in the presence of other standard assumptions on the social evaluation relation, transfer neutrality implies a particular social evaluation function and that the corresponding AKS relative inequality index coincides with C2. This inequality index and the corresponding social evaluation function is then applied in a relatively unexplored area of empirical research. It is shown that in India inequality (as measured by C2) in the distribution of a variable that indicates the width of accessibility of bank credit increased in the ten or so years following the introduction of economic reforms in the early 1990s. At the same time there was an increase in the average value of this indicator. The question, therefore, arises as to the direction of change of over-all social welfare from this particular attribute. The social evaluation underlying C2 implies that, on balance, there was a decline in the welfare of the country in this respect.
C69|Decentralised Defence of a (Directed) Network Structure|We model the decentralised defence choice of agents connected in a directed graph and exposed to an external threat. The network allows the players to receive goods from one or more producers through directed paths. Each agent is endowed with a finite and divisible defence resource that can be allocated to their own security or to that of their peers. The external threat is represented by an intelligent attacker who aims to maximise the flow-disruption by seeking to destroy one node. The set of the attacker’s potential targets is a subset of the set of middleman nodes and producers. These are the critical nodes with highest brokerage power in a directed network and therefore crucial to the system-flow. We show that a decentralised defence allocation is efficient when we assume perfect information: a centralised allocation of defence resources which minimises the flow-disruption coincides with a decentralised allocation. On the other hand, when we assume imperfect information, the decentralised allocation is inefficient and involves no reallocation of defence resources between the nodes. Finally, for a given connected graph, by increasing the link-density we can reduce the set of middleman nodes and thus the number of the potential targets. This also decreases the probability of a successful attack.
C69|Network design and imperfect defense|The question how to optimally design an infrastructure network that may be subject to intelligent threats is of highest interest. We address this problem by considering a Designer-Adversary game of optimal network design for the case of imperfect node defense. In this two-stage game, first the Designer defends network connectivity by forming costly links and additionally protecting nodes. Then, the Adversary attacks a fixed number of nodes, aiming to disconnect the network. In contrast to the existing literature, defense is imperfect in the sense that defended nodes can still be destroyed with some fixed probability. We completely characterize the solution of the game for attack budgets of one and two nodes, while for larger budget we present a partial characterization of the solution. To do so, we determine the minimum number of links necessary to construct a network with any degree of connectivity and any given number of essential nodes.
C69|Microeconomic Reform And Income Distribution: The Case Of Australian Ports And Rail Freight|" type=""main"" xml:id=""coep12059-abs-0001""> We analyze structural changes in the Australian ports and rail freight industries that were driven by microeconomic reform; we find such reforms may generate welfare gains with reduced inequality. We estimate the effects on household income groups of these industry changes by applying a computable general equilibrium model incorporating microsimulation behavior. The structural changes lead to a small increase in household welfare in most regions, with an overall increase of 0.18%, and a small decrease in inequality. Our analysis suggests that policy makers in Australia and other high-income nations should give serious consideration to microeconomic reform of infrastructure industries . ( JEL C68, C69, D31, L92)"
C69|Valoración de derivados europeos con mixtura de distribuciones Weibull|El modelo Black-Scholes para valoración de opciones europeas se usa bastante en el mercado por su fácil ejecución. Sin embargo, empieza a ser poco preciso en diferentes activos cuya dinámica no es de una distribución lognormal, por lo que se necesita buscar nuevas distribuciones para valorar opciones emitidas sobre diferentes activos subyacentes. Varios investigadores han trabajado en nuevas fórmulas de valoración de derivados suponiendo diferentes distribuciones ya sea para el precio del activo subyacente o para su retorno. Este artículo presenta dos fórmulas para valoración de activos: una modifica la fórmula usando una distribución de Weibull de dos parámetros propuesta por Savickas (2002) añadiendo dos nuevos parámetros (escala y localización) y otra supone que la distribución del activo es una mixtura de distribuciones de Weibull. Se presentan también comparaciones de estos modelos con otros ya existentes como Black-Scholes y el modelo de Savickas con distribución Weibull simple. ***** The Black-Scholes valuation model for European options is widely used in the stock markets due to its easy implementation. However, the model is not accurate for different assets whose dynamics do not follow those of a lognormal distribution, so it is necessary to investigate new distributions to price different options written on various underlying assets. Several researchers have worked on new valuation formulas, assuming different distributions for either the price of the underlying asset or for the return of the same. This paper presents two methods for European derivatives valuation, one of them, modifying the formula using a Weibull distribution with two parameters given by Savickas (2002) adding two new parameters (scale and location), and another assuming that the underlying distribution is a Weibull mixture. Comparisons are also presented with these models against existing models such as the Black-Scholes model and Savickas with a simple Weibull distribution.
C69|Earthquakes in the Netherlands Cannot Shake the European Natural Gas Market|The rising number of earthquakes in the northeastern part of the Netherlands has been attributed to the extraction of natural gas from the Groningen field. This has led tostrong opposition to natural gas production from the Dutch population, a matter that is increasingly preoccupying not only policy-makers on the local and provincial levels,but also the central government. In response, the Dutch government has decided a drastic reduction of production from the Groningen gas field, the largest natural gas field in the country. This has an impact on several Western European countries that import natural gas from the Netherlands. Model calculations by DIW Berlin based on a substantially reduced production of natural gas in the Netherlands show that due to diversified imports effects on the European natural gas market would only be small. Even if the lower Dutch production comes in addition to the disruption of the Russian supplies to Europe, it would not result in serious supply shortages or price increases in Western Europe since gas from other regions are possible. However, these supplies of natural gas would come partly from providers whose reliability might be called into question due to an unstable political situation, as for instance in North Africa.
C69|Liquefied Natural Gas Will Have to Play a Larger Role in the Future: Six Questions to Franziska Holz|No abstract is available for this item.
C69|Erdbeben in den Niederlanden können den europäischen Erdgasmarkt nicht erschüttern|The rising number of earthquakes in the northeastern part of the Netherlands has been attributed to the extraction of natural gas from the Groningen field. This has led to strong opposition to natural gas production from the Dutch population, a matter that is increasingly preoccupying not only policy-makers on the local and provincial levels, but also the central government. In response, the Dutch government has decided a drastic reduction of production from the Groningen gas field, the largest natural gas field in the country. This has an impact on several Western European countries that import natural gas from the Netherlands. Model calculations by DIW Berlin based on a substantially reduced production of natural gas in the Netherlands show that due to diversified imports effects on the European natural gas market would only be small. Even if the lower Dutch production comes in addition to the disruption of the Russian supplies to Europe, it would not result in serious supply shortages or price increases in Western Europe since gas from other regions are possible. However, these supplies of natural gas would come partly from providers whose reliability might be called into question due to an unstable political situation, as for instance in North Africa. Die vermehrt auftretenden Erdbeben im Nordosten der Niederlande werden auf die Förderung von Erdgas im Groningen-Feld zurückgeführt. Dadurch entstand erheblicher Widerstand gegen die Erdgasförderung in der niederländischen Bevölkerung, der über die Lokal- und Provinzpolitik hinaus zunehmend auch die Zentralregierung beschäftigt. Inzwischen hat die niederländische Regierung einen starken Rückgang der Förderung aus dem Groningen-Gasfeld, dem größten des Landes, angeordnet. Dies ist für mehrere westeuropäische Länder von Bedeutung, die aus den Niederlanden größere Mengen Erdgas beziehen. Modellrechnungen des DIW mit einer stark reduzierten niederländischen Erdgasförderung zeigen, dass der europäische Markt aufgrund diversifizierter Importe nur geringe Auswirkungen spüren würde. Selbst wenn Russland seine Exporte nach Europa zusätzlich zu der Einschränkung der Erdgasförderung in den Niederlanden einstellen würde, käme es in Westeuropa nicht zu gravierenden Versorgungsengpässen und Preiserhöhungen, da zusätzliche Importe aus anderen Regionen möglich wären. Jedoch würden diese Erdgaslieferungen teilweise von Anbietern kommen, deren Zuverlässigkeit aufgrund instabiler politischer Verhältnisse in Frage gestellt werden kann, beispielsweise Nordafrika.
C69|Flüssiggas wird künftig eine größere Rolle spielen: Sechs Fragen an Franziska Holz|No abstract is available for this item.
C69|Shaking Dutch grounds won’t shatter the European gas market|The Netherlands have been a pivotal supplier in Western European natural gas markets in the last decades. Recent analyses show that the Netherlands would play an important role in replacing Russian supplies in Germany and France in case of a Russian export disruption. Lately, however, the Netherlands have suffered from a series of earthquakes that are related to the natural gas production in the major Groningen field. By consequence, natural gas production rates – that are politically mandated in the Netherlands – have been substantially reduced, by almost 45% in 2015 compared to 2013-levels. We implement this reduced production path for the next decades in the Global Gas Model and analyse the geopolitical impacts. We find that the diversification of European natural gas imports allows spreading the replacement of Dutch natural gas over many alternative sources, with diverse pipeline and LNG supplies. There will be hardly any price or demand reduction effect. Even if Russia fails to supply Europe, the additional impact of the lower Dutch production is moderate. Hence, the European consumers need not to worry about the declining Dutch natural gas production and their security of supplies.
C69|Shaking Dutch grounds won’t shatter the European gas market|The Netherlands have been a pivotal supplier in Western European natural gas markets in the last decades. Recent analyses show that the Netherlands would play an important role in replacing Russian supplies in Germany and France in case of a Russian export disruption. Lately, however, the Netherlands have suffered from a series of earthquakes that are related to the natural gas production in the major Groningen field. By consequence, natural gas production rates – that are politically mandated in the Netherlands – have been substantially reduced, by almost 45% in 2015 compared to 2013-levels. We implement this reduced production path for the next decades in the Global Gas Model and analyse the geopolitical impacts. We find that the diversification of European natural gas imports allows spreading the replacement of Dutch natural gas over many alternative sources, with diverse pipeline and LNG supplies. There will be hardly any price or demand reduction effect. Even if Russia fails to supply Europe, the additional impact of the lower Dutch production is moderate. Hence, the European consumers need not to worry about the declining Dutch natural gas production and their security of supplies.
C69|The Use of Financial and Credit Tools to Minimize the Risks in the Organization of Production|The article describes such form of financing as import revolving leveraged leasing for the purpose of fixed assets modernization. Mathematical modeling techniques are applied in the research. According to the results of the study, the mathematical model of the generalized method of the lease payment calculation is suggested by the authors. The presented method combines several types of leasing. The novelty of this method lies in the fact that on the basis of suggested leasing types the amount of the lease payment is calculated taking into account insurance, financial and currency risks aimed at minimizing losses at downtime due to the limited use of the basic pro duction assets of the company in the production process organization. The authors suggest calculating the payment amount using a floating rate of interest. This proprietary methodology is designed to minimize the risk of production equipment downtime, which ultimately will enable to provide the stability and continuity of the production process.
C69|Reform of Australian urban transport: A CGE-microsimulation analysis of the effects on income distribution|Australian urban transport industries experienced substantial reform during the 1990s leading to significant structural change. Urban transport is typically an important expenditure item for households and structural change in these services may affect households differently depending on their position in the distribution of income and expenditure. We estimate the effects on household income groups of this structural change by applying a computable general equilibrium model incorporating microsimulation behaviour with top-down and bottom-up links. We compare estimates based on a pure microsimulation approach, a top-down approach and a hybrid top-down/bottom-up approach. We estimate small reductions in real income and small reductions in inequality; this pattern is largely replicated across regions. Our results are insensitive to the inclusion of bottom-up links; in contrast, applying a pure microsimulation approach gives accurate results at the aggregate level but underestimates the variation in effects across deciles and regions.
C69|Game, set and match: evaluating the efficiency of male professional tennis players|We exploit the natural distinction between the attacking and defensive aspects of tennis to get a better understanding of the origins of relative inefficiency. Attacking is simply when a player is serving and defending is when a player is returning serve. We use data envelopment analysis to compute the attacking, defensive and overall efficiencies of the top 100 male professional players for the 2009 season. An analysis of the efficiency scores using non-parametric kernel smoothing suggests that there are four groups of players in the sample—those that are relatively efficient in attack and defence; those that are relatively inefficient in attack and defence; and those that are relatively efficient in attack or defence. Truncated regression equations for the technical and super attacking, defensive and overall efficiencies as a function of off-court variables (e.g. height, age, etc.) suggest that being a left-handed player has a significant positive effect on the overall efficiencies. Copyright Springer Science+Business Media New York 2015
C69|Conglomerability and representations|We prove results concerning the representation of a given distribution by means of a given random quantity. The existence of a solution to this problem is related to the notion of conglomerability, originally introduced by Dubins. We show that this property has many interesting applications in probability as well as in analysis. Based on it we prove versions of the extremal representation theorem of Choquet and of Skhorohod theorem.
C69|Quantum macroeconomics theory|The quantum macroeconomics theory is formulated for the first time, assuming that the business cycle has the discrete-time oscillations spectrum in analogy with the electronics excitations discrete-time spectrum in the Bohr’s atom model in the quantum physics. The quantum macroeconomics theory postulates that the discrete-time transitions from one level of GIP((t), GDP(t), GNP(t) to another level of GIP((t), GDP(t), GNP(t) will occur in the nonlinear dynamic economic systems at the time, when: 1) The land, labour and capital resources are added / released to the production/service processes in the form of quanta; 2) The disruptive scientific/technological/financial/social/political innovation is introduced, creating the resonance conditions necessary to amplify/attenuate the value of GIP((t), GDP(t), GNP(t), during the evolution process of the nonlinear dynamic economic system in the time domain. The authors think that the general information product on the time GIP((t), the general domestic product on the time GDP(t), and the general national product on the time GNP(t), are the discrete-time digital signals (the Ledenyov discrete-time digital waves with the Markov information) in distinction from the continuous-time signals (the Kitchin, Juglar, Kuznets, Kondratieff continuous waves), because of the discrete-time nature of the disruptive scientific/technological/financial/social/political innovations. The authors apply the quantum macroeconomics theory to research and develop a new software program for the accurate characterization and forecasting of GIP((t), GDP(t), GNP(t) dependences changes in the economies of scales and scopes in the time domain for the use by the central / commercial banks.
C69|Über die Anwendungsmöglichkeiten des Zustands-Grenzpreismodells|This article considers the question whether the State Marginal Pricing Model is practicable, by which kind of decision and with which investment calculation method the State Marginal Pricing Model can used.
C69|Adjusted Wilcoxon signed rank test tables|Ordinary Wilcoxon signed rank test table provides the confidence interval of median for a single population. Adjusted Wilcoxon signed rank test tables which can provide confidence intervals of median and the 10th percentile for a single population are created in this paper. Base-(n+1) number system and theorems about property of symmetry of the adjusted Wilcoxon signed rank test statistic are derived for programming. Theorem 1 states that the adjusted Wilcoxon signed rank test statistic are symmetric around n(n+1)/4. Theorem 2 states that the adjusted Wilcoxon signed rank test statistic with the same number of negative ranks k are symmetric around k(n+1)/2. 87.5% and 85% confidence intervals of the median are given in the table for n=12, 13,?, 30 to create approximated 95% confidence intervals of the ratio of medians for two independent populations. 95% and 92.5% confidence intervals of the 10th percentile are given in the table for n=26, 27,?, 30 to create approximated 95% confidence regions of the ratio of the 10th percentiles for two independent populations. Finally two large datasets from wood industry will be partitioned to verify the correctness of adjusted Wilcoxon signed rank test tables for small samples.
C69|Editor’s Overview|The 29th issue of the International Productivity Monitor features six articles on the following topics: the role of productivity in long-term economic projections for the Canadian provinces and territories; productivity trends in the residential care sector in Canada; agricultural productivity in Australia, Canada and the United States; a mathematical reconciliation of gross output-based total factor productivity (TFP) growth with value added-based TFP growth; an empirical illustration with Australian industry data of the relationship between the two TFP measures; and a review article on the OECD report The Future of Productivity.
C69|Reconciling Gross Output TFP Growth with Value Added TFP Growth|This article obtains relatively simple exact expressions that relate value added total factor productivity growth (TFP) in a value added framework to the corresponding measures of TFP growth in a gross output framework when Laspeyres or Paasche indexes are used to aggregate outputs and inputs. Basically, as the input base becomes smaller, the corresponding estimates of TFP growth become larger. A fairly simple approximate relationship between Fisher indexes of gross output TFP growth and the corresponding Fisher index of value added TFP growth is also derived. The methodology developed in this article has a number of applications.
C69|On the Relationship between Gross Output-based TFP Growth and Value Added-based TFP Growth: An Illustration Using Data from Australian Industries|Diewert (2015) develops simple expressions for the exact relationship between value added TFP growth and gross output TFP growth. These expressions suggest that the magnification factor relating the two TFP growth measures is approximately equal to the share of primary inputs in total costs. We apply these simple approximations to data on Australian industries, finding that they tend to provide very close approximations over short time periods, but are less reliable over longer time horizons. We find that magnification factors vary significantly across industries so that the results of comparative studies can be quite sensitive to the choice of output measure chosen to construct TFP. In particular, industries in which intermediate inputs account for a large share of total inputs exhibit much smaller TFP growth (in absolute value) compared to industries where intermediate inputs are relatively unimportant when gross output is used to construct TFP measures rather than value added.
C69|When terminal facelift enforces delta constraints|This paper deals with the superreplication of non-path-dependent European claims under additional convex constraints on the number of shares held in the portfolio. The corresponding superreplication price of a given claim has been widely studied in the literature, and its terminal value, which dominates the claim of interest, is the so-called facelift transform of the claim. We investigate under which conditions the superreplication price and strategy of a large class of claims coincide with the exact replication price and strategy of the facelift transform of this claim. In one dimension, we observe that this property is satisfied for any local volatility model. In any dimension, we exhibit an analytical necessary and sufficient condition for this property, which combines the dynamics of the stock together with the characteristics of the closed convex set of constraints. To obtain this condition, we introduce the notion of first order viability property for linear parabolic PDEs. We investigate in detail several practical cases of interest: multidimensional Black–Scholes model, non-tradable assets, and short-selling restrictions. Copyright Springer-Verlag Berlin Heidelberg 2015
C69|Solving the utility maximization problem with CES and Cobb-Douglas utility function via mathematical inequalities|This paper presents a new, non-calculus approach to solving the utility maximization problem with CES utility function, as well as with Cobb-Douglas utility function in case of n≥2 commodities. Instead of using the Lagrange multiplier method or some other method based on differential calculus, these two maximization problems are solved by using Jensen's inequlity and weighted arithmetic-geometric mean (weighted AM-GM) inequality. In comparison with calculus methods, this approach does not require checking the first and the second order conditions.
C69|Perceiving Infinity. Different Facets|By means of a historical approach, we expound three different ways of perceiving the notion of infinity: mathematically, physically, and theologically. In the book of Genesis we are told of Man's attempt at reaching the skies, at becoming akin to the Gods. In Christian faith, down here is, at once, a place distant and much closer to its divine origin. He cannot be circumscribed. He is like an endless ocean of infinity. Furthermore, we use examples to emphasise how this notion is perceived by children and adolescents in the education system. The inferences at the end of this article underline how important it is for the tutor to understand the fascinating notion of infinity, and to find a useful place for it, inside the structure of the classes that tutor teaches.
C69|Modelación basada en agentes en el sistema pensional colombiano. Una aproximación desde el mercado laboral y la dinámica poblacional|Resumen Este artículo corresponde a un estudio del sistema pensional colombiano (SPC), reglamentado por la Ley 100 de 1993. Por medio de un Modelo Basado en Agentes (MBA), se analizan características propias de los agentes en el SPC con respecto a su articulación al mercado laboral y a la dinámica poblacional, quienes asumen uno de los roles en el sistema pensional en procura de lograr su pensión. Las probabilidades de los agentes de adoptar un régimen están condicionadas por las características del sistema pensional y por variables económicas, sociales y del sistema político; las variables pueden cambiar junto a la evolución del sistema pensional, debido a las acciones colectivas de los agentes y a las decisiones de política pública.
C69|Structural change and income distribution: the case of Australian telecommunications| The Australian telecommunications sector experienced substantial structural change during the 1990s, a change that increased productivity and reduced costs. At this time, telecommunications was already an important item of household expenditure and input to production. We estimate the effect of the structural change on households depending on their location in the distribution of income and expenditure. Our estimates are calculated by applying a computable general equilibrium model incorporating microsimulation behaviour with top-down and bottom-up links. We estimate significant increases in real income and small increases in inequality from the changes; the pattern of effects is largely uniform across regions. Sensitivity analysis indicates that our results are insensitive to variations in model parameters.
C69|The Dynamics of Personal Norms and the Emergence of Cultural Diversity|In this paper we study cultural diversity in values or personal norms concerning effort or work ethics, the related and observable diversity in behavior and its economic consequences. Our goal is to investigate the impact on this type of cultural diversity of primitive economic and behavioral parameters of the group such as the distribution of skills in the group population, the sharing rule on total income that determines income distribution and the levels of materialism, conformism and consistency in the group. Agents participate each period in a team production game by choosing their level of costly effort. We analyze the emergence and evolution of a culture in a group in which members are guided by economic incentives and also follow personal norms of behavior. We take materialism, skills and the income distribution rule as given, but personal norms evolve along the life-cycle of the individuals according to two psychological forces: cognitive dissonance or consistency and informational conformity. We characterize the long-run outcomes of the group and study how the levels of diversity, both in personal norms and in behavior and the level of incoherence between both variables are determined by the primitives of the model. We also analyze how these parameters affect group aggregate production and social welfare.
C69|A Geospatial Dynamic Microsimulation Model for Household Population Projections|Forecasting Populations (FPOP) is a microsimulation model (MSM) that is the demographic core of an extensible modeling framework. The framework, with FPOP at its core, enables the geospatial projection of a population under purely demographic processes or under the additional influence of exogenous factors such as disease, policy changes and prevention programs, or environmental stressors. Empirically-derived transition probabilities of life events such as birth, death, marriage, divorce and migration, captured in lookup table format, drive the simulation. These transition probabilities can be modified dynamically by external user-defined functions or other external MSMs. The use of MSM structures and methodologies enables FPOP to portray the impact of heterogeneity in the geospatial dimension (e.g., distribution of environmental factors or distribution of intervention programs), as well as the social dimension (e.g., household or social network correlates), on the projections. POP is designed and structured to: enable linking with external MSMs of any kind; support inclusion or configuration of more detailed transition probabilities; be scalable to millions of agents; use either an existing baseline synthetic population or a custom synthetic population of the userÂ’s design; and, run under computing environments that donÂ’t require a high degree of specialized software or hardware. In this paper we describe the design and structure of FPOP and then apply FPOP first under purely demographic processes and, secondly, in conjunction with an external disease model of obesity.The objective of FPOP is to provide a demographically realistic projection of the size, structure, and movement of populations and households decades into the future.
C69|Does evidence challenge the DSGE model|DSGE are for a time the favorite models in the simulation of monetary policies at the central banks. Two of its basic assumptions are discussed in this paper: (a) the absence of endogenous nonlinearities and the exogenous nature of shocks and (b) the persistence of or the return to equilibrium after a shock, or the absence of dynamics. Our analysis of complex financial markets, using historical data of S&P500, suggests otherwise that financial regimes endogenously change and that equilibrium is an artifact.
C69|Analyzing the Pathway to Improve Tiger Conservation in India|Despite substantial conservation investments by governments and international agencies, the existence of tigers in the wild is still threatened. The main threats to the survival of wild tigers are poaching, prey depletion, and habitat degradation and fragmentation. All international trade in tiger parts has been prohibited since 1975, with China introducing a domestic ban in 1993. The domestic trade ban in China was followed by the establishment of captive tiger breeding farms in East Asia. China has considered partially lifting the trade ban to permit sales from tiger farms. This has been a matter of much debate with the proponents to the trade ban opposing it on the grounds that it result in an increase in the illegal killing of tigers and would also result in an increase in demand for tiger products, while the proponents to tiger farming favouring a supply side approach to conservation with products from tiger farms meeting all the demand. This research paper argues that it is possible to protect wild tigers by permitting the sale of products from tiger farms. India has mainly targeted tiger conservation with the establishment of tiger reserves all over the country, but this has resulted in the displacement of local communities from land that was traditionally belonged to them. Community based conservation seeks to conserve wildlife by giving local people a stake in its conservation and thus, providing an incentive to conserve it. This paper using a bio-economic model argues that giving local communities a stake in conservation of tigers like a share of tourism revenues aids conservation, as it would result in an increase in anti-poaching effort undertaken by the local communities, but this is contingent upon the additional revenue being higher than the cost of intrusion.
C69|Macrodynamics of debt-financed investment-led growth with interest rate rules| This article demonstrates the diverse dynamic possibilities arising out of a simple macroeconomic model of debt-financed investment-led growth in the presence of interest rate rules. We show possibilities of convergence to steady state, and growth cycles around it as well as various complex dynamics. We investigate whether, given this framework, the financial sector can provide endogenous bounds to an otherwise unstable system. The effectiveness of monetary policy in the form of an interest rate rule targeting capacity utilization is examined under this context.
C69|Choosing put option parameters based on quantiles from the distribution of portfolio value|This paper explores how a put option changes the probability distribution of portfolio value. The paper extends the model introduced in Bell (2014) by allowing both the quantity and strike price to vary. I use the 5% quantile from the portfolio distribution to measure riskiness and compare different put options. I report a so-called ‘quantile surface’ that shows the quantile across different combinations of quantity and strike price. I find that it is possible to maximize the quantile by purchasing a put with quantity equal to one and strike deep in the money; however, the distribution with such a put option collapses to a single point because the option hedges all variation in stock price. This result is analogous to full-insurance in insurance economics, but has practical limitations. The quantile surface also shows that certain put options will decrease the quantile, which is equivalent to increasing the riskiness of the portfolio, and leads me to ask: what return will an investor receive in return for bearing that extra risk? I find that one such put option will cause the distribution to have an asymmetric shape with positive skewness, which is interesting to some speculators.
C69|Greek football clubs’ efficiency before and after Euro 2004 Victory: a bootstrap approach|This paper examines the technical efficiency of Greek football clubs, taking into account the period before the Euro 2004 victory and the period thereafter. The first stage of analysis is based on a bootstrapped data envelopment analysis approach so as to determine Greek clubs’ efficiency scores during these two distinct time periods. The second stage of analysis investigates possible factors that may have affected the efficiency scores during the examined periods. Our findings reveal that Greek football clubs exhibit surprisingly lower efficiency scores after Euro victory. In effect and explained in the context of the Resource Based Theory, there appears to be no classification of types of football clubs into various divisions, viz. laggards, followers and champions. Finally, it is also found that clubs’ financial health appears to be a crucial factor for their performance in both periods. Copyright Springer-Verlag Berlin Heidelberg 2014
C69|A method based on the ideal and nadir solutions for stochastic MADM problems|Many real life decision making problems can be modeled as stochastic multi-attribute decision making (MADM) problems. A novel method for stochastic MADM problems is developed based on the ideal and nadir solutions as in the classical TOPSIS method. In a stochastic MADM problem, the evaluations of the alternatives with respect to the different attributes are represented by discrete stochastic variables. According to stochastic dominance rules, the probability distributions of the ideal and nadir variates, both are discrete stochastic variables, are defined and determined for a set of stochastic variables. A metric is proposed to measure the distance between two discrete stochastic variables. The ideal solution is a vector of ideal variates and the nadir solution is vector of nadir variates for the multiple attributes. As in the classical TOPSIS method, the relative closeness of an alternative is determined by its distances from the ideal and nadir solutions. The rankings of the alternatives are determined using the relative closeness. Examples are presented to illustrate the effectiveness of the proposed method. Through the examples, several significant advantages of the proposed method over some existing methods are discussed.
C69|The importance of Perron-Frobenius Theorem in ranking problems|The problem of ranking a set of elements, namely giving a ``rank'' to the elements of the set, may be tackled in many different ways. In particular a mathematically based ranking scheme can be used and sometimes it may be interesting to see how different can be the results of a mathematically based method compared with some more heuristic ways. In this working paper some remarks are presented about the importance, in a mathematical approach to ranking schemes, of a classical result from Linear Algebra, the Perron--Frobenius theorem. To give a motivation of such an importance two different contexts are taken into account, where a ranking problem arises: the example of ranking football/soccer teams and the one of ranking webpages in the approach proposed and implemented by Google's PageRank algorithm.
C69|Earnings Distributions and Dimensions of Inequality|An Analysis Based on the European Union Structure of Earnings Survey (SES) This study provides an in-depth evaluation of earnings differences within and across countries and their evolution over time using three different waves of the Structure of Earnings Survey (SES) – for 2002, 2006 and 2010. Earnings inequalities for the EU stayed roughly constant at a Gini coefficient around 0.3 with, however, large and persistent differences being observed across countries. The crisis had no significant impact on changes in earnings inequalities of those people remaining employed. The report highlights the impacts of individual, job and firm characteristics on earnings differences applying Mincer regressions and provides information to which extent these determinants contribute to the observed earnings inequalities using a Shapley value decomposition approach Differences in earnings by occupation and education are the two most important determinants of wage inequality contributing with about 25% and 12%, respectively, followed by industry (with about 10%), enterprise size (about 6%), job duration (6%), age (5%) and gender (3.5%).
C69|The distributional effects of the Hilmer reforms on the Australian gas industry|We analyse changes in the Australian gas industry during 1990s that were driven by the Hilmer Reforms. We estimate the direct and indirect effects on household income of these gas industry changes by combining a computable general equilibrium model with a microsimulation model in a two-stage simulation procedure. The changes lead to minor effects on household income in all regions due to the unimportance of the gas industry at that time. Some regions benefit from the changes and some lose. Income inequality is only slightly affected by the changes.<br><small>(This abstract was borrowed from another version of this item.)</small>
C69|The distributional effects of the Hilmer reforms on the Australian gas industry| We analyse changes in the Australian gas industry during 1990s that were motivated by the Hilmer Reforms. We estimate the effects on real household income of the changes by combining a computable general equilibrium model with a microsimulation model. Although the structural changes were significant in their effects on the gas industry, they are estimated to have had minor effects on real household income in all Australian regions owing to the small size of the gas industry and household gas consumption at that time, and low importance of gas as an input to other industries. The changes are estimated to have slightly increased income inequality owing to the redistribution of income from labour to other primary factors.
C69|Integrating biophysical and economic systems in a Bayesian Network Hydro-economic framework| Management of water resources needs to jointly consider the multiple, interdependent, uses of water. Decision support tools that aim to assist efficient integrated water resources management should integrate the environmental and socio-economic systems affected by changes in resource allocation. There exist, however, few models that assess the trade-offs between environmental and economic impacts of water management changes in an integrated framework. This paper presents a hydro-economic model that integrates hydrological and ecological systems with economic costs and nonmarket benefits in a Bayesian Network modelling framework. A suite of different modelling tools were used to assess the biophysical and economic impacts of catchment management scenarios, for a case study in Tasmania, Australia. The Bayesian Network provides a flexible modelling approach to incorporate different types of data and had the advantage of explicitly accounting for accumulated uncertainty in information.
C69|Patrones Visuales en Análisis Técnico: Identificación Algorítmica y Evaluación de Estrategias de Inversión|El análisis técnico es un método que busca pronosticar movimientos en los precios a partir de información pasada. Aunque la subjetividad asociada a esta técnica dificulta un estudio científico, los fundamentos lógicos del análisis técnico permiten la creación de algoritmos que pueden mitigar dicha subjetividad. Este trabajo utiliza un procedimiento computacional que se aproxima a la capacidad humana para reconocer patrones visuales. Con base en la evaluación estadística de los retornos obtenidos a partir del reconocimiento de estos patrones, es posible comprobar que el análisis técnico es una forma científicamente válida de extraer información a partir de los precios de mercado. Asimismo, el algoritmo permite obtener rendimientos positivos y significativos en tasa de cambio, bonos de renta fija y acciones.
C69|Does Catching-up or Innovations Drive Total Factor Productivity Growth in Indian Sugar Industry? A Non-Parametric Analysis|The study is an endeavor to identify the sources of Total Factor Productivity (TFP) growth in Indian sugar industry at both aggregated and regional levels using non-parametric Malmquist Productivity Index (MPI). The empirical analysis is confined to the period of 31 years from 1974/75 to 2004/05, which has been further divided into two sub-periods on the basis of changes in macroeconomic policy governing the Indian economy: i) Prereforms period (1974/75 to 1990/91); and ii) Post-reforms period (1991/92 to 2004/05). The analysis reveals that TFP growth is primarily attributable to overall efficiency change in general and managerial efficiency change (PECH) in particular during the entire and pre-reforms period. However, during the post-reforms period, Hicks neutral type of technical progress observed to be the dominant source whereas efficiency change observed to be restricting the potential TFP growth rates in Indian sugar industry. The analysis of factors affecting TFP growth discloses that improved mechanization, profitability, industrial concentration and reduction in government interference are the possible policy alternatives to improve TFP growth in Indian sugar industry.
C69|Structural change in the Australian electricity industry during the 1990s and the effect on household income distribution: A macro–micro approach|The Australian electricity industry experienced significant structural change during the 1990s mainly as a result of microeconomic reform. We analyse the effects of the structural change on the distribution of household income using a macro–micro approach. Our work shows that, nationwide, all income deciles experience higher real incomes in the order of 2%. Our results show that a previously state-owned monopoly industry can experience significant structural change while generating significant improvements in household real income without leading to significantly adverse impacts on national or regional income inequality. It suggests that policy makers in advanced economies should seriously consider such reforms given that they may generate large economic benefits with rather small economic costs.
C69|Network design and defence|Infrastructure networks are a key feature of an economy. Their functionality depends on the connectivity and sizes of different components and they face a variety of threats, from natural disasters to intelligent attacks. How should networks be defended and designed to ensure the best functionality?
C69|Pricing in social networks|We analyze the problem of optimal monopoly pricing in social networks where agents care about consumption or prices of their neighbors. We characterize the relation between optimal prices and consumersʼ centrality in the social network. This relation depends on the market structure (monopoly vs. oligopoly) and on the type of externalities (consumption versus price). We identify two situations where the monopolist does not discriminate across nodes in the network (linear monopoly with consumption externalities and local monopolies with price externalities). We also analyze the robustness of the analysis with respect to changes in demand, and the introduction of bargaining between the monopolist and the consumer.
C69|Complex Networks Analysis of European International Trade: An Agent-Based Model|Economic systems involve many heterogeneous agents and their complex interactions. These lead many studies, in recent years, to focus on the complex networks. Agent based modelling and simulation (ABMS) is a powerful tool for analyzing such systems. This model enables interacting agents to assess individually their positions and makes decisions on the basis of a set of rules that configure the system. International trade can be thought of as a complex network since it consists of interacting heterogeneous agents (countries) with special characteristics. Network representation also makes it possible to analyze indirect trade interaction among countries. In this study the network of international trade of European countries is modelled by using an agent-based model. The aim is to display briefly the network structure of the European international trade.
C69|In Search of the Right Tool: From Formalism to Constructivist Modelling|The object of this paper is to assert the implications, in terms of practices of the community of economists, of the adoption of specific mathematical tools. More precisely, the aim of this paper is to assert the non-neutrality of the mathematical tools used by economists and to show that, after half a century of domination of a peculiar vision of mathematics, namely formalism, economics is ready to switch to a diverse conception thanks to the availability of new mathematical tools, constructivist tools.
C69|Láthatóvá tehető-e a láthatatlan kéz? Egy ágensalapú piaci modell tapasztalatai<BR>[Can the invisible hand be rendered visible? Experiences of an agent-based market model]|A szerzők egy ágensalapú modell kialakításával próbáltak válaszolni arra a kérdésre, hogy milyen dinamikát követnek a piaci folyamatok, ha nem teljesülnek a főáramú közgazdaságtan erős megszorításai (a láthatatlan kéz explicit megjelenése a walrasi árverező képében, amely kizárja a nem egyensúlyi tranzakciókat, a szereplők racionális viselkedése, az információáramlás tökéletessége, a szereplők homogenitása, az ár- és mennyiségi alkalmazkodás szétválasztása stb.). Egy egyszerű, alulról építkező modell segítségével elemezték a piaci mikrostruktúrák, illetve a döntési szabályok paramétereinek egyensúlyi folyamatokra gyakorolt hatását. Vizsgálataik során azt találták, hogy a piaci szereplők száma akkor is lényegesen befolyásolja az alkalmazkodási folyamatokat, ha azok homogének; az ár- és mennyiségi szabályozás aránya nem gyakorol jelentős hatást a piaci ár és mennyiség alakulására; az információáramlás kiterjesztése javítja a piaci alkalmazkodást; a heterogén szereplők bevezetésének elsősorban a termelők esetén van jelentősége. Journal of Economic Literature (JEL) kód: B41, C69, D01, D49, D59, L11.
C69|Stock-flow Consistent Modeling through the Ages|The aim of the paper is to provide an overview of the current stock-flow consistent (SFC) literature. Indeed, we feel the SFC approach has recently led to a blossoming literature, requiring a new summary after the work of Dos Santos (2006) and, above all, after the publication of the main reference work on the methodology, Godley and Lavoie's Stock-flow Consistent Approach (2007). The paper is developed along the following lines. First, a brief historical analysis investigates the roots of this class of models that can be traced as far back as 1949 and the work of Copeland. Second, the competing points of view regarding some of its main controversial aspects are underlined and used to classify the different methodological approaches followed in using these models. Namely, we discuss (1) how the models are solved, (2) the treatment of time and its implication, and (3) the need-or not-of microfoundations. These results are then used in the third section of the paper to develop a bifocal perspective, which allows us to divide the literature reviewed according to both its subject and the methodology. We explore various topics such as financialization, exchange rate modeling, policy implication, the need for a common framework within the post-Keynesian literature, and the empirical use of SFC models. Finally, the conclusions present some hypotheses (and wishes) over the possible lines of development of the stock-flow consistent models.
C69|Formulación lineal de extensiones del problema de localización competitiva del líder-seguidor/Linear Formulation for Extensions of the Leader-Follower Competitive Location Problem|El problema del líder-seguidor es un problema de decisión secuencial en un mercado sin centros de servicio, donde una empresa, la empresa líder, abre primero sus centros y otra empresa competidora, la empresa seguidora, entra más tarde en el mercado abriendo los suyos. La empresa líder elige las localizaciones teniendo en cuenta que la empresa seguidora abrirá sus instalaciones y capturará parte de la cuota de mercado. El objetivo de cada una de las firmas competidoras es maximizar su cuota de mercado. Consideramos que el consumidor se comporta haciendo una elección binaria utilizando la distancia como criterio de elección. Extendemos el modelo básico contemplando un umbral en la regla de elección del cliente y costes de apertura dependientes de la localización. Formulamos las extensiones del problema como un programa lineal a partir del modelo lineal básico. The leader-follower problem is a sequential decision problem where, in a market initially without service centers, a firm, the leader, opens its centers and another competing firm, the follower, will enter later the market opening its centers. The leader chooses the locations taking into account that the follower will enter the market opening its centers and capturing part of the market share. The objective of each competing firm is to maximize its market share. We consider that the clients will behave making a binary choice using the distance as basis for her/his choice crite¬rion. We extend the basic model by considering a threshold in the client choice rule and opening costs depending on the location. We get formulations of the problem extensions as linear programs from the basic linear model.
C69|On the Pointwise Spectrum of the Operators of the Commutant of a General Operator Increasing the Powers|This paper is a follow-up of previous research and offers various cases in which the pointwise spectrum of the operators of the commutant can be described
C69|Foundations of the economic and social history of the United States: Apologia|This set of three volumes argues that the mind – human consciousness – may be measured by considering mathematically the aggregate of that consciousness, i.e. social history. From this beginning theme of discussion three questions must arise. 1. How might this measurement be made? 2. Of what value is this measurement? and 3. How does this measurement affect our present understanding of the reality in which we live? Each of these three volumes attempts to provide answers to one of these questions.
C69|Foundations of the economic and social history of the United States: Empirical|I argue that a form of consciousness may be found in American economic history, one which is both mathematically demonstrable and important. In this book I present a model of economic and political growth based upon systematic addition. We begin with a philosophic model of trade (pp. 34-46); aggregate this model over the course of year to state the real Gross National Product of the United States and its relationship to the rate of employment (pp. 47-62); aggregate this model over the course of many years to find the growth of the United States stated as a natural “14-year octave” within real GNP data (pp. 63-91); multiply this octave times two to find the 28-year natural rate of price fluctuation (pp. 92-112); and multiply this octave times four to find the 56-year natural rate of political change (p. 92-112). The final model (pp. 113-136) is the larger “fractal” of the model of trade which begins these essays, in essence demonstrating that the United States “trades” values over a period of time in much the same way the individual citizen trades goods and services for money on a personal basis.
C69|Third Generation University Strategic Planning Model Development|The paper discusses implementation of a research that is aimed at development of a simulation model which would allow analyzing different development strategies of the third generation university. Small countries’ universities have limits of growth. The problem can be solved with a new approach to university role. The third generation defines university as innovation generation, transfer and implementation center, while maintaining the traditional university functions. The 3G university activities change number of innovative companies in the country. With growth of the number of innovative companies, potential researches and innovation customers’ amount grow. With time the amount of conducted research and developed innovative products growth. Innovative products and technologies is the basis of university competitiveness in the 21st century. Universities must develop, accumulate, implement and get benefits from innovative products and technologies.
C69|Robustness and Stability of Limit Cycles in a Class of Planar Dynamical Systems|Using a macroeconomic example, the paper proposes an algorithm to symbolically construct the topological normal form of Andronov-Hopf bifurcation. It also offers a program, using the Computer Algebra System `Maxima', to apply this algorithm. In case the limit cycle turns out to be unstable, the possibilities of the dynamics converging to another limit cycle is explored.
C69|Convergence, cycles and complex dynamics of financing investment|This paper demonstrates the diverse dynamical possibilities of a simple macroeconomic model of debt-financed investment-led growth in the presence of interest rate rules. We show possibilities of convergence to steady state, growth cycles around it as well as various complex dynamics from codim 1 and codim 2 bifurcations. The effectiveness of monetary policy in the form of interest rate rules is examined under this context.
C69|Investing equally in risk|Classical optimal strategies are notorious for producing remarkably volatile portfolio weights over time when applied with parameters estimated from data. This is predominantly explained by the difficulty to estimate expected returns accurately. In Lindberg (Bernoulli 15:464–474, 2009 ), a new parameterization of the drift rates was proposed with the aim to circumventing this difficulty, and a continuous time mean–variance optimal portfolio problem was solved. This approach was further developed in Alp and Korn (Decis Econ Finance 34:21–40, 2011a ) to a jump-diffusion setting. In the present paper, we solve a different portfolio problem under the market parameterization in Lindberg (Bernoulli 15:464–474, 2009 ). Here, the admissible investment strategies are given as the amounts of money to be held in each stock and are allowed to be adapted stochastic processes. In the references above, the admissible strategies are the deterministic and bounded fractions of the total wealth. The optimal strategy we derive is not the same as in Lindberg (Bernoulli 15:464–474, 2009 ), but it can still be viewed as investing equally in each of the n Brownian motions in the model. As a consequence of the problem assumptions, the optimal final wealth can become non-negative. The present portfolio problem is solved also in Alp and Korn (Submitted, 2011b ), using the L 2 -projection approach of Schweizer (Ann Probab 22:1536–1575, 1995 ). However, our method of proof is direct and much easier accessible. Copyright Springer-Verlag 2013
C69|Credit gap risk in a first passage time model with jumps| The payoff of many credit derivatives depends on the level of credit spreads. In particular, credit derivatives with a leverage component are subject to gap risk, a risk associated with the occurrence of jumps in the underlying credit default swap spreads. In the framework of first passage time models, we consider a model that addresses these issues. The principal idea is to model a credit quality process as an Itô integral with respect to a Brownian motion with a stochastic volatility. Using a representation of the credit quality process as a time-changed Brownian motion, one can derive formulas for conditional default probabilities and credit spreads. An example for a stochastic volatility process is the square root of a Lévy-driven Ornstein--Uhlenbeck process. The model can be implemented efficiently using a technique called Panjer recursion. Calibration to a wide range of dynamics is supported. We illustrate the effectiveness of the model by valuing a leveraged credit-linked note.
C69|Construction and updating of a Ugandan CGE database|This paper documents (1) the structure of a CGE database; (2) the data manipulation steps in creating such a database from published data; (3) updating a SAM; and (4) describe features of the updated SAM. The database is constructed for a Ugandan CGE model. The building blocks for creating a database for a CGE model are official data from an Input/output (IO) table, or from a Supply Use Table (SUT), or from a SAM. Often the structure of the published data is not in the required format of a CGE database, and so a major task is to transform the official data into a form required by a CGE database. The first step in this task is typically a review of the primary source of data. We then proceed by identifying any implausible, unusual and negative values. We adjust these elements and rebalance the database to ensure that the balancing conditions hold. We then proceed to create the matrices required by the CGE model. Typically we create (1) a source dimension for all user-specific matrices, (2) user and source-specific margin matrices, (3) user and source-specific tax matrices and (4) industry-specific land rentals. It is likely that as we adjust data and create the required matrices, we violate the balancing conditions. Therefore in each step in the database construction stage, we check the balancing conditions and when appropriate we rebalance the database to ensure that the balancing conditions hold. Having constructed the 2002 database that conforms to the CGE structure, we update the database to 2009. We then proceed to create an additional sector namely, RawOil sector. In terms of the database, we create an additional industry and an additional commodity. Our final task is to create, based on the 2009 database, an updated SAM. The CGE database does not provide information on transfers between economic agents. We therefore adjust the transfer elements based on shares estimated for 2002.
C69|Microeconomic Reform and Income Distribution: The case of Australian Ports and Rail Freight Industries|We analyse structural changes in the Australian ports and rail freight industries during 1990s that were driven by microeconomic reform. We estimate the direct and indirect effects on household income groups of these industry changes by applying a computable general equilibrium model incorporating detailed household income and expenditure accounts, and microsimulation behaviour. The model contains both top-down and bottom-up linkages. The structural changes lead to a small increase in household welfare in most regions, with an overall increase of 0.18%. Income inequality is estimated to have decreased slightly by 0.02%.
C69|Knowledge Analysis in Terms of Representation,Processing based Mobilisation and Distribution|Understanding, defining and using knowledge can be based on a number of many approaches, such as the synthesis of Knowledge Management Systems, Knowledge Agents, Knowledge Discovery and Data Mining, Organizational Semantic Webs. Knowledge is based on the accumulation of facts, procedural rules or heuristics. Knowledge is supported by both formal and informal processes and structures in their acquisition, sharing and applications. Workers and employees communicate and assimilate values, procedures, rules and data from the beginning of their activity in an organization, and hypothetically should begin to be increasingly willing to share what they know as their length of service increases. This paper presents a deep analysis of knowledge, as the basic pillar of the intelligent enterprise and of many other Intelligent Economic Systems. In this respect I emphasize that it is essential to realize that Knowledge Management is both a cultural and a technological provocation. We might say that the cultural aspect is a priority. Any system designed to support these challenges must extend far beyond the technological boundaries and take into account the people who will use it and contribute to its success. Our work demonstrates the main aspects and strategic advantages of knowledge representation, processing based mobilisation and distribution in the long process from integrating information and applications to automate knowledge worker functions. Developing systems that incorporate knowledge within organizations differs significantly from other systems, because it is absolutely necessary to associate operational interpretations with the information, in order to transform them into knowledge useful in various acts of decision.
C69|Evidence of Market Power in the Atlantic Steam Coal Market Using Oligopoly Models with a Competitive Fringe|Before 2004 South Africa was the dominant steam coal exporter to the European market. However a new market situation with rising global demand and prices makes room for a new entrant: Russia. The hypothesis investigated in this paper is that the three incumbent dominant firms located in South Africa and Colombia reacted to that new situation by exerting market power and withheld quantities from the market in 2004 and 2005. Three market structure scenarios of oligopoly with a competitive fringe are developed to investigate this hypothesis: a Stackelberg model with a cartel, a Stackelberg model with a Cournot-oligopoly as leader and a Nash-bargaining model. The model with a Cournot oligopoly as leader delivers the best reproduction of the actual market situation meaning that the dominant players exert market power in a non-cooperative way without profit sharing. Furthermore some methodological clarifications regarding the modeling of markets with dominant players and a competitive fringe are made. In particular we show that the use of mixed aggregated conjectural variations can lead to outcomes that are inconsistent with the actions of rational profit-maximizing players.
C69|Emergence and complexity in Austrian economics|Emergence is often argued to be a deep property of complex systems, with such systems exhibiting wholes that are in some way greater than the sum of their parts. These ideas have played an important part in discussions of spontaneous order within Austrian economics, particularly by Hayek drawing on arguments dating from Mill and Menger, although with other traditions such as that of Böhm-Bawerk not relying on such ideas. Philosophical discussions of these terms are considered that raise questions about the relationship between the emergent whole and the lower level parts that comprise it. A major issue is the role of these ideas and processes within evolution, with Hayek in particular moving strongly towards identifying their linkage, something advocated by many non-Austrian economists and non-economists as well.
C69|Time Series Prediction with Neural Networks for the Athens Stock Exchange Indicator|The main aim of this study is to predict the daily stock exchange price index of the Athens Stock Exchange (ASE) using back propagation neural networks. We construct the neural network based on the minimum embedding dimension of the corresponding strange attractor. Multistep prediction for nine days ahead is achieved with this particular network indicating the increased possibility of this technique for immediate forecasts for very time-short data sets, mostly daily and weekly.
C69|The Moore'S Closure For Analyzing Relationships Between Agents In Industrial Clusters|Industrial clusters try to exploit the effect of external economies and joint actions that come from the collaboration between their agents. But in order that these effects arise it is needed close cooperation partnerships between the agents in the industrial cluster, which could improve competitiveness. It’s obvious, therefore, that analyzing which are the relationships between the agents in the industrial cluster is critical to make strategic decisions that promote and improve the competitiveness of the industrial cluster. This paper proposes a methodology based on obtaining a fuzzy relation from which, applying Moore’s closure in an uncertain situation, we can identify subrelations that group industrial cluster agents depending on their degree of affinity based on the intensity of their relationships.
C69|Avoiding path dependence of distributional weights: Lessons from climate change economic assessment|In some cost benefit analysis (CBA) applications, such as those used for the valuation of climate change damage, distributional weights are used to account for diminishing utility of marginal income. This is usually done by means of intra-temporal distributional weights, which are combined with discounting to account for inter-temporal equity and efficiency. Here, I show that this approach might introduce some inconsistencies in terms of path dependence. In short, this inconsistency means that regional economic growth is double counted. This is because income weighting is performed both through the discount rate and through the distributional weights such that growth shows up twice in the weighting process. Using the PAGE2002 model, it is found that the inconsistency problem in the original model erases the influence of distributional weights on the social cost of carbon dioxide (SCCO2) compared to a standard CBA approach. The alternative approaches proposed here yield about 20%–40% higher values of SCCO2 than the old approach. While this has been briefly commented on in previous work, it has not yet been more thoroughly analyzed nor communicated to the broader community of climate policy and economic analysts who are not deeply interested in the specifications of the climate impact assessment models.
C69|"Un problema de consenso para problemas de toma de decisiones multicriterio en grupo mediante relaciones de preferencia intervalares difusas lingüísticas || A Consensus Model for Group Multicriteria Decision Making Problems with Interval Fuzzy Preference Relations"|"En el contexto de toma de decisiones multicriterio y bajo ciertas circunstancias, puede ocurrir que no se pueda expresar una cierta valoración mediante una única etiqueta lingüística, ya que puede haber duda en esa valoración. En este trabajo, presentamos un modelo de consenso para problemas de toma de decisiones en grupo con relaciones de preferencia intervalares lingüísticas. Este modelo está basado en dos criterios de consenso, una medida de consenso y una de proximidad, y en el concepto de coincidencia entre preferencias. Calcularemos ambos criterios en los tres niveles de representación de una relación de preferencia y diseñaremos un mecanismo de realimentación automático para guiar a los expertos en el proceso para alcanzar el consenso. || In some circumstances a decision maker, expert, in a group decision making problem cannot express his/her preferences with a unique linguistic fuzzy preference because he/she is dubious into some preferences. In this paper, we present a consensus model for group decision making problems with interval fuzzy preference relations. This model is based on two consensus criteria, a consensus measure and a proximity measure, and on the concept of co- incidence among preferences. We compute both consensus criteria in the three representation levels of a preference relation and design an automatic feedback mechanism to guide experts in the consensus reaching process."
C69|The Evaluation Of Conflicts’ Degree In Group Decision Making|In group decision making conflicts arise from the fact that individuals or groups of individuals have often different opinions about problems’ solutions. These conflicts might have various degrees ranging from almost complete agreement to an absolute opposition of two equally strong sides. The aim of this article is to extend the evaluation of conflicts’ degree introduced by Z. Pawlak and others originally in the rough set theory context. The scope of this generalization embraces an arbitrary number of groups or individuals involved in a conflict, an arbitrary number of their attitudes as well as different degrees of agreement or disagreement on an issue (fuzzy conflicts). The evaluation of a conflict degree is divided into two levels, as both conflict situation as a whole and each individual in a conflict can be evaluated. The proposed measures of conflicts’ degree can be used in initial stages of decision making processes to the quantitative evaluation of conflict intensity, so they can provide useful information for a conflict potential resolution; and also, they might help to describe conflicts’ dynamics. Numerical examples of the evaluation of conflics’ degree are provided as well.
C69|Spatial Allocation of Economy as a Fiber Bundle|This paper considers the approach to specification and modeling of transport influence on spatial allocation of economy, which is essentially new for economics. By applying the concept of fiber bundle, a general model of spatial allocation of market with regard to transport costs is developed. Corresponding mathematical formulation of model equilibrium condition and transition dynamics is stated based on the principle of least action and gauge invariance. Further development of obtained theoretical results within the framework is reviewed.
C69|Evaluating professional tennis players’ career performance: A Data Envelopment Analysis approach|This paper by applying a sporting production function evaluates 229 professional tennis players’ career performance. By applying Data Envelopment Analysis (DEA) the paper produces a unified measure of nine performance indicators into a single career performance index. In addition bootstrap techniques have been applied for bias correction and the construction of confidence intervals of the efficiency estimates. The results reveal a highly competitive environment among the tennis players with thirty nine tennis players appearing to be efficient.
C69|European Union Economy System Dynamic Model Development|The formation of the European Union (EU) is the one of the biggest political – economic events of the last 50 years. The aim of this study is to develop EU economy functioning system dynamic model. Main research method is system dynamics. General scheme of EU economy system dynamic model is shown. Implementing the model in practice, new EU member economic integration model in EU is developed. Model is tested only for one EU country, Latvia. Results of the paper show failure of the mechanism of EU operations. The available mechanism contradicts EU principles; it doesn't promote the cohesion in European Union, but quite opposite - leads to solving problems of well-developed EU countries at the expense of developing countries. In the given conditions the example of Latvia shows that there is no possibility to overcome the system crisis. These circumstances specify necessity of changes in EU internal migratory policy, changes in principles of developing countries’ support in EU, and changes in distribution of EU means, taking into account internal migration.
C69|Cycles and Crises in a Model of Debt-financed Investment-led Growth|The paper demonstrates possibilities of both convergence to the steady state and emergence of stable growth cycles around it in a simple macrodynamic model of debt-financed investment-led growth. The growth cycles are robust and are generated endogenously, either due to the existence of a supercritical Andronov-Hopf bifurcation, or due to the global stability condition through an application of the Poincaré-Bendixson theorem. The emergence of multiple limit cycles is also observed under certain conditions. The possibility of a deterioration of financial variables during a boom, with the resulting financial crisis providing an endogenous ceiling to a business cycle is examined in this context.
C69|Optimization and Simulation Modeling of Disaster Relief Supply Chain: A Literature Review|Recent natural and man-made disasters underscore the need of a resilient and agile disaster relief supply chain to mitigate the damages and save people’s lives. Optimization and simulation modeling have become powerful and useful tools to help decision makers tackle problems related to disaster relief supply chain. This paper reviews optimization and simulation models used in the field of disaster relief supply chain. We review the literature of the facility location optimization problems of disaster relief supply chain under different types of disastrous events. We review the literature of simulation models on supply chain design and disaster relief distribution operations. Finally, we propose two future research directions for disaster relief supply chain modeling.
C69|Modeling the Electricity Sector: A Summary of Recent Analyses of New EPA Regulations|Several different economic models have been applied to try to understand how new regulations by the U.S. Environmental Protection Agency (EPA) could impact coal-fired generation in the United States as well as the electricity system as a whole. This paper provides an overview of many of the key studies and the models used to analyze the potential impacts of EPA’s rules. The regulations surveyed include the Cross-State Air Pollution Rule (CSAPR), the Mercury and Air Toxics Standards (MATS), the proposed Clean Water Act (CWA) Section 316(b) rule, and the proposed Coal Combustion Residuals (CCR) rule. The models generally agree that these regulations will result in coal plant retirements, though there is far less agreement on how much generation may retire. Assumptions about the price of natural gas and the expected stringency of regulations play a key role in determining modeling results. The models provide useful guidance for policymakers when considering the potential impact of EPA regulation.
C69|Basics of copula’s theory|The most important properties of p-variate distributions on the hypercube whose univariate marginals are uniformly distributed on [0; 1] are discussed. These distributions, also called p-copulas, have become a popular tool in order to study financial markets, macroeconomics and other fields. The study of Russian articles shows that in most cases these articles contain a list of several typical copulas and techniques of their using but they hold no discussions about meaning of acts over copulas. The review is an attempt to change for the better this situation, even if it were a little.
C69|Modelowanie CLV przy użyciu łańcucha Markowa – wykorzystanie danych panelowych|No abstract is available for this item.
C69|The role of saving and investment in a SAM price model|No abstract is available for this item.
C69|Bourbaki's Destructive Influence on the Mathematization of Economics|The first appearance of a reference to a Bourbaki mathematical result was the spoof by D.D. Kosambi, published in the first volume of the Bulletin of the Academy of Sciences of the United Provinces of Agra and Oudh, eighty years ago, although it was not the first reference to Bourbaki in a mathematical context. In mathematical economics there seems to be an increasing identification of Debreu’s mathematization of economics with Bourbakism, although the Post WW II mathematics of general equilibrium theory can be shown to be consistent also with the contributions of the Polish School of Mathematics in the interwar period. In this paper an attempt is made to summarise the story of the emergence of Bourbakism, originating in India, and its recent demise as well as how it played a destructive role in mathematising economics in one, uncompromisingly nonconstructive, mode.
C69|Computational Modelling Of The Parallel Logistic System|The paper highlights the problem of mathematical modelling of the highly complex logistic system consisting of parallel production lines. Each production route is arranged in a series of stands equipped with manufacturing machines. It is assumed that all production lines are identical. Each production stand performs a manufacturing operation with the use of the specified tool. Tools get worn out and require either regeneration or immediate replacement. The tool subjected to regeneration can be regenerated a certain number of times only. When this number is reached, the tool must be replaced with a new one. The logistic system is controlled by a determined heuristic algorithm. The production process is optimized by means of the stated criterion respecting defined bounds. Adequate equations of state illustrate the flow of charge material. The time scaling method in order to search for the satisfactory solution with the use of the simulation method is proposed.
C69|Optimizing The Allotment Of Construction Equipment By Type Of Activity And Site|The aim of the study is to design a mathematical model for the effective allotment of construction equipment by type of activity and site. There is also put forward a theoretically substantiated method and the corresponding algorithm for finding the optima l solution of the proposed model. The method has been tested on a case with numeral data, through which its practical applicability is demonstrated.
C69|Modellierung von Hofübernahmeund Hofaufgabeentscheidungen in agentenbasierten Modellen|Das Agentenbasierte Agrarsektormodell SWISSland erhebt den Anspruch, Strukturwandelprozesse in der Schweizer Landwirtschaft möglichst realitätsnah zu beschreiben. Dieser Beitrag zeigt, dass Hofübernahme- und -aufgabeentscheidungen und dessen Auswirkungen auf den strukturellen Wandel in der Schweizer Landwirtschaft im Trend der letzten 10 Jahre prognostiziert werden können, wenn hierzu statistisch gesicherte Informationen zur Wahrscheinlichkeit für das Vorhandensein einer Hofnachfolge und der Bereitschaft zur Hofübernahme in Kombination mit ökonomisch begründeten Stabilitätskriterien genutzt werden. Mit Hilfe dreier Szenarien wird gezeigt, dass die Abbildung der Strukturentwicklungsprozesse im Wesentlichen von der Interpretation und Integration der relevanten Bestimmungsfaktoren in agentenbasierte Modellen abhängt.
C69|Automation of the Work intensively based on Knowledge, a Challenge for the New Technologies|Knowledge Management or knowledge-based management (noted and used throughout this paper as KM) is defined as a collaborative practice, by which organizations deliberately and intelligibly create, organize, distribute and analyze their own knowledge, in terms of resources, documents and people’s skills. It is widely regarded as an internal tool for increasing the operational efficiency of any organization, and has the potential to revolutionize the intelligent interaction between humans and agents (intelligent), based on more and more advanced technology. Semantic Technologies (STs) are distributed software technologies that make that meaning more explicit, principally so that it can be understood by computers. STs will dramatically impact enterprise architecture and the engineering of new system and infrastructure capabilities. They are tools that represent meanings, associations, theories, and know-how about the uses of things separately from data and knowledge, using reasoning algorithms. Time restrictions are not excessive in usual STs as distributed applications. Critical time reasoning problems may occur in case of faulty operations and overloading. At present, the reasoning depth developed for such system is still poor. This work represents research results for incorporating and considering appropriate semantic foundations in future technologies that can automate knowledge based work.
C69|Cost performance of Brazilian soccer clubs: A Bayesian varying efficiency distribution model|This paper analyzes the cost efficiency of Brazilian first league soccer clubs using a Bayesian Varying Efficiency Distribution (VED) model. We confirm that the model fits the data well with all coefficients correctly signed and in line with the theoretical requirements. From the efficiency results, it was clear that the Brazilian soccer league operates at a lower performance in comparison to other international soccer leagues. Factors which contributed to this finding as well as other policy implications are provided.
C69|Inequality across countries in energy intensities: An analysis of the role of energy transformation and final energy consumption|This paper analyzes the role of the energy transformation index and of final energy consumption per GDP unit in the disparities in energy intensity across countries. In that vein, we use a Theil decomposition approach to analyze global primary energy intensity inequality as well as inequality across different regions of the world and inequality within these regions. The paper first demonstrates the pre-eminence of divergence in final energy consumption per GDP unit in explaining global primary energy intensity inequality and its evolution during the 1971-2006 period. Secondly, it shows the lower (albeit non negligible) impact of the transformation index in global primary energy inequality. Thirdly, the relevance of regions as unit of analysis in studying cross-country energy intensity inequality and their explanatory factors is highlighted. And finally, how regions around the world differ as to the relevance of the energy transformation index in explaining primary energy intensity inequality.
C69|Computability of simple games: A complete investigation of the sixty-four possibilities|"Abstract Classify simple games into sixteen ""types"" in terms of the four conventional axioms: monotonicity, properness, strongness, and nonweakness. Further classify them into sixty-four classes in terms of finiteness (existence of a finite carrier) and algorithmic computability. For each such class, we either show that it is empty or give an example of a game belonging to it. We observe that if a type contains an infinite game, then it contains both computable ones and noncomputable ones. This strongly suggests that computability is logically, as well as conceptually, unrelated to the conventional axioms."
C69|Working Paper 02-11 - Analyse de politiques de transport : rapprochement des accises sur les carburants et Eurovignette III|This study aims to analyse the impact of two transport pricing policies using the PLANET model. The transport policies are (1) a harmonisation of excise duties on petrol and diesel and (2) road pricing for heavy goods vehicles in accordance with the EU proposal for the Eurovignette III directive. The effects studied concern the consequences for the transport activity for persons and goods, the environmental impact and the impact on social welfare. For both policy types, the impact on the public budget is neutralized through general taxation or labour taxation.
C69|The Forgotten Effects Model In A Crm Strategy|Caring and retaining the customers is now days a fundamental business strategy for the organizations, to confront the market pressures and the competitors’ innovations. Companies have done investments worth millions in customer service, market research, customized support and others. However, it still exists an important gap between the investment and the profit. In many cases recurrent claims are still present, and customer perception of services is not aligned with the business expectations about relationship management efforts. Faced with this apparent dissociation, it stands to reason that companies may be failing to take into account important aspects in their customer relationships, or may not be taking into account attributes that customers value when they want to be treated with a product or service. The purpose of this study is to explore through the Forgotten Effects Model, and reveal hidden attributes that customers value about a product or service in respect of the business objectives. The conclusion of the paper will show how some fundamental aspects of the dimensions of quality of service may be being overlooked.
C69|La Innovación Centrada En El Cliente Utilizando El Modelo De Inferencias En Una Estrategia Crm / Customer Centered Strategic Innovation Using The Inference Model In A Crm Strategy|Todas las áreas de la empresa contactan de alguna forma con sus clientes, algunas directamente y otras desde dentro de la organización. Las estrategias CRM1 conjuntamente con el área de I+D trabajan en la mejora de productos y servicios para cumplir las expectativas de los clientes. Pero, ¿Podría estarse perdiendo internamente información valiosa sobre los clientes? ¿Cómo influye cada área en el proceso innovador? Este artículo presenta el modelo de inferencias lógicas relacionando la injerencia de cada área de la empresa sobre otra en cuanto a la información que comparten de los clientes, buscando así ajustar las estrategias CRM y responder a las expectativas agregando valor / All the areas within the company contact their customers, some directly and others from within the organization. CRM strategies, in conjunction with the R & D area, work on improving products and services to meet customer expectations. But could be missing valuable information of customers internally? How each area does influences in the innovation process? This p+P40aper presents the model of logical inferences, linking the interference of each area of the company over another in terms of client’s information in order to adjust CRM strategies to meet the expectations and adding value.
C69|Benford’s Law as an Instrument for Fraud Detection in Surveys Using the Data of the Socio-Economic Panel (SOEP)|This paper focuses on fraud detection in surveys using Socio-Economic Panel (SOEP) data as an example for testing newly methods proposed here. A statistical theorem referred to as Benford’s Law states that in many sets of numerical data, the significant digits are not uniformly distributed, as one might expect, but adhere to a certain logarithmic probability function. In order to detect fraud, we derive several requirements that should, according to this law, be fulfilled in the case of survey data.We show that in several SOEP subsamples, Benford’s Law holds for the available continuous data. For this analysis, we developed a measure that reflects the plausibility of the digit distribution in interviewer clusters. We are thus able to demonstrate that several interviews that were known to have been fabricated and therefore deleted in the original user data set can now be detected using this method. Furthermore, in one subsample, we use this method to identify a case of an interviewer falsifying ten interviews not previously detected by the fieldwork organization.
C69|Productivity drivers and market dynamics in the Spanish first division football league|No abstract is available for this item.
C69|A remark on static hedging of options written on the last exit time|No abstract is available for this item.
C69|Does Complex Hydrology Require Complex Water Quality Policy? NManager Simulations for Lake Rotorua|This paper examines six different approaches to nutrient management, and simulates the economic costs and environmental impacts associated with them using NManager, a partial equilibrium simulation model developed by Motu and NIWA, the National Institute for Water and Atmospheric Research. We focus on Lake Rotorua in the Bay of Plenty in New Zealand, where the regional council is concerned with the decline in the lake's water quality and has set a goal to restore the lake to its condition during the 1960s. Reaching this goal will require significant reductions in the amount of nutrients discharged into the lake, especially from non-point sources such as farm land. Managing water quality is made difficult by the presence of groundwater lags in the catchment: nutrients that leach from the soil arrive at the lake over multiple years. The mitigation schemes we consider are land retirement, requiring best practice, explicit nitrogen limits on landowners, a simple nutrient trading scheme, and two more complex trading schemes that account for groundwater lags. We demonstrate that best practice alone is not sufficient to meet the environmental target for Lake Rotorua. Under an export trading scheme, the distribution of mitigation across the catchment is more cost effective than its distribution under explicit limits on landowners or land retirement. However, the more complex trading schemes do not result in sufficient, or sufficiently certain, gains in cost effectiveness over the simple trading scheme to justify the increase in complexity involved in their implementation.
C69|Mathematical Approach of an Oligopol Model|"Modern analysis of strategic interactions through game theory has allowed to make some concepts clear. The equillibrium cannot be explained by the process of behaviour study. Each firm should guess the choice of the other firm, just like in a game of type ""scissors-leaves-stone"". The game theory eliminates this arbitrage showing that people act rationally, making decisions strictly individually. Three elements are taken into account:players, strategies and results. The two firms are the two players, the gains are the profits of the two firms and the strategies are represented by the product amount the two firms can produce. Within the present paper, an algebric model will be developed which is in condition to offer to the interested ones a new perspective on (1) how the interaction between firms in a Stackelberg model can be studied and, (2) the way this framework can be extended to a talking about getting into an industry."
C69|A non-parametric analysis of the efficiency of the top European football clubs|This paper analyses how European football clubs’ current value and debt levels influence their performance. The Simar and Wilson (J Econometrics, 136: 31–64, 2007) procedure is used to bootstrap the data envelopment analysis DEA scores in order to establish the influence of football clubs’ current value and debt levels on their obtained efficiency performances. The results reveal that football clubs’ current value levels have a negative influence on their performances, indicating that football clubs’ high value doesn’t ensure higher performance. At the same time, the empirical evidence suggests that there is no influence associated of football clubs’ debt to their efficiency levels.
C69|Applying conditional DEA to measure football clubs’ performance: Evidence from the top 25 European clubs|This paper applies a probabilistic approach to investigate how the top European football clubs’ current value and debt levels influence their performance. Specifically, a bootstrapped conditional data envelopment analysis (DEA) is used in order to measure the effect of football clubs’ current value and debt levels on their obtained efficiency performances. The results indicate that football clubs’ current value levels have a positive influence up to a certain point. But as the current value increases the effect is neutral to football clubs’ performance. At the same time, the empirical evidence suggests that there is no influence on football clubs’ efficiencies associated with lower and medium football clubs’ debt levels while higher debt levels appear to have a direct negative effect.
C69|Method Of Supply Chain Optimization In E-Commerce|E-commerce systems are tools meant to support the supply chain (SC), the quality of which as well as other parts of the e-commerce system largely depend on management processes representing supply chain management (SCM). The optimal way to ensure the success of SCM is to use the methods of modelling and simulation based on appropriate models and mathematical representation of a real SC. Such models are constructed with the use of process and value-chain oriented approaches or based on the concept of multi-agent systems. Different types of models in conjunction with a suitable mathematical representation allow us to perform the simulation process which outputs can help managers make suitable decisions. The paper aims at presenting contemporary approaches to the supply chain modelling within e-commerce systems. Moreover, the case study emphasized hereby is oriented to present the sample simulation approach in order to find the optimal allocation of resources which are meant to minimize shipping costs.
C69|Regional specialization: a measure method and the trends in China|This paper elaborates on a method of measuring regional specialization and examines the trend of regional specialization in China, 1987 - 2007. It constructs a simple coefficient incorporating the effect of regional industrial scale, based on location quotients, and then measures the regional specialization of China using official statistical data. The results indicate a remarkable increase in China’s overall regional specialization during this time, as well as obvious regional and industrial differences, i.e., that the regional specialization of eastern coastal China is relatively less than that of the inland. Findings further demonstrate that special-resource-dependent industries are concentrated in regions with resource endowment, whereas industries with strong technical barriers are mainly located in regions with strong research and innovation ability.
C69|Analysis of multidimensional probability distributions with copula functions. II|This article contains the second part of the consultation series on copula functions and their use in modeling multidimensional probability distributions. It describes pair-copula functions (including the concept of canonical and D-vines), alternative measures of dependence useful to summarize the dependence structure of the analyzed variables (including measures of tail dependence, particularly relevant in the case of asymmetric distributions), as well as parametric, semi-parametric and nonparametric methods of statistical estimation of copula functions.
C69|Analysis of multidimensional probability distributions with copula functions|Problems which are related to copula functions, their properties, selection methods for specific baseline data, evaluation, and possible applications are extremely sparingly discussed in the world literature, and are almost not discussed at all in the Russian literature. At the same time, we already had impressive examples of their applications in situations when the construction, statistical estimation and analysis of multidimensional probability distributions turn out to be an essential tool of applied research, and the use of the multivariate normal (Gaussian) distributions for these purposes does not reflect the specific features of the available data. There are grounds to argue that models which are based on copula functions will be in particular demand for applied econometric studies regarding problems of assessment, analysis and management of financial and insurance risks, as well as the returns of various financial instruments. The material proposed in this issue of the journal is, in fact, a fragment of the forthcoming textbook «Methods of econometrics. Advanced level» by S. A. Aivazian, D. Fantazzini
C69|Analysis of multidimensional probability distributions with copula functions. III|The final part of the consultation series on copula functions is devoted to the description of copula selection methods to choose the copula model that provides the best fit for the empirical data at hand, as well as to the description of copula evaluation methods by using goodness-of-fit tests.
C69|Discretely sampled variance and volatility swaps versus their continuous approximations|Discretely sampled variance and volatility swaps trade actively in OTC markets. To price these swaps, the continuously sampled approximation is often used to simplify the computations. The purpose of this paper is to study the conditions under which this approximation is valid. Our first set of theorems characterize the conditions under which the discretely sampled swap values are finite, given that the values of the continuous approximations exist. Surprisingly, for some otherwise reasonable price processes, the discretely sampled swap prices do not exist, thereby invalidating the approximation. Examples are provided. Assuming further that both swap values exist, we study sufficient conditions under which the discretely sampled values converge to their continuous counterparts. Because of its popularity in the literature, we apply our theorems to the 3/2 stochastic volatility model. Although we can show finiteness of all swap values, we can prove convergence of the approximation only for some parameter values. Copyright Springer-Verlag 2013
C69|Computable and Dynamical Systems Foundations of Bounded Rationality and Satisficing|Formally, the orthodox rational agentís 'Olympian' choices ([14], p.19) are made in a static framework. However, a formalization of consistent choice, underpinned by computability, suggests satisficing in a boundedly rational framework is not only more general than the model of 'Olympian' rationality; it is also consistently dynamic. This kind of naturally process-oriented approach to the formalization of consistent choice can be interpreted and encapsulated within the framework of decision problems - in the formal sense of metamathematics and mathematical logic - which, in turn, is the natural way of formalizing the notion of Human Problem Solving in the Newell-Simon sense. Casting Simon's insights and suggestions on boundedly rational, satisficing and adaptive choice in the formalisms of time computational complexity theory and algorithmic dynamics makes it possible to take some small first steps in the direction of a formal demonstration of this proposition. A more complete attempt would require the additional consideration of space computational complexity, which will be the next step in this research program. The latter consideration would allow one to go beyond the P?=NP conundrum and thereby justify the relative, implicit unimportance, Simon gave this issue
C69|How location decisions influence transport costs of processed and unprocessed bioenergy digestates: The impact of plant size and location on profitability of biogas plants in Germany|The production of bioenergy is considered to be a promising energy source for a sustainable energy mix and it is politically promoted in many countries. With the exception of Brazilian ethanol, bioenergy not competitive to fossil energy sources, and therefore needs to be subsidised. Several types of bioenergy are based on bulky raw biomass with high per unit transport costs, importantly impacting on the plant's production costs and profitability. In addition, considerable quantities of digestates are released, causing disposal costs. Various studies in the past aimed primarily at analysing transport costs of inputs. In this paper we focus on disposal costs of fermentation digestates from biogas production in Germany and analyse different processing techniques and their impact on profitability for three plant size in three case study areas. Our results show that especially in regions with only a small amount of agricultural land and a large heterogeneity in its agricultural area, processing of digestates increases the profitability of biogas production. The same accounts for regions with high livestock density, where the area needed for disposal is comparatively large. The cost efficiency is enforced by a high share of animal excrements on input and the biogas plant size.
C69|How Effective are WTO Disciplines on Domestic Support and Market Access for Agriculture?| A new round of trade negotiations through the World Trade Organization (WTO) was launched in 2001. One of the major aims of the Doha Development Round is to reduce agricultural protection and impose greater discipline on domestic agricultural subsidies, particularly those that are the most trade distorting. In this article, we examine whether the proposed WTO modalities for agriculture will actually achieve this aim in Norway, which ranks among the top providers of government assistance for agriculture. Norway has a complex system of farm subsidies buttressed by substantial import protection. The extent to which its agricultural support policies will have to change in response to new WTO disciplines provides an important indication of how successful these are likely to be. We find that Norway will probably be able to sustain its current agricultural activity and production levels while staying within the new WTO rules. Following recent practice in some other WTO members, Norway will be able to reduce its notified support without making real changes in some of its programmes. However, there will have to be a shift from market price support, which is paid for by consumers through higher food prices, to budgetary support paid by taxpayers. This could generate increased domestic pressure for policy reform.
C69|Structural Change in the Australian Electricity Industry During the 1990s and the Effect on Household Income Distribution|We develop a framework for estimating the direct and indirect effects on household income of industry changes; it combines a computable general equilibrium model with a microsimulation model in a two-stage simulation procedure. We apply the framework to analysing changes in the Australian electricity industry during 1990s and their effect on household income across households. Almost all income deciles are found to have benefited from the changes but the pattern of effects meant that there was also a small increase in income inequality.
C69|COALMOD-World: A Model to Assess International Coal Markets until 2030|"Coal continues to be an important fuel in many countries' energy mix and, despite the climate change concerns, it is likely to maintain this position for the next decades. In this paper a numerical model is developed to investigate the evolution of the international market for steam coal, the coal type used for electricity generation. The main focus is on future trade ows and investments in production and transport infrastructure until 2030. ""COALMOD-World"" is an equilibrium model, formulated in the complementarity format. It includes all major steam coal exporting and importing countries and represents the international trade as one globalized market. Some suppliers of coal are at the same time major consumers, such as the USA and China. Therefore, domestic markets are also included in the model to analyze their interaction with the international market. Because of the different qualities of steam coal, we include different heating values depending on the origin of the coal. At the same time we observe the mass-specific constraints on production, transport and export capacity. The time horizon of our analysis is until 2030, in 5-year steps. Production costs change endogenously over time. Moreover, endogenous investments are included based on a net present value optimization approach and and the shadow prices of capacities constraints. Investments can be carried out in production, inland freight capacities (rail in most countries), and export terminals. The paper finishes with an application of the model to a base case scenario and suggestions for alternative scenarios."
C69|Characterization of the Walrasian equilibria of the assignment model|We study the assignment model where a collection of indivisible goods are sold to a set of buyers who want to buy at most one good. We characterize the extreme and interior points of the set of Walrasian equilibrium price vectors for this model. Our characterizations are in terms of demand sets of buyers. Using these characterizations, we also give a unique characterization of the minimum and the maximum Walrasian equilibrium price vectors. Also, necessary and sufficient conditions are given under which the interior of the set of Walrasian equilibrium price vectors is non-empty. Several of the results are derived by interpreting Walrasian equilibrium price vectors as potential functions of an appropriate directed graph.
C69|Welfare change of China's cotton supply chain under the shock of financial crisis|Purpose - The financial crisis, which broke in the USA has impacted greatly on the world economy, especially on China's cotton supply chain. It is necessary to understand the welfare change of the cotton chain under this shock of financial crisis in order for relevant policy decisions to be made. The purpose of this paper is to measure the welfare change of all the consumers, producers, circulation and farmers in the cotton supply chain under the shock of financial crisis. Design/methodology/approach - There is no existing mature method to calculate the welfare change of a special supply chain, such as the cotton supply chain. The method most used in such situations is the equilibrium displacement model, created by Muth, and developed by Gardner. Findings - The financial crisis has had important impacts on China cotton industry. Farmers' losses are bigger than people estimate. Circulation link's loss is a little lower than cotton farmers'. Producers' loss is far lower than circulation and cotton farmers. Consumers' loss is the biggest loss in the whole cotton supply chain: however, some of these are foreign consumers – especially foreign wholesalers and retailers. Originality/value - This paper is the first to study the quantitative welfare change of China's cotton supply chain under the shock of financial crisis, providing useful information for government and company decision making.
C69|Clustering of categorical variables around latent variables|In the framework of clustering, the usual aim is to cluster observations and not variables. However the issue of variable clustering clearly appears for dimension reduction, selection of variables or in some case studies (sensory analysis, biochemistry, marketing, etc.). Clustering of variables is then studied as a way to arrange variables into homogeneous clusters, thereby organizing data into meaningful structures. Once the variables are clustered into groups such that variables are similar to the other variables belonging to their cluster, the selection of a subset of variables is possible. Several specific methods have been developed for the clustering of numerical variables. However concerning categorical variables, much less methods have been proposed. In this paper we extend the criterion used by Vigneau and Qannari (2003) in their Clustering around Latent Variables approach for numerical variables to the case of categorical data. The homogeneity criterion of a cluster of categorical variables is defined as the sum of the correlation ratio between the categorical variables and a latent variable, which is in this case a numerical variable. We show that the latent variable maximizing the homogeneity of a cluster can be obtained with Multiple Correspondence Analysis. Different algorithms for the clustering of categorical variables are proposed: iterative relocation algorithm, ascendant and divisive hierarchical clustering. The proposed methodology is illustrated by a real data application to satisfaction of pleasure craft operators.
C69|Rotation in Multiple Correspondence Analysis: a planar rotation iterative procedure|Multiple Correspondence Analysis (MCA) is a well-known multivariate method for statistical description of categorical data (see for instance Greenacre and Blasius, 2006). Similarly to what is done in Principal Component Analysis (PCA) and Factor Analysis, the MCA solution can be rotated to increase the components simplicity. The idea behind a rotation is to find subsets of variables which coincide more clearly with the rotated components. This implies that maximizing components simplicity can help in factor interpretation and in variables clustering. In PCA, the probably most famous rotation criterion is the varimax one introduced by Kaiser (1958). Besides, Kiers (1991) proposed a rotation criterion in his method named PCAMIX developed for the analysis of both numerical and categorical data, and including PCA and MCA as special cases. In case of only categorical data, this criterion is a varimax-based one relying on the correlation ratio between the categorical variables and the MCA numerical components. The optimization of this criterion is then reached by the algorithm of De Leeuw and Pruzansky (1978). In this paper, we give the analytic expression of the optimal angle of planar rotation for this criterion. If more than two principal components are to be retained, similarly to what is done by Kaiser (1958) for PCA, this planar solution is computed in a practical algorithm applying successive pairwise planar rotations for optimizing the rotation criterion. A simulation study is used to illustrate the analytic expression of the angle for planar rotation. The proposed procedure is also applied on a real data set to show the possible benefits of using rotation in MCA.
C69|Confidence and ambiguity|This paper proposes a model of the decision-maker’s confidence in his probability judgements, in terms of an implausibility measure – a real-valued function on the set of probability functions. A decision rule is axiomatised according to which the decision-maker evaluates acts using sets of probability functions which vary depending on the agent’s implausibility measure and on what is at stake in the choice of the act. The framework proposed yields a natural notion of comparative aversion to lack of confidence, or ambiguity aversion, and allows the definition of an ambiguity premium. It is shown that these notions are equivalent and can be characterised in terms of the implausibility measure representing the agent’s confidence. A simple portfolio example is presented.
C69|Dynamic causal linkages between the US stock market and the stock markets of the East Asian economies|This paper presents an empirical study in the dynamic causal relationships between each of national stock market of the East Asian economies (Hong Kong, Singapore, Korea (Rep. of), and Taiwan) and the U.S. stock market. This paper complements the existing studies by analyzing the dynamic causal relationship between the U.S. stock market and the East Asian stock markets at different time scales by employing wavelet analysis. Analyses of pre-crisis, East Asian financial crisis (year 1997-2000), inter-crisis and the subprime mortgage crisis (year 2007-2009) periods are conducted to compare the international transmission mechanism of stock market movements. The main empirical insight is that the causal relationship is stronger at finer time scales, whereas the relationship is less and less apparent at longer time horizons. The empirical evidence of the current study indicates that the U.S. stock market Granger-causes almost all the East Asian stock markets regardless of non-crisis periods or not, yet it applies only to the later two sub-sample periods. In general, the empirical results show that short-run causal linkages of the U.S. market to the East Asian economies are more dominant than the causal linkages of the other direction. The results also show that those stock markets are more integrated after the East Asian financial crisis period. Innovations in the U.S. market are transmitted to the stock markets of the East Asian economies in a similar fashion, whereas the degree of responsiveness of those East Asian stock markets differs between the inter-crisis period and the subprime mortgage crisis.
C69|Simulation and Prosecution of a Cartel with Endogenous Cartel Formation|In many cases, collusive agreements are formed by asymmetric firms and include only a subset of the firms active in the cartelized industry. This paper endogenizes the process of cartel formation in a numeric simulation model where firms differ in marginal costs and production technologies. The paper models the incentive to collude in a differentiated products Bertrand-oligopoly. Cartels are the outcomes of a dynamic formation game in mixed strategies. I find that the Nash-equilibrium of this complex game can be obtained efficiently by a Differential Evolution stochastic optimization algorithm. It turns out that large firms have a higher probability to collude than small firms. Since firms' characteristics evolve over time, the simulation is used to generate data of costs, prices, output-quantities, and profits. This data forms the basis for an evaluation of empirical methods used in the detection of cartels.
C69|Aggregating the single crossing property: theory and applications to comparative statics and Bayesian games|The single crossing property plays a crucial role in monotone comparative statics (Milgrom and Shannon (1994)), yet in some important applications the property cannot be directly assumed or easily derived. Difficulties often arise because the property cannot be aggregated: the sum of two functions with the single crossing property need not have the same property. We obtain the precise conditions under which functions with the single crossing property add up to functions with this property. We apply our results to certain Bayesian games when establishing the monotonicity of strategies is an important step in proving equilibrium existence. In particular, we find conditions under which first-price auctions have monotone equilibria, generalizing the result of Reny and Zamir (2004).
C69|Is it worth investing further in AFNR programs?: simulations from a supply-and-demand model|The recent proliferation of state and local universities and colleges compounded with the high unemployment rate among graduates of fields related to agriculture, fisheries, and natural resources (AFNR) questions the validity of government making it a standing policy to make AFNR tertiary education more attractive.This paper attempts to address this issue by way of a supply-and-demand model of AFNR services. Results of the simulations indicate that there are bleak prospects for AFNR graduates in paid employment.The source of the problem appears to be weak demand such that further expansion in AFNR programs and enrolment as well as proposals to further subsidize these programs should be reconsidered.
C69|Trajectories in Physical Space out of Communications in Acquaintance Space: An Agent-Based Model of a Textile Industrial District|This article presents an agent-based model of an Italian textile district where thousands of small firms specialize in particular phases of fabrics production. It is an empirical and methodological model that reconstructs the communications between firms when they arrange production chains. In their turn, production chains reflect into road traffic in the geographical areas where the district extends. The reconstructed traffic exhibits a pattern that has been observed, but not foreseen, by policy makers.
C69|Program Evaluation and Research Designs|"This chapter provides a selective review of some contemporary approaches to program evaluation. One motivation for our review is the recent emergence and increasing use of a particular kind of ""program"" in applied microeconomic research, the so-called Regression Discontinuity (RD) Design of Thistlethwaite and Campbell (1960). We organize our discussion of these various research designs by how they secure internal validity: in this view, the RD design can been seen as a close ""cousin"" of the randomized experiment. An important distinction which emerges from our discussion of ""heterogeneous treatment effects"" is between ex post (descriptive) and ex ante (predictive) evaluations; these two types of evaluations have distinct, but complementary goals. A second important distinction we make is between statistical statements that are descriptions of our knowledge of the program assignment process and statistical statements that are structural assumptions about individual behavior. Using these distinctions,we examine some commonly employed evaluation strategies, and assess them with a common set of criteria for ""internal validity"", the foremost goal of an ex post evaluation. In some cases, we also provide some concrete illustrations of how internally valid causal estimates can be supplemented with specific structural assumptions to address ""external validity"": the estimate from an internally valid ""experimental"" estimate can be viewed as a ""leading term"" in an extrapolation for a parameter of interest in an ex ante evaluation."
C69|The Minimum Food Security Quota (MFS-Quota) in Food Security Policy Modelling|This paper proposes the construction of the Minimum Food Security Quota (MFSQuota)using mathematical economic modelling in real time. The MFS-Quota fixes a certain amount of annual food storage to prepare a country for any natural or social disasters. Any country can construct its own MFS-Quota for “food security policy”.
C69|Types and Priorities of Multi-Agent System Interactions|Multi-Agent Systems may be classified as containing No Direct Interactions, Simple Interactions or Complex, Conditional Interactions between agents. This paper argues and illustrates that models with simple interactions, even though possibly less fascinating for the Multi-agent system theorists than complex interaction models are, deserve more attention in the Multi-agent system community. Simple interaction models may contain social learning and reciprocal relationships. Maybe most importantly, Simple interaction models enable cross-scale connections by linking local to global actors in their local and global 'life worlds'. Classification-ACM-1998: J.4 [Computer Applications]; Social and behavioral sciences - Sociology
C69|Equilibrio financiero del régimen contributivo de aseguramiento en salud, 2010-2050: dinámica laboral, poblacional y crecimiento económico|Este trabajo tiene como objetivo analizar el equilibrio financiero del re?gimen contributivo de aseguramiento en salud, para el peri?odo 2010-2050, a partir de la construccio?n de un modelo que simula el comportamiento de afiliacio?n y financiacio?n de este re?gimen, e incorporando elementos de la dina?mica laboral, poblacional (feno?meno de transicio?n demogra?fica) y crecimiento econo?mico en Colombia. Se estima para cada an?o simulado el balance de la Subcuenta de Compensacio?n del fosyga, cuenta encargada de administrar los recursos del re?gimen contributivo. El estudio revela que bajo diversos escenarios el re?gimen no es autofinanciable, consolidando un de?ficit que se encuentra entre el 4% y 6% del pib de 2008. Los resultados obtenidos sen?alan que para garantizar la sostenibilidad del sistema es necesario incrementar las contribuciones en un punto porcentual, superior al 0,9% de los aportes a salud actuales que se dirigen al proceso de compensacio?n interno. Abstract: This article analyzes the financial sustainability of the Colombian contributive health insurance regime for the 2010-2050 period, by constructing a model that simulates affiliation behavior and the financing of the regime, incorporating aspects of labor market and population dynamics (demographic transition) and economic growth.
C69|A viability theory approach to a two-stage optimal control problem of technology adoption|"A new technology adoption problem can be modelled as a two-stage control problem, in which model parameters (""technology"") might be altered at some time. An optimal solution to utility maximisation for this class of problems needs to contain information on the time, at which the change will take place (0, finite or never), along with the optimal control strategies before and after the change. For the change, or switch, to occur the ""new technology"" value function needs to dominate the ""old technology"" value function, after the switch. We charaterise the value function using the fact that its hypograph is a viability kernel of an auxiliary problem and we study when the graphs can intersect. If they do not, the switch cannot occur at a positive time. Using this characterisation we analyse a technology adoption problem and showmodels, for which the switch will occur at time zero or never."
C69|Confidence and ambiguity|This paper proposes a model of the decision-maker's confidence in his probability judgements, in terms of an implausibility measure – a real-valued function on the set of probability functions. A decision rule is axiomatised according to which the decision-maker evaluates acts using sets of probability functions which vary depending on the agent's implausibility measure and on what is at stake in the choice of the act. The framework proposed yields a natural notion of comparative aversion to lack of confidence, or ambiguity aversion, and allows the definition of an ambiguity premium. It is shown that these notions are equivalent and can be characterised in terms of the implausibility measure representing the agent's confidence. A simple portfolio example is presented.
C69|Testing Models With Multiple Equilibria by Quantile Methods| This paper proposes a method for testing complementarities between explanatory and dependent variables in a large class of economic models. The proposed test is based on the monotone comparative statics (MCS) property of equilibria. Our main result is that MCS produces testable implications on the (small and large) quantiles of the dependent variable, despite the presence of multiple equilibria. The key features of our approach are that (i) we work with a nonparametric structural model of a continuous dependent variable in which the unobservable is allowed to be correlated with the explanatory variable in a reasonably general way; (ii) we do not require the structural function to be known or estimable; (iii) we remain fairly agnostic on how an equilibrium is selected. We illustrate the usefulness of our result for policy evaluation within Berry, Levinsohn, and Pakes's (1999) model. Copyright 2009 The Econometric Society.
C69|The Dynamic of Bicycle Finals: A Theoretical and Empirical Analysis of Slipstreaming|The finals of bicycle races have certain peculiarities compared to other sports. The leading group in a bicycle race rides comparatively slowly until one of the competitors tries to shake off his opponents. Only then do all riders perform to the limit. This raises the question of who takes the thankless early lead and why. The rider who is in front just before the final sprint is seldom the one who wins. The relevant physics and their implications for sport economics are analysed and tested empirically.
C69|When is there state independence?|Whether a preference relation can be represented using state-independent utilities as opposed to state-dependent utilities may depend on which acts count as constant acts. This observation underlies an extension of Savage's expected utility theory to the state-dependent case that was proposed in this journal by Edi Karni. His result contains a condition requiring the existence of a set of acts which can play the role of constant acts and support a representation involving a state-independent utility function. This paper contains necessary and sufficient conditions on the preference relation for such a set of acts to exist. Results are obtained both for the Savage and the Anscombe and Aumann frameworks. Among the corollaries are representation theorems for state-dependent utilities. Relationships to Karni's work and extensions of the results are discussed.
C69|Exploring time diaries using semi-automated activity pattern extraction|Identifying patterns of activities in time diaries in order to understand the variety of daily life in terms of combinations of activities performed by individuals in different groups is of interest in time use research. So far, activity patterns have mostly been identified by visually inspecting representations of activity data or by using sequence comparison methods, such as sequence alignment, in order to cluster similar data and then extract representative patterns from these clusters. Both these methods are sensitive to data size, pure visual methods become too cluttered and sequence comparison methods become too time consuming. Furthermore, the patterns identified by both methods represent mostly general trends of activity in a population, while detail and unexpected features hidden in the data are often never revealed. We have implemented an algorithm that searches the time diaries and automatically extracts all activity patterns meeting user-defined criteria of what constitutes a valid pattern of interest for the user’s research question. Amongst the many criteria which can be applied are a time window containing the pattern, minimum and maximum occurrences of the pattern, and number of people that perform it. The extracted activity patterns can then be interactively filtered, visualized and analyzed to reveal interesting insights. Exploration of the results of each pattern search may result in new hypotheses which can be subsequently explored by altering the search criteria. To demonstrate the value of the presented approach we consider and discuss sequential activity patterns at a population level, from a single day perspective.
C69|Algorithm For Generalized Garman Equation In Option Pricing Of A Financial Derivatives With Stochastic Volatility Models|In our paper we build a reccurence from generalized Garman equation and discretization of 3-dimensional domain. From reccurence we build an algorithm for computing values of an option based on time, momentan volatility of support and value of support on a
C69|Evaluación de los efectos de la remoción de medidas para-arancelarias sobre las exportaciones argentinas de productos textiles<BR>[Assessing the efects of eliminating non-tariff barriers over the Argentine Textile Exports]|This paper offers a quantification of price differentials not explained by tariff policy and the assessment of efficiency costs burned on different economic agents involved in textile products trade between Argentina (exporter) and Brazil (domestic producer). Simulations are carried out to show the effects of the distortion of price differentials, considered like non tariff barriers or a set of them and others obstacle to trade. From the removal of non tariff barriers results that consumers and exporters obtain grater consumer surplus and profits, respectively, while domestic producers loose part of their producer surplus. Consumers and exporters are better because of changes in terms of trade; in some products consumers obtain graters benefits than exporters and vice versa. Likewise, changes in elasticities (direct elasticity of supply and demand) were simulated to observe distortions in previous results.
C69|Voting Features based Classifier with Feature Construction and its Application to Predicting Financial Distress|Voting features based classifiers, shortly VFC, have been shown to perform well on most real-world data sets. They are robust to irrelevant features and missing feature values. In this paper, we introduce an extension to VFC, called voting features based classifier with feature construction, VFCC for short, and show its application to the problem of predicting if a bank will encounter financial distress, by analyzing current financial statements. The previously developed VFC learn a set of rules that contain a single condition based on a single feature in their antecedent. The VFCC algorithm proposed in this work, on the other hand, constructs rules whose antecedents may contain conjuncts based on several features. Experimental results on recent financial ratios of banks in Turkey show that the VFCC algorithm achieves better accuracy than other well-known rule learning classification algorithms.
C69|Exploring the effect of countries’ economic prosperity on their biodiversity performance|This paper demonstrates an evaluation of 71 developed and under-developed countries’ biodiversity performance using a methodological framework based to the new advances of Data Envelopment Analysis (DEA). By using conditional DEA, bootstrapping and kernel density estimations, efficiency levels of 71 countries are compared and analyzed. In such a way the paper by modelling and measuring countries’ biodiversity performance analyses whether the countries environmental policies have been used efficiently in order to enhance biodiversity. Our empirical results indicate that there are major inefficiencies among the 71 countries in terms of their biodiversity performances which have been negatively influenced by their higher levels of population and of GDP per capita.
C69|Концептуальная Модель Координации Процессов Управления Региональным Инвестиционным Проектом<BR>[Conceptual Model of Coordination of Regional Investment Project Management Processes]|The article explores new actual problem of investment processes’ coordination modeling at regional level. The research is driven to develop conception and complex of models to coordinate investments. Methods and tools of their implementation under current economic conditions at regional level in Ukraine are examined as well. Conception of coordination of regional investment processes that provide effective investment resources allocation including different level budget and off-budget resources is proposed. Article also develops complex of economic and mathematical models that promote coordination of investment processes and regional development programs. Structure of DSS in the field of investments management is improved. The outcome of implementation the research results in Donetsk Regional State Administration is improvement of investment processes management system that led to better economic efficiency of regional investment projects.
C69|Global Simulation of Quality and Security of Human Life|"A system of factors (indices and indicators) and a new method of quantitative and qualitative evaluation are developed. This system, named “Sustainable Development Gauging Matrix” (SDGM) and data presented by reliable international organizations culminated in a Global Simulation regarding quality of life and security of the world population. Specifically, this study focuses on the analysis of the Systematic Regularity of World Conflicts over the Course of Time. A prognosis is detailed of the next world conflict, labeled the ""Conflict of XXI Century”, and an analysis is provided of its nature and main characteristics; duration, main phases of the conflict and intensity. This prognosis details a set of basic global threats that spawn this conflict. Using cluster analysis, its influence on different countries of the world is accurately defined. These results were obtained by applying the capabilities of the world data centers network as a tool for providing a variety of scientific interdisciplinary data."
C69|Global recessions as a cascade phenomenon with interacting agents|No abstract is available for this item.
C69|La desigualdad en las intensidades energéticas y la composición de la producción. Un análisis para los países de la OCDE|Esta investigación analiza las desigualdades de las intensidades energéticas entre países de la OCDE, su evolución y sus causas. Estas intensidades constituyen uno de los principales factores determinantes de las emisiones per cápita y, por tanto, de las diferencias que se dan entre países y grupos de países. Se desarrolla una metodología que permite la descomposición de la desigualdad en los consumos de energía per cápita en factores explicativos, además de analizar la contribución de diferentes grupos de países. Destaca que, si bien las diferencias en afluencia económica son el factor más relevante en la explicación las desigualdades en el consumo energético per cápita, la desigualdad en intensidad energética juega un papel prominente en su reducción en el periodo analizado. A continuación, se desarrolla una metodología que permite determinar la importancia de las diferentes estructuras productivas y de las diferencias en eficiencia energética en el mayor o menor uso de energía por unidad de PIB en los diferentes países y grupos de países. Los resultados muestran que la especialización productiva gana peso en la explicación de las desigualdades en las intensidades energéticas, mientras que se da una importante tendencia a la igualación de la eficiencia energética entre países sector a sector. Esta tendencia explicaría, a su vez, el peso decreciente de la intensidad energética como factor explicativo de las desigualdades en consumos energéticos.
C69|Credit dynamics in a first passage time model with jumps|The payoff of many credit derivatives depends on the level of credit spreads. In particular, the payoff of credit derivatives with a leverage component is sensitive to jumps in the underlying credit spreads. In the framework of first passage time models we extend the model introduced in [Overbeck and Schmidt, 2005] to address these issues. In the extended a model, a credit quality process is driven by an Itô integral with respect to a Brownian motion with stochastic volatility. Using a representation of the credit quality process as a time-changed Brownian motion, we derive formulas for conditional default probabilities and credit spreads. An example for a volatility process is the square root of a Lévy-driven Ornstein-Uhlenbeck process. We show that jumps in the volatility translate into jumps in credit spreads. We examine the dynamics of the OS-model and the extended model and provide examples.
C69|The virtues and vices of equilibrium and the future of financial economics|The use of equilibrium models in economics springs from the desire for parsimonious models of economic phenomena that take human reasoning into account. This approach has been the cornerstone of modern economic theory. We explain why this is so, extolling the virtues of equilibrium theory; then we present a critique and describe why this approach is inherently limited, and why economics needs to move in new directions if it is to continue to make progress. We stress that this shouldn't be a question of dogma, but should be resolved empirically. There are situations where equilibrium models provide useful predictions and there are situations where they can never provide useful predictions. There are also many situations where the jury is still out, i.e., where so far they fail to provide a good description of the world, but where proper extensions might change this. Our goal is to convince the skeptics that equilibrium models can be useful, but also to make traditional economists more aware of the limitations of equilibrium models. We sketch some alternative approaches and discuss why they should play an important role in future research in economics.
C69|"Auf dem Weg zu einer ""COAL-PEC""?"|"Die Bedeutung von Kohle wird heute oft unterschätzt, da sie lange als eine Ressource der Vergangenheit galt. Dabei ist Kohle nach wie vor Grundpfeiler der Stromerzeugung in den meisten Ländern: Ein Viertel des weltweiten Primärenergieverbrauchs wird durch Kohle gedeckt. Während die größten Kohleproduzenten China, USA und Indien auch gleichzeitig die größten Konsumenten sind, beteiligen sich kleinere Kohleproduzenten und -verbraucher in umfangreichem Maße am internationalen Handel. Insbesondere der seewärtige Kohlehandel hat seit Anfang der 90er Jahre stark zugenommen. In den vergangenen zwei Jahren sind auch die Preise für Importkohle deutlich gestiegen. In den letzten Wochen mussten Importeure in Europa Spitzenpreise von über 200 US-Dollar pro Tonne zahlen, ein Vielfaches des langjährigen Durchschnitts. In diesem Zusammenhang wird zunehmend die Befürchtung laut, der internationale Kohlemarkt könne sich - analog zum Ölmarkt, welcher nach wie vor von der OPEC dominiert wird - in Richtung eines Anbieterkartells entwickeln, einer ""COAL-PEC"". Tatsächlich war in den vergangenen Jahren eine starke Tendenz der Unternehmenskonzentration auf dem internationalen Kohlemarkt zu beobachten. Die gestiegenen Preise könnten somit auch aus Marktmacht resultieren. Weitere Gründe für den Preisanstieg sind stark steigende Nachfrage, insbesondere aus China und Indien, Kapazitätsengpässe in der Produktion und der Verschiffung sowie mangelnde Investitionen. Auch in Zukunft ist mit einem engen Markt und hohen Kohlepreisen zu rechnen."
C69|Analysis of the World Market for Steam Coal Using a Complementarity Model|With its resource availability and the prospect of climate friendly technology, coal continues to play an important role in the global energy sector. We develop a complementarity model of the international market for steam coal. We want to analyze the level of competition in this market which is strategic for the importers' security of energy supply. In a spatial equilibrium framework, we assume the steam coal exporters to maximize their profits by choosing the optimal quantity to sell to each importing country. We compare two possible scenarios: perfect competition and Cournot competition. The results, especially the price levels, indicate that the Cournot model is not realistic, suggesting that the producing countries do not exert market power. However, the trade flows and prices observed in reality suggests that there is some form of market power with price discrimination, possibly following a Bertrand model in a spatial setting.
C69|"Moving towards a ""COAL-PEC""?"|"Coal has for many years been considered as a resource of the past and as a result its importance has been underestimated. Yet coal still is the main pillar for generating electricity in most countries: A quarter of the worldwide primary energy consumption is provided by coal. While the world's largest coal producers, China, the USA and India, are at the same time the largest consumers of coal. Smaller producers and consumers of coal engage extensively in international trade. In particular the seaborne coal trade has increased significantly since the 1990's. In the past two years prices of import coal also have increased considerably. In September 2008, importers in Europe had to pay prices of more than 200 US dollars per ton, a price level many times higher than the historical average. In this context, fears have increasingly been voiced that the international coal market - analogous to the oil market which continues to be dominated by the OPEC-might witness the emergence of a supplier cartel, a ""COAL-PEC"". A strong tendency towards the concentration of companies has in fact been observed in the international coal market in the past years. Increased prices could have resulted from the use of market power. Drivers for the price increase were the strong rise in demand, in particular from China and India, capacity bottlenecks in production and shipment as well as a lack of investments. In the future a tight market and high coal prices have to be expected."
C69|Computability of simple games: A characterization and application to the core|It was shown earlier that the class of algorithmically computable simple games (i) includes the class of games that have finite carriers and (ii) is included in the class of games that have finite winning coalitions. This paper characterizes computable games, strengthens the earlier result that computable games violate anonymity, and gives examples showing that the above inclusions are strict. It also extends Nakamura’s theorem about the nonemptyness of the core and shows that computable simple games have a finite Nakamura number, implying that the number of alternatives that the players can deal with rationally is restricted.<br><small>(This abstract was borrowed from another version of this item.)</small>
C69|Automatismos y racionalidad en la toma de decisiones para sustituir a un deportista en momentos decisivos| [ES] Cada vez más el deporte-espectáculo se está abriendo paso como objeto de estudio en los centros de investigación avanzada, como consecuencia de la necesidad de gestionar los altos presupuestos de las entidades deportivas.
C69|How Much is Location Information Worth? A Competitive Analysis of the Online Traveling Salesman Problem with Two Disclosure Dates|In this paper we derive the worst-case ratio of an online algorithm for the Traveling Salesman Problem (TSP) with two disclosure dates. This problem, a variant of the online TSP with release dates, is characterized by the disclosure of a job’s location at one point in time followed by the disclosure of that job’s release date at a later point in time. We present an online algorithm for this problem restricted to the positive real number line. We then derive the worst-case ratio of our algorithm and show that it is best-possible in two contexts – the first, one in which the amount of time between the disclosure events and release time are fixed and equal for all jobs; and a second in which the time between disclosure events varies for each job. We conclude that the value of advanced information can be attributed to the location information alone – yielding an optimal solution in favorable instances.
C69|Analysis and Synthesis of Terminal Control Reduction Problem|One of the most important problems of terminal control reduction problem is considered and solved. On the base of spinor representation of spatial rotation group, the control law functions are obtained. A mathematical model of reduction process is constructed. The results can be used for practical purposes to elaborate simple control algorithms of spatial movement reduction process in many different fields.
C69|Modelling of Deceleration Process of Spatial Movements|Solution of breaking problem of moving mechanical object is discussed. Five boundary values are used for the problem. Mathematical model of the process has been obtained. Also all dynamic functions and characteristics are represented. They shoe the accuracy of terminal positioning of deceleration.
C69|Çevresel düzeyde sürdürülebilirlik performansının ölçülmesi: Parekende sektöründe bir uygulama|Firmalar arası çevreye duyarlı faaliyetlere yönelik girisimler, çevresel gerekliliklerin tedarik zincirleri boyutunda incelenmesini ve bu fi rmaların uyumlu çalısmalarının sürdürülebilir büyümeye olan etkisini ortaya koymayı gerektirmektedir. Bununla birlikte, farklı tedarik zincirleri üzerindeki üyelerin çevresel gelismelere neden olan ortak faaliyetlerinin arzu edilen basarıya ulasması, bu dogrultuda belli bir piyasa gücüne ve güdüye sahip lider firmaların sorumluluk üstlenmelerini zorunlu kılmaktadır. Perakendeci fi rmalar, deger zincirleri üzerinde oynamıs oldukları önemli roller ve çevreye duyarlı ürünlerin üretiminde tedarikçileri üzerinde yaratmıs oldukları etkiler sebebi ile sürdürülebilir kalkınmayı tetikleyici temel aktörler olabilirler. Geçtigimiz on yıl içerisinde, artan tüketici farkındalıgı, ticari birliklerin baskısı, yeni yasal düzenlemeler, bilgi teknolojilerinde meydana gelen degisiklikler ve medyanın konuya olan ilgisi gibi birçok etken, perakendecileri gerçeklestirdikleri faaliyetlerin neden oldugu çevresel etkileri dikkate almak zorunda bırakmıstır. AB sınırları içerisinde faaliyet göstermekte olan perakende birlikleri, perakendeciligin sürdürülebilirligi yönünde yeni stratejiler belirlemekte ve bu stratejilerin perakendecilik sektöründe yeni is yapma biçimlerinin gelistirilmesine neden olacagını vurgulamaktadırlar. Bu çalısmada, sürdürülebilirligin çevresel boyutu üzerinde durulacak ve perakende sektörüne yönelik bir çevresel sürdürülebilirlik karsılastırılması yapılacaktır. Bildiri izleyen bölümlerden olusacaktır: Birinci bölümde konuya iliskin literatür analizinin verilmesi amaçlanmıstır, ikinci bölümde çok kriterli karar verme yöntemlerine dayalı arastırma yönteminin ortaya konulmaktadır, üçüncü bölümde ise üç perakendeci fi rmanın önerilen yöntem kullanılarak çevresel sürdürülebilirlik performansı ölçülmekte, ve nihayet dördüncü bölümde sonuçlar tartısılmaktadır.
C69|"A Mathematical Representation of ""Excitement"" in Games: A Contribution to the Theory of Game Systems"|"Researchers have long believed the concept of ""excitement"" in games to be subjective and difficult to measure. This paper presents the development of a mathematically computable index that measures the concept from the viewpoint of an audience and from that of a player. One of the key aspects of the index is the differential of the probability of ""winning"" before and after one specific ""play"" in a given game. The index makes a large contribution to the study of games and enables researchers to compare and analyze the “excitement” of various games. It may be applied in many fields, especially the area of welfare economics, and applications may range from those related to allocative efficiency to axioms of justice and equity."
C69|Introduction to the Special Issue on Agent-Based Models for Economic Policy Advice|This special issue of the Journal of Economics and Statistics is devoted to the use of agent-based models for economic policy advice. It presents a collection of research papers in different fields of applications. Special emphasis is laid on discussing the potential and possible limitations of agent-based models for economic policy advice. The editorial provides an overview on the role of agent-based modeling in economic policy referring also to the papers presented. Furthermore, it highlights the strength of the approach, i.e., the explicit microfoundation and the modeling of heterogenous agents. Finally, we also report on current limitations of the method with regard to economic policy advice and point at some areas deserving further research.
C69|Complex Price Dynamics in a Financial Market with Imitation|No abstract is available for this item.
C69|ICT in Czech companies: business efficiency potentials to be achieved|The paper deals with business potential analysis based on the data published by Czech Statistic Authority (SÚ). It shows that the infrastructure state of the art even in small Czech companies enables to expand ERP and CRM systems, trading over Internet, Supply Chain Management and other new trends. Internet security is here of greatest importance, however it cannot be seen as major obstacle for new trading methods. The greatest challenge identified is the process and workflow optimization. To streamline workflow the document management supporting nearly seamless integration crossover the functional areas is of greatest importance. Moreover, process optimization can run into difficulties due to cross-organization functionalities of new IT architecture concepts like Service Oriented Architecture, WEB2 concepts and other methods and means. In this paper the value flow approach is shortly mentioned as an alternative to process modeling and workflow approach. Value oriented methods can overcome the process oriented approach limitations.
C69|Dominant, weakly stable, uncovered sets: properties and extensions|Twelve sets, proposed as social choice solution concepts, are compared: the core, five versions of the uncovered set, two versions of the minimal weakly stable sets, the uncaptured set, the untrapped set, the minimal undominated set (strong top cycle) and the minimal dominant set (weak top cycle). The main results presented are the following. A criterion to determine whether an alternative belongs to a minimal weakly stable set is found. It establishes the logical connection between minimal weakly stable sets and covering relation. In tournaments and in general case it is determined for all twelve sets, whether each two of them are related by inclusion or not. In tournaments the concept of stability is employed to generalize the notions of weakly stable and uncovered sets. New concepts of k-stable alternatives and k-stable sets are introduced and their properties and mutual relations are explored. A concept of the minimal dominant set is generalized. It helps to establish that in general case all dominant sets are ordered by strict inclusion. In tournaments the hierarchies of the classes of k-stable alternatives and k-stable sets combined with the system of dominant sets constitute tournament’s structure (“microstructure” and “macrostructure” respectively). This internal structure may be treated as a system of reference, which is based on difference in degrees of stability.
C69|A Social Accounting Matrix of Mexico for the Year 2000|The usefulness of a Social Accounting Matrix (SAM) has been solidly established, both, as a major element for economic analysis and policy studies, and for designing and implementing multisectoral models. In this paper we present a Social Accounting Matrix of Mexico for the year 2000, documenting a detailed methodology used for its construction. It is shown that, with an Input Output Table of Mexico for the year 2000 as a basis, and using available information from the System of National Accounts of Mexico, it is possible to build a balanced macro SAM, and then a consistent micro SAM, without resorting to any of the several balancing and estimation procedures developed for the cases in which incomplete, and/or inconsistent information, prevents construction of a fully documented SAM. Therefore, this transparent SAM can be used (modified and/or extended) to apply a wide array of analytical methodologies to study a wide variety of policy issues.
C69|Efficacité technique des banques de la CEMAC<BR>[Technical efficiency of the banks of the CEMAC]|In one decade, the CEMAC's countries passed from a banking crisis context to an excess systemic liquidity. In the present survey, we valued the relative levels of technical efficiency of 24 commercial banks of the CEMAC from January 2001 to December 2004 using the DEA method, and searched for the factors of the banking management susceptible to explain these evolutions. The results shows that, on average, under the hypothesis of constant scale outputs, the banks of the CEMAC only produced 36,9% of the quantity of outputs that they could have produced from their resources. While rather supposing the outputs variable, the middle level of technical efficiency settled to 0,693. Of other parts, The explanatory factors of the evolution of the technical efficiency of the banks during this period are: i) the risk of defect; ii) the importance of the Bank, identified by the proportion of the capital stocks on the assets of the banks, iii) the level of the treasury excesses, and iv) the proportion of capital stock in the total of the credits.
C69|Unanimous subjective probabilities|No abstract is available for this item.
C69|The Nakamura numbers for computable simple games|The Nakamura number of a simple game plays a critical role in preference aggregation (or multi-criterion ranking): the number of alternatives that the players can always deal with rationally is less than this number. We comprehensively study the restrictions that various properties for a simple game impose on its Nakamura number. We find that a computable game has a finite Nakamura number greater than three only if it is proper, nonstrong, and nonweak, regardless of whether it is monotonic or whether it has a finite carrier. The lack of strongness often results in alternatives that cannot be strictly ranked.<br><small>(This abstract was borrowed from another version of this item.)</small>
C69|Random matrix theory and the evolution of business cycle synchronisation 1886-2006|The major study by Bordo and Helbing (2003) analyses the business cycle in Western economies 1881-2001. They examine four distinct periods in economic history, and conclude that there is a secular trend towards greater synchronisation for much of the 20th century. Their analysis, in common with the standard economic literature on business cycle synchronisation, relies upon the estimation of an empirical correlation matrix of time series data of macroeconomic aggregates. However because of the small number of observations and economies, the empirical correlation matrix may contain considerable noise. Random matrix theory was developed to overcome this problem. I use random matrix theory, and the associated technique of agglomerative hierarchical clustering, to examine the evolution of business cycle synchronisation between the capitalist economies in the long-run. Contrary to the findings of Bordo and Helbing, it is not possible to speak of a 'secular trend' towards greater synchronisation over the period as a whole. During the pre-First World War period, the cross-country correlations of annual real GDP growth are indistinguishable from those which could be generated by a purely random matrix. The periods 1920-38 and 1948-72 do show a certain degree of synchronisation, but it is very weak. In particular, the cycles of the major economies cannot be said to be synchronised. Such synchronisation as exists in the overall data is due to meaningful co-movements in sub-groups. So the degree of synchronisation has evolved fitfully. It is only in the most recent 1973-2006 period that we can speak meaningfully of anything resembling an international business cycle.
C69|Random Matrix Theory and Macro-Economic Time-Series: An Illustration Using the Evolution of Business Cycle Synchronisation, 1886-2006|The aim of this paper is to show that random matrix theory (RMT) can be a useful addition to the economist?s tool-kit in the analysis of macro-economic time series data. A great deal of applied economic work relies upon empirical estimates of the correlation matrix. However due to the finite size of both the number of variables and the number of observations, a reliable determination of the correlation matrix may prove to be problematic. The structure of the correlation matrix may be dominated by noise rather than by true information. Random matrix theory was developed in physics to overcome this problem, and to enable true information in a matrix to be distinguished from noise. There is now a large literature in which it is applied successfully to financial markets and in particular to portfolio selection. The author illustrates the application of the technique to macro-economic time-series data. Specifically, the evolution of the convergence of the business cycle between the capitalist economies from the late 19th century to 2006. The results are not in sharp contrast with those in the literature obtained using approaches with which economists are more familiar. However, there are differences, which RMT enables us to clarify.
C69|Aufkommens- und Verteilungseffekte der Unternehmensteuerreform 2008: eine Analyse mit dem Unternehmensteuer-Mikrosimulationsmodell BizTax|The DIW Berlin microsimulation model of business taxation BizTax allows a representative and detailed analysis of the fiscal and distributional effects of business taxation in Germany. The model is based on extrapolated individual local business tax files. We simulate essential elements of the business tax reform 2008 proposed by the German government. The simulation results confirm the government's estimation of the revenue effects to a large extent. While the reform reduces the tax burden of non-incorporated firms, corporations benefit only temporarily because the tax base broadening takes increasing effect in the forthcoming years. Firms with high profits benefit from the generally reduced tax rates, while small non-incorporated firms with low profits Das Mikrosimulationsmodell zur Unternehmensbesteuerung BizTax des DIW Berlin basiert auf fortgeschriebenen Einzeldaten der Gewerbesteuerstatistik. Damit können erstmals die Aufkommens- und Verteilungswirkungen der Unternehmensbesteuerung repräsentativ und realitätsnah beschrieben werden. Simulationsergebnisse zu wesentlichen Elementen der Unternehmensteuerreform 2008 bestätigen weitgehend die Aufkommensschätzung der Bundesregierung. Personenunternehmen werden durch die Reform tendenziell entlastet. Kapitalgesellschaften werden nur vorübergehend entlastet, da sich bei ihnen die Verbreiterung der Bemessungsgrundlage in den kommenden Jahren verstärkt bemerkbar machen wird. Ertragsstarke Unternehmen profitieren von den Steuersatzsenkungen, kleinere oder ertragsschwächere Personenunternehmen werden durch den Wegfall des Staffeltarifs stärker mit Gewerbesteuer belastet.
