C49|The Phillips Curve at 60: time for time and frequency|We estimate the U.S. New Keynesian Phillips Curve in the time-frequency domain with continuous wavelet tools, to provide an integrated answer to the three most controversial issues on the Phillips Curve. (1) Has the short-run tradeoff been stable? (2) What has been the role of expectations? (3)Is there a long-run tradeoff? First, we find that the short-run tradeoff is limited to some specific episodes and short cycles and that there is no evidence of nonlinearities or structural breaks. Second, households' expectations captured trend inflation and were anchored until the Great Recession, but not since 2008. Then, inflation over-reacted to expectations at short cycles. Finally, there is no significant long-run tradeoff. In the long-run, inflation is explained by expectations.
C49|The evolution of US and UK GDP components in the time-frequency domain : A continuous wavelet analysis|Understanding the relationship between national income GDP components is an essential part of macroeconomics. This study investigates quarterly real GDP component data for the U.S. and the U.K. and applies continuous wavelet analysis on cross comparisons of the data, from both within and between the two datasets. The results show that the cyclical interactions between consumption and investment are the most complex and most substantial at several different frequencies. The relationship of exports with other macroeconomic variables has also developed over time, likely due to the evolution of an international business cycle.
C49|Social Capital and Health: A Meta-Analysis|This study investigates the extensive empirical literature on social capital and health using meta-analysis. Our final sample consists of 12,459 estimated effects taken from 450 studies. Our main result is that the overall mean size of the effect of social capital on health is very small, though it is statistically significant. This low association follows from a relatively large share of individually insignificant estimates, combined with the large sample sizes that characterize this literature. Furthermore, despite an extensive theoretical literature concerned with delineating different kinds of social capital, we find few systematic empirical differences. While cognitive social capital has a significantly stronger association with health than structural social capital, especially for mental health, the difference is empirically minor. There is no evidence of significant differences between bonding, bridging, and linking social capital.
C49|Risk and Rationality:The Relative Importance of Probability Weighting and Choice Set Dependence|We analyze the relative importance of probability weighting and choice set dependence in describing risky choices both non-parametrically and with a structural model. Our experimental design uses binary choices between lotteries that may trigger Allais Paradoxes. We change the choice set by manipulating the correlation structure of the lotteries' payoffs while keeping their marginal distributions constant. This allows us to discriminate between probability weighting and choice set dependence. There are three main results. First, probability weighting and choice set dependence both play a role in describing aggregate choices. Second, the structural model uncovers substantial individual heterogeneity which can be parsimoniously characterized by three types: 38% of subjects engage primarily in probability weighting, 34% are in uenced predominantly by choice set dependence, and 28% are mostly rational. Third, the classification of subjects into types predicts preference reversals out-of-sample. These results may not only further our understanding of choice under risk but may also prove valuable for describing the behavior of consumers, investors, and judges.
C49|Risk and Rationality:The Relative Importance of Probability Weighting and Choice Set Dependence|The literature suggests that probability weighting and choice set dependence influence risky choices. However, their relative importance has not been tested jointly.We present a joint test that uses binary choices between lotteries provoking Common Consequence and Common Ratio Allais Paradoxes and manipulates their correlation structure. We show non-parametrically that probability weighting and choice set dependence both play a role at describing aggregate choices. To parsimoniously account for heterogeneity, we also estimate a structural model using a finite mixture approach.The model uncovers substantial heterogeneity and classifies subjects into three types: 38% Prospect Theory types whose choices are predominantly driven by probability weighting, 34% Salience Theory types whose choices are predominantly driven by choice set dependence, and 28% Expected Utility Theory types. The model predicts typespecific dierences in the frequency of preference reversals out-of-sample. Moreover, the out-of-sample predictions indicate that the choice context shapes the influence of choice set dependence.
C49|The Phillips Curve at 60: time for time and frequency|We estimate the U.S. New Keynesian Phillips Curve in the time-frequency domain with continuous wavelet tools, to provide an integrated answer to the three most controversial issues on the Phillips Curve. (1) Has the short-run tradeoff been stable? (2) What has been the role of expectations? (3)Is there a long-run tradeoff? First, we fi nd that the short-run tradeoff is limited to some speci c episodes and short cycles and that there is no evidence of nonlinearities or structural breaks. Second, households expectations captured trend inflation and were anchored until the Great Recession, but not since 2008. Then, inflation over-reacted to expectations at short cycles. Finally, there is no signi cant long-run tradeoff. In the long-run, inflation is explained by expectations.
C49|A simple time-insensitive index of instability as a proxy for the “Africa dummy” variable – A Note|This paper calculates a simple time-insensitive index of instability using discrete series of events. The calculation of the index does not require complex statistical analysis of event series, discrete-event systems analysis, or categorical analysis. It uses a simple, single-equation regression to estimate the effects of instability on Africa’s per capita GDP over the 1961-2018 period. The results are mixed, with some showing that instability has constrained Africa’s performance and others implying it has helped. The findings are not quite econometrically pure, but reasonable given that many relevant variables are missing from the regression. Hence, I resist the temptation to comment further until at least conventional factors like capital are included in this regression, while I insist that the index itself is sound.
C49|Dealing with Endogenous Shocks in Dynamic Friendship Network|Different types of shocks, or the treatment of one of the players in a specific network, may influence not only the future performance of themselves but also affect their network connections. It is crucial to explore the behaviour of the whole network in response to such an event. This paper focuses on the cases of endogenously formed shock. The logic used in the peer effect literature is adopted to develop the dynamic model and accounts for the endogeneity of the shock. The model allows us to predict the endogenous part of the shock and use the remaining unexpected component to estimate the effect of the shock on the changes in the performance of network connections. The identification conditions for effect are derived, and the consistent estimation procedure is proposed.
C49|Endogenous Shocks in Social Networks: Exam Failures and Friends' Future Performance|Exam failures of the students in a specific network may influence not only the future performance of the student but also all students from their friendship networks, affecting the overall cohort's performance. Therefore, it is crucial to understand how the whole network responses to failure. The difficulty of such analysis is incorporated in the probability of the failures being highly endogenous. In this paper, I am applying the novel identification and estimation approach to deal with such endogeneity. I am exploring the dynamic data on the students' networks in HSE, Nizhniy Novgorod. The results suggest that, on average, the exam failure of the friend have a negative effect on future performance.
C49|Dealing with Endogenous Shocks in Dynamic Friendship Network| Different types of shocks, or the treatment of one of the players in a specific network, may influence not only the future performance of themselves but also affect their network connections. It is crucial to explore the behaviour of the whole network in response to such an event. This paper focuses on the cases of endogenously formed shock. The logic used in the peer effect literature is adopted to develop the dynamic model and accounts for the endogeneity of the shock. The model allows us to predict the endogenous part of the shock and use the remaining unexpected component to estimate the effect of the shock on the changes in the performance of network connections. The identification conditions for effect are derived, and the consistent estimation procedure is proposed.
C49|Endogenous Shocks in Social Networks: Exam Failures and Friends' Future Performance| Exam failures of the students in a specific network may influence not only the future performance of the student but also all students from their friendship networks, affecting the overall cohort's performance. Therefore, it is crucial to understand how the whole network responses to failure. The difficulty of such analysis is incorporated in the probability of the failures being highly endogenous. In this paper, I am applying the novel identification and estimation approach to deal with such endogeneity. I am exploring the dynamic data on the students' networks in HSE, Nizhniy Novgorod. The results suggest that, on average, the exam failure of the friend have a negative effect on future performance.
C49|The Many Faces of Human Sociality: Uncovering the Distribution and Stability of Social Preferences|There is vast heterogeneity in the human willingness to weigh others’ interests in decision making. This heterogeneity concerns the motivational intricacies as well as the strength of other-regarding behaviors, and raises the question how one can parsimoniously model and characterize heterogeneity across several dimensions of social preferences while still being able to predict behavior over time and across situations. We tackle this task with an experiment and a structural model of preferences that allows us to simultaneously estimate outcome-based and reciprocity-based social preferences. We find that non-selfish preferences are the rule rather than the exception. Neither at the level of the representative agent nor when we allow for several preference types do purely selfish types emerge. Instead, three temporally stable and qualitatively different other-regarding types emerge endogenously, i.e., without pre-specifying assumptions about the characteristics of types. When ahead, all three types value others’ payoffs significantly more than when behind. The first type, which we denote as strongly altruistic type, is characterized by a relatively large weight on others’ payoffs – even when behind – and moderate levels of reciprocity. The second type, denoted as moderately altruistic type, also puts positive weight on others’ payoff, yet at a considerable lower level, and displays no positive reciprocity while the third type is behindness averse, i.e., puts a large negative weight on others’ payoffs when behind and behaves selfishly otherwise. We also find that there is an unambiguous and temporally stable assignment of individuals to types. Moreover, the three-type model substantially improves the (out-of-sample) predictions of individuals’ behavior across additional games while the information contained in subject-specific parameter estimates leads to no or only minor additional predictive power. This suggests that a parsimonious model with three types captures the bulk of the predictive power contained in the preference estimates.
C49|Remittances and Dutch Disease: A Meta-Analysis|Remittance flows are an important source of foreign exchange for various developing countries around the world. Given their growing importance in the last decade, their role in inducing Dutch disease symptoms in the developing countries has been extensively studied. However, the results of the analyses so far have been mixed. In this study, we conduct a meta-analysis of existing literature to estimate the over all effect of remittances on receiving countries’ real effective exchange rate (REER). We run fixed and random effect meta-analysis on studies taken from EconLit, Google Scholar and various working paper series and examine a total of 53 regressions taken from seven published and unpublished studies. We come up with evidence of a net appreciation of real exchange rate in the developing countries. Both the fixed and random effect models indicate a highly significant impact of foreign remittances on the REER. The results show also that the nature of the dependent variable, countries considered and the econometric technique used influence the impact of remittances REER, However the type of data (panel or times series) does not affect the results. Our investigations support the presence of selection bias. The findings support the view that in spite of their utility for the recipient households, remittances pose a challenge to the developing country on the macroeconomic level.
C49|A Principal Component Simulation of Age-Specific Fertility - Impacts of Family and Social Policy on Reproductive Behavior in Germany|This contribution proposes a simulation approach for the indirect estimation of age-specific fertility rates (ASFRs) and the total fertility rate (TFR) for Germany via time series modeling of the principal components of the ASFRs. The model accounts for cross-correlation and autocorrelation among the ASFR time series. The effects of certain measures are also quantified through the introduction of policy variables. Our approach is applicable to probabilistic sensitivity analyses investigating the potential outcome of political intervention. A slight increase in the TFR is probable until 2040. In the median scenario, the TFR will increase from 1.6 in 2016 to 1.68 in 2040 and will be between 1.46 and 1.92 with a probability of 75 percent. Based on this result, it is unlikely that the fertility level will fall back to its extremely low levels of the mid-1990s. Two simple alternate scenarios are used to illustrate the estimated ceteris paribus effect of changes in our policy variables on the TFR.
C49|Deciphering Professional Forecasters’ Stories - Analyzing a Corpus of Textual Predictions for the German Economy|We analyze a corpus of 564 business cycle forecast reports for the German economy. The dataset covers nine institutions and 27 years. From the entire reports we select the parts that refer exclusively to the forecast of the German economy. Sentiment and frequency analysis confirm that the mode of the textual expressions varies with the business cycle in line with the hypothesis of adaptive expectations. A calculated 'uncertainty index' based on the occurrence of modal words matches with the economic policy uncertainty index by Baker et al. (2016). The latent Dirichlet allocation (LDA) model and the structural topic model (STM) indicate that topics are significantly state- and time-dependent and different across institutions. Positive or negative forecast 'surprises' experienced in the previous year have an impact on the content of topics.
C49|Grading Journals in Economics: The ABCs of the ABDC|The Australian Business Deans Council (ABDC) have graded journals in the fields of Economics and Statistics to evaluate the quality of research. This paper examines the consistency of these grades with 44 bibliometric indicators of journal quality and measures of interrater agreement. First, we categorise the bibliometrics employing a unique cluster analysis based on an interrater agreement statistic. Then, we determine which journals have been assigned ABDC grades that do not reflect the rank of the bibliometrics. These cases provide an indication of the extent to which the ABDC journal grades are determined by non-bibliometric factors.
C49|Estimating the Taylor rule in the time-frequency domain|We present the first assessment of U.S. monetary policy across time and frequencies within the Taylor Rule framework. We derive a novel wavelet tool — the partial wavelet gain — to estimate a parametric equation relating the federal funds rate to inflation and the output gap. We detect a gradual shift of the focus of policy from short cycles to intermediate cycles at the beginning of the Great Moderation, followed by a strengthening of policy’s reaction to long fluctuations once credibility was attained, and, during the Great Recession, a renewed interest in shorter output cycles. We document that the violation of the Taylor principle until the early 1980s and the strengthening of the reaction of policy to inflation thereafter were more marked at intermediate than at long cycles. Overall, we also detect lead-lag relationships between the policy rate and inflation and the output gap that differ along time and cyclical frequencies.
C49|The predictive relationship between exchange rate expectations and base metal prices|In this paper we show that survey-based-expectations about the future evolution of the Chilean exchange rate have the ability to predict the returns of the six primary non-ferrous metals: aluminum, copper, lead, nickel, tin and zinc. Predictability is also found for returns of the London Metal Exchange Index. Previous studies have shown that the Chilean exchange rate has the ability to predict copper returns, a world commodity index and base metal prices. Nevertheless, our results indicate that expectations about the Chilean peso have stronger predictive ability relative to the Chilean currency. This is shown both in-sample and out-of-sample. By focusing on expectations of a commodity currency, and not on the currency itself, our paper provides indirect but new and strong evidence of the ability that commodity currencies have to forecast commodity prices. Our results are also consistent with the present-value-model for exchange rate determination.
C49|The impact of oil prices on CO2 emissions in China: A Wavelet coherence approach|This paper observes the possible co-movements of oil price and CO2 emissions in China by following wavelet coherence and wavelet partial coherence analyses to be able to depict short-run and long-run co-movements at both low and high frequencies. To this end, this research might provide the current literature with the output of potential short run and long run, structural, changes in CO2 emissions upon a shock (a change) in oil prices in China together with the control variables of World oil prices, fossil energy consumption, and renewables consumption, and, urban population in China. Therefore, this research aims at determining wavelet coherencies between the variables and phase differences to exhibit the leading variable in potential co-movements. By following the time domain and frequency domain analyses of this research, one may claim that the oil prices in China has considerable negative impact on CO2 emissions at high frequencies for the periods 1960-2014 and 1971-2014 in China. Besides, one may underline as well other important output of the research exploring that the urban population and CO2 emissions have positive associations, move together for the period 1960-2014 in China. Eventually, this paper might suggest that authorities follow demand side management policies considering energy demand behavior at both shorter cycles and longer cycles to diminish the CO2 emissions in China.
C49|Growth volatility and inequality in the U.S.: A wavelet analysis|This study applies wavelet coherency analysis to explore the relationship between the U.S. economic growth volatility, and income and wealth inequality measures over the period 1917 to 2015 and 1962 to 2014. We consider the relationship between output volatility during positive and negative growth scenarios. Wavelet analysis simultaneously examines the correlation and causality between two series in both the time and frequency domains. Our findings provide evidence of positive correlation between the volatility and inequality across high (short-run)- and low-frequencies (long-run). The direction of causality varies across frequencies and time. Strong evidence exists that volatilities lead inequality at low-frequencies across income inequality measures from 1917 to 1997. After 1997, however, the direction of causality changes. In the time-domain, the time-varying nature of long-run causalities implies structural changes in the two series. These findings provide a more thorough picture of the relationship between the U.S. growth volatility and inequality measures over time and frequency domains, suggesting important implications for policy makers.
C49|A wavelet analysis of the relationship between oil and natural gas prices|In this paper, we aim to explore the relationship between natural gas and crude oil prices for the U.S. economy over the time period 1997 and 2017 in both the unconditional and conditional framework by conditioning the relationship on natural gas production. The time period covers the recent shale gas supply boom. Our results indicate that during the shale gas revolution period of 2007–2013, oil and natural gas prices were procyclical and oil prices were leading natural gas prices. Once we control for the natural gas production we find that significant or high wavelet coherency is observed during 2000–2015 for 3–4 years scale. These results have implications for cross-market policy effects.
C49|Oil Price-Inflation Pass-Through in the United States over 1871 to 2018: A Wavelet Coherency Analysis|This paper analyzes the oil price-inflation pass-through by studying the relationship between oil prices and U.S. Consumer Price Index (CPI) over the period January 1871- June 2018, at different frequencies, using a wavelet coherency analysis. Our main results suggest that the relationship between oil prices and CPI has changed over the analyzed time period, implying a decrease in the oil price- inflation pass-through over time. Furthermore, this relationship also varies across frequencies, suggesting that the evidence of oil price-inflation pass-through with oil prices leading CPI is weaker in the short-run.
C49|Value of Public Goods Generated by National Sport Training Center (NSTC): The CVM Approach|This research objects to value of a public investment project, National Sport Training Center (NSTC), which generates valuable public goods and positive externalities, though such benefits are difficult to measure. It specifically describes the use of the Contingent Valuation Method (CVM) to conduct such surveys and to analyze the data to measure the benefits produced by sports public goods. The survey showed the feasibility of using the CVM to estimate willingness-to-pay for sports public goods. Also, to answered the question of how much sports are worth since the government has subsidized the construction the NSTC. The valuation of public goods are examined. The data and analysis indicate that NSTC can produce public goods such as national pride and spirit and the value of those public goods may be substantial. The study found that the willingness to pay on national pride and spirit are depended on gender, occupation, income, and attention to sports. The result shown that national spirit value averagely equals 19.24 baht per month and national pride is averagely 20.22 baht per month.
C49|Application Of The Positional Pot-Topsis Method To The Assessment Of Financial Self-Sufficiency Of Local Administrative Units|In this paper we propose new approach to the construction of synthetic measure, where the objects are described by the characteristics with strong asymmetry and outliers. The aim of the paper is to present the application potential of the tools of the Extreme Values Theory (EVT) i.e. Peaks over Threshold Model (POT) in constructing a synthetic measure based of positional Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS), that utilize the spatial median of Weber. POT model has been used for identification of outliers and to determination of the positive and negative ideal solutions of financial self-sufficiency of local administrative units (LAUs). This approach is used in the assessment of financial self-sufficiency of LAUs in Poland in 2016.
C49|A fuzzy approach to measuring violence against women and its severity|We develop a scale of severity of violence against women based on fuzzy set theory. The scale can be used to derive fuzzy indexes of violence which account for the prevalence, frequency and severity of violence. Using the results of the survey conducted by the European Agency for Human Rights (FRA) we find strong congruence of ranking between the proposed scale and three widely used alternatives – the Conflict Tactic Scale, The Severity of Violence Against Women Scale and the Index of Spouse Abuse. Unlike existing alternatives, however, the scale that we propose is based on objective information rather than subjective assessment; it is parsimonious in terms of the amount of information that it requires; and it is less vulnerable to risks of cultural bias. As an example of the uses to which fuzzy measurement of violence can be put, we compute fuzzy indexes of intimate partner violence for European countries and find a clear, inverse correlation across countries with the degree of gender equality.
C49|Crude Oil Market And Geopolitical Events: An Analysis Based On Information-Theory-Based Quantifiers|This paper analyzes the informational efficiency of oil market during the last three decades, and examines changes in informational efficiency with major geopolitical events, such as terrorist attacks, financial crisis and other important events. The series under study is the daily prices of West Texas Intermediate (WTI) in USD/BBL, commonly used as a benchmark in oil pricing. The analysis is performed using information-theory-derived quantifiers, namely permutation entropy and permutation statistical complexity. These metrics allow capturing the hidden structure in the market dynamics, and allow discriminating different degrees of informational efficiency. We find that some geopolitical events impact on the underlying dynamical structure of the market.
C49|Wavelet decomposition of the financial cycle : An early warning system for financial tsunamis|We propose a wavelet-based approach for construction of a financial cycle proxy. Specifically, we decompose three key macro-financial variables – private credit, house prices, and stock prices – on a frequency-scale basis using wavelet multiresolution analysis. The resulting “wavelet-based” sub-series are aggregated into a composite index representing our cycle proxy. Selection of the sub-series deemed most relevant is done by emphasizing early warning properties. The wavelet-based financial cycle proxy is shown to perform well in detecting banking crises in out-of-sample exercises, outperforming the credit-to-GDP gap and a financial cycle proxy derived using the approach of Schüler et al. (2015).
C49|Q, investment, and the financial cycle|The empirical performance of the Q theory of investment can be significantly improved by simultaneously considering the time- and the frequency-varying features of the investment-Q relationship. Using continuous wavelet tools, I assess the investment-Q sensitivity at different frequencies and its evolution over time, as well as the interaction of the financial cycle with the Q theory. The results show that there is a positive, stable medium-to-long-run relationship between investment and Q that begins after a positive, stable long-run relationship between credit and Q materializes. In such case, credit leads and slowly fuels the stock price boom.
C49|Time-varying leads and lags across frequencies using a continuous wavelet transform approach|A precise understanding of lead–lag structures in economic data is important for many economic agents such as policymakers, traders in financial markets, and producers in goods markets. To identify time-varying lead–lag relationships across various frequencies in economic time series, recent studies have used phase difference on the basis of a continuous wavelet transform. However, the extant literature includes several conflicting interpretations of phase difference. In this study, we extensively discuss wavelet phase difference, determine its most plausible interpretation, and thus attempt to address gaps in the existing literature. Consequently, this study suggests that some lead–lag results of previous works have been driven by incorrect interpretations of wavelet phase difference.
C49|Local Product Space and Firm Level Churning in Exported Products|This paper explores the determinants of changes in the range of exports at the firm level with a particular interest in the role played by the locality via product relatedness. To this aim, we introduce a multi-regional setting to the theoretical framework proposed by Bernard et al. (2010), which explains multiple product firms and product switching. We test the propositions of the extended framework using French micro-data that covers information on mono-regional firms operating primarily in manufacturing industry over the period 2002-2007. Our main finding is that the local product space matters in the decisions firms make. Specifically, firms tend to modify their mix of exported products such that their production and export capabilities get more aligned with capabilities that lie beneath core capabilities of the region. Our results also suggest that once firms alter their range of exports, among all new products they start exporting, they enjoy greater export revenues in those that are more related to the core capabilities of the locality.<br><small>(This abstract was borrowed from another version of this item.)</small>
C49|Legislative Cycles in a Semipresidential System|The political-legislation-cycle theory predicts a peak of legislative production in the pre-electoral period, when the legislator focuses on voters' welfare in order to be reelected. This paper tests the theory on the French semipresidential system, characterized by direct election of both the executive and the legislative branch. We use a data set that encompasses all the legislation passed in France from 1959 to 2012 at a monthly rate, and find a dual cycle of the production of laws, connected to both the presidential and the legislative elections.
C49|Local Product Space and Firm Level Churning in Exported Products|This paper explores the determinants of changes in the range of exports at the firm level with a particular interest in the role played by the locality via product relatedness. To this aim, we introduce a multi-regional setting to the theoretical framework proposed by Bernard et al. (2010), which explains multiple product firms and product switching. We test the propositions of the extended framework using French micro-data that covers information on mono-regional firms operating primarily in manufacturing industry over the period 2002-2007. Our main finding is that the local product space matters in the decisions firms make. Specifically, firms tend to modify their mix of exported products such that their production and export capabilities get more aligned with capabilities that lie beneath core capabilities of the region. Our results also suggest that once firms alter their range of exports, among all new products they start exporting, they enjoy greater export revenues in those that are more related to the core capabilities of the locality.
C49|Using Machine Learning To Model Interaction Effects In Education: A Graphical Approach|Educational systems can be characterized by a complex structure: students, classes and teachers, schools and principals, and providers of education. The added value of schools is likely influenced by all these levels and, especially, by interactions between them. We illustrate the ability of Machine Learning (ML) methods (Regression Trees, Random Forests and Boosting) to model this complex ‘education production function’ using Hungarian data. We find that, in contrast to ML methods, classical regression approaches fail to identify relevant nonlinear interactions such as the role of school principals to accommodate district size policies. We visualize nonlinear interaction effects in a way that can be easily interpreted.
C49|On the Returns of Trend-Following Trading Strategies|Paper [I] tests the success rate of trades and the returns of the Opening Range Breakout (ORB) strategy. A trader that trades on the ORB strategy seeks to identify large intraday price movements and trades only when the price moves beyond some predetermined threshold. We present an ORB strategy based on normally distributed returns to identify such days and find that our ORB trading strategy result in significantly higher returns than zero as well as an increased success rate in relation to a fair game. The characteristics of such an approach over conventional statistical tests is that it involves the joint distribution of low; high; open and close over a given time horizon. Paper [II] measures the returns of a popular day trading strategy; the Opening Range Breakout strategy (ORB); across volatility states. We calculate the average daily returns of the ORB strategy for each volatility state of the underlying asset when applied on long time series of crude oil and S&P 500 futures contracts. We find an average difference in returns between the highest and the lowest volatility state of around 200 basis points per day for crude oil; and of around 150 basis points per day for the S&P 500. This finding suggests that the success in day trading can depend to a large extent on the volatility of the underlying asset. Paper [III] performs empirical analysis on short-term and long-term Commodity Trading Advisor (CTA) strategies regarding their exposures to unanticipated risk shocks. Previous research documents that CTA strategies offer diversification opportunities during equity market crisis situations when evaluated as a group; but do not separate between short-term and long-term CTA strategies. When separating between short-term and long-term CTA strategies; this paper finds that only short-term CTA strategies provide a significant; and consistent; exposure to unanticipated risk shocks while long-term CTA strategies do not. For the purpose of diversifying a portfolio during equity market crisis situations; this result suggests that an investor should allocate to short-term CTA strategies rather than to long-term CTA strategies.
C49|Autocorrelation in an unobservable global trend: does it help to forecast market returns?| In this paper, a Kalman filter-type model is used to extract a global stochastic trend from discrete non-synchronous data on daily stock market index returns from different markets. The model allows for the autocorrelation in the global stochastic trend, which means that its increments are predictable. It does not necessarily mean the predictability of market returns, since the global trend is unobservable. The performance of the model for the forecast of market returns is explored for three markets: Japan, UK, USA.
C49|Does a mother’s exposure to drought in utero increase the resistance of her offspring to in utero shocks?|This paper seeks to determine whether, by being exposed to a drought in utero, a mother can transfer resistance of in utero exposure to drought to her offspring. Results of the difference-in-difference model show that there is a form of resistance transfer from mother to child, with double exposed children having better weight-for age and weight-for height measures than children whose mothers were not exposed in utero. In addition to the above, the paper also shows that by using a difference-in-difference model and identifying two shocks, the effect of in utero drought on child health and the intergenerational transfer of in utero shocks from mother to child can also be estimated.
C49|A time-frequency analysis of the Canadian macroeconomy and the yield curve|We use wavelet analysis to study the relationship between the yield curve and macro- economic indicators in Canada. We rely on the Nelson-Siegel approach to model the zero coupon yield curve, and use the Kalman lter to estimate its time-varying factors: the level, the slope and the curvature. Apart from the bidirectional yield-macro relation, the paper broadens the existing literature by exploring the link between the monetary policy and the yield curve.
C49|Testing the Q theory of investment in the frequency domain|We revisit the empirical performance of the Q theory of investment, explicitly taking into account the frequency dependence of investment, Tobin’s Q, and cash flow. The time series are decomposed into orthogonal components of different frequencies using wavelet multiresolution analysis. We find that the Q theory fits the data much better than might be expected (both in-sample and out-of-sample) when the frequency relationship between the variables is taken into account. Merging the wavelet approach and proxies for Q recently suggested in the investment literature also significantly improves the quality of short-term forecasts.
C49|Approaches and Techniques to Validate Internal Model Results|The development of risk model for managing portfolio of financial institutions and insurance companies require both from the regulatory and management points of view a strong validation of the quality of the results provided by internal risk models. In Solvency II for instance, regulators ask for independent validation reports from companies who apply for the approval of their internal models. Unfortunately, the usual statistical techniques do not work for the validation of risk models as we lack enough data to significantly test the results of the models. We will certainly never have enough data to statistically estimate the significance of the VaR at a probability of 1 over 200 years, which is the risk measure required by Solvency II. Instead, we need to develop various strategies to test the reasonableness of the model. In this paper, we review various ways, management and regulators can gain confidence in the quality of models. It all starts by ensuring a good calibration of the risk models and the dependencies between the various risk drivers. Then applying stress tests to the model and various empirical analysis, in particular the probability integral transform, we build a full and credible framework to validate risk models.
C49|A Decomposition of the Herfindahl Index of Concentration|The Herfindahl index is one of the most known indices used to measure the concentration of a variable distributed over a certain number of units, and tipically to measure the degree of concentration of business in a market. Its worth is the sensitivity both to the dimensional variability of these units and to their numerical consistency. In the this note a decomposition of the H-index into these two terms is offered.
C49|Analyse Multidimensionnelle Temps-Fréquence du MEDAF<BR>[Multidimensional Time-Frequency Analysis Of The Capm]|The CAPM theory provides a measure of the sensitivity of an asset to the market called the systematic risk. The Beta of equity is estimated by its market line. According to the OLS hypothesis, it is stable over time but this is not empirically verified. Many studies are in favour with this fact (Unstable Beta), and more particularly the Beta dispersion according to the frequencies which is related to the heterogeneous behaviour of agents. We can calculate the coherence and the phase between the stock's returns and those of the market over time using the wavelets method and it is also possible to visualize it. In order to confirm the correctness of the methodology, we use three French equities with different Betas (AXA, LVMH and Orange) for the period from 2005-2015 including the crisis. We show that the wavelets coherence, associated with the phase, improve our understanding and the classification of equities according to there characteristics. Our study reveal the contagion and interdependence phenomenons between the stocks and the market. The contagion effects (from the market to the stock) is principally located on the High-Frequencies whereas the interdependence effect is located on the Low-Frequencies (Long-run investment).The link between beta and coherence-phase can help the investors to choose more efficiently the time they should invest.
C49|Are stock returns an inflation hedge for the UK? Evidence from a wavelet analysis using over three centuries of data|This paper analyzes the relationship between stock returns and the inflation rates for the UK over a long time period (February 1790–February 2017) and at different frequencies, by employing a wavelet analysis. We also compare the results for the UK economy with those for the US and two developing countries (India and South Africa). Overall, our results tend to suggest that, while the relationship between stock returns and inflation rates varies across frequencies and time periods, there is no evidence of stock returns acting as an inflation hedge, irrespective of whether we look at the two developed or the two developing markets in our sample.
C49|On the Inconsistency of Instrumental Variables Estimators for the Coefficients of Certain Dummy Variables|Abstract In this paper we consider the asymptotic properties of the Instrumental Variables (IV) estimator of the parameters in a linear regression model with some random regressors, and other regressors that are dummy variables. The latter have the special property that the number of non-zero values is fixed, and does not increase with the sample size. We prove that the IV estimator of the coefficient vector for the dummy variables is inconsistent, while that for the other regressors is weakly consistent under standard assumptions. However, the usual estimator for the asymptotic covariance matrix of the I.V. estimator for all of the coefficients retains its usual consistency. The t-test statistics for the dummy variable coefficients are still asymptotically standard normal, despite the inconsistency of the associated IV coefficient estimator. These results extend the earlier results of Hendry and Santos (Oxf Bull Econ Stat 67:571–595, 2005), which relate to a fixed-regressor model, in which the dummy variables are non-zero for just a single observation, and OLS estimation is used.
C49|Transaction balances of small denomination banknotes: findings from the introduction of ES2|At the end of 2015, the Deutsche Bundesbank had issued a total net amount of just over €45 billion in €20 banknotes. In statistical terms, each resident living in Germany was therefore issued with around 30 banknotes of this denomination. Up until now, it was not clear how many of these German-issued euro banknotes are actually used for payment purposes. Owing to the introduction of the new Europa series of banknotes on 25 November 2015, it was possible to estimate the volume of €20 banknotes that are held for transaction purposes both in Germany and outside the euro area. The estimation of the volume of €20 banknotes held for domestic transaction purposes (known as the domestic transaction balance) is primarily based on the observed return flows of the old series (ES1) of €20 banknotes received by the Deutsche Bundesbank. The cash balance of €20 banknotes held for domestic transaction purposes was estimated at around €8.5 billion at the end of October 2015. This means that only 19% of the total (net) amount of €20 banknotes issued by the Deutsche Bundesbank up to the end of October 2015 were used for transaction purposes within Germany. The remaining 81% has either migrated abroad, been hoarded or got lost. The results of the analysis are also important as a means of explaining the just over €36 billion worth of ES1 €20 banknotes which are still outstanding in the Deutsche Bundesbank's balance sheet. Given that the cash balance held for domestic transaction purposes has since been almost fully replaced, it is no longer to be expected that ES1 banknotes will flow back to the Deutsche Bundesbank in any sizeable amounts. The volume of German-issued €20 banknotes – officially stemming from banknote shipments by the Deutsche Bundesbank – held for transaction purposes outside the euro area was estimated at just over €3 billion at the end of July 2016 using the biometric method. This estimate represents a lower level for the actual cash balance held for transaction purposes, as it does not incorporate banknote exports resulting from foreign travel and cash amounts sent abroad. It is derived from cumulated shipments of ES2 €20 banknotes up to the end of July 2016 and the value of the ES1 and ES2 €20 notes deposited in July 2016 at the shipment branches. In terms of the Deutsche Bundesbank's cumulated net shipments of €20 banknotes in the amount of around €12 billion at the end of 2015, the estimated cash balance (resulting from shipments) held for transaction purposes outside the euro area accounts for around 28%.
C49|Small Sample Properties Of Panel Cointegration Tests In The Presence Of Structural Change|Panel tests for non-stationarity are increasingly popular in recent years, also for macroeconomic data. Given that panels used in practice are rather small, there is a need of exploring the small sample properties of the tests in various cases. For annual data the N dimension of the panels is limited to no more than 25, and spatial dimension is also limited, because of the nature of studied entities. So, the main concern of researchers remains the relatively small panels – theoretical critical values should be applied with caution, given that they are taken in limits. An additional feature of macroeconomic panels are cycles – with business cycles one can expect even more than one structural break in the series, because up to 3 major cycles can fit in a series with T=25. In the paper small sample properties for the three “group” statistics of Pedroni (1999) under presence of structural breaks are explored. A set of Monte Carlo experiments is applied to processes with a structural break for three possible break dates at 0.3T, 0.5T and 0.7T. Tested for power against the general alternative.
C49|Mutual Trustworthiness as a Governance Mechanism in Business Relationships – A Dyadic Data Analysis|Based on a literature review, we develop a research profile that illustrates that survey-based, trust-related empirical research has severe limitations. It usually carries out general relationship analysis using single end or quasi two-sided sampling and classic statistical constructs. We designed and carried out an empirical research that was highly situational, applied dyadic operationalisation, pairwise sampling, and dyadic data analysis – a special statistical approach and toolset developed by psychologists and used to analyse interdependencies in relationships. Our main contribution is methodological and theoretical since the paper gives a structured overview on the methodological challenges in analysing mutuality in trust, but also in other relational attributes. The paper not only makes these methodological problems explicit, but also offers a potential solution to overcome some of their limitations.
C49|Time–frequency characterization of the U.S. financial cycle|Despite an increase in research–motivated by the global financial crisis of 2007–08–empirical studies on the financial cycle are rare compared to those on the business cycle. This paper adds some new evidence to this scarce literature by using a different empirical methodology–wavelet analysis–to extract financial cycles from the data. Our results confirm that the U.S. financial cycle is (much) longer than the business cycle, but we do not find strong evidence supporting the view that the financial cycle has lengthened during the Great Moderation period.
C49|Analysis of the balance between U.S. monetary and fiscal policy using simulated wavelet-based optimal tracking control|This paper uses wavelet-based optimal control to simulate fiscal and monetary strategies under different levels of policy restrictions. The model applies the Maximal Overlap Discrete Wavelet Transform (MODWT) to United States quarterly GDP data, and then uses the decomposed variables to build a large 80 dimensional state-space linear-quadratic tracking model. Using a political targeting design for the frequency range weights, we simulate jointly optimal fiscal and monetary policy where: (1) both fiscal and monetary policy are dually emphasized, (2) fiscal policy is unrestricted while monetary policy is restricted to achieving a steady increase in the market interest rate, and (3) only monetary policy is relatively active, while fiscal spending is restricted to achieving a target growth rate. The results show that fiscal policy must be more aggressive when the monetary authorities are not accommodating the fiscal expansion, and that the dual-emphasis policy leads a series of interest rate increases that are balanced between a steadily increasing target and a low, fixed rate. This research is the first to construct integrated fiscal and monetary policies in an applied wavelet-based optimal control setting using U.S. data.
C49|Vyrobené V Číne: Hrozba Pre Európsky High-Tech Sektor? (Made In China: A Threat To European High-Tech Sector?)|V posledných dekádach zaznamenala Čína mimoriadny nárast celkového objemu exportov a zároveň zmenu exportnej štruktúry. Z prevažne jednoduchých výrobkov, náročných na prácu, sa čínske exporty posunuli smerom k sofistikovanejším produktom. Obzvlášť významný bol nárast v sektore elekroniky a high-tech výrobkov, ktoré boli až doposiaľ doménou vyspelých priemyslových krajín. Použitím gravitačného modelu sa v tejto práci snažíme zistiť, do akej miery predstavujú čínske high-tech exporty konkurenciu pre krajiny Európskej únie na partnerskom trhu krajín OECD v roku 2013. Výsledky nášho výskumu poukazujú na fakt, že nárast čínskych exportov nemá negatívny, ale naopak pozitívny vplyv na európske exporty v sektore high-tech, aspoň pre obdobie roku 2013. (In the last decades China has seen a spectacular rise in its export performance. In the same time it has experienced an important change in its export structure. Chinese exports have moved from predominantly exports of low-labor intensive goods towards higher sophistication of its export products. A particular rise was observed in the products such as electronics and other high-tech products which were for long time believed to be a domain of industrialized countries. Using gravity model we try to evaluate whether Chinese exports in the high-tech products during the year 2013 were competition for the European exporters in its OECD export markets. The results of our model suggest that the competition in the developed markets is not very high, in contrast, we observe that there is a small, but positive impact of rising Chinese exports on the European exports, at least in the year 2013.)
C49|Income distribution in the Colombian economy from an econophysics perspective|Recently, in econophysics, it has been shown that it is possible to analyze economic systems as equilibrium thermodynamic models. We apply statistical thermodynamics methods to analyze income distribution in the Colombian economic system. Using the data obtained in random polls, we show that income distribution in the Colombian economic system is characterized by two specific phases. The first includes about 90% of the interviewed individuals, and is characterized by an exponential Boltzmann-Gibbs distribution. The second phase, which contains the individuals with the highest incomes, can be described by means of one or two power-law density distributions that are known as Pareto distributions. ***** En el marco de la econofísica se ha demostrado recientemente que es posible analizar sistemas económicos como modelos termodinámicos en equilibrio. En este artículo aplicamos métodos de termodinámica estadística para analizar la distribución de ingresos dentro del sistema económico colombiano. Utilizando datos de encuestas aleatorias, demostramos que la distribución de ingresos presenta dos fases particulares. La primera corresponde a cerca del 90% del grupo analizado y se caracteriza por una distribución exponencial del tipo Boltzmann-Gibbs. La segunda fase, en la que están incluidos los entrevistados con ingresos más altos, se puede describir mediante una o dos distribuciones de potencias: distribuciones de Pareto.
C49|Does mass deworming affect child nutrition ? meta-analysis, cost-effectiveness, and statistical power|The WHO has recently debated whether to reaffirm its long-standing recommendation of mass drug administration (MDA) in areas with more than 20 percent prevalence of soil-transmitted helminths (hookworm, whipworm, and roundworm). There is consensus that the relevant deworming drugs are safe and effective, so the key question facing policymakers is whether the expected benefits of MDA exceed the roughly $0.30 per treatment cost. The literature on long run educational and economic impacts of deworming suggests that this is the case. However, a recent meta-analysis by Taylor-Robinson et al. (2015), (hereafter TMSDG), disputes these findings. The authors conclude that while treatment of children known to be infected increases weight by 0.75 kg (95 percent CI: 0.24, 1.26; p=0.0038), there is substantial evidence that MDA has no impact on weight or other child outcomes. This paper updates the TMSDG analysis by including studies omitted from that analysis and extracting additional data from included studies, and finds that the TMSDG analysis is underpowered: Power is inadequate to rule out weight gain effects that would make MDA cost effective relative to comparable interventions in similar populations, and underpowered to reject the hypothesis that the effect of MDA is different from the effect that might expected, given deworming's effects on those known to be infected. The hypothesis of a common zero effect of multiple-dose MDA deworming on child weight at longest follow-up is rejected at the 10 percent level using the TMSDG dataset, and with a p value
C49|Machine Learning Techniques For Stock Market Prediction.Acase Study Of Omv Petrom|The research reported in the paper focuses on the stock market prediction problem, the main aim being the development of a methodology to forecast the OMV Petrom stock closing price. The methodology is based on some novel variable selection methods and an analysis of neural network and support vector machines based prediction models. Also, a hybrid approach which combines the use of the variables derived from technical and fundamental analysis of stock market indicators in order to improve prediction results of the proposed approaches is reported in this paper. Two novel variable selection methods are used to optimize the performance of prediction models. In order to identify the most informative time series to predict a stock price, both methods are essentially based on the general forecasting error minimization when a certain stock price is expressed exclusively in terms of other indicators. After the variable selection is over, the forecasting is performed in terms of the historical values of the given stock price and selected variables respectively. The performance of the proposed methodology is evaluated by a long series of tests, the results being very encouraging as compared to similar developments.
C49|The role of returns to scale in measuring frictions in resource allocation: Revisiting misallocation and manufacturing TFP in China|This paper extends the study by Hsieh and Klenow (2009) on productivity implication of resource misallocation by relaxing the assumption of constant returns to scale (CRS) for differentiated products. We show that when the CRS assumption fails, measuring frictions in resource allocation by variation in revenue productivity, as proposed by Hsieh and Klenow (2009), overestimates the resource misallocation in China.
C49|GEL estimation for heavy-tailed GARCH models with robust empirical likelihood inference|We construct a Generalized Empirical Likelihood estimator for a GARCH(1, 1) model with a possibly heavy tailed error. The estimator imbeds tail-trimmed estimating equations allowing for over-identifying conditions, asymptotic normality, efficiency and empirical likelihood based confidence regions for very heavy-tailed random volatility data. We show the implied probabilities from the tail-trimmed Continuously Updated Estimator elevate weight for usable large values, assign large but not maximum weight to extreme observations, and give the lowest weight to non-leverage points. We derive a higher order expansion for GEL with imbedded tail-trimming (GELITT), which reveals higher order bias and efficiency properties, available when the GARCH error has a finite second moment. Higher order asymptotics for GEL without tail-trimming requires the error to have moments of substantially higher order. We use first order asymptotics and higher order bias to justify the choice of the number of trimmed observations in any given sample. We also present robust versions of Generalized Empirical Likelihood Ratio, Wald, and Lagrange Multiplier tests, and an efficient and heavy tail robust moment estimator with an application to expected shortfall estimation. Finally, we present a broad simulation study for GEL and GELITT, and demonstrate profile weighted expected shortfall for the Russian Ruble–US Dollar exchange rate. We show that tail-trimmed CUE-GMM dominates other estimators in terms of bias, mse and approximate normality.
C49|Unobserved heterogeneity and endogeneity in nonparametric frontier estimation|In production theory, firm efficiencies are measured by their distances to a production frontier. In the presence of heterogeneous conditions (like environmental factors) that may influence the shape and the position of the frontier, traditional measures of efficiency obtained in the space of inputs/outputs are difficult to interpret, since they mix managerial inefficiency and shift of the frontier. This can be corrected by using nonparametric conditional efficiencies. In this paper we extend these concepts in the case where the heterogeneity is not observed. We propose a model where the heterogeneity variable is linked to a particular input (or output). It is defined as the part of the input (or the output), independent from some instrumental variable through a nonseparable nonparametric model. We discuss endogeneity issues involved in this model. We show that the model is identified and analyze the asymptotic properties of proposed nonparametric estimators. When using FDH estimators we achieve a limiting Weibull distribution, whereas when using the robust order-m estimators we obtain the asymptotic normality. The method is illustrated with some simulated and real data examples. A Monte-Carlo experiment shows how the procedure works for finite samples.
C49|On time-varying predictability of emerging stock market returns|The two recent studies of Cajueiro and Tabak (2004b) and Hull and McGroarty (2014) investigate the predictability of emerging stock market returns based on the Hurst coefficient—a simple but powerful measure of long-range dependence. Unfortunately, the insights gained in these studies are limited because they (i) present conflicting evidence on the time-varying nature of the estimated Hurst coefficients and (ii) incorrectly equate random walk behaviour with market efficiency. In this note, we revisit the issue of time-varying predictability for a rich sample of 21 emerging markets in the 27-year period from 1988 to 2015. Extending the two aforementioned studies by various alternative fractal estimators of the Hurst coefficient, trend regressions and several robustness checks, our analysis reveals significant downward trends in the local Hurst coefficients of almost all markets. Specifically, we document vanishing predictability over time, which indicates that profitable emerging market investment strategies based on past returns may not continue their good performance in the future. Furthermore, we explicitly point out why a random walk is neither a necessary nor a sufficient condition for rationally determined security prices, and thus signs of predictability (randomness) should not be interpreted as evidence for market inefficiency (efficiency).
C49|A consistent two-factor model for pricing temperature derivatives|In the past decade, the Chicago Mercantile Exchange began to trade weather derivatives to hedge weather risk. The pricing of weather derivatives is challenging since the underlying is not tradable and thus classical arbitrage approaches have to be used with caution. In typical pricing approaches all information available to the market is assumed to be incorporated in the underlying and thus forward-looking information about non-tradable assets such as meteorological forecasts is often ignored. In this article, we analyze a new pricing methodology for temperature derivatives that accounts for forward-looking information. More precisely, we provide an empirical back-up for the theoretical framework of so-called consistent factor models for temperature forecast curves introduced previously in the literature and put this pricing approach into practice. First, we perform a thorough statistical analysis of meteorological forecast curve data. Second, based on this analysis we propose a specific consistent two-factor model, derive explicit temperature derivative prices, and calibrate the market price of risk (MPR). The power of the model is demonstrated against alternative pricing models. This confirms that at least parts of the irregularity of the MPR observed in earlier studies are not due to irregular risk perception but rather due to information misspecification.
C49|A thermodynamical view on asset pricing|The dynamics of stock market systems was analyzed from the stand point of viscoelasticity, i.e. conservative and nonconservative (or elastic and viscous) forces. Asset values were modeled as a geometric Brownian motion by generating random Wiener processes at different volatilities and drift conditions. Specifically, the relation between the return value and the Wiener noise was investigated. Using a scattering diagram, the asset values were placed into a ‘potentiality–actuality’ framework, and using Euclidean distance, the market values were transformed into vectorial forms. Depending on whether the forthcoming vector is aligned or deviated from the direction of advancement of the former vector, it is possible to split the forthcoming vector into its conservative and nonconservative components. The conservative (or in-phase, or parallel) component represents the work-like term whereas the nonconservative (or out-of-phase, or vertical) component represents heat-like term providing a treatment of asset prices in thermodynamical terms. The resistances exhibited against these components, so-called the modulus, were determined in either case. It was observed that branching occurred in the values of modulus especially in the modulus of the conservative component when it was plotted with respect to the Euclidean distance of Wiener noise, i.e. Wiener length. It was also observed that interesting patterns formed when the change of modulus was plotted with respect to the value of Wiener noise. The magnitudes of work-like and heat-like terms were calculated using the mathematical expressions. The peaks of both heat-like and work-like terms reveal around the zero value of Wiener noise and at very low magnitudes of either term. The increase of both the volatility and the drift acts in the same way, and they decrease the number of low heat-like and work-like terms and increase the number of the ones with larger magnitudes. Most interestingly, the increase either in volatility or in drift decreases the heat-like term but increases the work-like term in the overall. Finally, the observation of the golden ratio in various patterns was interpreted in terms of physical resistance to flow.
C49|On the performance of simple trading rules derived from the fractal dynamics of gold and silver price fluctuations|In a recent study of the fractal dynamics of gold-silver spreads, Batten et al. (2013) suggest that the Hurst coefficient (a simple measure of long-range dependence) may be a promising tool for the development of profitable trading rules in precious metals markets. In this note, we put this proposal to the test and significantly extend their preliminary evidence by (i) implementing more sophisticated Hurst coefficient estimators, (ii) modelling a simple trading rule in the spirit of De Souza and Gokcan (2004) and (iii) explicitly considering the role of transaction costs. For the period from 1979 to 2015, an analysis of gold, silver and the gold-silver spread shows that our Hurst coefficient strategy tends to outperform passive buy-and-hold approaches. In other words, we find that Hurst coefficients are predictors of future returns and thus contain important investment information. Interestingly, this result holds regardless of the choice of Hurst coefficient estimator and is robust to transaction costs, different holding period lengths and a series of other sensitivity checks.
C49|Do carry trade returns show signs of long memory?|Using Hurst coefficient approaches within rescaled range, detrended fluctuation, periodogram regression and average wavelet coefficient frameworks, this article examines the dynamics of currency carry trades. Specifically, we look for evidence of long-range dependence (LRD) in carry trade returns (CTR) of thirteen developed and nine emerging markets. Our analysis provides two important insights. (a) We find strong and robust evidence of LRD for CTR in developed markets and somewhat weaker evidence in emerging markets. Considering that CTR are vital components of modern financial models, these results have far-reaching consequences because, in the presence of LRD, traditional asset pricing methods/tests are no longer valid. (b) We also show that portfolios focusing on only the most persistent carry trades (highest Hurst coefficients among the ones above 0.5) can significantly outperform their all-encompassing counterparts. This implies that Hurst coefficients contain important investment information which can be used to enhance the performance of practical carry trade strategies.
C49|R&D and productivity in OECD firms and industries: A hierarchical meta-regression analysis|The relationship between R&D investment and firm/industry productivity has been investigated widely following seminal contributions by Zvi Griliches and others from late 1970s onwards. We aim to provide a systematic synthesis of the evidence, using 1253 estimates from 65 primary studies that adopt the so-called primal approach. In line with prior reviews, we report that the average elasticity and rate-of-return estimates are positive. In contrast to prior reviews, however, we report that: (i) the estimates are smaller and more heterogeneous than what has been reported before; (ii) residual heterogeneity remains high among firm-level estimates even after controlling for moderating factors; (iii) firm-level rates of return and within-industry social returns to R&D are small and do not differ significantly despite theoretical predictions of higher social returns; and (iv) the informational content of both elasticity and rate-of-return estimates needs to be interpreted cautiously. We conclude by highlighting the implications of these findings for future research and evidence-based policy.
C49|Exploring the childless universe: profiles and fertility intentions of men and women without children in Italy|In the last decades, several western countries experienced a large increase in childlessness. Relatively little is known about the profiles of childless women in Italy, and virtually nothing about men, as well as their fertility intentions. This paper aims to fill this gap by identifying typical life course trajectories of childless women and men in Italy, and by exploring how childless peopleâ€™s fertility intentions differ according to the various life course profiles. For eliciting typical patterns, I followed a holistic perspective and applied sequence analysis to a childless sample derived from the Italian 2009 Family and Social Subjects survey, taking into account a few relevant spheres, including partnership, employment, and education. Reconstructing the major life course trajectories, several similarities emerged between childless women and men, who shared some typical patterns. Determinants of fertility intentions were investigated through a logistic regression approach applied to a subsample of childless people nearly at the end of their reproductive period. Interestingly, similar childless profiles did not lead to similar attitudes towards fertility intentions.
C49|Modeling Naïve Causality In Everyday Reasonig With Fuzzy Logic|The aim of this paper is to present a new approach to the representation and elaboration of fuzzy causal reasoning. The proposed approach is based on some results obtained by several studies on causal explanation in the field of cognitive sciences. Drawing form such results, we present a fuzzy linguistic inference called generalized equivalence that permits to represent causal relationships contained in causal linguistic explanations though fuzzy relationships between antecedents and consequents. The generalized equivalence expresses the uncertainty of the causal link in an approximate way. The proposed model can be used to represent verbal explanation containing fuzzy evaluations of variables and of the relationships among them, such as in the statementusually bad weather causes a remarkable increase in car accidents, where usually, bad weather and remarkable increase are fuzzy constructs. The generalized equivalence can be applied to fuzzy causal maps to represent the intensity of causal relationships between fuzzy concepts.
C49|Technological innovation and employment in derived labour demand models: A hierarchical meta-regression analysis|The effect of technological innovation on employment is of major concern for workers and their unions, policy-makers and academic researchers. We aim to provide a quantitative synthesis of the evidence base and the extent of heterogeneity therein. Analysing 567 estimates from 35 primary studies that estimate a derived labour demand model we report the following findings: (i) the effect on employment is positive but small and highly heterogeneous; (ii) publication selection bias reflects a tendency to support the twin hypotheses that process innovation is associated with job destruction whereas product innovation is associated with job creation; (iii) the effects of process and product innovations do not conform to theoretical predictions or narrative review findings after selection bias is controlled for; (iv) only a small part of the residual heterogeneity is explained by moderating factors; (v) country-specific effect-size estimates are related to labour-market and product-market regulation in six OECD countries in a U-shaped fashion; and (vi) OLS estimates reflect upward bias whereas those based on time-differenced or within estimators reflect a downward bias. Our findings bridge the evidence gap in the research field and point out to data quality and modeling issues that should be considered in future research.
C49|Co-movements and contagion between international stock index futures markets|Abstract In this paper, we explore the co-movements and contagion between six international stock index futures markets. In contrast to the empirical studies which dominate the literature and focus on the case of spot markets, relatively little is known about the returns and the volatility dynamics of the futures markets. To address this deficiency, we employ a time–frequency approach and discover that the co-movements between the international markets manifest especially in the long run. Nevertheless, the contagion phenomenon associated with the very short-run horizon is present in particular in the case of the European markets, due to their higher level of integration. The rolling wavelet correlation increases after severe turbulence episodes, but fluctuates over time and across frequencies. Our findings can guide the international investors in stock index futures markets to accurately diversify their portfolio in crisis periods.
C49|Tweet-tales: moods of socio-economic crisis?|The widespread adoption of highly interactive social media like Twitter, Facebook and other platforms allow users to communicate moods and opinions to their social network. Those platforms represent an unprecedented source of information about human habits and socio-economic interactions. Several new studies have started to exploit the potential of these big data as fingerprints of economic and social interactions. The present analysis aims at exploring the informative power of indicators derived from social media activity, with the aim to trace some preliminary guidelines to investigate the eventual correspondence between social media indices and available labour market indicators at a territorial level. The study is based on a large dataset of about 4 million Italian-language tweets collected from October 2014 to December 2015, filtered by a set of specific keywords related to the labour market. With techniques from machine learning and userâ€™s geolocalization, we were able to subset the tweets on specific topics in all Italian provinces. The corpus of tweets is then analyzed with linguistic tools and hierarchical clustering analysis. A comparison with traditional economic indicators suggests a strong need for further cleaning procedures, which are then developed in detail. As data from social networks are easy to obtain, this represents a very first attempt to evaluate their informative power in the Italian context, which is of potentially high importance in economic and social research.
C49|Does Family Background Affect Earnings through Education? A Generalised Approach to Mediation Analysis|We seek to quantify the role of education as a mechanism through which family background affects earnings. To this end, we propose a generalisation of statistical 'mediation analysis'. In our approach, the treatment and mediator can be multidimensional. This allows us to directly and flexibly account for a range of background characteristics which affect child earnings through the pathway of education and through other mechanisms. The results suggest that educational attainment explains 24%-39% of the overall family background effect on earnings in Australia. The mediating role of education seems to be larger for Australia than for the UK.
C49|Evolution Of Monetary Policy Transmission Mechanism In Malawi: A Tvp-Var Approach|This paper investigates the evolution of monetary transmission mechanism in Malawi between 1981 and 2010 using a time varying parameter vector autoregressive (TVP-VAR) model with stochastic volatility. We evaluate how the responses of real output and general price level to bank rate, exchange rate and credit shocks have changed over time since Malawi adopted financial reforms in 1980s. It is becoming clear from literature that financial reforms can change the monetary transmission by changing the overall impact of the policy or by altering the transmission channels overtime. Therefore, the impact of monetary policy on price stability and output growth can vary and portray delayed effects overtime. The paper finds that inflation and real output responses to monetary policy shocks changed over the period under the review. Importantly, beginning mid-2000s, the monetary transmission performed consistently with predictions of economic theory partly due to stable macroeconomic conditions and positive structural changes in the economy. However, the statistical significance of the private credit supply remains weak and this calls for more financial reforms targeting the credit market which can contribute to monetary transmission and promote further economic growth in Malawi.
C49|The Many Faces of Human Sociality: Uncovering the Distribution and Stability of Social Preferences|There is vast heterogeneity in the human willingness to weigh others’ interests in decision making. This heterogeneity raises the question how one can parsimoniously model and characterize heterogeneity across several dimensions of social preferences while still being able to predict behavior over time and across situations. We tackle this task with an experiment and a structural model of preferences that allows us to simultaneously estimate outcome-based and reciprocity-based social preferences. We find that non-selfish preferences are the rule rather than the exception. Neither at the level of the representative agent nor when we allow for several preference types do purely selfish types emerge. Instead, three qualitatively different other-regarding types emerge endogenously, i.e., without pre-specifying assumptions about the characteristics of types. When ahead, all three types value others’ payoffs significantly more than when behind. The first type, denoted strongly altruistic type, is characterized by a relatively large weight on others’ payoffs and moderate levels of reciprocity. The second type is, moderately altruistic and also puts positive weight on others’ payoff, yet at a considerable lower level, and displays no positive reciprocity while the third type is behindness averse, i.e., puts a large negative weight on others’ payoffs when behind and behaves selfishly otherwise. We also find that there is an unambiguous and temporally stable assignment of individuals to these types. Moreover, the three-type model substantially improves the predictions of individuals’ behavior across additional games while the information contained in subject-specific parameter estimates leads to no or only minor additional predictive power. This suggests that a parsimonious model with three types captures the bulk of the predictive power contained in the preference estimates.
C49|Forward or Backward Looking? The Economic Discourse and the Observed Reality|Is academic research anticipating economic shake-ups or merely reflecting the past? Exploiting the corpus of articles published in the Journal of Economics and Statistics (Jahrbücher für Nationalökonomie und Statistik) for the years 1949 to 2010, this pilot study proposes a quantitative framework for addressing these questions. The framework comprises two steps. First, methods from computational linguistics are used to identify relevant topics and their relative importance over time. In particular, Latent Dirichlet Analysis is applied to the corpus after some preparatory work. Second, for some of the topics which are closely related to specific economic indicators, the developments of topic weights and indicator values are confronted in dynamic regression and VAR models. The results indicate that for some topics of interest, the discourse in the journal leads developments in the real economy, while for other topics it is the other way round.
C49|Forward or Backward Looking? The Economic Discourse and the Observed Reality|Is academic research anticipating economic shake-ups or merely reflecting the past? Exploiting the corpus of articles published in the Journal of Economics and Statistics (Jahrbücher für Nationalökonomie und Statistik) for the years 1949 to 2010, this pilot study proposes a quantitative framework for addressing these questions. The framework comprises two steps. First, methods from computational linguistics are used to identify relevant topics and their relative importance over time. In particular, Latent Dirichlet Analysis is applied to the corpus after some preparatory work. Second, for some of the topics which are closely related to specific economic indicators, the developments of topic weights and indicator values are confronted in dynamic regression and VAR models. The results indicate that for some topics of interest, the discourse in the journal leads developments in the real economy, while for other topics it is the other way round.
C49|Bizalom az üzleti kapcsolatokban. A diadikus adatelemzés egy alkalmazása<BR>[Trust in business relations - an application of dyadic data analysis]|A tanulmány arra a feltevésre épül, hogy minél erősebb a bizalomra méltóság szintje egy adott üzleti kapcsolatban, annál inkább igaz, hogy nagy kockázatú tevékenységek mennek végbe benne. Ilyen esetekben a bizalomra méltóság a kapcsolatban zajló események, cselekvések irányítási eszközévé válik, és azüzleti kapcsolatban megjelenik a cselekvési hajlandóságként értelmezett bizalom. A tanulmány felhívja a figyelmet a bizalom és a bizalomra méltóság fogalmai közötti különbségre, szisztematikus különválasztásuk fontosságára. Bemutatja az úgynevezett diadikus adatelemzés gazdálkodástudományi alkalmazását. Empirikus eredményei is igazolják, hogy ezzel a módszerrel az üzleti kapcsolatok társas jellemzőinek (köztük a bizalomnak) és a közöttük lévő kapcsolatoknak mélyebb elemzésére nyílik lehetőség. Journal of Economic Literature (JEL) kód: C49, D22, L20, M20.
C49|The Performance Evaluation of Teachers of Higher Public Education in East Timor: The Need for a New Model (The Evaluation of the Lecturing Performance in East Timor)|The evaluation of the lecturing performance in East Timor is a key part of the Timorese education system that declares, in accordance with the Law on Education (2008), that higher education is oriented towards the development of national human resources. Higher education institutions are therefore called upon to provide a wider public service and simultaneously more efficient and with better results. However, the evaluation of professors in the public higher education sphere follows the exact same procedures and criteria that are being applied to all public servants of Timorese administration. This article aims to argue there is a real need for the implementation in the higher education institutions of an assessment tool that meets the specific role and goals of public higher education institutions, thus filling a gap in the study of lecturer’s performance evaluation in East Timor. Classification JEL : A2, C49, I2.
C49|La proximidad geográfica en el contagio del fracaso empresarial en la pyme: Una aplicación empírica con el modelo probit espacia/The Geographic Proximity in the Spillover Effects of Business Failure in SMes: Empirical Application with the Spatial Probit Model|Este trabajo analiza el efecto de contagio en el fracaso empresarial como consecuencia de la proximidad geográfica entre empresas de reducido tamaño. Para ello, se desarrolla una aplicación empírica sobre una base de 2.710 pymes españolas localizadas en el municipio de Murcia. Con esta información, se estima un modelo de regresión espacial probit a partir del cual se contrasta la significatividad del efecto del contagio empresarial. Nuestros resultados indican que la probabilidad de fracaso de una pyme, no solo depende de las características específicas de cada empresa, sino que también influye la probabilidad de fracaso de empresas geográficamente próximas. Factores asociados a interacciones de carácter social y/o económico entre los agentes vinculados a las distintas empresas de una misma región estarían detrás de estos resultados. This paper tests the role of spillover effects derived from the geographic proximity among reduced size firms in business failure. To get this purpose, we develop an empirical application on a sample of 2.710 Spanish Small, Medium size Enterprises (SMEs) located in the region of Murcia. With this information, we estimate a spatial probit regression model to contrast the significance of business spillover effects in business failure models. Our results show that the probability of business failure in SMEs depends not only on its own characteristics but also on the probability of failure of geographically close firms. Factors associated with social and/or economic interactions among the agents linked to the different firms in the same region would be behind these results.
C49|Consumption over the life cycle in Poland|The article attempts to verify the existence and strength of the buffer stock and precautionary savings’ behaviours of households in Poland, with the use of the dynamic stochastic model of permanent income with life cycle hypothesis (PILCH). The theoretical part of the model relies heavily on Gourinchas & Parker [14], while numerical solutions are based on Carroll [3]. The model includes partial insurance of households against idiosyncratic risk. The data relies on two household surveys: on budgets (HBS) and wealth (HWS), with parametrisation based on the 1% sample from the social insurance administrative data. The results generally seem to confirm the initial presumption on doubtful reflection of the dynamic economic reality of the fast converging market economy in the applied version of the model. The reason may stem from the lack of sufficiently stable economic environment through at least one full working career path of the household generation. Polish households, in general, are not (yet) patient enough to create buffer stock behaviour based on financial means, so precautionary behaviour prevails. The detailed results for decomposed types of households show proof for buffer stock behaviour for high school graduates from richer regions, and specific professions.
C49|Does Mass Deworming Affect Child Nutrition? Meta-analysis, Cost-Effectiveness, and Statistical Power|The WHO has recently debated whether to reaffirm its long-standing recommendation of mass drug administration (MDA) in areas with more than 20% prevalence of soil-transmitted helminths (hookworm, whipworm, and roundworm). There is consensus that the relevant deworming drugs are safe and effective, so the key question facing policymakers is whether the expected benefits of MDA exceed the roughly $0.30 per treatment cost. The literature on long run educational and economic impacts of deworming suggests that this is the case. However, a recent meta-analysis by Taylor-Robinson et al. (2015) (hereafter TMSDG), disputes these findings. The authors conclude that while treatment of children known to be infected increases weight by 0.75 kg (95% CI: 0.24, 1.26; p=0.0038), there is substantial evidence that MDA has no impact on weight or other child outcomes. We update the TMSDG analysis by including studies omitted from that analysis and extracting additional data from included studies, such as deriving standard errors from p-values when the standard errors are not reported in the original article. The updated sample includes twice as many trials as analyzed by TMSDG, substantially improving statistical power. We find that the TMSDG analysis is underpowered: it would conclude that MDA has no effect even if the true effect were (1) large enough to be cost-effective relative to other interventions in similar populations, or (2) of a size that is consistent with results from studies of children known to be infected. The hypothesis of a common zero effect of multiple-dose MDA deworming on child weight at longest follow-up is rejected at the 10% level using the TMSDG dataset, and with a p-value
C49|Policy Regimes and the Shape of the Phillips Curve in Australia|We document an evolving pattern in the slope of the Phillips curve in Australia at different frequencies under different monetary policy regimes and labor market regulations. Our estimation strategy relies on the frequency domain estimation but is also complemented by the time domain estimation. We document an upward sloping medium-run Phillips curve in the pre-1977 period, a downward sloping long-run Phillips curve from 1977 to 1993, and a flattened Phillips curve from 1993 onwards. Inflation lagged unemployment during the first period but led during the second period. The Phillips curve at business-cycle frequencies is downward sloping in all periods. We explain our results in terms of the monetary targeting in 1976 and the inflation targeting in 1993 by the RBA, respectively, and important changes in labor relations from the mid-1980s to the mid-1990s. The flattened Phillips curve is also observed in several industrialized countries since their adoption of inflation targeting.
C49|Analysis of average value of a Fourier series using z-transform: comparison with Hodrick-Prescott filter|This paper develops a method of analyzing average value of a complex-valued function that can be represented as a Fourier series satisfying a few realistic restrictions. This method may be useful when Discrete Fourier transform is highly inefficient, and comparison with Hodrick-Prescott filter is made.
C49|A three-pole filter understanding of the average value of a Fourier series|This paper extends the idea in ``Analysis of average value of a Fourier series using z-transform'' by the author. The main difference is that a three-pole filter is used instead of a two-pole filter. This paper reaches qualitatively the same conclusion.
C49|What's BEPS got to do with it? Exploring the effectiveness of thin capitalisation rules|In October 2015, the OECD made a best practice recommendation in Action 4 of its BEPS project, suggesting a Fixed Ratio Rule in place of thin capitalisation rules. This review was almost 3 decades in the making, with the most recent OECD report on thin capitalisation rules published in 1986, which omitted guidance on how these rules could best be designed. Thin capitalisation rules’ strong emphasis on revenue base protection has resulted in their exponentially increasing popularity internationally since the 1960s. However, there is a growing body of literature critiquing the effectiveness of thin capitalisation rules. Accordingly, this paper approaches the issue of thin capitalisation from a novel perspective by conceptualising the cross-border debt bias as the ‘disease’ and thin capitalisation as merely the ‘symptom’. Grounded in the tax principle of efficiency, the overarching question guiding this paper is whether, given the opportunity to start over, the tax-induced cross-border debt bias would be better addressed by retaining thin capitalisation rules in their current form or whether an alternative reform would be more suited to dealing with this ‘disease’. The optimisation model developed in this paper shows that the OECD’s Fixed Ratio Rule is more effective than the current regime of thin capitalisation rules at protecting the tax revenue base from the most tax-aggressive multinational enterprises (MNEs). However, the model also indicates that it is ultimately more effective to align the tax treatment of intercompany funding to eliminate the ‘underlying disease’ (the tax incentive for thin capitalisation), rather than adopting rules that mitigate the ‘symptom’ (such as the OECD’s Fixed Ratio Rule). This research presents a unique contribution to the literature by simulating complex cross-border intercompany tax planning strategies. This facilitates a formal analysis of one of the most significant challenges presented by the mobility and fungibility of capital; namely, anticipating how an MNE structures its internal affairs in a tax-optimal manner given the current tax regime and suggesting tax administrative responses to BEPS accordingly.
C49|Konkurecieschopnosť ako cieľ hospodárskej politiky<BR>[Competitiveness as a Goal of Economic Policy]|Until now there is no scientific consensus about the concept of national competitiveness. Despite the ambiguity of its definition, it has become a goal of numerous political documents. Economic policies in many countries are devoted to raise their overall competitiveness. But an unclear definition of relations between different components of national competitiveness represents an obstacle to formulate effective political measures. The aim of this paper is to clarify the relation between the competitiveness of the Czech Republic and its export performance which is considered as one of ways to improve overall competitiveness. The contribution of external competitiveness to the export performance of the Czech Republic in European Union is quantified using an econometric version of Constant Market Shares analysis. The results suggest that the external competitiveness of the Czech Republic has significantly positive effects on its export performance. Moreover we conclude that the positive spillover effect from external to aggregate competitiveness could be reach via increasing productivity.
C49|The Effects of Institutional Structure on Economic Growth: An Application on G-20 Countries (1996-2014)|In parallel to the evolution of the economic growth theories regarding the main indicators of long term economic growth, this article econometrically analyses the long term effects of the institutional structure on the economic growth of G-20 countries with different development levels for the period of 1996-2014. In order to examine the impact of the institutional structure on economic growth more coherently and to compare the results, G-20 countries are included in the analysis under two sub-groups respectively as economically developed G-9 countries and developing G-10 countries. Thus the article aims to evaluate the impact of the institutional structure on the differentiation of the long term economic growth performances and economic development levels of the countries under the groups G-9 and G-10. The article concludes that, effects of the institutional structure indicators on the economic growth have been positive and significant in statistical terms in the sub-group G-9, while they have been usually negative and significant in sub-group G-10 during the period analysed. Nonetheless, the article indicates that, along with the physical and human capital accumulation, possession of different institutional structures are more effective in differentiation of the long term economic growth performances and development levels of the countries in the groups of G-9 and G-10 during the sample period.
C49|Barriers to Women Entrepreneurship. PLS vs. QCA: Do Different Methods Yield Different Results?|Building on research by Akehurst, Simarro and Mas-Tur (2012), this study analyzed internal and external factors in women entrepreneurship and linked these factors to the barriers that women face when starting businesses. To do so, two contrasting statistical techniques were used: PLS and QCA. Partial least squares (PLS) is an extension of principle component analysis (PCA) (Would et al., 1983). Both methods follow the principle known as soft modelling, which consists of analyzing models based on empirical data rather than on theoretical or logical constructions, as is the case in hard modelling (Sundbom, 1992). Therefore, PLS can be used to clarify complex patterns in the data (Semb, 2011).QCA is a set-theoretical method that assumes that the influence of certain elements on a specific outcome depends on combinations of these elements rather than the prevalence of the individual elements per se (Ragin, 2008). This method uses Boolean algebra to identify which combinations of properties are sufficient and/or necessary conditions to produce an outcome of interest (Fiss, 2007).This study had two objectives. The first objective was to extend the literature on barriers faced by women entrepreneurs, and the second objective was to observe differences between results of the same analysis conducted using two statistical methodologies: one quantitative (PLS) and one qualitative (QCA). After analyzing results from each of these techniques, we observed that family duties and difficulties in obtaining financing (both internal and external) were the main factors related to barriers faced by women entrepreneurs.
C49|Analyzing regional economic development patterns in a fast developing province of China through geographically weighted principal component analysis|Abstract Understanding the spatial structure of regional economic development is of importance for regional planning and provincial development strategy making. Taking Jiangsu Province in the economically richest Yangtze Delta as a case study, this paper aims to explore regional economic development level on a provincial scale. Using the data sets from provincial statistical yearbook of 2010, eleven variables are selected for statistical and spatial analyses at a county level. Both the traditional principal component analysis (PCA) and its local version—geographically weighted PCA (GWPCA)—are employed to these analyses for the purpose of comparison. The results have confirmed that GWPCA is an effective means of analyzing regional economic development level through mapping its local principal components. It is also concluded that the regional economic development in Jiangsu Province demonstrates spatial inequality between the North and South.
C49|Lassoing the HAR Model: A Model Selection Perspective on Realized Volatility Dynamics| Realized volatility computed from high-frequency data is an important measure for many applications in finance, and its dynamics have been widely investigated. Recent notable advances that perform well include the heterogeneous autoregressive (HAR) model which can approximate long memory, is very parsimonious, is easy to estimate, and features good out-of-sample performance. We prove that the least absolute shrinkage and selection operator (Lasso) recovers the lags structure of the HAR model asymptotically if it is the true model, and we present Monte Carlo evidence in finite samples. The HAR model's lags structure is not fully in agreement with the one found using the Lasso on real data. Moreover, we provide empirical evidence that there are two clear breaks in structure for most of the assets we consider. These results bring into question the appropriateness of the HAR model for realized volatility. Finally, in an out-of-sample analysis, we show equal performance of the HAR model and the Lasso approach.
C49|Robust frontier estimation from noisy data: a Tikhonov regularization approach|The aim of this paper is to construct a robust nonparametric estimator for the production frontier. The main tool is a concept of robust regression boundary defined as a special probability-weighted moment (PWM). We first study this problem under a regression model with one-sided errors where the regression function defines the achievable maximum output, for a given level of inputs-usage, and the regression error defines the inefficiency term. Then we consider a stochastic frontier model where the regression errors are assumed to be composite. It is more realistic to assume that the actually observed outputs are contaminated by a stochastic noise. The additive regression errors in the frontier model are then composed from this noise term and the one-sided ineficiency term. In contrast to the one-sided error model, where the direct use of empirical PWMs is fruitful, the composite error problem requires a substantial different treatment based on deconvolution techniques. To ensure the identifiability of the model we can only assume an independent Gaussian noise. In doing so, the estimation of the robust PWM frontiers, including the true regression boundary, necessitates the computation of a survival function estimator from an ill-posed equation. A Tikhonov regularized solution is constructed and nonparametric frontier estimation is performed. We unravel the asymptotic behavior of the resulting frontier estimators in both one-sided and composite error models. The procedure is very easy and fast to implement. Practical guidelines to effect the necessary computations are described via a simulated example. The usefulness of the approach is discussed through two concrete data sets from the sector of Delivery Services.
C49|Causality Between Per Capita Real GDP and Income Inequality in the U.S.: Evidence from a Wavelet Analysis|Abstract This study applies wavelet coherency analysis to examine the relationship between the U.S. per capita real GDP and six income inequality measures over the period 1917 to 2012. Wavelet analysis allows the simultaneous examination of correlation and causality between the two series in both the time and frequency domains. Our findings provide robust evidence of positive correlation between the growth and inequality across frequencies. Yet, directions of causality vary across frequencies and evolve with time. Evidence that inequality leads per capita real GDP at both high- and low-frequencies exists for the Top 1 and 10% measures of inequality with little evidence that real GDP per capita leads inequality. In the time-domain, the time-varying nature of long-run causalities implies structural changes in the two series. These findings provide a more thorough picture of the relationship between the U.S. per capita real GDP and inequality measures over time and frequency, suggesting important implications for policy makers.
C49|Foreign Branches of US Global Banks: Geography, Balance Sheet Structure and Contagion|This paper contributes to the understanding of the international financial linkages created by US banks by looking at the geographical composition and structure of the balance sheet of foreign branches. The empirical investigation, which is based on a novel dataset containing balance sheet statistics of foreign branches by country of location, has a threefold objective. First, it provides geographical mapping and distribution of foreign activities of branches by host country by accounting also for those balance sheet items not included in the available international banking statistics, i.e. gross interoffice positions and transactions with third-countries. Secondly, this paper presents a classification of host countries by balance sheet structure of foreign offices. A partioning-based clustering analysis allows to identify 4 distinct types of foreign branches: liquidity importers, liquidity exporters, liquidity conduits and locally implanted. Lastly, the paper provides evidence in support of the fact that US branches’ banking foreign operations are a good measure of financial integration with US as they can significantly explain business cycle synchronisation between the host country and the US during the Great Recession.
C49|Differential item functioning in the EQ-5D: An exploratory analysis using anchoring vignettes|Inter-group comparisons using the EQ-5D, or any self-reported measure of health, rely on the measure being an accurate reflection of the true health of the groups or individuals concerned. However, responses to questions on subjective scales, such as those used in the EQ-5D, will be inaccurate if groups of individuals systematically differ in their use of the response categories, a phenomenon known as differential item functioning(DIF). This paper reports on an exploratory analysis involving the use of anchoring vignettes to identify differential item functioning (DIF) in the EQ-5D-5L. We demonstrate that using vignettes to appropriately identify DIF in EQ-5D reporting is possible, at least in certain age groups. We find that the EQ-5D is indeed subject to DIF, and that failure to account for DIF can lead to conclusions that are misleading when using the instrument to compare health or quality of life across heterogeneous groups. For instance, when adjusting for DIF in a sample aged 55-65 years, we found that differences between the highest and lowest education groups doubled in value afteradjusting for DIF, and increased from quantities that would not have had relevance in a clinical settings to ones that would (based on a suggested minimally important difference). Thus, our research provides evidence that the EQ-5D should be used with caution when comparing health or quality of life across heterogeneous groups. We also provide several important insights in terms of the identifying assumptions of response consistency and vignette equivalence.
C49|On the applicability of maximum likelihood methods: From experimental to financial data|This paper addresses whether and to what extent econometric methods used in experimental studies can be adapted and applied to financial data to detect the best-fitting preference model. To address the research ques- tion, we implement a frequently used nonlinear probit model in the style of Hey and Orme (1994) and base our analysis on a simulation study. In detail, we simulate trading sequences for a set of utility models and try to identify the underlying utility model and its parameterization used to generate these sequences by maximum likelihood. We find that for a very broad classification of utility models, this method provides acceptable outcomes. Yet, a closer look at the preference parameters reveals several caveats that come along with typical issues attached to financial data, and that some of these issues seems to drive our results. In particular, deviations are attributable to effects stem- ming from multicollinearity and coherent under-identification problems, where some of these detrimental effects can be captured up to a certain degree by adjusting the error term specification. Furthermore, additional uncertainty stemming from changing market parameter estimates affects the precision of our estimates for risk preferences and cannot be simply remedied by using a higher standard deviation of the error term or a different assumption regarding its stochastic process. Particularly, if the variance of the error term becomes large, we detect a tendency to identify prospect theory as utility model provid- ing the best fit to simulated trading sequences. We also find that a frequent issue, namely serial correlation of the residuals, does not seem to be an im- portant issue. However, we detected a tendency to prefer nesting models over nested utility models, which is particularly prevalent if rank-dependent utility and exponential power utility models are estimated along with expected utility with constant relative risk aversion utility models.
C49|Are current EU cereal prices correlated?| This paper evaluates the correlations between European cereal prices in up to 87 markets of 24 Member States. History and geography play a role: The highest correlations are observed between closely located internal markets of the “old” Union; prices are more correlated along transport routes, in particular rivers. We observe that 10 years after the Accession (8 in the case of Romania and Bulgaria) we do not have a complete integration between the “old” and the “new” Member States. We advance several possible explanations: Weaker producers’ organisations, lack of storage facilities, less efficient transport facilities.
C49|Fast Fashion And Sustainable Supply Chain Management|Sustainability is a sensitive issue in the fast fashion industry, a field confronted with high competition, intense use of resources and breach of basic human rights and working conditions in some of the outsourced countries, which affect the sustainability of fashion supply chains. In this paper, we will examine the sustainability of Inditex Group’s supply chains and the activities they underwent with, to ensure the constant improvement of their overall activity throughout their supply chains, from a triple perspective: economic, social and environmental.
C49|Time-scale analysis of co-movement in EU sovereign bond markets|We study the co-movement of the 10-year sovereign bond yields of 11 EU countries. Our analysis is focused mainly on changes in co-movement during the financial crisis period, especially around two significant dates - the fall of Lehman Brothers, September 15, 2008, and the announcement of the increase of Greece's public deficit on October 20, 2009. We study co-movement dynamics using wavelet analysis, which allows us to observe how co-movement changes across frequencies and over time. We divide the countries into three groups: the core of the Eurozone, the periphery of the Eurozone and the states outside the Eurozone. The results indicate that co-movement decreased considerably during the crisis period for all country pairs but that there are significant differences among the groups. Furthermore, we demonstrate that the co-movement of bond yields is frequency (scale) dependent.
C49|The Study Of The Impact Of Active Measures On Labour Market By Factor Techniques|If before the outbreak of the great recession in the year 2008 the European labour markets were added almost 30 million new jobs, during the crisis the same markets eliminated six million jobs, and unemployment reached a peak of 11% in 2013, the highest rate in more than a decade.At European level, even though political and economic decision factors took firm measures for alleviating the negative effects of the economic crisis, many economies are still faced with the actual perspective of an extended period of tempered economic growth or even economic decline. The employment of vulnerable labour force and employed population poverty are very important issues needing to be tackled and solved. The statistical methods and techniques of quantification, the factor analysis for estimating and testing are both represented by a wide and varied multitude of procedures and statistic-mathematical instruments. For deepened analysis of the impact of adopting active measures on the evolution of the main macroeconomic indicators which highlight the employment of labour force, the paper used the method of principal components
C49|Procedural transparency in Latin American central banks under inflation targeting schemes. A text analysis of the minutes of the Boards of Directors|The disclosure of the minutes of the Boards of Directors of central banks (procedural transparency within the inflation targeting (IT) literature) implies the challenge of sending a clear message. Regardless of whether the document released is a brief, moderate, or highly detailed (verbatim) account of a Board's discussion, its contents often align expectations and define an effective monetary policy to curb inflation. This paper provides a quantitative perspective of procedural transparency by performing a text analysis of the minutes of Board meetings in the central banks of Brazil, Chile, Colombia, Mexico, and Peru. The study examined the lengths of the minutes, their frequent vocabulary (including its association with a predefined central-bank terminology), and their readability (through a reading ease index). ****** La divulgación de las actas de las juntas directivas de los bancos centrales (transparencia procedimental dentro de la literatura de inflación objetivo) supone el reto de enviar un mensaje claro. Independientemente de si el documento publicado es un resumen breve, moderado o muy detallado (literal) de una reunión de la junta, los contenidos suelen converger las expectativas y definir una política económica eficaz para contener la inflación. El presente ensayo arroja una perspectiva cuantitativa de la transparencia en los procedimientos por medio de un análisis textual de las actas de las reuniones de las juntas en los bancos centrales de Brasil, Chile, Colombia, México y Perú. El estudio examinó la longitud de las actas, el vocabulario más frecuente (entre el que se incluye la asociación a una terminología predefinida del banco central) y su comprensión (a través de un índice de legibiligad).
C49|Procedural transparency in Latin American central banks under inflation targeting schemes. A text analysis of the minutes of the Boards of Directors|The disclosure of the minutes of the Boards of Directors of central banks (procedural transparency within the inflation targeting (IT) literature) implies the challenge of sending a clear message. Regardless of whether the document released is a brief, moderate, or highly detailed (verbatim) account of a Board's discussion, its contents often align expectations and define an effective monetary policy to curb inflation. This paper provides a quantitative perspective of procedural transparency by performing a text analysis of the minutes of Board meetings in the central banks of Brazil, Chile, Colombia, Mexico, and Peru. The study examined the lengths of the minutes, their frequent vocabulary (including its association with a predefined central-bank terminology), and their readability (through a reading ease index).
C49|Deprivation and the Dimensionality of Welfare: A Variable-Selection Cluster-Analysis Approach|" type=""main""> We approach the problems of measuring the dimensionality of welfare and that of identifying the multidimensionally poor, by first finding the poor using the original space of attributes, and then reducing the welfare space. The starting point is the notion that the “poor” constitutes a group of individuals that are essentially different from the “non-poor” in a truly multidimensional framework. Once this group has been identified through a clustering procedure, we propose reducing the dimension of the original welfare space using recent blinding methods for variable selection. We implement our approach to the case of Latin America based on the Gallup World Poll, which contains ample information on many dimensions of welfare."
C49|Are monetary unions more synchronous than non-monetary unions?|Within currency unions, the conventional wisdom is that there should be a high degree of macroeconomic synchronicity between the constituent parts of the union. But this conjecture has never been formally tested by comparing sample of monetary unions with a control sample of countries that do not belong to a monetary union. In this paper we take euro area data, US State macro data, Canadian provincial data and Australian state data — namely real Gross Domestic Product (GDP) growth, the GDP deflator growth and unemployment rate data — and use techniques relating to recurrence plots to measure the degree of synchronicity in dynamics over time using a dissimilarity measure. The results show that for the most part monetary unions are more synchronous than non-monetary unions, but that this is not always the case and particularly in the case of real GDP growth. Furthermore, Australia is by far the most synchronous monetary union in our sample.
C49|Euro area monetary and fiscal policy tracking design in the time-frequency domain|This paper first applies the MODWT (Maximal Overlap Discrete Wavelet Transform) to Euro Area quarterly GDP data from 1995 – 2014 to obtain the underlying cyclical structure of the GDP components. We then design optimal fiscal and monetary policy within a large state-space LQ-tracking wavelet decomposition model. Our study builds a MATLAB program that simulates optimal policy thrusts at each frequency range where: (1) both fiscal and monetary policy are emphasized, (2) only fiscal policy is relatively active, and (3) when only monetary policy is relatively active. The results show that the monetary authorities should utilize a strategy that influences the short-term market interest rate to undulate based on the cyclical wavelet decomposition in order to compute the optimal timing and levels for the aggregate interest rate adjustments. We also find that modest emphasis on active interest rate movements can alleviate much of the volatility in optimal government spending, while rendering similarly favorable levels of aggregate consumption and investment. This research is the first to construct joint fiscal and monetary policies in an applied optimal control model based on the short and long cyclical lag structures obtained from wavelet analysis.
C49|Politiche di sostegno al settore agroindustriale in Piemonte: una valutazione controfattuale [Supporting agro-food enterprises in Piedmont: a counterfactual evaluation]|This paper aims at analysing the role played by the Rural Development Programme (RDP) in supporting the Piedmont (Italy) agro-food industry, i.e. that part of the agricultural production chain characterised by the highest added value. This is a first attempt to extend the previous in itinere evaluation to an ex-post quasi experimental counterfactual evaluation of the subsidies’ net impact. Since the agri-food industry is characterised by an extreme variety of firms, and having observed that the treated firms do not share the characteristics of the average population. The counterfactual group has been selected by adopting the coarsened exact matching technique, a quite recent imbalance-reducing matching method. The final results do suggest, above all, a stabilizing effect of the subsidy in a period characterized by a sever worldwide economic crisis. However, since results are quite uncertain, we expect that on-going further research (on the data-base, the model, and balance sheet indicators) will lead to stronger conclusion on the effectiveness of the policy. Nonetheless, this exercise already shows that the selected matching set and methodology, the chosen timing, and the quality of the available data do strongly influence the impact analysis.
C49|A Spectral Representation of the Phillips Curve in Australia|We document evolving patterns in the inflation-unemployment relationship in Australia in the frequency domain under different monetary policy regimes and labor market regulations. The RBA adopted monetary targeting in 1976 and inflation targeting in 1993. There were important changes in the labor relations during mid-1980s-mid-1990s. We document an upward sloping medium-run Phillips curve in the pre-1977 period, a downward sloping long-run Phillips curve during 1977-1993, and a flattened Phillips curve from 1993 onwards. Inflation lags unemployment during the first period but leads during the second period. The Phillips curve at business-cycle frequencies is downward sloping in all periods. Similar patterns are also observed in several industrialized countries that adopted inflation targeting.
C49|Fiscal policy tracking design in the time–frequency domain using wavelet analysis|In this paper discrete wavelet filtering techniques are applied to decompose macroeconomic data so that they can be simultaneously analyzed in both the time and frequency domains. The MODWT (Maximal Overlap Discrete Wavelet Transform) is applied to US quarterly GDP data to obtain the underlying cyclical structure of the GDP components. A MATLAB program is then used to design optimal fiscal policy within an LQ tracking model with wavelet decomposition, and the results are compared with an aggregate model with no frequency decomposition. The results show that fiscal policy is more active under the wavelet-based model, and that the consumption and investment trajectories under the aggregate model are misaligned. We also simulate FHEC (Frequency Harmonizing Emphasis Control) strategies that allow policymakers to concentrate the policy thrust on tracking frequencies that are optimally aligned with policy goals under different targeting priorities. These strategies are only available by using time–frequency analysis. This research is the first to construct fiscal policy in an applied optimal control model based on the short and long cyclical lag structures obtained from wavelet analysis. Our wavelet-based optimal control procedure allows the policymaker to construct a pragmatic tracking policy, avoid suboptimal policies gleaned from an aggregate model, and reduce the potential for destabilization that might otherwise result due to improper thrust and timing.
C49|Frontier estimation in the presence of measurement error with unknown variance|Frontier estimation appears in productivity analysis. Firm’s performance is measured by the distance between its output and an optimal production frontier. Frontier estimation becomes difficult if outputs are measured with noise and most approaches rely on restrictive parametric assumptions. This paper contributes to nonparametric approaches, with unknown frontier and unknown variance of a normally distributed error. We propose a nonparametric method identifying and estimating both quantities simultaneously. Consistency and rate of convergence of our estimators are established, and simulations verify the performance of the estimators for small samples. We illustrate our method with data on American electricity companies.
C49|Tail risk and systemic risk of US and Eurozone financial institutions in the wake of the global financial crisis|We evaluate multiple market-based measures for US and eurozone individual bank tail risk and bank systemic risk. We apply statistical extreme value analysis to the tails of bank equity capital losses to estimate the likelihood of individual institutions' financial distress as well as individual banks' exposure to each other (“spillover risk”) and to global shocks (“extreme” systematic risk). The estimation procedure presupposes that bank equity returns are “heavy tailed” and “tail dependent” as identifying assumption. Using both US and eurozone banks allows one to make a cross-Atlantic comparison of tail risks and systemic stability. We also assess to what extent magnitudes of tail risk and systemic risk have been altered by the global financial crisis. The results suggest that both tail risk and systemic risk in the US are higher than in the eurozone regardless of the considered sample period.
C49|On the spatial scale of industrial agglomerations|Standard approaches to studying industrial agglomeration have been in terms of scalar measures of agglomeration within each industry. But such measures often fail to distinguish spatial scales of agglomeration. In a previous paper, Mori and Smith (2014) proposed a pair of quantitative measures for distinguishing both the scale and degree of industrial agglomeration based on an explicit method for detecting spatial clusters. The first, designated as the global extent of industrial clusters, measures the spatial spread of these clusters in terms of the areal size of their essential containment, defined to be the (convex-solid) region containing the most significant subset of these clusters. The second, designated as the local density of industrial clusters, measures the spatial extent of individual clusters within their essential containment in terms of the areal share of that containment occupied by clusters. The present paper applies this pair of measures to manufacturing industries in Japan, and the results obtained are systematically compared to those of the most prominent scalar measures currently in use. Finally, these measures are shown to support certain predictions of new economic geography models concerning the relationship between shipment distances and spatial scales of agglomeration for individual industries.
C49|Combining momentum, value, and quality for the Islamic equity portfolio: Multi-style rotation strategies using augmented Black Litterman factor model|This study constructs active Islamic portfolios using a multi-style rotation strategy, derived from the three prominent styles, namely, momentum, value, and quality investing. We use the stocks that are consistently listed in the U.S. Dow Jones Islamic index for a sample period from 1996 to 2012. We also include two macroeconomic mimicking portfolios to capture the premiums of industrial production growth and inflation innovation, accommodating the economic regime shifts.
C49|Money growth and inflation in China: New evidence from a wavelet analysis|This paper provides a fresh new insight into the dynamic relationship between money growth and inflation in China by applying a novel wavelet analysis. From a time-domain view, our findings show strong but not homogenous links between money growth and inflation in the mid-1990s and the period since the early 2000s. Especially since the early 2000s, China's monetary policy has achieved much better performance in terms of inflation management compared to previous years. From a frequency-domain view, we find that money growth and inflation are positively related in one-to-one fashion in the medium or long run whereas they deviates from such a positive relation in the short run due to temporary shocks and significant lag effects. We can also conclude for China that the long-run relationship between M0 growth and inflation supports the modern quantity theory of money (QTM), while the medium-run relationship between M1 growth and inflation as well as M2 growth and inflation supports the modern QTM. In general, however, our results fit well with the fact that China has experienced economic transitions and structural adjustments in monetary policy over the past two decades. Based on the above analysis, this paper provides an overall view of monetary policy operations and some beneficial implications for China.
C49|The co-movement and causality between the U.S. housing and stock markets in the time and frequency domains|This study applies wavelet analysis to examine the relationship between the U.S. housing and stock markets over the period 1890–2012. Wavelet analysis allows the simultaneous examination of co-movement and causality between the two markets in both the time and frequency domains. Our findings provide robust evidence that co-movement and causality vary across frequencies and evolve over time. Examining market co-movement in the time domain, the two markets exhibit positive co-movement over recent decades, except for 1998–2002 when a high negative co-movement emerged. In the frequency domain, the two markets correlate with each other mainly at low frequencies (longer term), except in the second half of the 1900s as well as in 1998–2002, when the two markets correlate at high frequencies (shorter term). In addition, we find that the causal effects between the markets in the frequency domain occur generally at low frequencies (longer term). In the time-domain, the time-varying nature of long-run causalities implies structural changes in the two markets. These findings provide a more complete picture of the relationship between the U.S. real estate and stock markets over time and frequency, offering important implications for policymakers (and practitioners).
C49|A measure of technological capabilities for developing countries|The study was conducted to develop an index as a new measurement tool analyzing the innovativeness of developing countries. The role of science and technology in enhancing the rate of innovation is also investigated. The index is estimated for 61 countries observed during 2003–2008. The countries are classified into three groups based on their innovation level. The highest rate of innovation was noticed in China, followed by Estonia and Malaysia. The lowest innovation rate was reported in Iran, Bangladesh, Tadzhikistan, and Cambodia. It is recommended that governments (1) to allocate significant share of their budgets to the factors that enhance technological capability such as the science education, gross education enrollment rate and internet connectivity, (2) to promote policies of national awards for scientists and researchers who make sound breakthroughs in science and technology, (3) to develop international relations in the social, economic, cultural, and scientific spheres, (4) to modify school curriculum and syllabus, so that higher emphasis is given to the creativity and spontaneity of the children, (5) to relax portion of corporate taxes for developing an innovative way of product and production processes, which are environmentally friendly and economically viable. Finally, (6) the special focus must be given to the encouragement of local organizations to conduct the specialized training programs to promote innovation activities.
C49|Measuring bipolarization in labour productivity in Italy: a new index and its decomposition by sectors and regional factors|This paper explores bipolarization in labour productivity among Italian regions. An index to measure bipolarization in labour productivity distribution is suggested. The index can be decomposed by sectors, explaining the contribution of each sector to bipolarization. From this sectoral decomposition, a further decomposition based on a reformulation of shift-share analysis is obtained. This shift-share decomposition captures the effects of regional factors on bipolarization since the roles played by the disparities in sectoral labour productivities, industry-mix and allocation of workers across sectors are explained. The index and its decompositions are used to measure the bipolarization in the aggregate labour productivity distribution across Italian regions over the 2000-2011 period. Our findings show that bipolarization is not particularly high and is mainly attributable to the disparities in sectoral labour productivities between regions. Keywords: bipolarization, decomposition, labour productivity, Shift-share analysis, Italian regions, sectors of activity
C49|The Italian Corporate System: SOEs, Private Firms and Institutions in a Network Perspective (1952-1983)|How did business networks among Italian firms evolve over time? We address this question by analyzing the Italian corporate boards network in four years (1952, 1960, 1972, 1983) with network theoretical methods. We find some typical properties of these networks, such as sparsity and connectedness in the same large network component. At the same time, clustering and assortativity are relatively high and stable, while we observe, over time, an increase of the average distance coupled with a decrease of density and of the relative size of the largest component. This is an indication of a rarefaction of connections which is detected also in other national systems. In order to seek the determinants of this phenomenon, we perform a panel regression for the average nodal degree, finding that rarefaction is mostly related to a genuine time trend and only partially to cross-sectional variables. We argue that a possible explanation is a significant increase of concentration which we observe in our dataset, consistently with historical evidence. The network shows a substantial stability in some structures, such as core-periphery subdivision. Looking at the main actors we find a persistent centrality of banks and insurances, as well as of State Owned Enterprises (SOEs). These play a growing role in the community structure of the network, while communities themselves become more and more diversified by sector.
C49|Heterogeneidad geográfica en la calidad de vida relacionada con la salud. Análisis multinivel para Argentina/Geographical Heterogeneity in the Quality of Life Related to Health. Multilevel Analysis for Argentina|Este trabajo examina el alcance de las diferentes fuentes de variación geográfica en los reportes de calidad de vida relacionada con la salud. Concretamente, el presente trabajo investiga tres importantes preguntas: ¿Existen diferen¬cias significativas a través de los grupos urbanos en los reportes de CVRS?; ¿Pueden los factores composicionales explicar las diferencias en la CVRS?, y ¿El factor contextual de pobreza estructural impacta en la percepción indivi¬dual de CVRS?. Mediante modelos multinivel que permiten analizar simultáneamente fuentes de variación individual y factores socio-contextuales se encuentra evidencia de la heterogeneidad geográfica en la CVRS. Las variables individuales, tales como los factores de riesgo, influyen significativamente aunque no explican completamente la variabilidad geográfica. La pobreza estructural como factor contextual afecta negativamente en la percepción de calidad de vida. Este trabajo destaca la necesidad de considerar explícitamente el vínculo de la salud individual al contexto socio-económico en donde el individuo interactúa. This paper examines the extent of geographic variation in the reports of quality life related to health. Specifically, this paper investigates three important questions: Are there significant differences across urban groups in reports of HRQOL?; Can compositional factors explain the differences in HRQOL?, and Does the contextual factor of struc¬tural poverty affects to the individual's perception of HRQOL?. Using multilevel models to simultaneously analyze sources of individual variation and social-contextual factors, we found evidence of geographical heterogeneity in HRQOL. Individual variables, such as risk factors, significantly influence but not completely explain the geographical variability. Structural poverty, as a contextual factor, negatively affects the perception of quality of life. This paper highlights the need to explicitly consider the linkage of individual social-economic context in which the individual interacts health.
C49|Optimisation Of Operations Using A Transportation Model|Hrvatske sume d.o.o. (limited liability company) is a state-owned enterprise for forest and woodland management in the Republic of Croatia. The area under its governance provides for annual increment of 9.6 million m3 of gross wood mass, whereas 5.4 million m3 is on a yearly basis. This cut wood mass needs to be transported to designated destinations. Wood mass transport has continuously increased, with 4.8 million m3 transported in 2013. Out of this quantity, the company Hrvatske šume d.o.o. transported 12.8% of wood mass using its own facilities, and the rest was transported by subcontractors. For these reasons, a transportation model can be an important part of operations. The paper aims to analyze transport-related issues in the company Hrvatske šume d.o.o. The insight into the current situation in wood mass transport will provide a basis for the proposed optimization of operations. Key factors of transport will be considered in devising an optimization proposal.
C49|The Tobin tax in a continuous-time non-linear dynamic model of the exchange rate|Starting from a new continuous-time non-linear dynamic model of the exchange rate, we formally show that the introduction of a Tobin tax reduces speculators’ profit and influences the dynamics of the system, making it more stable and less prone to chaotic motion.
C49|"Una nota sobre un procedimiento bayesiano para meta-análisis con datos binarios con alta presencia de ceros || A note on a Bayesian procedure for meta-analysis of rare data"|"El objetivo de este trabajo es construir un procedimiento bayesiano, fácil de implementar en la práctica, que soslaye los problemas encontrados en los métodos de meta-análisis para el caso de datos binarios con alta presencia de ceros. Para ello, consideraremos el problema dentro de uno general de selección bayesiana de modelos identificando de forma adecuada sus elementos. En particular definiendo una sencilla distribución “link” entre las efectividades por estudios y la meta-efectividad del tratamiento. Hemos desarrollado un procedimiento objetivo bayesiano para las medidas de interés así como para el test de comparación de efectividades entre tratamientos. Presentamos dos aplicaciones con datos reales. Básicamente, probamos en este trabajo que es posible desarrollar un test de hipótesis bayesiano de igualdad de tratamientos sin necesidad de procedimientos ad-hoc artificiales que actúan sobre transformaciones de las variables y observaciones que no siempre son adecuadas. Respecto a los ejemplos, no existen evidencias empíricas para considerar que existen diferencias entre tratamientos. || The propose of this paper is to develop a Bayesian procedure that adequately account for studies with zero observations in meta-analysis and then we focus the problem in the context of the Bayesian selection models. Also, attention is focused to the link distribution between effectiveness in each study/center and the meta-effectiveness. We present an objective Bayesian method where all quantities of interest jointly with a Bayesian test for equality between treatments are also obtained. A couple of examples with are developed in depth using the pro- posed Bayesian meta-analysis for the binomial model. Basically, we obtain a Bayesian model for meta-analysis for sparse binomial data without considering transformations and/or corrections in variable/parameters. In respect to the examples considered, we do not find a relevant difference between treatments."
C49|Research Trends Of Public-Private Partnerships (Ppps) In Poland|Over the last two decades the attention given to the research on Public-private partnerships (PPPs) has been steadily increasing. Literature surveys on the research trends of PPP in English language publications suggest some emerging trends in the topics dedicated to the PPP. A similar compilation of PPP literature is not readily available on the grounds of national scientific research. That is why the aim of the article is to present contemporary trends that are being developed in Poland in the PPP filed. The indication of possible further research in the area of PPP is also an essential issue tackled in this article.
C49|Entropy, competitiveness and UEFA football ranking|This paper intends to explore the utilization of entropy through football, generalizing the interpretation of entropy. We consider it as a measure of competitiveness of football leagues and relate it to the UEFA ranking, which ranks yearly the performance of countries in European Cups. We expect that more competitive leagues, meaning that a championship is more leveled, have a better UEFA ranking. Correlating entropy with UEFA ranking, we find evidence of that relationship
C49|Forecasting coherent volatility breakouts|The paper develops an algorithm for making long-term (up to three months ahead) predictions of volatility reversals based on long memory properties of financial time series. The approach for computing fractal dimension using sequence of the minimal covers with decreasing scale (proposed in [1]) is used to decompose volatility into two0dynamic components: specific A (t ) and structural Hµ(t ). We introduce two separate models forA (t ) and Hµ(t ), based on different principles and capable of catching long uptrends in volatility. To test statistical significanceof its abilities we introduce several estimators of conditional and unconditional probabilities of reversals in observed and predicted dynamic components of volatility. Our results could be used for forecasting points of market transition to an unstable state.
C49|Identifying a Country As ¨Developed¨ Based On Their Structural Similarities|This research begins with the following questions: Is there consistency between the identification of development and the economic structure it possesses?; Are there similarities between the economies identified with differences in their levels of development?; and, are there non- developed economies with the same structure of developed economies? To answer these questions, similarities of input-output tables obtained from the OECD (Mid90, Early00 and Mid00) are reviewed, and after, a case study is performed on the Chilean economy. The similarities and changes are investigated by using a structural similarity index, and then by comparing correlations. The results show that: traditional indicators can only be used as references and are non-categorical in their identifications of development; the economies show significant similarities according to their level of development, and there exists significant structural similarities between developed economies and the economy of Chile.
C49|Extreme Linkages in Financial Markets: Macro Shocks and Systemic Risk|The recent IMFWorld Economic Outlook (2013) investigates how real and financial shocks can cause a sharp increase in cross country output co-movements.This paper looks at the reverse issue by asking how macro regimes of extreme low and high in flation or productivity growth are conducive to spillover of financial market shocks between major open economies. Using a non-parametric measure we study the largest movements in the US and German equity index returns conditional on a specific macro regime in one or both of the countries. It is known that the unconditional probability of different stock markets crashing jointly is non-negligible, see e.g.Hartmann et al.(2004) and Poon et al. (2004).The results suggest that the factor related to real economy, i.e. industrial production growth, is a major driver behind the extreme loss linkage, but in flation is not. One explanation is that monetary policy shocks are absorbed by the exchange rate, whereas technology shocks do spillover.
C49|Scenarios for regionalization: analysis on Romania’s population using Onicescu informational statistics|Regionalization is an important topic in Romania, as it is considered that it would help to obtain easy access to European funding and it would stimulate economic development. In order to meet this purpose, it is necessary to find the optimal formula for reorganizing Romania’s territory. It was shown that the decision regarding regionalization needs to be taken considering many criteria. One of them is population. This paper aims to study the homogeneity of the Romanian regions’ population, regarding age, area of residence and gender. With the help of Onicescu informational statistics it was shown that regions are homogenous from the mentioned points of view. This led to the conclusion that the decision on regionalization can only be taken after considering other aspects as well.
C49|Scenarios for regionalization: analysis on Romania’s industry using Onicescu informational statistics|We have shown that in order to make a decision regarding the optimal formula for Romania’s regionalization it is necessary to consider more than one criteria. The aim of this paper is to study one of these criteria – the industrial sector. Using instruments provided by Onicescu’s informational statistics we analyze the homogeneity of the Romanian regions regarding two variables, the industrial production index and the turnover value index in industry. We find out that from this point of view regions are not homogeneous, which leads to the conclusion that industry is an aspect that can be considered when deciding on regionalization.
C49|Linear and Non-linear Market Model Specifications for Developed and Emerging Markets|The way various linear and non-linear qualifications of the market model will be compared in this paper in order to appraise the success of the linear market model when it only permits of the constant beta risk parameter?. A number of time-varying market models using state space model are proffered in order to take into consideration the time-varying systematic risk components of co-kurtosis, co-skewness, and beta. This framework's theoretical underpinnings rely Sharpe-Linter-Mossin (1960's) proposition that these models should maximize the investors' expected utility. This paper analyses weekly data from the stock indices of several emerging and developed markets from 2002 to 2012. The findings suggest that time-varying market model approaches, which surpass linear market model qualifications both in terms of in-sample modelling and out-of-sample forecasting procedure for both emerging and developed stock markets, should be favoured.
C49|Time-varying Multivariate Extension of the Linear Market Model for Developed and Emerging Markets|This paper aims to evaluate the effectiveness of a Linear Market Model (consistent with the Two-moment CAPM) which permits beta risk. This evaluation leads to our positing two extensions. The first extension is a time-varying Linear Market Model using state space model which permits for time-varying beta risk. The second is a multivariate extension of the time-varying Linear Market Model permitting the between country stock market correlation structure to be constant over time. The analysis utilises weekly data from several emerging and developed markets for periods both before and after the October 2008 financial crisis. The findings lend great credence to the hypothesis that utilising the multivariate time-varying Linear Market Model is better in terms of in-sample modelling and out-of-sample forecasting procedure for both emerging and developed markets.
C49|Internal migration in polish cities – the analysis using the spatial dynamic shift-share method|The main aim of this paper is to examine internal population movements for permanent stay in polish cities. The spatial dynamic shift-share method is used to analyze internal migrations (internal emigrations) according to the sex and direction (urban, rural) from 2001 to 2013. The study also analyses the pace of changes in the volume of the phenomenon as well as the share and identifies structural and local factors in the size of the net global effect in specific cities. Moreover, it takes into consideration a spatial weights matrix which allows one to include spatial aspects in the study. The analysis was conducted on panel data, covered 65 polish and thirteen years.
C49|The multiplex structure of interbank networks| The interbank market has a natural multiplex network representation. We employ a unique database of supervisory reports on Italian banks to the Banca d'Italia that includes all bilateral exposures broken down by maturity and by the secured and unsecured nature of the contract. We find that layers have different topological properties and persistence over time. The presence of a link in a layer is not a good predictor of the presence of the same link in other layers. Maximum entropy models reveal different unexpected substructures, such as network motifs, in different layers. Using the total interbank network or focusing on a specific layer as representative of the other layers provides a poor representation of interlinkages in the interbank market and could lead to biased estimation of systemic risk.
C49|The Port Attractiveness Index:Application On African Ports|The overall operational reputation of a port is based on objective factors, including infrastructure endowments and efficiency in the logistics chain as well as on perceived subjective factors such as reliability, and level of corruption. In this work we analyze the concept of port attractiveness, starting with the hypothesis that subjective port determinants (i.e., user perception) and objective/endogenous and exogenous factors can be quantified together. We thus determine the Port Attractiveness Index and test it using 41 container ports of 23 African countries for the period 2006-2010. We apply a bottom-up ap-proach to investigate the structural relationships among the three sets of deter-minants (endogenous, exogenous and subjective) that impact on port attractive-ness. Our methodological approach employs structural equation modeling. Results indicate that subjective factors are indeed influential variables for port attractiveness. Moreover, when examining port attractiveness and investment strategies, we demonstrate that in many cases in African ports governments should implement soft infrastructure as a first step rather than investing in hard infrastructures.
C49|Time-scale analysis of sovereign bonds market co-movement in the EU|We study co-movement of 10-year sovereign bond yields of 11 EU countries. Our analysis is focused mainly on changes of co-movement in the crisis period, especially near two significant dates - the fall of Lehman Brothers, September 15, 2008, and the announcement of increase of Greek's public deficit in October 20, 2009. We study co-movement dynamics using wavelet analysis, it allows us to observe how co-movement changes across scales, which can be interpreted as investment horizons, and through time. We divide the countries into three groups; the Core of the Eurozone, the Periphery of the Eurozone and the states outside the Eurozone. Results indicate that co-movement considerably decreased in the crisis period for all countries pairs, however there are significant differences among the groups. Furthermore, we demonstrate that co-movement of bond yields significantly varies across scales.
C49|Analysis of the Romanian Insurance Market Based on Ensuring and Exercising Consumers` Right to Claim|In the financial market of insurance, consumer protection represents an important component contributing to the stability, discipline and efficiency of the market. In this respect, the activity of educating and informing insurance consumers on ensuring and exercising their right to claim plays a leading role in the mechanism of consumer protection. This study aims to improve the decision-making capacity of the financial services consumers from the Romanian insurance market through better information on ensuring and exercising their right to claim under the legislation. Thus, by applying three data analysis techniques – principal components analysis, cluster analysis and discriminant analysis – to the data regarding the petitions that were registered by the 41 insurance companies which operated in the Romanian market in 2012, a classification that assesses the insurance market transparency is achieved, resulting in a better information for consumers and, hence, the improvement of their protection through reducing the level of transactions that are harmful to consumers.
C49|A new methodological approach for studying intergenerational mobility with an application to Swiss data|Despite the widespread interest in the topic and a vast international literature, very little is known about the development of intergenerational mobility in Switzerland. Based on a new harmonized database for Switzerland (comprising various surveys such as different waves of the ISSP, EVS, and the ESS), we provide a systematic account of changes in the link between social origin and destination over time (covering birth cohorts from around 1935 to 1980). We analyze effects of parental education and class on own educational achievement and social class for both men and women, using a refined variant of the methodological approach proposed by Jann and Combet (2012). The approach is based on the concept of proportional reduction of error (PRE) and features a number of advantages over more traditional approaches. For example, it provides smooth estimates of changes in social mobility that have a clear interpretation and it can easily incorporate control variables and multiple dimensions of parental characteristics. To evaluate the validity of our approach, we employ the oft-used log-multiplicative layer effect (a.k.a Unidiff) model (Xie 1992, Erikson and Goldthorpe 1992) as a benchmark. Results indicate that our approach performs well and produces qualitatively similar findings as Xie's model. For both men and women, effects of social origin initially decreased, but then, towards the end of the observation period, increased again. This u-shaped pattern, which can be observed with respect to both education and class, appears to be more pronounced for women than for men.
C49|The Effects of Elite Sports on Later Job Success|This paper analyses the income effect of the participation in elite sports. To quantify the average difference in the monthly net income of former elite athletes and non-athletes we estimate sample average treatment effect scores (SATT) by using covariate nearest-neighbour matching (CVM). While our treatment group consists of formerly funded top-level athletes, the control group of non-athletes is drawn from the SOEP database. Matching takes place by socio-demographic variables as well as measures of personal qualities and attitudes. On average, former athletes receive higher incomes than similar non-athletes. The income premium for former team sports and male athletes is even higher. Comparing the income of former female athletes with male non-athletes, we find that the participation in elite sports closes the gender-wage gap. Our results are robust to variations in the specification and statistically as well economically significant.
C49|Hedging Strategy Using Copula and Nonparametric Methods: Evidence from China Securities Index Futures|Calculating accurately the optimal hedge ratio plays an important role in the futures market for both practitioners and academicians. In this paper, we combine copula and nonparametric technique, where marginal setting is modeled by nonparametric technique and bivariate is linked by dynamic Patton (2006)'s SJC copula function, to estimate the parameters of optimal hedge ratio. Various types of GARCH models to fit the marginal distribution are also compared. Furthermore, model specification for marginal setting is investigated by Hong and Li (2005)'s statistics, which test the i.i.d. and U(0,1) simultaneously. The empirical results show that transformed residuals generated by nonparametric technique are i.i.d. U(0,1), while most of one generated by popular GARCH-type are not. For hedging effectiveness, our methods perform better than traditional copula-GARCH models. The robust test also supports the results .
C49|Frontier estimation in nonparametric location-scale models|Conditional efficiency captures efficiency of firms facing heterogeneous environmental conditions. Traditional approaches estimate nonparametrically conditional distribution requiring smoothing techniques. We rather use a flexible nonparametric location-scale model to eliminate the dependence of inputs/outputs on these factors. These “pre-whitened” inputs/outputs define the optimal frontier function and a “pure” measure of efficiency more reliable to produce rankings, since the influence of external factors has been eliminated. Both full and order-m frontiers are used. The asymptotic properties are established. We can also derive the frontiers in the original units with their asymptotic properties. The approach is illustrated with some simulated and real data.
C49|Fuzzy Evaluation Of Service Quality In The Banking Sector: A Decision Support System|This study aims at proposing a modified 7-category fuzzy SERVQUAL to measure service quality for the banking sector. We have added new categories to the conventional SERVQUAL to account for the impacts of the bank’s Corporate Social Responsibility (CSR) initiatives, and e-banking. A questionnaire was distributed among the banks’ customers to measure the criteria’s weights, perceived performance and expected performance. We use the criteria weights, perceived performance and expected performance to test the proposed index for three of the largest Iran’s banks, namely: Bank Melli Iran, Bank Mellat and Bank Saderat Iran which henceforth will be referred to as banks A, B, C throughout the study. A simple Decision Support System (DSS) was devised to determine the most successful bank with regard to CS using Gap model. The result of this study showed that Bank B has the lowest weighted performanceexpectation gap (-0.051) among the three banks. It also has the highest average performance score in all dimensions and rank the best on 22 out of 30 criteria. Finally, sensitivity analyses are conducted to assess the impact of criteria weights and fuzzy numbers on the evaluation/ranking process. The resultant index helps managers in micro, meso and macro levels to detect the frailty zones and atone for the dissatisfying functions.
C49|Quake'n and Shake'n...Forever! Long-Run Effects of Natural Disasters: A Case Study on the 1970 Ancash Earthquake|This study estimates the effects of the 1970 Ancash earthquake on human capital accumulation on the affected and subsequent generation, 37 years after the shock, using the Peruvian censuses of 1993 and 2007. The main finding is that males affected by the earthquake in utero completed on average 0. 5 years less schooling while females affected by the earthquake completed 0. 8 years less schooling. Surprisingly, those whose mothers were affected at birth by the earthquake have 0. 4 less years of education, while those whose fathers were affected by the earthquake at birth have no effects on their education. The evaluation of other outcomes also suggests that the level of welfare of the affected individuals has been negatively impacted in the long run. The present investigation supports previous literature on shocks in early childhood, providing evidence of the existence of intergenerational transmission of shocks.
C49|From the glass door to the glass ceiling: An analysis of the gender wage gap by age groups|Using 2009 EU-SILC data for France, Italy, the Netherlands and the United Kingdom, we decompose the gender wage gap for prime age workers. We adopt an age group approach to identify when and how the glass door and the glass ceiling effects arise and their persistency over time. The empirical results verify that the raw gender wage gap increases with age. In all considered countries, the glass ceiling effect is completely realized by the age of 30 and increases over time. French, Italian and British women have also to cope with the glass door as they enter the labor market.
C49|Predictions vs. Preliminary Sample Estimates: The Case of Eurozone Quarterly GDP|Economic agents are aware of incurring a loss in basing their decisions on their own extrapolations instead of on sound statistical data, but this loss may be smaller than the one related to waiting for the dissemination of the final data. Broad guidelines on deciding when statistical offices should release preliminary and final estimates of the key statistics may come from comparing the loss attached to users’ predictions with the loss associated to possible preliminary estimates from incomplete samples. Furthermore, the cost of delaying decisions may support the dissemination of very early estimates of economic indicators, even if their accuracy is not fully satisfactory from a strict statistical viewpoint. Analysing the vintages of releases of quarterly Euro area GDP supports the view that even very inefficient predictions may beat some official preliminary releases of GDP, suggesting that the current calendar of data dissemination requires some adjustment. In particular, actual “flash” estimates could be anticipated, while some later intermediate releases are likely less informative for the users.
C49|Does evidence challenge the DSGE model|DSGE are for a time the favorite models in the simulation of monetary policies at the central banks. Two of its basic assumptions are discussed in this paper: (a) the absence of endogenous nonlinearities and the exogenous nature of shocks and (b) the persistence of or the return to equilibrium after a shock, or the absence of dynamics. Our analysis of complex financial markets, using historical data of S&P500, suggests otherwise that financial regimes endogenously change and that equilibrium is an artifact.
C49|Political legislation cycle in the Czech Republic|Politicians’ efforts to stay in office may lead to the occurrence of political cycles in legislation activity. The aim of this article is to analyze the political legislation cycles in a post-socialist economy of a young democracy, namely in the Czech Republic. Our estimation of the relationship between the number of approved laws and various explanatory variables suggests that the timing of elections has an impact on legislation activity. As an electoral term matures and upcoming elections approach, an increase is observed in legislation activity through which an incumbent government seeks to maximize its chances of re-election. Copyright Springer Science+Business Media New York 2014
C49|Spatial Patterns and Size Distributions of Cities|City size distributions are known to be well approximated by power laws across many countries. One popular explanation for such power-law regularities is in terms of random growth processes, where power laws arise asymptotically from the assumption of iid growth rates among all cities within a given country. But this assumption has additional consequences. Since all subsets of cities have the same statistical properties, each subset must exhibit essentially the same power law. Moreover, this common power law (CPL) property must hold regardless of the spatial relations among cities. Using data from the US, this paper shows first that spatial partitions of cities based on geographical proximity are significantly more consistent with the CPL property than are random partitions. It is then shown that this significance becomes even stronger when proximity among cities is measured in terms of trade linkages rather than simple geographical distance. These results provide compelling evidence that spatial relations between cities do indeed matter for city-size distributions. Further analysis shows that these results hinge on the natural “spacing out” property of city patterns in which larger cities tend to be widely spaced apart with smaller cities organized around them.
C49|The application of ensemble methods in forecasting bankruptcy|In practice, one chosen method is generally used to solve classification tasks. Although the most modern procedures yield excellent accuracy rates, international research findings show that a concurrent (ensemble) application of methods with weaker classification performance achieves comparable rates of high accuracy. This article’s main objective is to compare the predictive power of the two ensemble methods (Adaboost and Bagging) most commonly used in bankruptcy prediction, using a sample consisting of 976 Hungarian corporations. The article’s other objective is to compare the accuracy rates of bankruptcy models built on the deviations in specific financial ratios from industry averages to those of models built on financial ratios and variables factoring in their dynamics.
C49|The Co-Movement and Causality between the U.S. Real Estate and Stock Markets in the Time and Frequency Domains|This study applies wavelet analysis to examine the relationship between the U.S. real estate and stock markets over the period 1890-2012. Wavelet analysis allows the simultaneous examination of co-movement and causality between the two markets in both the time and frequency domains. Our findings provide robust evidence that co-movement and causality vary across frequencies and evolve with time. Examining market co-movement in the time domain, the two markets exhibit positive co-movement over recent past decades, exception for 1998-2002 when a high negative co-movement emerged. In the frequency domain, the two markets correlate with each other mainly at low frequencies (longer term), except in the second half of the 1900s as well as in 1998-2002, when the two markets correlate at high frequencies (shorter term). In addition, we find that the causal effects between the markets in the frequency domain occur generally at low frequencies (longer term). In the time-domain, the time-varying nature of long-run causalities implies structural changes in the two markets. These findings provide a more complete picture of the relationship between the U.S. real estate and stock markets over time and frequency, offering important implications for policymakers and practitioners.
C49|The Effects of Path Dependence and Economy of Scale in Russian Legislature|The paper presents the results of the regular monitoring of the legislative process in the Russian Federation, which is carried out at the Institute of Economics, RAS since 2008. An original database of Russian federal (federal constitutional) laws’ attributes ‘LAWSTREAM.RU’ (open access www.inecon.ru & www.kirdina.ru) is used. The database is formed on the basis of two open sources: the official website of the State Duma of the Federal Assembly of the Russian Federation and the online version of the legal system ‘ConsultantPlus’. It covers the period from 1994 to 2014. The average term from initiating a bill to its enactment, the type of activities that laws regulate, the structure of actors who initiated laws, the ratio of new laws and amendments to existing legislation are analyzed. Increasing returns and path dependence effects in the legislative sphere of modern Russia are presented.
C49|A probabilistic modeling approach to the detection of industrial agglomerations|Dating from the seminal work of Ellison and Glaeser in 1997, a wealth of evidence for the ubiquity of industrial agglomerations has been published. However, most of these results are based on analyses of single (scalar) indices of agglomeration. Hence, it is not surprising that industries deemed to be similar by such indices can often exhibit very different patterns of agglomeration—with respect to the number, size and spatial extent of individual agglomerations. The purpose of this article is thus to propose a more detailed spatial analysis of agglomeration in terms of multiple-cluster patterns, where each cluster represents a (roughly) convex set of contiguous regions within which the density of establishments is relatively uniform. The key idea is to develop a simple probability model of multiple clusters, called cluster schemes, and then to seek a ‘best’ cluster scheme for each industry by employing a standard model-selection criterion. Our ultimate objective is to provide a richer characterization of spatial agglomeration patterns that will allow more meaningful comparisons of these patterns across industries.
C49|A Comparison Between Direct and Indirect Seasonal Adjustment of the Chilean GDP 1986–2009 with X-12-ARIMA|Abstract It is well known among practitioners that the seasonal adjustment applied to economic time series involves several decisions to be made by the econometrician. As such, it would always be desirable to have an informed opinion on the risks taken by each of those decisions. In this paper, I assess which disaggregation strategy delivers the best results for the case of the Chilean 1986–2009 GDP quarterly dataset (base year: 2003). This is done by performing an aggregate-by-disaggregate analysis under different schemes, as the fixed base year dataset allows this fair comparison. The analysis is based on seasonal adjustment diagnostics contained in the X-12-ARIMA program plus some statistical tests for robustness. This exercise is relevant for conjunctural economic assessment, as it concerns signal extraction from seasonal, noisy series, direction of change detection, and econometric applications based on reliable and accurate unobserved variables. The results show that it is preferable, in terms of stability, to use the first block of supply-side disaggregation, while demand-side disaggregation tends to be less reliable. This result carries important implications for policymakers aiming to evaluate its short-term effectiveness in both households and firms.
C49|R&D investment, productivity and rates of return: A meta-analysis of the evidence on OECD firms and industries|The volume of work on productivity effects of research and development (R&D) investment has expanded significantly following the contributions of Zvi Griliches and others to microeconometric work in late 1970s and early 1980s. This study aims to meta-analyse the research findings based on OECD firm and industry data, with a view to establish where the balance of the evidence lies and what factors may explain the variation in reported evidence. Drawing on 1,262 estimates from 64 primary studies, we report that the average effect of R&D capital on productivity and the average rate of return on R&D investment are both positive, but smaller than the summary measures reported in previous narrative reviews and meta-analysis studies. We also report that a range of moderating factors have significant effects on the variation among productivity and rates-of-return estimates reported in primary studies. Moderating factors with significant effects include: (i) measurement of inputs and output; (ii) model specifications; (iii) estimation methods; (iv) levels of analysis; (v) countries covered; and (vi) publication type among others.
C49|A finite mixture latent trajectory model for hirings and separations in the labor market|We propose a finite mixture latent trajectory model to study the behavior of firms in terms of open-ended employment contracts that are activated and terminated during a certain period. The model is based on the assumption that the population of firms is composed by unobservable clusters (or latent classes) with a homogeneous time trend in the number of hirings and separations. Our proposal also accounts for the presence of informative drop-out due to the exit of a firm from the market. Parameter estimation is based on the maximum likelihood method, which is efficiently performed through an EM algorithm. The model is applied to data coming from the Compulsory Communication dataset of the local labor office of the province of Perugia (Italy) for the period 2009-2012. The application reveals the presence of six latent classes of firms.
C49|Simulating Bivariate Stationary Processes with Scale-Specific Characteristics|By modifying and generalizing the wavelet-based approach of approximately simulating univariate long-memory processes that is available in the literature, we propose a methodology for simulating a bivariate stationary process, whose components exhibit different relationships at different scales. We derive the formulas for the autocovariance and cross-covariance sequences of the simulated bivariate process. We provide a setting for the parameters of the simulation which might generate a bivariate time series resembling that of stock log returns. Using this setting, we study the properties of our methodology via Monte Carlo simulation.
C49|Analysis of Europe 2020 Indicators Using Regression Analysis|Europe 2020 is a set of eight indicators used by the European Commission for monitoring headline targets of the Strategy for Smart, Sustainable and Inclusive Growth, which is considered to be the successor of the Lisbon Strategy. Values of these indicators vary among the European countries. Because some countries can be identified as outliers, robust regression as an acceptable analytic tool was applied. The aim of the paper is to construct relevant regression models for each Europe 2020 indicator as a dependent variable. The targets of the Europe 2020 indicators can be achieved by targeting some specific economic, social and environmental indicators.
C49|Additive Decomposition and Boundary Conditions in Wavelet-Based Forecasting Approaches|An interesting approach to economic and financial time series forecasting consists of decomposing an input time series additively into several components, each component capturing the dynamics of a different frequency range. Consequently, each component is modelled and forecasted separately, the predictions being summed up to form an overall forecast of the input time series. The present paper considers one very important aspect of the forecasting procedure. More specifically, it provides a better understanding of how an additive decomposition of the input time series into several components can be obtained using the wavelet transform and how boundary conditions in the individual components should be properly treated. Even though these aspects are presented as a part of the wavelet theory in several books on wavelets, their implementation is prone to misinterpretations in the literature on applied time series forecasting, possibly due to the complexity of the wavelet transform. Since our exposition is focused predominantly on these aspects, it provides a concise explanation which may be helpful to practitioners. The maximal overlap discrete wavelet transform is employed, other types of wavelet transforms also being briefly discussed.
C49|Autocorrelation in the global stochastic trend|Korhonen and Peresetsky (2013) suggested a new Kalman-filter type model of financial markets to extract a global stochastic trend from discrete non-synchronous data on daily stock market index returns from different markets. We extend this model to allow the correlation between increments of this global trend on neighbor intervals. Existence of that non-zero correlation is demonstrated. However it does not mean that it helps forecast daily returns of the stock indices itself, since the global stochastic trend is unobservable. Forecasting performance of the model with three stock markets is explored.
C49|The Effects of Elite Sports on Later Job Success|This paper analyses the income effect of the participation in elite sports. To quantify the average difference in the monthly net income of former elite athletes and non-athletes we estimate sample average treatment effect scores (SATT) by using covariate nearest-neighbour matching (CVM). While our treatment group consists of formerly funded top-level athletes, the control group of non-athletes is drawn from the SOEP database. Matching takes place by socio-demographic variables as well as measures of personal qualities and attitudes. On average, former athletes receive higher incomes than similar non-athletes. The income premium for former team sports and male athletes is even higher. Comparing the income of former female athletes with male non-athletes, we find that the participation in elite sports closes the gender-wage gap. Our results are robust to variations in the specification and statistically as well economically significant.
C49|Эффекты path dependence и экономии от масштаба в российском законотворчестве<BR>[The effects of path dependence and economies of scale in the Russian lawmaking]|В статье представлены результаты очередного этапа мониторинга законодательного процесса в Российской Федерации, который производится в Институте экономики РАН с 2008 г. Для мониторинга используется оригинальная база данных атрибутики федеральных (федеральных конституционных) законов Российской Федерации LAWSTREAM.RU, выложенная в открытом доступе (www.inecon.org и www.kirdina.ru). База сформирована на основе 2-х открытых источников: официального сайта Государственной Думы РФ и интернет-верссии справочной правовой системы КонсультантПлюс, охватывает период с 1994 по 2014 г. Анализируются сроки принятия законов; охват сфер регулирования; структура инициаторов внесения законов; соотношение новых законов и поправок в действующее законодательство. Продемонстрированы эффекты возрастающей отдачи и зависимости от предшествующего развития в законодательной сфере современной российской власти.
C49|The use of quantitative methods in managing the process of creation a competitive advantage in the industrial region|Building the region which will be characterized by high industrialism and competitiveness requires an examination of its production capabilities. It is important to know the close environment, which will determine the suppliers and the society. This will allow to learn about the culture and preferences of the local community in terms of education and practical skills. Close environment is also approximately industrial businesses, its characteristics indicate both a glut and a shortage of organizations and businesses in terms of local government institutions as well as financial or service e.g. in the field of logistics services, improving the industry functioning. Such knowledge enables for building a strong local and regional industry.The most suitable methods used for this type of activity are quantitative methods. This article will describe the practical use of index method as a way to explore the potential of the region. Acquiring information in this area, allows for creation a strong economy industrially oriented, for the purpose of stabilizing its competitive position considered in national and global way.
C49|Claims reserving with HGLM|We consider the problem of estimating IBNR (Incurred But Not Reported) loss reserves in non-life insurance. The literature proposes a wide variety of methods to estimate IBNR reserves, mostly based on the chain-ladder approach (Mack, 1993). In this paper we focus on two methods, in which unobservable risk parameters U=(U1,...,Uk)' are taken into account. Firstly, we propose HGLM model based in GLM loss reserving (Wüthrich and Mertz, 2008), where conditional inceremental payments (resonse variables) taken form loss triangle follow the distribution of an exponential dispersion family. Secondly, we modify the CapeCode method which uses the grow curve modelling (Clark, 2003). This method is based on two-stage estimation of the expected amount of loss to emerge: the estimation of the ultimate loss by year and the estimation of the pattern of loss emergence. As the pattern of loss to emerge, log-logistic and Weilbull growth curves are assumed. We imply another form of the growth curve and we add random effect yield the hierarchical model like in (Guszcza, 2008). Treating the ultimate losses in accident years as repeated measurements allows us to model parameters that determine the pattern of loss emergence in separately sub-models.
C49|The predictive power of yield spread: evidence from wavelet analysis|This paper examines whether the spread between long- and short-terminterest rates contains information about future economic activity in India. Using the yields on securities with maturities ranging from three months to ten years, we construct five different yield spreads at shorter end, longer end, and policy relevant area of the yield curve. We study the predictive power of each of these spreads for output growth within aggregate and time scale framework using wavelet methodology. We find that predictive power holds only at lower frequencies for the spreads which are constructed at shorter end and policy relevant areas of yield curve. However, spreads which are constructed at the longer end of the yield curve do not seem to have predictive information for output growth. Copyright Springer-Verlag Berlin Heidelberg 2014
C49|Mjerenje međuzavisnosti poslovnih ciklusa i ekonomskoga rasta u Hrvatskoj primjenom spektralne analize|U ovome su radu po prvi puta analizirani ciklusi i ekonomski rast primjenom metode spektralne analize u razdoblju od 1991. - 2013. godine. Metode spektralne analize pokazale su se izuzetno primjenjivima u uvjetima šokova, kratkih serija i strukturnih lomova u serijama. U radu je također primijenjena metoda spektralne Granger uzročnosti. Primjenom spektralne analize dokazana je endogenost poslovnih ciklusa i ekonomskoga rasta u Hrvatskoj. Poslovni ciklusi i ekonomski rast u Hrvatskoj su jedna pojava – dvije strane iste medalje. Poslovni ciklusi Granger uzrokuju ekonomski rast dok povratna veza nije dokazana. Također je dokazano postojanje histerije rasta u hrvatskome gospodarstvu – šokovi u agregatnoj potražnji nisu privremeni već imaju trajne i nepovratne poslje dice u hrvatskoj ekonomiji. Fiskalna politika ima veliki udio u šokovima, a novac nije neutralan u dugome roku, čime se iziskuje cjelovito preispitivanje primjene fiskalne i monetarne politike u hrvatskome gospodarstvu. U Hrvatskoj je potrebno uvesti jedinstveni pristup izučavanju ciklusa i rasta kako bi se konačno dao odgovor na pitanja koja je uloga monetarne i fiskalne politike u Hrvatskoj i kakva bi ona trebala biti.
C49|Extracting global stochastic trend from non-synchronous data|"We use a Kalman filter type model of financial markets to extract a global stochastic trend from the discrete non-synchronous data on daily stock market index returns of different stock exchanges. The model is tested for robustness. In addition, we derive ""most important"" hours of world financial market and estimate the relative importance of local versus global news for different stock markets. The model generates results that are consistent with intuition. Key words: emerging stock markets, transition economies, financial market integration, stock market returns, global stochastic trend, state space model, Kalman filter, non-synchronous data. JEL codes: C49, C58, G10, G15, F36, F65"
C49|Is Europe growing together or growing apart?|While it is painfully clear that the 'ever closer' monetary and financial union in the EU has run into serious trouble there has been very little study of the degree to which the countries have become similar or different in their economic growth dynamics. This paper therefore goes beyond the traditional convergence literature to look at their dynamic convergence and explore the path of their changing similarity in the frequency domain. The results show that while a core group of countries may be developing together, there appears to be at least seven identifiable groups of countries with different growth dynamics. Greece appears to be in a class on its own. Business cycles are important but longer-term trends and higher frequency fluctuations all have a role to play in facilitating adjustment. These results provide awkward implications for policy, particularly for those who thought that simply having a union would draw countries closer together (endogenous OCA criteria). Keywords: Business cycles, growth cycles, frequency domain, wavelet analysis, cluster analysis, euro area, European Union, optimal currency area JEL Classification: C49, E32
C49|Limitele Informaționale Ale Situațiilor Financiare În România|Raportarea financiară are un rol semnificativ pentru mediul de afaceri, oferind informații relevante despre activitatea desfășurată într-o anumită perioadă de timp de către entitățile economice care constituie un punct de plecare în stabilirea strategiilor. Analiza detaliată a conținutului acestora permite desprinderea detaliilor ce pot favoriza corecta direcționare a activității spre creștere și dezvoltare, iar prognozele realizate având la bază un istoric economico-financiar reduc gradul de incertitudine în realizarea activității economice și scot în evidență elementele de impact atât la nivel micro, cât și la nivel macroeconomic. Din cauza scandalurilor profesionale din domeniu, dar și a condițiilor economice dificile, precum și a implicațiilor directe ale persoanelor interesate în manipularea informațiilor economico-financiare, limitele informaționale ale situațiilor financiare în cadrul societăților din România defavorizează utilitatea acestora în procesul de conducere și luare a deciziilor. Efectele negative sunt semnificative, dezavantajând atât dezvoltarea internă a întreprinderilor, cât și dezvoltarea economică la nivel național.
C49|Imputación de ingresos en la Gran Encuesta Integrada de Hogares (GEIH) de 2010|Este trabajo presenta el problema del manejo de encuestas con datos faltantes, y para hacerle frente reseña una técnica conocida como imputación. Además se implementan algunas metodologías en la imputación de los ingresos y las ganancias de la Gran Encuesta Integrada de Hogares de Colombia de 2010. En ese sentido se evaluaron siete métodos para el total de la muestra y por grupos de estratos de la vivienda: la eliminación del caso, la imputación por media no condicionada, imputación por regresión estocástica, el hot-deck, el hot-deck con regresión, la imputación múltiple normal multivariada y la imputación múltiple con ecuaciones encadenadas. Se concluye que al no contar con porcentajes altos de no respuesta y dado que es posible que los datos faltantes sigan un patrón que pueda ignorarse, los resultados de los métodos aplicados son relativamente similares.
C49|Indicadores Del Capital Intelectual En El Área De Ingenierías De Una Universidad|El Capital Intelectual permite valorar y potencializar el conocimiento, los procedimientos institucionales y la productividad. Dicha valoración proporciona información para tomar decisiones en la búsqueda de mejoramiento de la competitividad. Este artículo presenta la medición del Capital Intelectual para el rea de Ingenierías de una Universidad y sus componentes: Capital Humano, Estructural, y Relacional, con un procedimiento basado en modelos de regresión Poisson y Análisis del Factor para encontrar los indicadores que cuantifican resultados asociados con cada tipo de Capital y con las actividades de docencia, investigación y extensión. El resultado refleja una fuerte asociación del Capital Humano con el Capital Intelectual, así como la influencia que estos reciben de productos como publicaciones de artículos y libros. Estos hallazgos permitirán a la Universidad identificar los posicionamientos de las sub-áreas de Ingenierías por tipo de Capital.
C49|The Properties of ATMs Development Stages - an Empirical Analysis|This paper addresses the crucial problem of the ATM’s network management which is so-called the saturation level of withdrawals. This notion refers to mean level of withdrawals after dropping particular withdrawals realized in the initial time period, (i.e. time period after activation of ATM) and the length of elapsing time period necessary to reach saturation level. One can observe that the level of withdrawals and their number stabilize as time elapses. The paper aims to define average withdrawals after achieving saturation level and mean time necessary to stabilize withdrawals (based on historical data). In addition, we established that – under condition of similarity in terms of location and date of start - ATMs exhibit similar characteristics of the development effects. This allows us for predicting the size of time necessary to achieve saturation and the average withdrawal in the state of saturation.
C49|Asset Market Linkages in Crisis Periods| We characterize asset return linkages during periods of stress by an extremal dependence measure. Contrary to correlation analysis, this nonparametric measure is not predisposed toward the normal distribution and can allow for nonlinear relationships. Our estimates for the G-5 countries suggest that simultaneous crashes between stock markets are much more likely than between bond markets. However, for the assessment of financial system stability the widely disregarded cross-asset perspective is particularly important. For example, our data show that stock-bond contagion is approximately as frequent as flight to quality from stocks into bonds. Extreme cross-border linkages are surprisingly similar to national linkages, illustrating a potential downside to international financial integration. 2004 President and Fellows of Harvard College and the Massachusetts Institute of Technology.
C49|Oil prices and the macroeconomy reconsideration for Germany: Using continuous wavelet|The cross wavelet analysis is used in the study to decompose the time–frequency effects of oil price changes on the German macroeconomy. We argue that the relationship between oil prices and industrial production is ambiguous. Our results show that there are both phase and anti-phase relationships between oil price returns and inflation and in most of the cases inflation is the leading variable. Additional evidence shows that there is a huge inconsistency between the phase-difference of the return series of oil price and industrial production at the 12–16month frequency bands but at the 16–24month frequency bands, we find that oil price changes that have occurred during 1982–2009 were demand-driven. In a nutshell our results suggest that oil price changes that have occurred after 1994 were demand-driven and the volatility of the inflation rate started to decrease after the 1990s but the volatility of the industrial output growth rate started to decrease after the 2000s.
C49|A mechanism for eliciting the mean and quantiles of a random variable|We present two Becker–DeGroot–Marschak type incentive compatible elicitation mechanisms. The first can be used to elicit an agent’s belief about the mean of a random variable while the second elicits the quantiles.
C49|Scale-specific importance of weather variables for explanation of variations of electricity consumption: The case of Prague, Czech Republic|In this paper we explore the relative importance of the outside temperature and sunshine duration for the explanation of variations of electricity consumption in Prague, Czech Republic. An assessment of relative importance is made on various time scales ranging from the shortest ones associated with abrupt changes up to those associated with medium-run changes. Wavelet analysis is used to accomplish this task. We show that relative importance is scale-specific, i.e. depends on the analyzed time scale. Sunshine duration is generally the more important explanatory variable on the shortest time scales and the outside temperature dominates on higher time scales. The reason for the outside temperature being an inferior explanatory variable on the shortest time scales is a low variability of the outside temperature on these time scales and a dampened reaction of electricity consumption to abrupt changes in the outside temperature. Our results show that sunshine duration should be considered relevant when modeling electricity consumption.
C49|Assessing the profitability of intraday opening range breakout strategies|Is it possible to beat the market by mechanical trading rules based on historical and publicly known information? Such rules have long been used by investors and in this paper, we test the success rate of trades and profitability of the Open Range Breakout (ORB) strategy. An investor that trades on the ORB strategy seeks to identify large intraday price movements and trades only when the price moves beyond some predetermined threshold. We present an ORB strategy based on normally distributed returns to identify such days and find that our ORB trading strategy result in significantly higher returns than zero as well as an increased success rate in relation to a fair game. The characteristics of such an approach over conventional statistical tests is that it involves the joint distribution of low, high, open and close over a given time horizon.
C49|Systemic risk and diversification across European banks and insurers|The mutual and cross company exposures to fat-tail distributed risks determine the potential impact of a financial crisis on banks and insurers. We examine the systemic interdependencies within and across the European banking and insurance sectors during times of stress by means of extreme value analysis. While insurers exhibit a slightly higher interdependency in comparison with banks, the interdependency across the two sectors turns out to be considerably lower. This suggests that downside risk can be lowered through financial conglomeration.
C49|Long-term asset tail risks in developed and emerging markets|A power law typically governs the tail decay of financial returns but the constancy of the so-called tail index which dictates the tail decay remains relatively unexplored. We study the finite sample properties of some recently proposed endogenous tests for structural change in the tail index. Given that the finite sample critical values strongly depend on the tail parameters of the return distribution we propose a bootstrap-based version of the structural change test. Our empirical application spans developed and emerging financial asset returns. Somewhat surprisingly, emerging stock market tails are not more inclined to structural change than their developed counterparts. Emerging currency tails, on the contrary, do exhibit structural shifts in contrast to developed currencies. Our results suggest that extreme value theory (EVT) applications in hedging tail risks can assume stationary tail behavior over long time spans provided one considers portfolios that solely consist of stocks or bonds.
C49|Statistical Equilibrium Models for Sparse Economic Networks|Real markets can be naturally represented as networks, and they share with other social networks the fundamental property of sparsity, whereby agents are connected by l = O (n) relationships. The exponential networks model introduced by Park and Newman can be extended in order to deal with this property. When compared with alternative statistical models of a given real network, this extended model provides a better statistical justification for the observed network values. Consequently, it provides more reliable maximum entropy estimates of partially known networks than previously known ME techniques.
C49|Day trading returns across volatility states|This paper measures the returns of a popular day trading strategy, the Opening Range Breakout strategy (ORB), across volatility states. We calculate the average daily returns of the ORB strategy for each volatility state of the underlying asset when applied on long time series of crude oil and S&P 500 futures contracts. We find an average difference in returns between the highest and the lowest volatility state of around 200 basis points per day for crude oil, and of around 150 basis points per day for the S&P 500. This finding suggests that the success in day trading can depend to a large extent on the volatility of the underlying asset.
C49|Does Part-Time Employment Widen the Gender Wage Gap? Evidence from Twelve European Countries|One of five workers work part-time in Europe, mainly women. This article examines the extent to which the overrepresentation of women in part-time employment explains the gender hourly earnings gap in twelve European countries. Using the EU-SILC 2009 data, a double decomposition of the gender wage gap is implemented: between men and women employed full-time and between full-time and part-time working women. The high prevalence of part-time employment plays only a minor role. The nature of part-time employment and labor market segregation are much more important factors. A large share of the gender wage gap still remains unexplained, however.
C49|Boylamsal Verilerde Cok Duzeyli Analizler: Dil Gelisimine Ýliskin Bir Uygulama|There are various methods and scales used for determining the deviations of the baby growth. A scale has been applied to 40 babies in the 12, 24 and 36 month periods and language development has been explained by the period of breast feeding without any additional food, social-emotional development during these periods and fine motor development variables. As a sub-model the period of breast feeding without any additional food has been explained by the gender of the baby, the educational status of the mother during birth and the birth weight of the baby. Furthermore other sub-models, the social-emotional development of the baby has been interpreted by the educational status and the age of the mother during birth variables, fine motor development of the baby has been explained by the baby's gender, mother's educational status, baby's birth height and weight variables. Multilevel analysis has been applied to these data which have longitudinal structure.
C49|Privacy and Data-Based Research|What can we, as users of microdata, formally guarantee to the individuals (or firms) in our dataset, regarding their privacy? We retell a few stories, well-known in data-privacy circles, of failed anonymization attempts in publicly released datasets. We then provide a mostly informal introduction to several ideas from the literature on differential privacy, an active literature in computer science that studies formal approaches to preserving the privacy of individuals in statistical databases. We apply some of its insights to situations routinely faced by applied economists, emphasizing big-data contexts.
C49|Development of the overconfidence measurement instrument for the economic experiment|In this article results of the two experiments, aimed at the development of the instrument (test) that would enable construction of the comprehensive measure of individual overconfidence for the use in economic overconfidence experiments, are presented. Instrument was obtained in a two-stage procedure. In the first experimental phase, a pilot test, consisting of fifty general-knowledge questions of the unknown difficulty, was conducted to divide the items into three difficulty levels: hard, average-difficulty and easy questions. The second phase was aimed at verification of the replicability of results. Statistical tests supported the existence of the hard-easy effect, verified the success of categorization of questions into three levels of difficulty, and showed that gender was not associated with overconfidence in the developed instrument. The average group overconfidence measures obtained from both experimental phases did not differ from each other significantly. Instrument’s internal consistency was found to be good and acceptable for the use in social research. Compared to the tests used in the foregoing economic experiments, the obtained test is believed to result in the improvement of the overconfidence measurement quality.
C49|Decoding Entropy|Since its evolution, the concept of Entropy has been applied in various fields like Computer Science, Quantitative Finance, Physics etc. The definition of Entropy has slightly different meanings depending on the field of science to which it is being applied. This paper aims to examine the concept of Entropy and its application in Credit Risk Model Development and Validation.
C49|Small & Medium Enterprise Assessment in Czech Republic & Russia Using Marketing Analytics Methodology|This paper aims to focus on the determinants influencing the internationalization of small and medium-sized enterprises (SMEs) in Czech Republic and Russia. The objective is to investigate and evaluate the business environment and, then, examine the importance of developing and promoting entrepreneurship to allow SMEs in Czech & Russia to develop a competitive position in the international marketplace. An overview of the current economic situation facing SMEs in CZ & RU is provided. Then the factors necessary for the expansion of the business will be discussed, along with the challenges of overcoming the resource gaps to be identified. We have conducted empirical surveys along with the use of SPSS statistical tools to predict the potential of revenue growth in SME sector. Information is provided concerning the current situation for SMEs in CZ & RU and the challenges encountered as they face a business environment that is becoming more competitive. We also found that SMEs are increasingly more integrated into the global economy and not limited to regional/international activities. Quantitative analysis shows that there is significant potential for SMEs for the next couple of years despite the economic uncertainty. This paper integrates entrepreneurship, and the resource-based internationalization of SMEs in Czech Republic & Russia, specifically focusing on the use of technology.
C49|Evolution of Monetary Policy Transmission Mechanism in Malawi: A TVP-VAR with Stochastic Volatility Approach|This paper investigates the evolution of monetary transmission mechanism in Malawi between 1981 and 2010 using a time varying parameter vector autoregressive (TVP-VAR) model with stochastic volatility. We evaluate how the responses of real output and general price level to bank rate, exchange rate and credit shocks have changed over time since Malawi adopted financial reforms in 1980s. The paper finds that inflation, real output and exchange rate responses to monetary policy shocks changed over the period under review. Importantly, beginning mid-2000, the monetary policy transmission performed consistently with predictions of economic theory and there is no evidence of a price puzzle as found in the previous literature on Malawi. However, the statistical significance of the private credit supply remains weak and this calls for more financial reforms targeting the credit market which can contribute to monetary transmission and promote further economic growth in Malawi.
C49|Illuminate the unknown: evaluation of imputation procedures based on the SAVE survey|Questions about monetary variables (such as income, wealth or savings) are key components of questionnaires on household finances. However, missing information on such sensitive topics is a well-known phenomenon which can seriously bias any inference based only on complete-case analysis. Many imputation techniques have been developed and implemented in several surveys. Using the German SAVE data, a new estimation technique is necessary to overcome the upward bias of monetary variables caused by the initially implemented imputation procedure. The upward bias is the result of adding random draws to the implausible negative values predicted by OLS regressions until all values are positive. To overcome this problem the logarithm of the dependent variable is taken and the predicted values are retransformed to the original scale by Duan’s smearing estimate. This paper evaluates the two different techniques for the imputation of monetary variables implementing a simulation study, where a random pattern of missingness is imposed on the observed values of the variables of interest. A Monte-Carlo simulation based on the observed data shows the superiority of the newly implemented smearing estimate to construct the missing data structure. All waves are consistently imputed using the new method. Copyright Springer-Verlag 2013
C49|Accounting for increased non-target-disease-specific mortality in decision-analytic screening models for economic evaluation|Some bias can occur when an increase in non-target-disease-specific mortality is not considered when modelling the outcomes of screening tests. Copyright Springer-Verlag Berlin Heidelberg 2013
C49|Null models of economic networks: the case of the world trade web|In all empirical-network studies, the observed properties of economic networks are informative only if compared with a well-defined null model that can quantitatively predict the behavior of such properties in constrained graphs. However, predictions of the available null-model methods can be derived analytically only under assumptions (e.g., sparseness of the network) that are unrealistic for most economic networks like the world trade web (WTW). In this paper we study the evolution of the WTW using a recently-proposed family of null network models. The method allows to analytically obtain the expected value of any network statistic across the ensemble of networks that preserve on average some local properties, and are otherwise fully random. We compare expected and observed properties of the WTW in the period 1950–2000, when either the expected number of trade partners or total country trade is kept fixed and equal to observed quantities. We show that, in the binary WTW, node-degree sequences are sufficient to explain higher-order network properties such as disassortativity and clustering-degree correlation, especially in the last part of the sample. Conversely, in the weighted WTW, the observed sequence of total country imports and exports are not sufficient to predict higher-order patterns of the WTW. We discuss some important implications of these findings for international-trade models. Copyright Springer-Verlag 2013
C49|Remittances and Dutch Disease: A Meta-Analysis|Remittance flows are an important source of foreign exchange for various developing countries around the world. Given their growing importance in the last decade, their role in inducing Dutch disease symptoms in the developing countries has been extensively studied. However, the results of the analyses so far have been mixed. In this study, we conduct a meta-analysis of existing literature to estimate the over all effect of remittances on receiving countries' real effective exchange rate (REER). We run fixed and random effect meta-analysis on studies taken from EconLit, Google Scholar and various working paper series and examine a total of 53 regressions taken from seven published and unpublished studies. We come up with evidence of a net appreciation of real exchange rate in the developing countries. Both the fixed and random effect models indicate a highly significant impact of foreign remittances on the REER. The results show also that the nature of the dependent variable, countries considered and the econometric technique used influence the impact of remittances REER, However the type of data (panel or times series) does not affect the results. Our investigations support the presence of selection bias. The findings support the view that in spite of their utility for the recipient households, remittances pose a challenge to the developing country on the macroeconomic level.
C49|The Dual Political Legislation Cycle in France|This paper tests the Political Legislation Cycle theory on French data. The theory predicts a peak of legislative production in the pre-electoral period, when the legislator increases voters’ utility in order to be reelected. France is unique in that two elections set up the pace of political life: the presidential and the legislative elections which potentially generate a dual legislation cycle. A hierarchical Poisson model is implemented on a sample containing the monthly legislative production from January 1959 to March 2012. We found that 1) a dual cycle of the production of laws emerges, following both the presidential and the legislative elections, 2) since the constitutional reform of 2000, which synchronized the two elections, the magnitude of the cycle increased, and 3) the President of the Republic does not have an impact on the legislative production, but relies on the government.
C49|The Co-Movement and Causality between the U.S. Real Estate and Stock Markets in the Time and Frequency Domains|This study applies wavelet analysis to examine the relationship between the U.S. real estate and stock markets over the period 1890-2012. Wavelet analysis allows the simultaneous examination of co-movement and causality between the two markets in both the time and frequency domains. Our findings provide robust evidence that co-movement and causality vary across frequencies and evolve with time. Examining market co-movement in the time domain, the two markets exhibit positive co-movement over recent past decades, exception for 1998-2002 when a high negative co-movement emerged. In the frequency domain, the two markets correlate with each other mainly at low frequencies (longer term), except in the second half of the 1900s as well as in 1998-2002, when the two markets correlate at high frequencies (shorter term). In addition, we find that the causal effects between the markets in the frequency domain occur generally at low frequencies (longer term). In the time-domain, the time-varying nature of long-run causalities implies structural changes in the two markets. These findings provide a more complete picture of the relationship between the U.S. real estate and stock markets over time and frequency, offering important implications for policymakers and practitioners.
C49|On the comparison of model-based clustering solutions|In this paper we propose a new similarity index, which can be used to compare model-based clustering solutions. We define also an adjusted-for-chance version, although we advise that, whenever feasible, bootstrap replications should be preferred to chance-corrected similarity indices. We describe the properties of the proposed index and of its chance-corrected version. Finally, we present some applications on simulated and real data.
C49|Finding communities in credit networks|In this paper the authors focus on credit connections as a potential source of systemic risk. In particular, they seek to answer the following question: how do we find densely connected subsets of nodes within a credit network? The question is relevant for policy, since these subsets are likely to channel any shock affecting the network. As it turns out, a reliable answer can be obtained with the aid of complex network theory. In particular, the authors show how it is possible to take advantage of the ''community detection'' network literature. The proposed answer entails two subsequent steps. Firstly, the authors verify the hypothesis that the network under study truly has communities. Secondly, they devise a reliable algorithm to find those communities. In order to be sure that a given algorithm works, they test it over a sample of random benchmark networks with known communities. To overcome the limitation of existing benchmarks, the authors introduce a new model and test alternative algorithms, obtaining very good results with an adapted spectral decomposition method. To illustrate this method they provide a community description of the Japanese bank-firm credit network, getting evidence of a strengthening of communities over time and finding support for the well-known Japanese main ''bank'' system. Thus, the authors find comfort both from simulations and from real data on the possibility to apply community detection methods to credit markets. They believe that this method can fruitfully complement the study of contagious defaults. Since network risk depends crucially on community structure, their results suggest that policy maker should identify systemically important communities, i.e. those able extend the initial shock to the entire system.
C49|Herramientas predictivas en política financiera para empresas rentables|El presente artículo es abordado desde la perspectiva estratégica en finanzas; el objetivo es mostrar el material técnico reciente sobre procedimientos/ prácticas de análisis financieros de predicción y su utilización en la gestión, así como entender en qué momento se da una estructura óptima de capital. Por tal razón se construye un soporte conceptual basado en la teoría del trade-off y el estudio de técnicas y herramientas que conduzcan a medir los resultados que se obtienen en un periodo de gestión. Se concluye que los autores, al hacer uso de la estadística, establecen patrones que caracterizan las organizaciones y que son tratados en el campo de la predicción y la descripción.
C49|On the endogeneity of the natural rate of growth|We discuss the case when the sum of the growth rate of productivity and that of the labour force is an increasing function f of the actual growth rate of income y. We show that a natural rate of growth is a solution of the equation y =f(y); hence its endogeneity to y requires the unlikely case that more than one solution exists, the shift within the set of solutions being determined by y. Léon-Ledesma and Thirlwall (2000a and b), attempting to investigate empirically the endogeneity of the natural rate, set up a procedure by which their OLS estimate of the natural rate produce two levels, the higher corresponding to the group of observations with higher y. But we prove their (widely replicated) procedure is seriously flawed, because an important variable is not statistically exogenous and most probably , according to our simulations, its coefficient is close to zero.
C49|The yield curve and the macro-economy across time and frequencies|We assess the relation between the yield curve and the macroeconomy in the U.S. between 1961 and 2011. We add to the standard parametric macro-finance models, as we uncover evidence simultaneously on the time and frequency domains. We model the shape of the yield curve by latent factors corresponding to its level, slope and curvature. The macroeconomic variables measure real activity, inflation and monetary policy. The tools of wavelet analysis, the set of variables and the length of the sample allow for a thorough appraisal of the time-variation in the direction, intensity, synchronization and periodicity of the yield curve–macroeconomy relation.
C49|The Euro/Dollar exchange rate: Chaotic or non-chaotic? A continuous time model with heterogeneous beliefs|The aim of this paper is to develop a continuous time exchange rate model that allows for heterogeneity of the agents' beliefs, in order to explore non-linearities and possible chaotic behaviour. The theoretical model contains an intrinsic non-linearity that gives rise to a jerk differential equation, which is in principle capable of generating chaos. The model is econometrically estimated in continuous time with Euro/Dollar data and examined for the possible presence of chaotic motion. Our results indicate that the possibility of chaotic dynamics in our model is rejected.
C49|A mechanism for eliciting a probability distribution|This work extends Karni’s direct revelation mechanism for eliciting agents’ subjective beliefs over the distribution of a random variable.
C49|Lifecycle effects on consumer financial product portfolios in South Africa: An exploratory analysis of four ethnic groups|This paper assesses ownership of 16 financial products by households in different lifecycle stages amongst four ethnic groups (Africans, Coloureds, Asians, and Whites) in South Africa. The lifecycle hypothesis indicates younger households should own more debt-related financial products, whereas households in intermediate lifecycle stages should own more financial products to accumulate assets; both these claims are disconfirmed for all groups. However, White households in intermediate household stages own more financial products than younger and older households, consistent with previously reported lifecycle findings in Western countries. Consistent with the literature on innovation adoption we find that younger, affluent and highly educated households amongst the other three ethnic groups tend to own more financial products than older Africans, Coloureds and Asians. These results indicate that innovation adoption literature may better describe financial product ownership in developing countries than the lifecycle hypothesis.
C49|The causal structure of bond yields|This paper implements an emerging data-driven method of directed acyclic graphs to study the contemporaneous causal structure among the federal funds rate and U.S. Treasury bond yields of various maturities. Using high frequency daily data from 1994 to 2009, we find that innovations in the two-year Treasury bond yield play a central role. They contemporaneously cause most other bond yields. Therefore, monetary policy makers would benefit from closely monitoring the two-year yield in setting the interest rate target, a result echoing the policy rule suggested by Piazzesi (Journal of Political Economy, 2005). Both Fed and investors should also watch the seven-year bond yield because it explains significant portions of variability in many other yields.
C49|Restructuring in privatised firms: A Statis approach|We analyse the dynamics and evolution of the corporate restructuring process in the Portuguese banking sector, where 10 banks were privatised during the period 1989–1996. We apply a novel methodological approach in this context, using a multidimensional measure of restructuring that links product and labour market variables. We find evidence of considerable heterogeneity in the restructuring process, where firms adjust at different speeds and intensities. We also find that the wage level is by far the firm attribute that changed more, which is shown to reflect substantial changes in terms of composition, and not size, of the workforce. Our empirical evidence also suggests that privatisation is associated with a higher level of rent sharing.
C49|Micro-geographies of clusters of creative industries in Europe|What makes special the geography of the clusters of creative industries (CI)? This paper considers the symbolic knowledge-base and the preference for location in urban spaces observed in those clusters. The study avoids classic research designs based on synthetic knowledge bases and regional-based administrative-constrained design, using instead micro-data (550,000 firms in creative industries) and geo-statistical algorithms. Results contribute to the economic geography by: (i) providing a specific observation of the spatial dimension (where) in the cluster theory; (ii) identifying and mapping the clusters of CI in Europe; (iii) exploring particular forms of agglomeration and co-location (urban and non-urban) followed by clusters of CI. Results present implications for scholars and policy-makers suggesting to stress the articulation of within and between-cluster policy strategies for existing clusters rather than fostering the generation of new clusters.
C49|Has the Financial Crisis Changed the Business Cycle Characteristics of the GIPSI Countries?| Since the financial crisis erupted in 2008, the governments of Portugal, Ireland, Italy Greece and Spain (GIPSI) find themselves in a position where financing their debts has become increasingly difficult. As a result, these governments reduced government expenditure and/or increased taxes in order to reduce their deficits. Hence, whilst other countries in the Eurozone – notably Germany - enjoy a recovery from the financial crisis, the GIPSI countries remain in recession. It is therefore no surprise that the business cycles of the northern and southern European countries have increasingly diverged. This in itself poses already a risk for the Eurozone, as it makes the common monetary policy less effective. In this paper we analyse these business cycles in detail. We ask whether the financial crisis has changed the characteristics of the business cycles of the GIPSI countries. For example, the austerity measures in Greece may lead to a convergence of government spending between Germany and Greece and to greater convergence of business cycles in both countries. If this is the case, then at least there is some hope that the common monetary policy will be more effective in the future. But the austerity measures could also lead to greater divergence between Greece and Germany, in which case leaving the monetary Union would not only be beneficial for Greece. It might be unavoidable.
