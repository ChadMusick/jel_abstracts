C89|Does Scientific Progress Affect Culture? A Digital Text Analysis|We study the interplay between scientific progress and culture through text analysis on a corpus of about eight million books, with the use of techniques and algorithms from machine learning. We focus on a specific scientific breakthrough, the theory of evolution through natural selection by Charles Darwin, and examine the diffusion of certain key concepts that characterized this theory in the broader cultural discourse and social imaginary. We find that some concepts in Darwin’s theory, such as Evolution, Survival, Natural Selection and Competition diffused in the cultural discourse immediately after the publication of On the Origins of Species. Other concepts such as Selection and Adaptation were already present in the cultural dialogue. Moreover, we document semantic changes for most of these concepts over time. Our findings thus show a complex relation between two key factors of long-term economic growth – science and culture. Considering the evolution of these two factors jointly can offer new insights to the study of the determinants of economic development, and machine learning is a promising tool to explore these relationships.
C89|¿Qué tan bien recuerdan las madres? Una validación de datos de desempeños al nacer para Uruguay|To assess maternal and child well-being and health goals derived from national and international agreements, many household surveys collect information on reproductive, maternal and child health. However, scarce representative validation exercises are comparing these data to administrative records information at the individual level. In this study, we contrast household surveys against data from clinical histories and vital statistics information. Also, we explore whether the significance and magnitude of the relationships between the variables change depending on the data source used. Based on the merging of vital statistics microdata with the official Uruguayan Nutrition, Child Development and Health Survey (ENDIS), we analyze the accuracy in mothers recall of weeks of gestation and prenatal visits. In general terms, our exercise validates the use of survey data, even though the identification of premature births and early prenatal visits have significant differences. We find that the accuracy of the recall by mothers is high and the discrepancies are associated with lower maternal education levels, the recall period (child´s age), and the birth order. However, the incidence of prematurity and early uptake is underestimated by 20%. Although the (respective) association of gestational weeks and prenatal controls with birth weight shows similar signs in both data sources, the levels of significance and effects magnitude appear to be greater in the administrative records.
C89|China’s Response to Nuclear Safety Post-Fukushima: Genuine or Rhetoric?|The Fukushima crisis has brought the nuclear safety problem to the world’s attention. China is the most ambitious country in the world in nuclear power development. How China perceives and responds to nuclear safety issues carries significant implications on its citizens’ safety and security. This paper examines the Chinese government’s promised and actual response to nuclear safety following the Fukushima crisis, based on (1) statistical analysis of newspaper coverage on nuclear energy, and (2) review of nuclear safety performance and safety governance. Our analysis shows that (i) the Chinese government’s concern over nuclear accidents and safety has surged significantly after Fukushima, (ii) China has displayed strengths in reactor technology design and safety operation, and (iii) China’s safety governance has been continuously challenged by institutional fragmentation, inadequate transparency, inadequate safety professionals, weak safety culture, and ambition to increase nuclear capacity by three-fold by 2050. We suggest that China should improve its nuclear safety standards, as well as safety management and monitoring, reform institutional arrangements to reduce fragmentation, improve information transparency, and public trust and participation, strengthen the safety culture, introduce process-based safety regulations, and promote international collaboration to ensure that China’s response to nuclear safety can be fully implemented in real-life.
C89|China's Response to Nuclear Safety Post-Fukushima: Genuine or Rhetoric?|No abstract is available for this item.
C89|The network of inter-industry flows in a SAM framework|The networks of nominal flows between industries in a Social Accounting Matrix (SAM) framework are studied. The flows of the SAM submatrices of production (or output of goods and services) and intermediate consumption, are identified, which are constructed from the supply and use tables of the National Accounts. From these flows, the inter-industry networks are induced. The structure of these networks are analysed, as well as, the underlying generation of income. An application to Portugal illustrates the approach.
C89|Amazon Mechanical Turk Workers Can Provide Consistent and Economically Meaningful Data|We explore the consistency of the characteristics of individuals who participate in studies posted on Amazon Mechanical Turk (AMT). The primary individuals analyzed in this study are subjects who participated in at least two of eleven experiments that were run on AMT between September of 2012 to January of 2018. We demonstrate subjects consistently report a series of demographic and personality characteristics. Further, subjective willingness to take risk is found to be significantly correlated with decisions made in a simple lottery experiment with real stakes - even when the subjective risk measure is reported months, sometimes years, in the past. This suggests the quality of data obtained via AMT is not significantly harmed by the lack of control over the conditions under which the responses are recorded.
C89|Analysis on the Influence of Government Efficiency on Taiwan?s Society, Economy, and Environment Using Data Mining: A Case Study on Open Government Data|This study uses DEA-SBM to obtain the target variables and the decision tree model to produce important indicators. The government can promote Taiwan's development in all aspects by improving social, economic, and environmental efficiency, while ensuring the sustainable development of environmental protection. The 15 social, economic, and environmental variables are used in the decision tree to obtain 3 repeatable important indicators that can affect Taiwan's social change, economic development, operational capability, environmental pollution, and change. K-means divides the 22 counties and cities into 1 capital city, 5 municipalities, and 16 other counties and cities, in order to understand the influence of the economy on social and environmental development during the period of 2013-2015 in Taiwan.
C89|The Relationship among Turkish EFL Learners? Perceived Communication Competence, Willingness to Communicate and Speaking Proficiency|This study aims to explore the relationship among Turkish EFL Learners? communicative competence, willingness to communicate (WTC), and their speaking proficiency in a Turkish EFL context. 213 students who are majoring in the School of Foreign Languages, English Language Department at a foundation university in Ankara during the academic year of 2015-2016 Spring Semester participated in the study. The students are monolingual and their ages range from 17 to 24. The participants completed 5-point likert-type questionnaires on Turkish-language version of the Perceived Communication Competence Test by Yashima (2002), MacIntyre & Charos (1996) and WTC Test by McCroskey (1992). These tests were used for measuring students? perceived communication competence and willingness to communicate in Turkish EFL context, which will later be compared with their speaking proficiency. The data obtained from the study will be analyzed and interpreted and relying on these findings some recommendations will be made for foreign language teachers.
C89|Copula–Based vMEM Specifications versus Alternatives: The Case of Trading Activity|We discuss several multivariate extensions of the Multiplicative Error Model to take into account dynamic interdependence and contemporaneously correlated innovations (vector MEM or vMEM). We suggest copula functions to link Gamma marginals of the innovations, in a specification where past values and conditional expectations of the variables can be simultaneously estimated. Results with realized volatility, volumes and number of trades of the JNJ stock show that significantly superior realized volatility forecasts are delivered with a fully interdependent vMEM relative to a single equation. Alternatives involving log–Normal or semiparametric formulations produce substantially equivalent results.
C89|A Comparison of Russian Practices in Industrial Statistics with Un Recommendations: Similarities and Differences in Classifications, Data Items and Indicators|This study compares Russian state information systems of industry with UN international recommendations. The harmonization of the Russian information system with successful international practices is necessary for measuring the main industrial indicator levels and dynamics in comparison with the information analogues of both cross-border and strategically important countries. This allows the estimation of the efficiency and competitiveness of Russian industry and the best decisions to be made at all levels of governance in Russia including in the technology and innovation policy sphere. The study shows that a significant number of annual, quarterly, monthly and weekly reporting forms within the Russian statistical system in the absence of a single questionnaire for obtaining comprehensive information from an enterprise and unified methodological recommendations do not solve the information gap problem. The available disaggregated information is not sufficient to analyse the quality and effectiveness of industrial policy, especially in comparison with global levels and tendencies of re-industrialization. The state statistical system needs modernization to reduce the reporting burden on enterprises and improve information transparency and comparability at the detailed level.
C89|GitHub API based QuantNet Mining infrastructure in R|QuantNet being an online GitHub based organization is an integrated environment consisting of different types of statistics-related documents and program codes called Quantlets. The QuantNet Style Guide and the yamldebugger package allow a standardized audit and validation of YAML annotated software repositories within this organization. The behavior statistics of QuantNet users are measured with Web Metrics from Google Analytics. We show how the search queries obtained from Google’s metrics can be used in the test collections in order to calibrate and evaluate the information retrieval (IR) performance of QuantNet’s search engine called QuantNetXploRer. For that purpose, different text mining (TM) models will be examined by means of the new TManalyzer package. Further, we introduce the Validation Pipeline (Vali-PP) and apply it on the YAML data. Vali-PP is a functional multi-staged instrument for clustering analysis, providing multivariate statistical analysis of the co-occurrence distribution of driving factors of the pipeline. The new package rgithubS, which enables a GitHub wide search for code and repositories using the GitHub Search API and which is an essential element of the QuantNet Mining infrastructure, is briefly presented. The TManalyzer results show that for all considered single term queries the number of true positives is maximal in a latent semantic analysis model configuration (LSA50). The Vali-PP analysis indicates that the optimality of the combination LSA50 and hierarchical clustering (HC) applies to 70 − 90% of the cluster sizes for most of the considered quality indices. Further, we can infer that more accurate and comprehensive metadata increases the clustering quality. Subsequently, the findings of our experimental design are implemented into the QuantNetXploRer. The GitHub API driven QuantNetXploRer can be found and mined under http://www.quantlet.de
C89|UQICD v2.1.2 User Guide|The University of Queensland International Comparison Database (UQICD) has been created as a part of the research project on developing an econometric approach to the construction of consistent panels of purchasing power parities (PPPs), real gross domestic product (GDP) and real incomes. The database developed from the research is made available to users through the dedicated website for UQICD, http://uqicd.economics.uq.edu.au. An enhanced UQICD Version 2.1.2 is now available for users. This User Guide is designed to provide the users with information regarding the data series made available through UQICD. Technical details on the econometric methodology that underpins the series generated and disseminated through UCQICD are provided in a series of appendices.
C89|Bibliometric spectroscopy of Russia’s nanotechnology: 2000–2014|Abstract The article investigates the scientific performance of Russia in the field of nanotechnology, focusing on production, impact and collaboration. An underlying multidisciplinary corpus of publications was extracted from the Science Citation Index Expanded database through relevant keywords. The various bibliometric findings are presented in a top-down sequence, starting with a comparative analysis of Russia and other selected countries, scrutinizing further a revitalization of science in universities and finally presenting some (possible) centers of excellence within the domestic scientific system. Focusing on the most highly-cited nano papers, I use the analysis not only in terms of percentages of world shares of publications, but also in terms of the proportions of top-1 and top-10% publications. It is shown that among the comparative countries, Russia maximally increases the citation impact depending on its internationalization efforts and that, for example, the co-authorship between Russia and Australia in the top-10% layer as well as between Russia and the UK in the top-1% layer is above expectation. Implementing the president’s initiative “Strategy of Nanoindustry Development” and the role of governmental university-centered policy are discussed in light of the performed bibliometric study.
C89|Rotten apples or just apples and pears? Understanding patterns consistent with cheating in international test data|The Southern and Eastern Africa Consortium for Monitoring Educational Quality (SACMEQ) programme has succeeded in generating valuable knowledge about the outcomes of schooling in the region, and in developing capacity to use data, including test data, in governments and amongst researchers. However, there is room for improvements in the programme. The current paper examines the extent to which patterns in the 2000 and 2007 test data suggest cheating occurred. The risk of cheating during the administration of the SACMEQ tests clearly exists, both because in-built controls can be subverted and because all pupils write exactly the same test, which is unlike the situation in a programme such as TIMSS, which employs a matrix sampling test design approach. Data analysis methods developed by Jacob and Levitt (2003) to detect cheating are adapted and then applied to the SACMEQ, but also TIMSS, data. It is concluded that whilst cheating does not substantially change the overall picture of performance derived from the 2000 and 2007 data, or country rankings, noteworthy patterns highly consistent with cheating can be found in some countries, and some regions within countries. Country-level indicators of cheating in SACMEQ correlate remarkably well with World Bank indicators of general corruption. An analysis of conditional correlations within the SACMEQ data reveals that schools serving more socio-economically disadvantaged pupils are more likely to cheat. In one country, having a male school principal is associated with a higher likelihood of cheating.
C89|Identification Of Materials Using Aerial Hyperspectral Images| The aerial hyperspectral imagery has a large information content and contains data not just only in the visible light spectra but in the near-infrared and the short-wave infrared spectra as well. Due to this, the technology is applicable to examine and detect preferences and conditions that visible identification is not possible or limited. During the last decade, hyperspectral imagery was successfully used for the analysis of vegetation, soil or minerals. During our research the AISA Fenix1K hyperspectral sensor of the Research Institute was used for data collection with the collaboration of experts from the Finnish sensor producer company near to Siófok. The collected aerial hyperspectral data and the ground spectral data as reference were compared and a spectral library of the examined materials was developed for future classifications. The ability to separate various materials was examined with statistical analyses with which we can determine the spectral separability of target objects. The analysis was fulfilled on the original and on transformed channels as well. According to the results we can conclude that the transformed channels are more applicable to separate these materials which was demonstrated on scatter plots too.
C89|Graphic Evaluation Of Copyright And Of Relations By The Method Of Discounted Cash-Flow (Dcf)|"According to the new technologies and due to the phenomenon of sustainability, in the knowledge economy, intangible assets are renamed, being limited by resources existential any economic entity, the terminology ""intangible"", ""invisible"", ""intellectual"" or ""us/immaterial"" which emphasizes knowledge by which human capital is undre different forms. Due to the existence of a variety of approaches, accounting literature, together with the economic but also the specific evaluation activity reflects complexity permanent classification of intangible assets. As we all know, the moment items related intangible assets can be identified, presented and defined in terms of a wide range and complex standards such as the International Accounting Standards, Financial Reporting Standards and not least the International Valuation Standards. To support the theme of the current research we have chosen as the case study approach to assess a sampling of copyright and relationships using the discounted cash flow method (DCF)."
C89|Mapping the evolution of the impact of economic transition on Central and Eastern European enterprises: A co-word analysis|Here we use co-word analysis on extant literature to map the intellectual structure of research addressing the impact of economic transition on Central and Eastern European enterprises during the 1989–2013 period. We collected and analyzed 2053 scholarly papers from the most comprehensive management databases, which were then used to develop. This paper contributes to the economic transition literature by providing an empirically derived framework based on the extant literature. This framework describes the main factors affecting enterprises during the transition process, the relationships among these factors and their evolution.
C89|Ensembles of Classifiers for Parallel Categorization of Large Number of Text Documents Expressing Opinions|Opinions provided by people that used some services or purchased some goods are a rich source of knowledge. The opinion classification, applying mostly supervised classifiers, is one of the essential tasks. Computerâ€™s technological capabilities are still a major obstacle, especially when processing huge volumes of data. This study proposes and evaluates experimentally a parallelism application to the classification of a very large number of contrary opinions expressed as freely written text reviews. Instead of training a single classifier on the entire data set, an ensemble of classifiers is trained on disjunctive subsets of data and a group decision is used for the classification of unlabelled items. The main assessment criteria are computational efficiency and error rates, combined into a single measure to be able to compare ensembles of different sizes. Support vector machines, artificial neural networks, and deci- sion trees, belonging to frequently used classification methods, were examined. The paper demonstrates the suggested method viability when the number of text reviews leads to com- putational complexity, which is beyond the contemporary common PCâ€™s capabilities. Classification accuracy and the values of other classification performance measures (Precision, Recall, F-measure) did not decrease, which is a positive finding.
C89|Farmers’ Willingness and Expected Economic Benefit to Adopt BMPs: an Application of Multivariate Imputation by Chained Equation Method| Water Quality Trading (WQT) programs may offer farmers compensation to adopt Best Management Practices (BMPs). We conducted a survey of farmers in the Kentucky River watershed from 2011 to 2012. With respect to the five types of BMPs considered in the survey, about 20% of respondents did not indicate how much they will adopt. Missing responses are common for surveys on farming decisions. We compare three methods to handle the missing data: deleting the observations with missing value, mean imputation, and Multivariate Imputation by Chained Equation (MICE). Following these missing data treatments, we estimate the factors affecting how much farmers may engage in BMPs using Tobit or Poisson model. The results show that increasing the compensation for using BMPs is more likely to encourage farmers to adopt riparian buffers. In addition, land area, percentage of household income from farming, percentage of total household income reinvested back to farm, and current experience of BMPs will affect BMP adoption. The results obtained after using the MICE are more promising and reasonable than using the deletion or the mean imputation method. Implications are discussed for farmers’ BMP adoptions under WQT while missing observations are present.
C89|Farmers’ Willingness to Engage in Best Management Practices: an Application of Multiple Imputation| The purpose of this article is to explore how much farmers may engage their lands in Best Management Practices (BMPs) through a water quality trading (WQT) program in Kentucky. We conducted a survey of farmers in the Kentucky River watershed from 2011 to 2012. The questions in our survey are whether and how much farmers may adopt the BMPs (in addition to what they have already used) if they are offered compensation through WQT. About 20% of respondents with respect to five different types of BMPs did not indicate how much they will adopt. We compare three strategies to handle the missing data: deleting the observations with missing value, simple imputation by imputing the mean of the observed value, and Multiple Imputation (MI). Follow these missing data treatments, we estimate the factors affecting how much farmers may engage in BMPs using Tobit model. The results show that increasing the compensation for using BMPs are more likely to encourage farmers to adopt riparian buffers, animal fences and nutrient management. Besides, land area, rent area, farming revenue, percentage of reinvestment to farms from household income, water quality near the farm, participation in government programs, and current experience of BMPs will affect BMPs adoption. The results by using the MI are more promising and reasonable than using the deletion method and mean imputation method.
C89|Training Assessment: A Premise For Training Transfer In Enterprises|The technical literature tackled the issues of training transfer and training assessment from two distinct research directions that sometimes happened to intermingle; in the light of recent discoveries, we considered these issues were interrelated via a causal connection. We used an analysis of the approach of these two topics in 30 enterprises that constantly provided their employees with training in the past two full years. The present paper demonstrated the fact that the training transfer rate is: a) strongly influenced by the extent to which training evaluation methods were used; b) moderately influenced by the support employees received when they returned to work in order to implement what they had learned; and c) it is not influenced by the proper training evaluation methods (which may be different depending on the specific of the training and the expertise of the human resources specialist who undertakes the assessment).
C89|Satellitendaten zur Schätzung von Regionaleinkommen – Das Beispiel Deutschland|Eine neue Möglichkeit zur Schätzung fehlender regionaler Einkommensdaten bieten Satellitenbilder der Erde bei Nacht. Die grundlegende Idee ist, dass wirtschaftliche Aktivitäten, die in den Abendstunden statt finden, Licht benötigen bzw. emittieren. Aus der Lichtemission bei Nacht kann ein Rückschluss auf wirtschaftliche Größen gezogen werden. Ziel dieses Beitrags ist, die in der Literatur verwendeten Daten vorzu stellen sowie die Möglichkeiten und Grenzen der Nutzung von Satellitendaten zur Schätzung von Einkommen zu diskutieren. Im Beitrag werden die Satellitendaten vorgestellt sowie damit verbundene Messprobleme diskutiert. Anhand des Beispiels Deutschlands wird untersucht, inwieweit sich die Lichtemissionsdaten für regionalökonomische Analysen eignen. Es wurde kein besonders großer und zudem wenig robuster Zusammenhang zwischen Lichtemissionen und regionalem Bruttoinlandsprodukt gefunden. Für weniger entwickelte Staaten können die Daten jedoch ein wertvoller Indikator des nationalen oder regionalen Einkommens sein und damit helfen, die sehr lückenhaften Regionalstatistiken zu vervollständigen.
C89|Monitoring Student Performance. A Data Driven Decision Support System Approach|Data Driven Decision Support Systems are mature technologies whose effectiveness in business and management seem to be well established and uncontroversial. Under the circumstances of increased competition between universities in their attempt to better position themselves on the market of educational services, a Data Driven Decision Support System could become a powerful instrument meant to enhance all the decisions that target various aspects of the educational process. This paper is a case study conducted in a Romanian university, presenting the development of such a system, emphasizing the analytical capabilities related to student results at exams, as this topic is of interest for the users of the system.
C89|Size and Momentum Profitability in International Stock Markets|We study the link between the profitability of momentum strategies and firm size, drawing on an extensive dataset covering 23 stock markets across the globe. We first present evidence of an “extreme” size premium in a large number of countries. These size premia, however, are most likely not realizable due to low stock market depth. We also show that international momentum profitability declines sharply with market capitalization. Momentum premiums are also considerably diminished by trading costs, when taking into account the actual portfolio turnover incurred when implementing this strategy. In contrast to strategies based on size, we find that momentum premia especially for medium-sized stocks still remain economically and statistically significant in most equity markets worldwide after adjusting for transaction costs.
C89|Path-breaking directions of nanotechnology-based chemotherapy and molecular cancer therapy|A fundamental question in the field of technological forecasting and foresight is how to detect likely fruitful technological trajectories in new research fields, such as nanomedicine. We confront this question by developing an approach based on trends and networks of vital variables, analyzed by bibliometrics, which endeavours to detect fruitful trajectories of nanotechnology applied to ground-breaking anti-cancer treatments. Results tend to show two main technological waves of cancer treatments by nanotechnology applications. The early technological wave in the early 2000s was embodied in some types of chemotherapy agents with a broad spectrum of application, while after 2006 the second technological wave appeared with new applications of chemotherapy agents and molecular target therapy by nanotechnology. The present study shows new directions of nanotechnology-based chemotherapy and molecular cancer therapy in new treatments for breast, lung, brain and colon cancers. A main finding of this study is the recognition that, since the late 2000s, the sharp increase of several technological trajectories of anticancer drugs applied by nanotechnology seems to be driven by high rates of mortality of some types of cancers (e.g. pancreatic and brain) in order to find more effective anticancer therapies that increase the progression-free survival of patients: the so-called technological trajectories mortality driven. The study also points out that global research leaders tend to specialize in anticancer drugs, via nanotechnology, for specific cancers (e.g. Switzerland in prostate cancer, Japan in colon cancer, China in ovarian cancer and Greece in pancreatic cancer). These ground-breaking technological trajectories are paving new directions in biomedicine and generating a revolution in clinical practice that may lead to more effective anticancer treatments in the not-too-distant future.
C89|Reliability of causes-of-death statistics: the Italian experience from the ICD-10 training course|Cause of death (CoD) statistics are a major health indicator.One of the most important instrument for improving their reliability is the appropriate use of the ICD-10 as instrument of harmonization and quality. Six research assistants recruited by Istat followed an in-depth coding course and a 8 weeks mentoring period in which they coded 4.050 cases previously coded by experts. The CoD attributed by the trainees was compared with the one attributed by experts. The overall agreement increased during the mentoring reaching the value of 78.4% which is comparable with the literature findings. From the study it emerges the relevance of having accurate and continuous training in order to achieve the best quality for official CoD statistics.
C89|Gli stranieri residenti per genere e cittadinanza: la stima per comune negli anni successivi al censimento|The data on foreign population currently captured from municipal population registers, are yearly validated and disseminated by the Italian National Institute of Statistics (Istat). They concern the number of EU and non-EU citizens regularly resident in Italy, distributed by gender and citizenship. The validation process - including its ex-ante consistency making step with the official census individual records - is a typical example of using administrative source information for statistical purposes. The aim of this work is to show that, given the information deriving from sources currently available, for the years immediately following the 2011 census the method of indirect net balances allowed to estimate foreign population distributed by sex and country of citizenship, ensuring the smoothest transition from the distribution detected via-census towards the post-censual yearly distributions of municipal population registers after their post-censual revision operations.
C89|Forecasting model for vehicular demand: an alternative methodology in the context of developing countries|Two most challenging problems facing transportation planners and policymakers in many developing countries are rapid urban traffic growth and lack of financial and technical resources to conduct major planning studies, especially for assessing the impacts of new sites and land-uses. The conventional urban transportation planning process, which is data and time intensive, has been of little value due to many transportation related obstacles (inadequate database, lack of funds, inadequate technical expertise, etc.). Advances in computer technology, especially in the areas of Geographic Information Systems (GIS), offer new ways of dealing with the aforementioned problems. This paper presents a new methodology for conducting transportation planning studies in developing countries. Integrating TransCAD, well-known GIS software for transportation applications, and Excel, spreadsheet software, the new model starts by estimating an Origin-Destination (O-D) table from traffic counts at the base year. Then, a modified O-D table is obtained from a simple procedure before determining the new traffic assignment, taking into consideration the new sites and land uses. The model was developed and applied for conducting regional transportation planning in the Gaza Strip, Palestine. A flexible, yet vigorous transportation planning mechanism was needed to assist planners in their efforts to plan for transportation in that highly populated area with a poor and old highway network. The results of the verification work conducted after each step during the development of the model have been acceptable. Moreover, transportation experts who live and work in the area have conducted complete validation of the results.
C89|The Determination of Deposit and Participation Banks’ Efficiency by Data Envelopment Analysis: A Research on Banks in Turkey|The determination of productivity and efficiency of firms directs strategic decisions in the eye of decision makers. The importance of productivity and efficiency measurement in banking sector which especially attracts foreign investors in Turkey increases gradually. In this context, efficiency measurement of 15 banks operating in Turkey has been done by using their data. Data Envelopment Analysis (DEA) technique which is used as a decision making tool in multiple input multiple output processes and is not parametric is used. In the method, number of staff, total assets and capital are used as input units and general deposit, total credits and net profit are used as output units. In the results, the efficiency of banks in 2013-2014 has been measured and efficiency difference between private capital deposit banks and participation banks has been examined.
C89|Automated Extraction of Typical Expressions Describing Product Features from Customer Reviews|The paper presents a procedure that helps in revealing topics hidden in large collections of textual documents (such as customer reviews) related to a certain group of products or services. Together with identification of the groups containing the topics the lists of important expressions is presented which helps in understanding what characterizes these aspects most typically from the semantic point of view. The procedure includes determining an appropriate number of groups representing the prevailing topics, partitioning the documents into a desired number of groups using clustering, extracting significant typical features of documents from each group with application of feature selection methods, and evaluating the outcomes with the assistance of a human expert. The results show that the presented approach, consisting mostly of automated steps, is able to separate and characterize the aspects of a certain product as discussed by the customers and be later useful, e.g., for handling customer complaints, designing promotional campaigns, or improving the products.
C89|Study Design Requirements To Realize A Software For Document Archives (Gad)|This paper studies the software market for the management and storage of documents. They identified three categories of software products for this area: the computerized management of electronic records, computerized management of existing domentelor in organizations and computerized management of physical archives of documents. All three categories of software interfere with each other, but they each have specific functions well developed information, addressing only tangentially other specific categories. Author very poor market accounting software products for managing physical documents computerized archives. Due to this aim and it manages to define the specific requirements of this gategorii software products will subsequently address such a product design software. In conclusion decision variables are analyzed for the design format and define the most appropriate version to be addressed.
C89|Econometric Predictions From Demographic Factors Affecting Overall Health|Efforts to accurately predict health outcomes with a focus on informing policy makers of where to best spend limited resources have been made in the past. This paper builds on the efforts of those studies in an attempt to build an accurate predictor of health from readily available data. The American Time Use Survey (2010, 2012, and 2013) provides the majority of the data from which this model is built, and it is then tested via several methods. The analysis finds that the existing freely available data is significant in its predictive power, however is missing too many predictors to reduce the confidence interval about each individual prediction to a point of bearing meaningful fruit. That does not eliminate the usefulness of the study however, as by reducing the confidence required and accepting that the data is used for predicting societal means, the model is able to accurately predict average outcomes. This paper further attempts to analyze state level date to provide a geographic target for public funds expenditures, and accomplishes this through the analysis of various risk factors by region. Notable in this analysis is an attempt to correct for self-reporting errors. The literature review did not reveal any previous attempts to do so using a similar methodology (beyond recognizing that such errors exist and using robust methods to account for them), making this attempt possibly unique. The correction did not result in significantly different estimates, however that may be a result of the minimal resources applied to this small aspect of the analysis.
C89|Romanian Linked Open Government Data(LOGD) Architecture|Linked Open Government Data(LOGD) facilitates the integration of data and allows the link between the disparate government data sets. The increasing use / reuse of the releases LOGD increases the need to improve the quality of data. The availability of LOGD allows the creation of new services offered by the public / private sector. The reuse of LOGD in the e-government applications leads to a considerable reduction in costs. The article is divided in 3 sections. The first section is describing the facilitators in developing romanian LOGD ecosystem, the second section is identifing the impediments and the third section propose an architecture for a coherent Romanian Linked Open Government Data Ecosystem.
C89|Detailed analysis of titles and short abstracts on cloud-computing research papers reachable on Google Scholar|Cloud computing has become a prevalent phenomenon in today computing industry. The evolution and trends of cloud computing inciting in the same extent, professionals, researchers, business, government institutions and common users. Generous web resources and literature is offering all those interested, details of the general concepts, developing and implementing models, detailed analysis of the functionalities and concrete aspects of security and privacy. This paper is based on a statistical research targeting titles and short abstracts for published articles related to cloud computing technologies available on Google scholar database. Main goal is to highlight the most common key concepts used to describe the research on cloud computing and to identify a research trend.
C89|Methodology for improving Romanian Linked Open Government Data ecosystem|Open Government Data (OGD) is seen as an enabler for Open Government. Open Data usually refers to public records that can be used and redistributed by anyone. Linked Open Government Data (LOGD) is a way of identifying, linking and accessing OGD Data. In the LOGD ecosystem, public administrations are data providers that provide Open Government Data as an online LOGD service to data consumers ? citizens, businesses and other public administrations. The article is divided in 2 sections. The first section is describing the Linked Open Government Data ecosystem, the second section propose a methodology for a coherent Romanian Linked Open Government Data Ecosystem.
C89|A dynamic analysis of relevant variables in the Spanish economy using decomposition data series with Daubechies wavelets|We illustrate some aspects of the economic situation in Spain following the dynamic of data series of six relevant economic and financial variables: A financial index (IBEX35), a row material (Crude Oil Price in euros, COP), a foreign exchange index (EUR/USD), a bonus (Spain 10-Years, S10YB), the total state debt (Spain State Debt, SSD) and Consumer Price Index (CPI) variables (from es.investing.com, indexmundi.com, www.bde.es and www.ine.es). We analyse the decomposition of non?stationary rates monthly series in the period 2000M1-2014M12 using Daubechies wavelets db8 to visualized high frequency variance, seasonality and trend. We present several figures illustrating the decomposition in both time and frequency domains and tables containing the relevant frequency indices for the different detail series obtained.
C89|Zu guter Forschungsinfrastruktur und forschungsbasierter Politikberatung gehört mehr als nur gute Statistikdaten|Der Beitrag ordnet die Bereitstellung von Forschungsinfrastruktur in den Sozial-, Verhaltens- und Wirtschaftswissenschaften in die Möglichkeiten und Grenzen einer forschungsbasierten Evaluation und Beratung von Politik ein. Entsprechend werden einige Hinweise für die Weiterentwicklung der einschlägigen Forschungsinfrastruktur in Deutschland und im internationalen Kontext gegeben.
C89|Amtliche Statistik und wissenschaftliche Forschung|No abstract is available for this item.
C89|Collecting information on job tasks - an instrument to measure tasks required at the workplace in a multi-topic survey|"""The analysis of job tasks has become a field of growing scientific activity in recent years. Information on such tasks has been used to analyze various research questions, especially regarding changes in the overall structure of the economy and their implications for persons and firms. Arguably the most prominent of these research questions is the analysis of the consequences of technological change for job tasks, skill demand, and wage inequality. Despite the growing importance of this field of research, the range of actual task measures to be used in empirical analyses is rather limited. Therefore, we considered it worthwhile to develop a survey instrument to measure job tasks by asking the job holders directly. The resulting questionnaire module was administered in the fourth panel wave of the German National Educational Panel Study's (NEPS) adult stage. In this paper, we provide an overview of our conceptual background as well as the steps taken during the development of the survey instrument. Furthermore, we present an initial exploratory analysis of the data collected to validate the instrument."" (Author's abstract, IAB-Doku) ((en))"
C89|Research infrastructures in the LHC era: a scientiometric approach|When a research infrastructure is funded and implemented, a new literature cycle is created. This new information is the measurable output of the discovery process. In this paper, we describe the impact of physics experiments in terms of publications and citations. In particular, we consider the Large Hadron Collider (LHC) experiments (ATLAS, CMS, ALICE, LHCb) and compare them to Large Electron Positron Collider (LEP) experiments (ALEPH, DELPHI, L3, OPAL), Tevatron experiments (CDF, D0). We provide an overview of the scientific output by projects over time and highlight the role played by remarkable project results in the publication-citation distribution trends. The methodological and technical contribution of this work provides a starting point for the development of a theoretical model to determine modern scientific knowledge propagation over time.
C89|Model For Designing An Information System With High Reliability|In the context of the generalization process of computerization in all areas of economic and social necessity author presents the design of information systems at risk as small operation. This paper defines the concept of reliability of systems, its basic components and create a model for accomplishing it. Reliability is a key factor considered by the author to reduce the risk of operating systems. The problem is even more important for embedded computing systems. The paper is designed and presented an original design of systems with high reliability. According to the author, the cost of preparing such a system is a factor that determines the level of reliability designed paper presents various design alternatives based on costs..
C89|National Data Centre and Financial Statistics Office: A Conceptual Design for Public Data Management|Data processes run by states, governments and the like have been a great deal and as old as the modern human history. Data had always been important. Tons were collected and siloed, but never in the past had its importance been felt as much as it had been when the last crisis broke out in 2008. Because these tons of data either, as some were redundant and occupying large spaces with huge storage costs, were not useful given the processing power and due to outdated mind-sets, or were not even the tiniest portion of the data necessary to do analysis , the experts realised. With the advances in the digital world dealing with data has become easier. Combined with the urgent needs and demands from the bottom up and top down there now is more enlightened and educated perception of data and whatever its extensions are, and its / their potential use, though a little bit late. In the late 90s, however, things were not as computerised and DataeXve was not as Big as it is today, and manual operations dominated the automated ones. There were definitely inefficiencies in DataeXve. Still, even then, there were efforts to improve these processes. This work focuses on one of those early efforts.
C89|Economic and Social Impacts of South East Anatolia Project: Gap And Beyond|This study analyses how the Regional Plan affects the social and economic lives of residents of South East Anatolia. The study particularly focuses on GAP (South East Anatolian Project in Turkish acronym), which covers regional policies and plans for the economic and social spheres of the South East Anatolia Region in both rural and urban areas. In this study, there have been two industrial inventory studies of GAP region in line with two projects conducted by Elmas (et al.) in 1999 and 2009. The Regional Development Plan (GAP) has changed the level of economic development, social life and urbanization in the region. The first section of this article mainly discusses GAP’s historical process as shaped by structural economic understanding before and after the 1980s. The major transformation experienced within the scope of GAP has been shaped by the changing role of the state in the project’s implementation, which goes hand in hand with understanding the ‘new regionalism’ that has emerged since the 1980s. Implementing neoliberal economic policies and globalization has brought significant changes in both the economic and social lives of the project’s beneficiaries. In this sense, in the following sections, in light of two previous inventory studies, we argue that there have been some development for GAP region in terms of agricultural and industrial investments, urbanization and migration comparing to other regions of Anatolia.
C89|Information Technology based Monitoring and Efficient Regional Development Management|This study is focused on possibilities of use of information systems of social and economic monitoring (ІSSEM) in the regional development management. The paper presents eight (8) principal aspects of efficiency increasing of regional development management on the basis of ІSSEM and draws the attention of regional policy-makers and managers to the development purpose of governance.
C89|Determinación del riesgo de fracaso financiero mediante la utilización de modelos paramétricos, de inteligencia artificial, y de información de auditoría|En este artículo aportamos evidencia empírica de predicción del fallo financiero en empresas no financieras. Hemos desarrollado diversos modelos para la evaluación del riesgo de fallo financiero en PYME. Contrastada la capacidad predictiva de modelos paramétricos (análisis discriminante multivariante, LOGIT) comparando con la información aportada por la auditoria. Los modelos están fundamentados en variables financieras relevantes y ratios, de lógica financiera y en situaciones de estrés. Examinamos una muestra aleatoria de empresas, comprobando la capacidad predictiva en distintos momentos del tiempo, verificando si los modelos muestran señales anticipadas de futuros eventos de fallo financiero, simulando el impacto de los costes de los errores de estimación en función del modelo previsional. Los resultados sugieren que nuestros modelos son efectivos en el corto y medio plazo, ofreciendo mayor capacidad predictiva que las auditorías externas.
C89|Operationalising ‘safe statistics’: the case of linear regression|The recent growth in research access to confidential government microdata has prompted the development of more general 'output-based statistical disclosure control' (OSDC) methods which go beyond tabular protection. Central to OSDC is the concept of 'safe/unsafe statistics', allowing researchers and facility owners to make informed judgments about the types of research output that pose a disclosure risk. While increasingly accepted in specialist environments, in the wider community this novel approach causes some concern: how can 'safe' be unconditional? This paper therefore demonstrates the new approach using linear regression, a key research output, as an example. In doing so, the paper reconsiders the objectivity of SDC decision-making, arguing that ‘safety’ be explicitly acknowledged as a relative concept.
C89|The Quality Of Data And Metadata In A Datawarehouse|The data quality is an important concept for the economic applications used in the process of analysis. The databases were revolutionized when they first started being used with large amountsof data. From this point on, an important process is represented by storing multidimensional data in datawarehouses, in order to be processed and analyzed with the purpose of obtaining information which can be used for decision making in various activities. Specialty studies show that most data is not useful for the purpose it has been collected because of both the lack of quality and incorrect techniques of manipulating this data. This study will try to offer a process of obtaining quality data in data archives and how to avoid quality anomalies inside metadata.
C89|Boylamsal Verilerde Cok Duzeyli Analizler: Dil Gelisimine Ýliskin Bir Uygulama|There are various methods and scales used for determining the deviations of the baby growth. A scale has been applied to 40 babies in the 12, 24 and 36 month periods and language development has been explained by the period of breast feeding without any additional food, social-emotional development during these periods and fine motor development variables. As a sub-model the period of breast feeding without any additional food has been explained by the gender of the baby, the educational status of the mother during birth and the birth weight of the baby. Furthermore other sub-models, the social-emotional development of the baby has been interpreted by the educational status and the age of the mother during birth variables, fine motor development of the baby has been explained by the baby's gender, mother's educational status, baby's birth height and weight variables. Multilevel analysis has been applied to these data which have longitudinal structure.
C89|Privacy and Data-Based Research|What can we, as users of microdata, formally guarantee to the individuals (or firms) in our dataset, regarding their privacy? We retell a few stories, well-known in data-privacy circles, of failed anonymization attempts in publicly released datasets. We then provide a mostly informal introduction to several ideas from the literature on differential privacy, an active literature in computer science that studies formal approaches to preserving the privacy of individuals in statistical databases. We apply some of its insights to situations routinely faced by applied economists, emphasizing big-data contexts.
C89|Extracting GDP signals from the monthly indicator of economic activity: Evidence from Chilean real-time data|Real-time data are analysed for information on the Chilean monthly economic activity indicator IMACEC and what it indicates of the final GDP, defined as the growth rate that has been subject to at least two annual revisions. Data are presented and revisions analysed briefly. Mincer-Zarnowitz tests suggest that forecast rationality is rejected with respect to the three-month IMACEC growth rate as a nowcast of the first released quarterly GDP, as well as the first published GDP as a nowcast of the final GDP. An out-of-sample nowcasting analysis was conducted using only data which were available in real-time. The results show that small models nowcast better than less parsimonious ones. The evidence from the empirical study suggests no improvement in the nowcasting performance when historical data are supplemented with the first monthly IMACEC of the quarter. On the other hand, when two monthly observations IMACEC are available, the root mean squared nowcast error (RMSNE) decreases by 24%, and a further decline of 33% is obtained when the third monthly observation of the quarter is published. Both of these advances are statistically significant. No further improvement is obtained with the publication of the first release of the quarterly GDP. JEL classifications: C89, E17 Keywords: Real-time data, data revisions, nowcasting
C89|Study Information Decision Underlying|The paper aims to study the different types of information used in decision making. We also analyzed the levels of aggregation, management and softwares that process these types of information. The study started from the fact that data underlying the decision are increasingly complex, and the management should focus on the essence of the decision process and not on the structure and complexity of data. The author clarifyies the concept of information in relation to the data. At the end of the paper the author proposes an approach for analysis data underlying the decision.
C89|‘Welcome to the experience economy’: assessing the influence of customer experience literature through bibliometric analysis|Some publications strongly influence how research in a field evolves and in which direction, particularly by introducing and developing new concepts and insights. The analysis of such seminal publications is an interesting way to examine a scholar’s or a theory’s influence on a discipline. It is a sound and valuable method for introducing newcomers to a field, while also providing incumbent researchers with thorough and encompassing updates. In the last few years there has been increasing interest from both academia and practitioners in the topic of customer experience. Pine II and Gilmore’s article published in 1998 in the Harvard Business Review (‘Welcome to the experience economy’) is seen by many as a key forerunner in this area of research. The present paper explores the ‘small world’ of Pine II and Gilmore, based on bibliometric tools. An in-depth analysis of the scientific influence of this article was performed, based on the citations it has received since it was published (1998) to 2012. The results confirm the broad scope of influence of the concept of ‘customer experience’. Indeed, Pine II and Gilmore’s article has been cited by authors from a wide range of scientific areas, not only in business and management but also tourism, sport, leisure and hospitality. Moreover, measurement and innovation emerge as underrepresented sub-topics within customer experience research. Finally, an appeal is made for more quantitative-led research in this field of study.
C89|Growth and Unemployment: A bibliometric analysis on mechanisms and methods|The relation between growth and unemployment is being studied throughout a diverse set of contributions over the last years. Taking into account the current economic situation, this topic is regaining attention amongst economists essentially due to the importance of this relationship as a way to overcome the high unemployment rate that has been characterizing the European labour market. In the first part of the paper we provide an analysis and a categorization of the most important contributions on the field until 2000s. In the second part we develop a bibliometric analysis in order to identify the evolution pattern of the main research lines, using a quantitative approach. Then, we provide an update of the literature by describing the new theoretical mechanisms and empirical evidence regarding the relationship between growth and unemployment. A substantial increase of new effects (reallocation effect, leapfrogging effect, disciplinary unemployment effect, minimum wage effect, updating technology effect, schooling and working effect and agglomeration economies effect) and a relative predominance of “formal” and “empirical” methodologies, with a very low weight of articles combining both methods are some of the main findings.
C89|The impact of population ageing on economic growth: an in-depth bibliometric analysis|The phenomenon of population ageing and its influence on the economic growth of countries has long been the focus of major concern for both governments and the scientific community. Considering the scientific contributions that have been published on the matter in recent years, it seems timely to take a comprehensive and objective account of this stream of the literature. Using bibliometric techniques and based on 144 articles centred on ageing and economic growth gathered from Scopus, we found some interesting evidence: 1) ageing has increasingly attracted more researchers within economics-related literature; 2) more recently, studies have revealed the willingness of researchers to evaluate less immediate mechanisms relating ageing and economic growth, most notably consumption and saving patterns, and human capital; 3) there is a growing need in ageing research to test economic phenomena with real–world data against the theory, as reflected by the noticeable increase in the use of empirical methods; 4) Multivariate analyses have become more prominent since 2006, contrasting with a continuous fall in empirical analyses based on ‘Mathematical modelling’; 5) the effect of an ageing population on economic growth does not essentially vary according to the main mechanism through which ageing impacts on growth (being predominantly negative), but it does vary with the empirical methodologies used; 6) there are very few or a complete lack of studies on developing and less developed countries. The absence of empirical studies on ageing and economic growth for less developed countries combined with the fact that the ratio of an older population in such countries is expected to significantly increase over the next thirty years, makes this topic an imperative for future research.
C89|Twenty years of rural entrepreneurship: a bibliometric survey|Entrepreneurship, in general, and rural entrepreneurship, in particular, has become a dynamic field of research in the last two decades. It seems therefore timely to present a quantitative survey of the literature in this area, aimed at identifying the most important sub-topics, contributors and their geographical distribution, major outlets, main empirical methodologies employed, as well as the most frequently studied countries. Based on 181 articles published in journals indexed in Scopus (until March 2013), we found that within the entrepreneurship literature, ‘rural entrepreneurship’ has been largely overlooked and has gradually lost momentum. Rural entrepreneurship is an essentially ‘European’ concern, whose most prolific authors are affiliated in institutions located in the UK and Spain. The most important outlets for this topic are Entrepreneurship and Regional Development, International Journal of Entrepreneurship and Small Businesses, and Journal of Rural Studies. The average quality of the research on rural entrepreneurship has risen, as reflected by the journals’ impact factor, implying that it has gained a measure of scientific visibility. More research on rural entrepreneurship is being published in economics and business-related journals, losing to some extent its initial multidisciplinary scope. In the field of rural entrepreneurship, ‘Organization-related characteristics’, ‘Policy measures’ and ‘Institutional frameworks and Governance’ have attracted considerable attention in recent years, being considered as ‘emergent’ topics of research. In contrast, ‘Theory building’ has not attracted much research over the period in analysis, which suggests that the theoretical body of rural entrepreneurship is still incipient, hindering the establishment of its boundaries and of a suitable research agenda. The absence of an axiomatic and theoretical corpus prevents the full use of causality and hypotheses testing methodologies and explains to some extent the predominance of more qualitative types of research. Empirical literature on rural entrepreneurship has mainly analyzed developed countries, most notably, the UK, USA, Spain, Finland and Greece. Given the potential rural entrepreneurship represents for less developed and underdeveloped countries, more research on the topic is an imperative.
C89|Estimation of house prices in regions with small sample sizes|House price indexes had become important economic indicators worldwide, since movements in house prices have been closely correlated with the economic cycle. In order to compute these kind of indexes it is imperative to produce reliable estimates of the average transaction price of houses, not only at the macrolevel (e.g. national and state level), but also at the microlevel (e.g. district, municipalities or further disaggregate regional level). In Portugal, there is a rapidly growing demand of such microlevel statistics since the beginning of the recent financial and economic crisis. The Portuguese Statistical Office provides a range of invaluable data at national level; however, this data cannot be used directly to produce reliable regional-level estimates due to small sample sizes. In this paper we employ small area estimation techniques to produce design and model-based estimates of average transaction price of houses for Portuguese regions with small sample sizes. Our results show that the model-based estimates based on spatial and temporal models are more accurate than the traditional direct design-based estimates. The use of these techniques allows the production of information at disaggregated regional levels that would not be available under the traditional direct estimation approaches. Furthermore, it is even possible to produce reliable model-based estimates for geographical areas without sample. The estimates are expected to provide invaluable information to policy-analysts and decision-making. Copyright Springer-Verlag 2013
C89|A Multidimensional Model for Analyzing Democratic Development in Central and Eastern Europe|Various indices and ratings describing democratic processes in countries around the world have been developed by international organizations (such as Freedom House) and analytical centers (such as the one affiliated with the journal Economist). The main drawback of such ratings is that they only provide a linear ordering of countries by averaging a multitude of criteria. Such approach does not make it obvious which particular problems exist in which countries and thus does not help comparing democratic processes in different countries. In this paper, we propose a multidimensional model for ratings based on the mathematical discipline of formal concept analysis, which deals, in particular, with automated taxonomy construction from object–attribute data. In our case, every node of a taxonomy would group countries similar in certain aspects, while at the same time providing a description of these aspects. The aim is not to question the existing ratings, but rather to provide a neutral instrument for uncovering the structure of the data underlying these ratings. The proposed representation is much more informative than linear ratings, since it shows the commonalities and differences in the democratic development of various countries. In addition, it provides a solid ground for discussing, comparing, and criticizing ratings. It can also help formulate theoretical hypotheses on the evolution of democracy, thereby advancing scientific discovery. We illustrate the proposed representation with the case study of countries in Central and Eastern Europe and the former Soviet Union. Copyright CEEUN 2013
C89|Comparison Of Apriori And Fp-Growth Algorithms On Determination Of Association Rules In Authorized Automobile Service Centres|Data Mining is used to describe the totality of techniques which aim to find the unexplored patterns in a set of data. The purpose of data mining is to create models of decision-making devoted to estimations of future behavior based on analysis of past activities. In this study the shopping data of the customers of an authorized service, operating in the automative sector in Turkey, were analyzed using Apriori and FP-Growth Algorithms. This way, it is observed which products were purchased together by customers and in line with this observation, campaigns and promotions were given a direction to increase the profit.
C89|A bibliometric account of Chinese economics research through the lens of the China Economic Review|Very few studies on the assessment and evolution of Chinese economics research draw on quantitative methods, namely bibliometrics. Bibliometrics is a powerful tool that helps to explore, organize and analyze large amounts of information in a quantitative manner. Selecting the most important economic journal focusing on the Chinese economy – the China Economic Review (CER) – we classified and assessed all the (512) articles that have been published in CER from its founding (1989) to December 2010. Based on these articles, and undertaking an exploratory statistical analysis on three databases – a ‘bibliographic’ database (512 articles), a ‘roots’ database (over 10 thousand citations), and an ‘influence’ database (over 3 thousand citations), we concluded that: 1) ‘Economic Development, Technological Change, and Growth’; ‘Economic Systems’, and ‘International economics’ are the most important topics for Chinese economics literature; 2) there is a trend in Chinese economics research for growing ‘rigor’, associated to a noticeable rise in the weight of formal/mathematical-based articles; 3) the ‘International economics’ topic does not influence nor is it influenced by Chinese economics literature; and 4) Chinese economics literature is characterized by a certain level of endogamy, given that its range of influence is rather concentrated (geographically) in China and the USA.
C89|List randomization for sensitive behavior: An application for measuring use of loan proceeds|Policymakers and microfinance institutions (MFIs) often claim to target poor entrepreneurs who then invest loan proceeds in their businesses. Typically in non-research settings these claims are assessed using readily available but unverified self-reports from client loan applications. Alternatively, independent surveyors could directly elicit how borrowers spent their loan proceeds. That too, however, could suffer from deliberate misreporting. We use data from the Peru and the Philippines in which independent surveyors elicited loan use both directly (i.e., by asking how individuals spent their loan proceeds) and indirectly (i.e., through a list-randomization technique that allows individuals to hide their answer from the surveyor). We find that direct elicitation under-reports the non-enterprise uses of loan proceeds.
C89|What are the starting points? Evaluating base-year assumptions in the Asian Modeling Exercise|A common feature of model inter-comparison efforts is that the base year numbers for important parameters such as population and GDP can differ substantially across models. This paper explores the sources and implications of this variation in Asian countries across the models participating in the Asian Modeling Exercise (AME). Because the models do not all have a common base year, each team was required to provide data for 2005 for comparison purposes. This paper compares the year 2005 information for different models, noting the degree of variation in important parameters, including population, GDP, primary energy, electricity, and CO2 emissions. It then explores the difference in these key parameters across different sources of base-year information. The analysis confirms that the sources provide different values for many key parameters. This variation across data sources and additional reasons why models might provide different base-year numbers, including differences in regional definitions, differences in model base year, and differences in GDP transformation methodologies, are then discussed in the context of the AME scenarios. Finally, the paper explores the implications of base-year variation on long-term model results.
C89|Common Risk Factors and the Macroeconomy: New Evidence from the Japanese Stock Market|Using new data on returns and risk factors the paper considers the stock performance on the Japanese market, which is the second largest in the world and operates under unique macroeconomic conditions. We find that the CAPM model is not an adequate approach for the Japanese market. The Carhart model performs reasonably well but fails to reject the null hypothesis of a zero intercept for the full period. Extended tests reveal a structural change in asset prices in the year 1998. When separating the sample into two periods, the standard four factor model explains market returns much better. We show that the relation between stock returns and risk factors is affected by macroeconomic conditions, especially when considering the momentum strategy. The Japanese case illustrates the necessity of considering structural instability related to the macroeconomic development, which is especially important for countries and time periods with a sluggish economy.
C89|Disparities in municipal waste management across EU-27. A geographical approach|Inadequate waste management leads to many environmental issues and the adoption of an efficient and sustainable waste management has become a priority objective of the EU. However, besides the demographic factors, the various socio-economic and geographical conditions of this complex space lead to major disparities in municipal waste management between North and South, East and West. This paper aims to do a spatial-temporal analysis of the Eurostat indicators using ascending hierarchical cluster analysis that divides the member states into five typological classes. The resulted maps highlight territorial disparities among Member States on municipal waste management and also reveal the evolution of environmental policies between 2003-2009 related to the EU acquis.
C89|UK cross-sectional equity data: The case for robust investability filters|We propose a novel approach to cross-sectional equities sample selection, derived from best market practice in index construction and focused on investability. Using the UK market as a template, we first demonstrate how the popular Datastream dataset is plagued by data deficiencies that would surely invalidate statistical inferences, and that are not addressed by commonly used filters. We show the benefits and need for a supplementary data source. We then develop robust investability filters to ensure statistical results from cross-sectional analysis are economically meaningful, an issue overlooked by most studies on cross-sectional equity risk pricing.
C89|Disparities in municipal waste management across EU-27. A geographical approach|Inadequate waste management leads to many environmental issues and the adoption of an efficient and sustainable waste management has become a priority objective of the EU. However, besides the demographic factors, the various socio-economic and geographical conditions of this complex space lead to major disparities in municipal waste management between North and South, East and West. This paper aims to do a spatial-temporal analysis of the Eurostat indicators using ascending hierarchical cluster analysis that divides the member states into five typological classes. The resulted maps highlight territorial disparities among Member States on municipal waste management and also reveal the evolution of environmental policies between 2003-2009 related to the EU acquis.
C89|Economic History or History of Economics? A Review Essay on Sylvia Nasar's Grand Pursuit: the Story of Economic Genius|In this essay I review Sylvia Nasar's long awaited new history of economics, Grand Pursuit. I describe how the book is really an economic history of the period from 1850-1950, with distinguished economists' stories inserted in appropriate places. Nasar's goal is to show how economists work, but also to show that they are people too--with more than enough warts and foibles to show they are human! I contrast the general view of the role of economics in Grand Pursuit with Robert Heilbroner's remarkably different conception in The Worldly Philosophers. I also discuss more generally the question of why economists might be interested in their history at all.
C89|Selection Of An Organization Specific Erp|Technology development and competitive conditions being changed encourages more medium and high level companies to find different solutions. The integrated software systems, starting with the use of the computers in the production sectors, turned into giant program packs, which today are named ERP. Before the use of these systems, there is a well thought selection process needed. The most important part of adopting an ERP system is the selection part where specialized consultancy is always of great help. Some companies choose to ignore this step because of the additional costs, taking bad decisions which as mentioned, can lead to significant financial losses.
C89|Máximo aprovechamiento de métodos de actualización matricial|There exist a huge number of updating methods for input-output tables, some of them simple and others more complex, depending on their formulation. The information available to enable the application of these methods differs; hence certain methods cannot be used in some models. In practice, the reference figures needed to use non-survey tools are published by statistical offices with certain delay. For this reason, updated tables are available only at a later stage. This paper puts forward, from a global perspective, an adjustment procedure for those cases where information is scarce. Specifically, an explanation is given as to how the RAS method can be applied without needing to know the row and column sums of the relevant matrices.
C89|Actualización global de tablas origen-destino: una alternativa al método Euro|The application of RAS-SU requires prior knowledge of the row and column sums of the matrices in question. The Euro method avoids this limitation; however it is only applicable to square matrices and it is not always convergent. In this paper, the global updating method is adapted to supply and use tables. The main focus is on indicating how rectangular matrices can be adjusted, without the need of any prior manipulation, and on ensuring the convergence of the results obtained. The global updating method is based on a distribution of the differences between vectorial estimations. It is more generic than the RAS method, and offers more routes to action. In general, one has to consider the relative weights attributable to each differential distribution. Needless to say, the availability of additional information in relation to the matrix structure would lighten the task.
C89|On the Construction of Common Size, Value and Momentum Factors in International Stock Markets: A Guide with Applications|Demand is growing for a better understanding of how assets are priced in countries outside of the U.S. While financial data are available for many firms world-wide, it is important to have a reliable and replicable method of constructing high-quality systematic risk factors from these data. This paper first documents that appropriately screened data from Thomson Reuters Datastream and Thomson Reuters Worldscope can be used to replicate closely not only U.S. market returns and the corresponding momentum risk factor (as existing work has suggested), but also the widely-used U.S. size and value risk factors. We then build novel pan-European and country-specific momentum, size, and value risk factors. By comparing our pan-European market returns and risk factors with their counterparts in the U.S., we find that they are astonishingly highly correlated. The factors we compute are made available to other researchers.
C89|Volunteer Computing Model Prospects in Performance Data Gathering for Broadband Policy Formulation|The recent unprecedented growth of telecom facilities has offered the Internet users in most Asian countries a flavour of broadband. Yet, despite rosy promises by telcos, the user experience has often been less than ideal. These challenges can only be overcome by right policy decisions based on evidences. Thus, monitoring the broadband Quality of Service Experience (QoSE) becomes more than an attempt to ensure quality delivery and create a basis for policy formulation. The first approach to monitoring QoSE, is the regulator reaching deep into the innards of the telecom network to install monitoring equipment and taking remedial actions, specified under the licenses or the governing statute, when the data indicate below-standard performance. Dearth of financial and human resources can be the key challenge in such a direct approach. The second approach is based largely on user activism, where educated users voluntarily contribute their time and computing resources towards building a performance database which in turn will be used in creating the bigger picture. A comprehensive methodology to benchmark Broadband Quality of Service Experience (QoSE), based on the latter approach has been developed jointly by LIRNEasia and TeNet group of Indian Institute of Technology (IIT) Madras. This methodology uses AT-Tester, an a open source based software tool to monitor all crucial QoSE broadband metrics over a longer period, on both week days and week days covering peak as well as off peak traffic. The traffic is also monitored within segments, ISP, local and international. The methodology adapts the concept of Volunteer Computing (or Public Service Computing). The paper analyses how this approach could be used in broadband policy formulation.
C89|Approaches to samples selection for machine learning based classification of textual data|The paper focuses on retrieval of relevant documents written in a natural language based on availability of several candidate examples which are used as the basis for the automatic selection of only items that are similar to these predefined patterns. Presented approach should face problems related to processing user created content in natural language that include a poor control over the topic and the structure of the content and often also huge computational complexity. Three methods of selecting the best samples from a large set of candidate samples are presented - random selection, manual selection and a new approach called automatic biased sample selection, and measures based on Euclidean distance and cosine similarity are used for classification. The experiments are carried out with real world data consisting of customer reviews downloaded from amazon.com, converted to different representations based on bag-of-words procedure. The experiments and the results of the presented approach provided satisfactory values and can lead to an alternative approach to manual selection and evaluation of textual samples.
C89|A Hybrid Architecture For Context-Aware Systems|Today applications give us complex services in behalf of the user no matter of location, time or hardware infrastructure. There is a growing realization that computer systems will need to be increasingly sensitive to their context. That is, the application can decide what to do, based not only on the explicitly presented input, but also on the context, and its result can affect not only the explicit output, but also the context. This paper describes the need for an extensible context framework with embedded features. A hybrid (symbolic/connectionist) architecture is proposed. It consists of a multitude of agents having both a symbolic and a connectionist part. The symbolic part represents some knowledge structure, while the connectionist part represents its relevance to the current context. The performance of the system emerges as a result of the work and interaction of the currently active agents, where the set of active agents is not predefined for a specific task but is dynamic and reflects the specific context.
C89|A Bibliometrics Portrait of Chinese Research through the Lens of China Economic Review. A research proposal|Notwithstanding, in the last two decades, there has been a noticeable increase in published work on the research field of Chinese economy. There are few studies, which analyze the evolution of Chinese economics research, and the weight of international economics within it, by resorting to objective methods, namely bibliometrics. Giving our focus on Chinese economics related research, we select to base our empirical analysis on the “seed journal” China Economic Review (CER), which is the most important economic journal especially concerned with the issues of Chinese economy. We classify and assess all the (522) articles that were published in CER from its genesis (1989) up to December 2010. We construct three main databases: the first database as bibliographic database that contains the more than 500 articles published in CER, where we classify articles by themes (such as Macroeconomics, Microeconomics and International Economics) and types(such as formal vs. empirical); the second database includes the references of those 500 articles, which we denominate ‘roots of Chinese economics research’; and the third database, the ‘influence of Chinese economics research’, where we have all the studies that cited (more than 3000 references) the 500 articles published in CER. By undertaking an exploratory statistical analysis on the three databases - bibliographic database, ‘roots’ database and ‘influence’ database, we are able to assess three main group of issues: 1) the importance, within Chinese economics of the topic ‘international economic’; the types of research that are pursued in the period of analysis (formal vs empirical); and the most prolific authors in the area; 2) the ‘roots’ of Chinese economics, that is, who and which outlets are influencing most Chinese economics research; 3) the scope of influence of Chinese economics literature.
C89|Mapping the (in)visible college(s) in the field of entrepreneurship|Abstract Despite the vitality and dynamism that the field of entrepreneurship has experienced in the last decade, the issue of whether it comprises an effective network of (in)formal communication linkages among the most influential scholars within the area has yet to be examined in depth. This study follows a formal selection procedure to delimit the ‘relational environment’ of the field of entrepreneurship and to analyze the existence and characterization of (in)visible college(s) based on a theoretically well-grounded framework, thus offering a comprehensive and up-to-date empirical analysis of entrepreneurship research. Based on more than a 1,000 papers published between 2005 and 2010 in seven core entrepreneurship journals and the corresponding (85,000) citations, we found that entrepreneurship is an (increasingly) autonomous, legitimate and cohesive (in)visible college, fine tuned through the increasing visibility of certain subject specialties (e.g., family business, innovation, technology and policy). Moreover, the rather dense formal links that characterize the entrepreneurship (in)visible college are accompanied by a reasonably solid network of informal relations maintained and sustained by the mobility of ‘stars’ and highly influential scholars. The limited internationalization of the entrepreneurship community, reflected in the almost total absence of non-English-speaking authors/studies/outlets, stands as a major quest for the field.
C89|Where are the poor in International Economics?|Despite the fact that a very significant proportion of the human population is living with financial difficulties and other constraints typical of poverty, scientific studies in the areas of Economics and especially in International Economics that address the issue of poverty and of poor countries are very few. Using bibliometric techniques, we measured the attention paid by authors from the field of International Economics to poverty and poor countries. To this end, we sorted and analyzed all articles published in the most important journal in the field, the Journal of International Economics (JIE) over the last forty years. Evidence shows that the authors who have published articles in the JIE have mostly developed studies focused on ‘Meso (industry, region) and microeconomic policies and issues of ‘International Trade’ and ‘International Finances’, and are usually of the ‘Formal’ and ‘Formal and Empirical’ types, where the topic ‘Poverty’ is very marginal (only 13 articles published in the JIE, less than 1% of the total, address this matter in any of its dimensions). Furthermore, in the more empirical articles, no country among those included in the group ‘Less Developed Countries’ deserved particular attention. The neglect of poverty and of the poor contrasts (and is related to) with the significant weight of articles that make use of formalization (more than 80%). Despite the trend for a decrease in exclusively ‘Formal’ articles, without any applied/empirical component, the (still) excessive focus on ‘mathematical’ accuracy (i.e., formalization), and the concomitant limited capacity to deal with the (social) problems of the real world, is an effective challenge to authors in the field of international economics and, in particular, to those who publish in the JIE, which must be overcome if we do not want international economics to become a “cyborg” science.
C89|A data-based power transformation for compositional data|Compositional data analysis is carried out either by neglecting the compositional constraint and applying standard multivariate data analysis, or by transforming the data using the logs of the ratios of the components. In this work we examine a more general transformation which includes both approaches as special cases. It is a power transformation and involves a single parameter�. The transformation has two equivalent versions. The �first is the stay-in-the-simplex version. This expression is the power transformation as de�fined by Aitchison (1986). The second version, which is a linear transformation of the stay-in-the-simplex, is a Box-Cox type transformation. We call the second version the isometric �alpha-transformation because of the multiplication with the Helmert sub-matrix. We discuss a parametric way of estimating the value of alpha�, which is maximization of its pro�le like-lihood (assuming multivariate normality of the transformed data) and the equivalence between the two versions is exhibited. Other ways include maximization of the correct classi�cation probability in discriminant analysis and maximization of the pseudo-R2 in linear regression. We examine the relationship between the transformation, the raw data approach and the isometric log-ratio transformation. Furthermore, we also de�fine a suitable family of metrics corresponding to the family of �alpha-transformation and consider the corresponding family of Fr�echet means.
C89|Research of higher engineering education quality on the base of students Interviewing data by nonlinear principal components analysis (NLPCA)|The paper explores a suitability of higher education quality measurement from student’s point of view, and analyses results of interviewing of students from engineering specialties in Perm universities. Nonlinear Principal Components Analysis (NLPCA) in interpretation of Gifi system was used as the tool for data processing. It takes into account a dissimilar statistical nature of questionnaire indicators. The method can be very promising for various socio-economic researches.
C89|Scientometric approach to nanotechnology|The article provides a brief bibliometric analysis of the development of nanotechnology with an estimate of the positions of Russia, including in areas such as carbon nanostructures, and nanophotonics. A number of characteristics of research personnel that are relevant for assessing the prospects of nanotechnology development in our country are calculated. Initial statistics for this analysis were extracted from the database SCI-Expanded (ISI Web of Knowledge). Some data from the domestic databases: of Russian Foundation for Basic Research (RFBR) and Rospatent were also used
C89|Amenazas ambientales y vulnerabilidad en un contexto de variabilidad climática en Bolivia|El objetivo del presente trabajo de investigación es mostrar el impacto de las amenazas de la inundación, la sequía y la helada en el bienestar de las diferentes regiones de Bolivia, tomando a las vulnerabilidades como variables de aproximación a los indicadores socioeconómicos de bienestar. La investigación aporta al estado del conocimiento con un nuevo método para estimar e identificar los impactos en el bienestar socioeconómico producido por el cambio climático, a partir de la combinación del análisis de la variabilidad climática con la inteligencia artificial. Para lograr el objetivo planteado de identificar las relaciones entre amenazas, vulnerabilidades y el bienestar se construyen diversos Sistemas Expertos (los mismos que pertenecen al área de la Inteligencia Artificial) con base en el algoritmo C4.5. El algoritmo tiene como característica principal que permite ensamblar los árboles de decisión con base en tablas de datos, haciendo de esta manera el trabajo de reconocimiento de patrones mediantes testores. El reconocimiento de patrones permite describir el incremento o decremento del bienestar producido por las variables objeto de estudio.
C89|Zur Stabilität von Saisonbereinigungsverfahren: Eine Echtzeitdaten-Analyse am Beispiel BV4.1 und X-12-ARIMA|No abstract is available for this item.
C89|Using social media data to understand mobile customer experience and behavior|Understanding mobile customer experience and behavior is an important task for cellular service providers to improve the satisfaction of their customers. To that end, cellular service providers regularly measure the properties of their mobile network, such as signal strength, dropped calls, call blockage, and radio interface failures (RIFs). In addition to these passive measurements collected within the network, understanding customer sentiment from direct customer feedback is also an important means of evaluating user experience. Customers have varied perceptions of mobile network quality, and also react differently to advertising, news articles, and the introduction of new equipment and services. Traditional methods used to assess customer sentiment include direct surveys and mining the transcripts of calls made to customer care centers. Along with this feedback provided directly to the service providers, the rise in social media potentially presents new opportunities to gain further insight into customers by mining public social media data as well. According to a note from one of the largest online social network (OSN) sites in the US [7], as of September 2010 there are 175 million registered users, and 95 million text messages communicated among users per day. Additionally, many OSNs provide APIs to retrieve publically available message data, which can be used to collect this data for analysis and interpretation. Our plan is to correlate different sources of measurements and user feedback to understand the social media usage patterns from mobile data users in a large nationwide cellular network. In particular, we are interested in quantifying the traffic volume, the growing trend of social media usage and how it interacts with traditional communication channels, such as voice calls, text messaging, etc. In addition, we are interested in detecting interesting network events from users' communication on OSN sites and studying the temporal aspects - how the various types of user feedback behave with respect to timing. We develop a novel approach which combines burst detection and text mining to detect emerging issues from online messages on a large OSN network. Through a case study, our method shows promising results in identifying a burst of activities using the OSN feedback, whereas customer care notes exhibit noticeable delays in detecting such an event which may lead to unnecessary operational expenses.
C89|A Best Evidence Synthesis On The Link Between Budgetary Participation And Managerial Performance|Using the best evidence synthesis method (Slavin, 1995), we find out an accurate summary on the link between budgetary participation (BP) and managerial performance (MP). The use of selection criteria allowed to decrease the heterogeneity. Our results report the presence of the heterogeneity by cultural and industrial contingencies. American surveys reveal a significant positive link but suffer from heterogeneity of the sample. Under the sample homogeneity principle, Australian surveys reveal a non-significant negative link and only Taiwanese surveys reveal a positive and significant link. This last result has to encourage researchers to continue the study of publicly traded firms in the Taiwan Stock Exchange to study the causal link between the two variables with a Granger test and to study the evolution of this link over time in other countries.
C89|Are International Databases on Corruption Reliable? A Comparison of Expert Opinion Surveys and Household Surveys in Sub-Saharan Africa|"Summary This study examines the limits of global corruption indicators based on experts' perceptions. It draws on a wave of original surveys conducted in eight African countries that combined two types of approaches. The first approach covers a sample of over 35,000 people and uses experience-based questions to measure petty bureaucratic corruption. The second (Mirror Survey) reports 350 experts' opinions. A comparison of these two sources paints a clear picture of the experts' errors of assessment. We also find evidence for ideological biases, with experts tending to rank countries based on their own political preferences, and the existence of an erroneous implicit cultural model of ""how Africa works""."
C89|Adjustment of age-related height decline for Chinese: a ‘natural experiment’ longitudinal survey using archival data|"""Height data are a useful and concise summary measure of human welfare for historical populations in absence of conventional economical data. Most historical studies use the final attained height of adults aged between about 20-23 and 49 years on the premise that younger subjects were still growing and older subjects had begun to shrink. Data outside this range are discarded. For many studies the data lost is small and of little consequence for the study. However, where the sample includes many people older than 50 years the exclusion of these may make analysis impractical because of the resulting small sample size. Several studies have used a variety of approaches adjust height-for-age of older subjects to estimate the original attained height before next estimating the secular trend in heights. These adjustments are based on studies of the aging of European-origin populations, which may not fit the pattern observed in other human populations, such as the Chinese. In this paper I use data for nineteenth-century born Chinese immigrants to Australia whose heights were recorded repeatedly to simulate a longitudinal age-related height shrinkage study. The estimates of shrinkage are compared with estimates from other studies and applied to other archive-derived height data for Chinese to examine the reliability of adjusted height estimates in calculating secular trends in height, and in turn making inferences about their welfare."""
C89|A Novel Suite of Methods for Mixture Based Record Linkage|Record Linkage (RL) aims at identifying pairs of records coming from different sources and representing the same real world object. Despite several methods have been proposed to face RL problems, none of them seems to be at the same time fully automated and very effective. In this paper we present a novel suite of methods that instead possesses both these abilities. We adopt a mixt pure-model based approach, which structures a RL process into two consecutive tasks. First, mixture parameters are estimated by fitting the model to observed distance measures between pairs. Then, a probabilistic clustering of the pairs into Matches and Unmatches is obtained by exploiting the fitted model. In particular, we use a mixture model with component densities belonging to the Beta parametric family and we fit it by means of an original perturbation-like technique. Moreover, we solve the clustering problem according to both Maximum Likelihood and Minimum Cost objectives. To accomplish this task, optimal decision rules fulfilling one-to-one matching constraints are searched by a purposefully designed evolutionary algorithm. We present several experiments on real data that validate our methods and show their excellent effectiveness
C89|Informatics Systems With Integrated Data Mining Techniques Designed for the Economic Environment|Data mining techniques can be successfully integrated into informatics systems from multiple fields to find solutions to problems. For these techniques to be used they need to be integrated into informatics systems with data to be analyzed. Among the many areas of application of data mining systems one of the most important is the economy. Applying data mining techniques in the economy can bring many benefits to companies that use them, both in their business and at management level. Therefore in the future the data mining systems market is expected to significantly, once this technology has reached maturity.
C89|Recent trends in the economics of innovation literature through the lens of Industrial and Corporate Change|Literature on the economics of innovation has been in constant change. We quantitatively assess recent trends in this literature in terms of research topics and types of research. Departing from a comprehensive qualitative and quantitative survey of influential innovation handbooks, this paper draws on the review and analysis of all articles published in Industrial and Corporate Change, since its foundation to 2009. Our results reveal that ‘Conceptual/Economic Thought’, ‘Intellectual Property Rights’, and ‘Measurement of Innovation’ topics have shown striking trends over the period in analysis. Moreover, although both ‘Appreciative plus Empirical’ and ‘Formal plus Empirical’ types of research have grown, suggesting a ‘virtuous’ trend towards the analytical and predictive efficacy of theory, purely ‘Empirical’ studies have markedly increased, which may indicate that a connection between theory and empirics is (increasingly) lacking in the field of the economics of innovation.
C89|Business intelligence as the support of decision-making processes in e-commerce systems environment|The present state of world economy urges managers to look for new methods, which can help to start the economic growth. To achieve this goal, managers use standard as well as new procedures. The fundamental prerequisite of the efficient decision-making processes are actual and right information. Managers need to monitor past information and current actual information to generate trends of future development based on it. Managers always should define strictly what do they want to know, how do they want to see it and for what purpose do they want to use it. Only in this case they can get right information applicable to efficient decision-making. Generally, managers´ decisions should lead to make the customers´ decision-making process easier. More frequently than ever, companies use e-commerce systems for the support of their business activities. In connection with the present state and future development, cross-border online shopping growth can be expected. To support this, companies will need much better systems providing the managers adequate and sufficient information. This type of information, which is usually multidimensional, can be provided by the Business Intelligence (BI) technologies. Besides special BI systems, some of BI technologies are obtained in quite a few of ERP (Enterprise Resource Planning) systems. One of the crucial questions is whether should companies and firms buy or develop special BI software, or whether they can use BI tools contained in some ERP systems. In respect of this, there is a question if the modern ERP systems can provide the managers sufficient possibilities relating to ad-hoc reporting, static and dynamic reports and OLAP analyses. A one of the main goals of this article is to show and verify Business Intelligence tools of Microsoft Dynamics NAV for the support of decision-making in terms of the cross-border online purchasing. Pursuant to above-mentioned, in this article authors deal with problems relating to managers´ decision-making, customers´ decision-making and a support of its using the BI tools contained in ERP system Microsoft Dynamics NAV. A great deal of this article is aimed at area of multidimensional data which are the source data of e-commerce systems.
C89|Commodity-industry classificationproxy: A correspondence table between SITC revision 2 and ISIC revision 3|The correspondence table is one of the important tools in categorizing existing records into different perspective. It helps to understand the pattern of various economic activities from single source of data. Nevertheless, most of the existing correspondence tables have been focusing more on the latest classification and neglect the correspondence for the older version. Since some analysis would require longer series of data, therefore it is necessary to create a correspondence table for the earlier version of classification. This paper devoted to create a correspondence table between SITC Revision 2 and ISIC Revision 3 using a proxy method. The proxy is done using the SITC Rev.2 – SITC Rev.3 correspondence table and the SITC Rev.3 – ISIC Rev.3 correspondence table. This method has capable to directly find an industrial match for more than 98 percent of commodities under SITC Rev.3. For remaining commodities which industrial category cannot be matched directly, the identification was done automatically based on the closest code.
C89|Modalităţi de integrare a tehnicilor data mining în sistemele informatice de management strategic|After the important progresses in information technology there appeared great volumes of data stored from different fields of human activity. From here there was a short way to developing advanced analysis techniques known as data mining. Using modern computer systems that integrate data mining techniques managers of economic enterprises have a powerful tool to analyze data previously collected. In most of the cases a data mining system works on data bases or data warehouses in order for managers to have access to useful knowledge that helps them to choose the enterprise future strategy.
C89|Analiza comparativă a instrumentelor data mining|Data mining systems on the market are usually produced by companies from fields of activity like databases, statistical analysis. Enterprises can choose from a wide variety of commercial data mining tools to pick one that best suites their needs and can operate with the type of data they have. In order to do this job there are a number of things to take into account before buying a data mining system. Finally there is an analysis of how much companies use data mining tools and how managers see these tools in solving different problems.
C89|Speicherung und Publikation von Forschungsdaten. Der Beitrag der Deutschen Zentralbibliothek für Wirtschaftswissenschaften|Die ZBW (Deutsche Zentralbibliothek für Wirtschaftswissenschaften) beschäftigt sich vor allem im Kontext ihrer Open-Access-Aktivitäten mit Forschungsdaten. Dabei stehen die Daten nicht allein, sondern sind jeweils auf eine bestimmte Text-Publikation bezogen und werden mit dieser zusammen veröffentlicht („related data“). Im Vortrag wird anhand des Open-Access-Journals „Economics“ und des EU-Projekts „NEEO – Networked of European Economists Online“ dargestellt, in welcher Form Forschungsdaten hier eine Rolle spielen und welche spezifischen Rahmenbedingungen für das Management der Daten bestehen. Daran anschließend werden die gewählten technischen und organisatorischen Lösungen zur Speicherung und Bereitstellung vorgestellt.
C89|DataCite: The International Data Citation Initiative Datasets Programme|DataCite is an international consortium which aims to increase acceptance of research data as legitimate, citable contributions to scholarly communication. To enable this DataCite assigns persistent identifiers for research datasets and manages the infrastructu res that support simple and effective methods of data citation, discovery and access. DataCite leverages the DOI infrastructure, which is already well-established. DOI names are the mostly widely used identifier for scientific journal articles, so researchers, authors, and publishers are familiar with their use. DataCite takes an open approach, however, and considers identifier systems and services that help forward its objectives. DataCite is represented in the UK by the British Library. This summary of the British Library’s involvement in DataCite was presented to the UK data Forum on Monday the 15th November 2010. Data publishers that wish to know more about DataCite or to use DataCite services are encouraged to contact the Library or their local DataCite members. Further information and useful websites: www.datacite.org.uk / www.datacite.org / www.doi.org
C89|Reform der Unternehmensstatistik in Deutschland: Qualitätskonzept des Programms|No abstract is available for this item.
C89|Do Forecasters Inform or Reassure? Evaluation of the German Real-Time Data|The paper evaluates the quality of the German national accounting data (GDP and its useside components) as measured by the magnitude and dispersion of the forecast / revision errors. It is demonstrated that government consumption series are the least reliable, whereas real GDP and real private consumption data are the most reliable. In addition, early forecasts of GDP, private consumption, and investment growth rates are shown to be systematically upward biased. Finally, early forecasts of all the variables seem to be no more accurate than naïve forecasts based on the historical mean of the final data.
C89|Implementation of Funding for the German Socio-Economic Panel (SOEP): A Personal Recollection|"The SOEP success story was not conceivable at its inception. SOEP's institutionalization is therefore a lesson demonstrating that it is not always possible to say - as is so often required of research proposals today - how a project will develop before it has even begun, and what significance it may one day have. Or, even worse, to show ""how a research project will pay off""."
C89|The German Socio-Economic Panel (SOEP) in the Nineties: An Example of Incremental Innovations in an Ongoing Longitudinal Study|The main aim of the present paper is to historically reappraise the development of the German Socio-Economic Panel Study (SOEP) in the 1990s after the first six waves had been collected. This development was closely connected to the opening of the Iron Curtain in Eastern Europe and the fall of the Wall separating the two German states. In addition to its relevance for the SOEP, this study is also of interest in relation to the contemporary history of science.
C89|Geben Konjunkturprognosen eine gute Orientierung?|Die vorliegende Bewertung der Treffgenauigkeit von Prognosen sowie von vorläufigen amtlichen Berechnungen zur wirtschaftlichen Entwicklung in Deutschland zeigt, dass frühe Prognosen nicht nur sehr ungenau sind, sondern auch systematisch zu optimistisch ausfallen. Die mehr als ein Jahr im voraus erstellten Schätzungen im Rahmen der Gemeinschaftsdiagnose zur Wachstumsrate des realen Bruttoinlandsprodukts lagen im Zeitraum 1996 bis 2006 durchschnittlich um etwa die Hälfte über den später festgestellten tatsächlichen Werten. Eine deutliche Verbesserung der Zuverlässigkeit wird bei Prognosen für das jeweils laufende Jahr erzielt, und die ersten vorläufigen Berechnungen des Statistischen Bundesamtes unmittelbar nach Ablauf eines Jahres liegen bereits recht nahe bei den endgültigen Werten. Die Prognosen und vorläufigen Berechnungen zum Bruttoinlandsprodukt und zu den privaten Konsumausgaben sind am zutreffendsten, während die Konsumausgaben des Staates die am schlechtesten vorausgesagte Größe ist.
C89|Blogs, Wikis and Official Statistics: New Perspectives on the Use of Web 2.0 by Statistical Offices|This paper explains the roles that blogs, wikis and social networking play in the provision and dissemination of official statistics.
C89|Enseignement d'une meta-analyse sur le lien participation budgétaire-performance managériale<BR>[Lesson from Meta-analysis for the relation between budgetary participation and managerial performance]|This meta-analysis is a critical comparison of three of quantitative synthesis. It applies some propositions of the Potsdam international consultation on meta-analysis, in the field of management control. Study design. After a traditional narrative review, three meta-analysis methodologies for the synthesis of articles with heterogeneous methodologies and fields are presented. After a short critical presentation of our results with “box score” and p-values combination methods, we show the result of best-evidence synthesis and its stability as recommended at the Potsdam international consultation on meta-analysis. Results. The results of the methods of meta-analysis implemented do not make it possible to conclude without prudence. The link “budget participation-managerial performance” paradoxically seems negative for the articles of better quality.
C89|The friction force mouse-pad and the forearm muscles efforts (preliminary results)|The objective of the article is to evaluate the impact of the friction force mouse-pad in the contraction level of the forearm muscles M. extensor carpi ulnaris, M. extensor digitorum M. extensor carpi radialis longus.A standard protocol of mouse movements was performed involving horizontal, vertical and diagonal mouse displacements drag-and-drop type. The operators were instructed to execute the protocol with their normal working speed. The movements protocol were performed by each subject (n=17) with three selected pairs mouse-pad, classified as low, medium and high friction force pairs. The mean time to execute the protocol with each mouse was ~138s. Mean values of ~13%MVE and ~17%MVE were found in the M. extensor carpi ulnaris and in the M. extensor digitorum respectively when performing the movements’ protocol. A 8.1% increase in %MVE was observed in the M. extensor digitorum and a 9.4% increase in %MVE was observed in the M. extensor carpi ulnaris when the high friction force pair was operated, relatively to the low friction force pair (p
C89|A Characterization for the Spherical Scoring Rule|No abstract is available for this item.
C89|Do forecasters inform or reassure?|The paper evaluates the quality of the German national accounting data (GDP and its use-side components) as measured by the magnitude and dispersion of the forecast/ revision errors. It is demonstrated that government consumption series are the least reliable, whereas real GDP and real private consumption data are the most reliable. In addition, early forecasts of GDP, private consumption, and investment growth rates are shown to be systematically upward biased. Finally, early forecasts of all the variables seem to be no more accurate than naive forecasts based on the historical mean of the final data.
C89|Notes on the Construction of Geometric Representations of Confidence Intervals of Ratios using Stata, Gauss and Eviews|These notes demonstrate how one can define optimization problems whose solutions can be interpreted as the Delta and the Fieller confidence intervals for a ratio of normally distributed parameter estimates. Also included in these notes are the details of the derivation of the slope of a constraint ellipse that is common to both optimizations. In addition, these notes provide an example of how one might generate a graphic representation of both optimization problems using the Stata, Gauss and Eviews statistical computer programs.
C89|Notes on the Construction of Geometric Representations of Confidence Intervals of Ratios using Stata, Gauss and Eviews|These notes demonstrate how one can define optimization problems whose solutions can be interpreted as the Delta and the Fieller confidence intervals for a ratio of normally distributed parameter estimates. Also included in these notes are the details of the derivation of the slope of a constraint ellipse that is common to both optimizations. In addition, these notes provide an example of how one might generate a graphic representation of both optimization problems using the Stata, Gauss and Eviews statistical computer programs.
C89|Toward A Distributed Data Mining System For Tourism Industry|Romania has a huge tourist’s potential, but currently it is too little valued and exploited. As a result, one of the strategic developments of the economy aimed the tourism industry. The strategic decisions are based on different trends obtained from soph
C89|Representation-Constrained Canonical Correlation-Analysis: A Hybridization Of Canonical Correlation And Principal Component Analysis|The classical canonical correlation analysis is extremely greedy to maximize the squared correlation between two sets of variables. As a result, if one of the variables in the dataset-1 is very highly correlated with another variable in the dataset-2, the canonical correlation will be very high irrespective of the correlation among the rest of the variables in the two datasets. We intend here to propose an alternative measure of association between two sets of variables that will not permit the greed of a select few variables in the datasets to prevail upon the fellow variables so much as to deprive the latter of contributing to their representative variables or canonical variates. Our proposed Representation-Constrained Canonical correlation (RCCCA) Analysis has the Classical Canonical Correlation Analysis (CCCA) at its one end (t=0) and the Classical Principal Component Analysis (CPCA) at the other (as t tends to be very large). In between it gives us a compromise solution. By a proper choice of t, one can avoid hijacking of the representation issue of two datasets by a lone couple of highly correlated variables across those datasets. This advantage of the RCCCA over the CCCA deserves a serious attention by the researchers using statistical tools for data analysis.
C89|Enseignements d'une meta-analyse sur le lien participation budgétaire - performance managériale|"This meta-analysis is a critical comparison of three of quantitative synthesis. It applies some propositions of the Potsdam international consultation on meta-analysis, in the field of management control. Study design. After a traditional narrative review, three meta-analysis methodologies for the synthesis of articles with heterogeneous methodologies and fields are presented. After a short critical presentation of our results with ""box score"" and p-values combination methods, we show the result of best-evidence synthesis and its stability as recommended at the Potsdam international consultation on meta-analysis. Results. The results of methods of meta-analysis implemented do not make it possible to conclude without prudence. The link ""budget participation-managerial performance"" is not statistically significant for the articles of better quality."
C89|E-commerce Systems and E-shop Web Sites Security|Fruitfulnes of contemporary companies rests on new business model development, elimination of communication obstacles, simplification of industrial processes, possibilities of responding in real-time and above all meeting the floating custom needs. Quite a number of company activities and transactions are realized within the framework of e-business. Business transactions are supported by e-commerce systems. One of the e-commerce system part is web interface (web sites). Present trend is putting the accent on security. E-commerce system security and web sites security is the most overlooked aspect of securing data. E-commerce system security depends on technologies and its correct exploitation and proceedings. If we want e-commerce system and e-shops web sites with all services to be safety, it is necessary to know all possible risks, use up to date technologies, follow conventions of web sites development and have good security management system. The article deals with definition and description of risk areas refer to e-commerce systems and e-shop web sites and show fundamental principles of e-commerce systems and e-shop web sites security.
C89|Communication and Procedural Models of the E-commerce Systems|E-commerce systems became a standard interface between sellers (or suppliers) and customers. One of basic condition of an e-commerce system to be efficient is correct definitions and describes of the all internal and external processes. All is targeted the customers´ needs and requirements. The optimal and most exact way how to obtain and find optimal solution of e-commerce system and its processes structure in companies is the modeling and simulation. In this article author shows basic model of communication between customers and sellers in connection with the customer feedback and procedural models of e-commerce systems in terms of e-shops. Procedural model was made with the aid of definition of SOA.
C89|A Neuro-Classification Model for Socio-Technical Systems|This paper presents an original classifier model based on an artificial neural network (ANN) architecture that is able to learn a specific human behavior and can be used in different socio-economic systems. After a training process, the system can identify and classify a human subject using a list of parameters. The model can be further used to analyze and build a safe socio-technical system (STS). A new technique is applied to find an optimal architecture of the neural network. The system shows a good accuracy of the classifications even for a relatively small amount of training data. Starting from a previous result on adaptive forecasting, the model is enhanced by using the retraining technique for an enlarged data set.
C89|Variable selection in model-based clustering using multilocus genotype data|No abstract is available for this item.
C89|On the divergence of evolutionary research paths in the past 50 years: a comprehensive bibliometric account|No abstract is available for this item.
C89|Determination of the internal cession price in the commercial banks through mathematical methods - A case study|Present a case study comes to confirm theoretical suppositions formulated by the authors, which asserts that in commercial banks we can determine internal cession price using mathematical methods – like the offered by matrix system of linear programming.
C89|Surveying structural change: Seminal contributions and a bibliometric account|Structural change analysis has an important tradition in economic theory. However, up to the present date, no attempt had been made to provide an overall survey on the matter. This paper aims to fill this gap. To this end, bibliometric methods were applied, combining 9703 citations from the area's 'seed journal' with a review of 910 abstracts of all theoretical and empirical articles on structural change that were published over the past 40 years in the journals indexed in the Econlit. We testify the recent rise of interest in structural change where technological issues gained increasing relevance. The 1990s witnessed a spurt in formal work, but more recently such trend was not confirmed; on the contrary, there has been a strong impetus towards empirically led work. Our analysis further reveals that most contributions put great emphasis on technology-driven growth and lack an appropriate treatment of the demand side.
C89|Automatic Term Identification for Bibliometric Mapping|A term map is a map that visualizes the structure of a scientific field by showing the relations between important terms in the field. The terms shown in a term map are usually selected manually with the help of domain experts. Manual term selection has the disadvantages of being subjective and labor-intensive. To overcome these disadvantages, we propose a methodology for automatic term identification and we use this methodology to select the terms to be included in a term map. To evaluate the proposed methodology, we use it to construct a term map of the field of operations research. The quality of the map is assessed by a number of operations research experts. It turns out that in general the proposed methodology performs quite well.
C89|Does the Effect of Incentive Payments on Survey Response Rates Differ by Income Support History?|This paper asks which sub-groups of the population are affected by the payment of a small cash incentive to respond to a telephone survey. We find that an incentive improves response rates primarily amongst those individuals with the longest history of income support receipt. Importantly, these individuals are least likely to respond to the survey in the absence of an incentive. The incentive thus improves both average response rates and acts to equalize response rates across different socio-economic groups, potentially reducing non-response bias. Interestingly, the main channel through which the incentive appears to increase response rates is in improving the probability of making contact with individuals in the group with heavy exposure to the income support system.
C89|Time for play – An exploratory analysis of the changing consumption contexts of digital games|This study posits that Internet technologies are relaxing the coupling constraints required for the consumption of digital games, resulting in entirely different modes of consumption than has been the norm for the past thirty years. The data collection and analysis found that players of traditional console-based games tend to play for several hours at a time while at a home during evenings and on weekends, the traditional scenario associated with leisure activities. Players of the latest breed of online browser-based digital games, on the other hand, tend to play them for only a few minutes at a time, and at many times throughout the day as a diversionary filler activ-ity between other daily activities. Because they utilize simple and readily available Internet technologies, online browser-based games have facilitated the penetration of digital games into new spaces, including the workplace and school, reflecting a growing trend in modern society.
C89|Computer Virus Propagation in a Network Organization: The Interplay between Social and Technological Networks| This paper proposes a holistic view of a network organization’s computing environment to examine computer virus propagation patterns. We empirically examine a large-scale organizational network consisting of both social network and technological network. By applying information retrieval techniques, we map nodes in the social network to nodes in the technological network to construct the composite network of the organization. We apply social network analysis to study the topologies of social and technological networks in this organization. We statistically test the impact of the interplay between social and technological network on computer virus propagation using a susceptible-infective-recovered epidemic process. We find that computer viruses propagate faster but reach lower level of infection through technological network than through social network, and viruses propagate the fastest and reach the highest level of infection through the composite network. Overlooking the interplay of social network and technological network underestimates the virus propagation speed and the scale of infection.
C89|National Systems of Innovation: a bibliometric appraisal|The literature on NSI is a relatively new field of research with a quite impressive diffusion rate in the last 15 years. Although the concept of NSI is nowadays widely used both in academic and policy contexts, and a set of comprehensive theoretical surveys were published in the most recent years, no ‘quantitative’ survey exists on this matter. The present paper aims to fill this gap. We offer a complementary, ‘quantitative’, description of the state-of-the-art in the literature resorting to bibliometric methods. Our exercise shows that the time evolution of articles published was quite irregular, and that the NSI contributions have not converged to an integrated framework. We further evidence that historically detailed descriptions on NSI à la Freeman are rare, and analyses using more rigorous and diversified quantitative methodologies for assessing the performance of NSI are on demand. The huge increase in the share of ‘Conceptual/critical meta-literature on NSI’ in the latter (2001-2007) periods interestingly documents the conceptual dynamism and methodological-analytical challenges faced presently by NSI approach.
C89|Time for play – An exploratory analysis of the changing consumption contexts of digital games|This study posits that Internet technologies are relaxing the coupling constraints required for the consumption of digital games, resulting in entirely different modes of consumption than has been the norm for the past thirty years. The data collection and analysis found that players of traditional console-based games tend to play for several hours at a time while at a home during evenings and on weekends, the traditional scenario associated with leisure activities. Players of the latest breed of online browser-based digital games, on the other hand, tend to play them for only a few minutes at a time, and at many times throughout the day as a diversionary filler activ-ity between other daily activities. Because they utilize simple and readily available Internet technologies, online browser-based games have facilitated the penetration of digital games into new spaces, including the workplace and school, reflecting a growing trend in modern society.
C89|Some new indicators and procedure to get additional information from the Business Tendency Surveys|This paper sets out some procedure allowing to deriving new information from the Business Tendency Surveys. Precisely, the volatility of respondents’ opinions will be computed that can be interpreted as a measure of radical (or true) uncertainty. This measure is strongly recommended by the present economic crisis originated by financial markets that the dominating idea of the impossibility of measuring and hence monitoring radical uncertainty has contributed to consign to an unconstrained and destabilizing speculation. Moreover, some indicators of the persistence of each modality of answer are proposed, as well as a correction of the usual percent of the modalities of survey answers that attributes a higher weight to the answers that do not change in successive survey periods. This correction is mainly suggested by the fact that the degree of persistence of respondents’ opinions is an important sign of entrepreneurs and firms’ behaviour and decisionmaking. The modified percents of the modalities of answers are confronted to the usual ones, and some econometric estimations are provided. The applications use data of the Italian and South African business tendency surveys on a number of variables. The resulting information and elaborations seem to suggest some critical consideration on the content of the harmonized EU surveys, mainly with reference to the reliability of the confidence indicators and the disregard of the volatility of answers with its attitude to provide a meaningful indicator of radical uncertainty
C89|Identifying Unknown Response Styles: A Latent-Class Bilinear Multinomial Logit Model|Respondents can vary significantly in the way they use rating scales. Specifically, respondents can exhibit varying degrees of response style, which threatens the validity of the responses. The purpose of this article is to investigate to what extent rating scale responses show response style and substantive content of the item. The authors develop a novel model that accounts for possibly unknown kinds of response styles, content of the items, and background characteristics of respondents. By imposing a bilinear structure on the parameters of a multinomial logit model, the authors can visually distinguish the effects on the response behavior of both the characteristics of a respondent and the content of the item. This approach is combined with finite mixture modeling, so that two separate segmentations of the respondents are obtained: one for response style and one for item content. This latent-class bilinear multinomial logit (LC-BML) model is applied to a cross-national data set. The results show that item content is highly influential in explaining response behavior and reveal the presence of several response styles, including the prominent response styles acquiescence and extreme response style.
C89|Some Comments on the Question Whether Co-occurrence Data Should Be Normalized|In a recent paper in the Journal of the American Society for Information Science and Technology, Leydesdorff and Vaughan assert that raw cocitation data should be analyzed directly, without first applying a normalization like the Pearson correlation. In this report, it is argued that there is nothing wrong with the widely adopted practice of normalizing cocitation data. One of the arguments put forward by Leydesdorff and Vaughan turns out to depend crucially on incorrect multidimensional scaling maps that are due to an error in the PROXSCAL program in SPSS.
C89|On the divergence of research paths in evolutionary economics: a comprehensive bibliometric account|In the last two decades there has been a noticeable increase in published research in evolutionary economics. The idea that formal modelling is a sine qua non condition for establishing a rigours and coherence scientific frame, has led to an over concern with formalization issues among evolutionary researchers. The general perception is that formalization lags behind the appreciative work. Notwithstanding, this general reading has not yet been supported by real data analysis. This work presents a comprehensive survey on evolutionary economics, intending at exploring the main research paths and contributions of this theorizing framework using bibliometric methods. This documentation effort is based on an extensive review of the abstracts from articles published in all economic journals gathered from the Econlit database over the past fifty years. Evolutionary contributions apparently have not converged to an integrated approach. In the present paper, we document the more important paths emergent in this field. Before 1990, the importance of published evolutionary related research is almost negligible - more than 90% of total papers were published after that date. Our results further show two rather extreme main research strands: â€˜History of Economic Thought and Methodologyâ€™ and â€˜Gamesâ€™. Moreover, formal approaches have a reasonable and increasing share of published papers between 1969 and 2005. In contrast, purely empirical-related works are relatively scarce, involving a meagre and stagnant percentage of published works. This recalls for a need to redirect the evolutionary research agenda.
C89|QuantNet – A Database-Driven Online Repository of Scientific Information|In this study a framework for an online database-driven repository of information – QuantNet – is presented. QuantNet is aimed at easing the process of web publishing for those who are unfamiliar with technical details and markup languages. At the same time advanced users are provided with easy user style markup tools while flexible and trouble-free application administration is being a top priority. In this realm a special emphasis is put on the construction of a metalanguage containing only simplest possible structures. Different stages – from low-level text processing via Atox to the transformation of XML documents via XSLT, PHP and mySQL – are thoroughly described. The motivation for further possible application extensions like DTD or preliminary document check, based on analytic grammar form, is provided.
C89|Rate of Return Parity with Robot Asset Traders|Human populated experimental asset markets produce data with two major qualitative consistencies; finite price bubbles and rate of return parity. Robot traders following different behavioural rules are used to create data that is qualitatively similar to that produced by human subjects in a laboratory setting. A trend pricing component of behaviour is required for robots to generate finite price bubbles. A single arbitrageur in combination with trend pricing and simple profit maximization is required to generate rate of return parity. Copyright Springer Science+Business Media, LLC 2007
C89|A new look into the evolution of clusters literature. A bibliometric exercise|In the contemporary globalising knowledge-based economies, local clusters have become crucial elements of regional development, assuming a significant role in both academic and political fields. Although there is an intuitive awareness about the raising importance of the theoretical debate on clusters, there is a substantial lack of empirical support of its precise magnitude and evolution. Moreover, the majority of literature surveys on clusters are exclusively qualitative-based. Aiming at filling this gap, the main purpose of this paper is to provide a quantitative survey of the cluster literature, using bibliometric techniques based on articles. Based on a throughout analysis of all abstracts of articles on clusters published in journals indexed on the Econlit and EBSCO databases, covering the period 1962-2007, our research show that besides their importance in academic fields, the role of clusters has also been widely acknowledged in political spheres. In parallel with the increasing interest in the ‘local’, there has been, as well, an emergent body of literature on global networks and clusters. Moreover, on the basis of the recent boom on clusters literature stands the emergent themes of ‘local networks and social approaches’ and ‘knowledge-based theories’. Literature associated to ‘regional and national innovation systems’ and to ‘institutional approaches’ (local enrooted cultures, governance and customs) has been object of a particular dynamism since the 1990s. Despite the evidence of a clear positive correlation between journals ‘quality’ and formal related research, the evolution of the literature on clusters continues to be mostly appreciative led.
C89|Privacy Metrics and Boundaries|This paper aims at defining a set of privacy metrics (quantitative and qualitative) in the case of the relation between a privacy protector ,and an information gatherer .The aims with such metrics are: -to allow to assess and compare different user scenarios and their differences; for examples of scenarios see [4]; -to define a notion of privacy boundary, and design it to encompass the set of information, behaviours, actions and processes which the privacy protector can accept to expose to an information gathering under an agreement with said party; everything outside the boundary is not acceptable and justifies not entering into the agreement; -to characterize the contribution of privacy enhancing technologies (PET). A full case is given with the qualitative and quantitative privacy metrics determination and envelope, i.e. a Cisco Inc. privacy agreement.
C89|Contabilitatea si Societatea Cunoasterii|In the use of complex data we can’t speak about an increase of informational quality for accounting (if the basic principles are respected, the valence of information remain the same), but it’s a better utilization in the entire informational system. For reaching this major purpose in the context of using the calculate technique, is necessary a joint purpose of the theoreticians and the specialists in practice for a perfection of the accountant theory, the correct adaptation of these at the conditions and needs impose at a microeconomic level. In this purpose, we propose a possible model of integration of accountant information as a part of the present informational system at a microeconomic level.
C89|Identifying and Assessing the Development of Populations of Undocumented Migrants: The Case of Undocumented Poles and Bulgarians in Brussels|"The stocks of undocumented migrants residing on the territory of Europe and the continuous flows of clandestine migrants are currently one of the ""hottest"" social and political topics. Even though the issue of irregular migration is on the top of many political and academic agendas the knowledge about who the undocumented migrants are, how they can be identified and how their population in a country develops numerically, remains limited. In this context, the aim of the current paper is twofold. In the first place, snowball sampling will be introduced as a technique for identifying undocumented migrants on the territory of a country and in the second, the empirical results from sampling and assessing the stability of the populations of undocumented Poles and Bulgarians in Brussels will be presented."
C89|Color Harmonization in Car Manufacturing Process|One of the major cost factors in car manufacturing is the painting of body and other parts such as wing or bonnet. Surprisingly, the painting may be even more expensive than the body itself. From this point of view it is clear that car manufacturers need to observe the painting process carefully to avoid any deviations from the desired result. Especially for metallic colors where the shining is based on microscopic aluminium particles, customers tend to be very sensitive towards a difference in the light reflection of different parts of the car. The following study, carried out in close cooperation with a partner from car industry, combines classical tests and nonparametric smoothing techniques to detect trends in the process of car painting. The localized versions motivated by t-test, Mann-Kendall, Cox-Stuart and a change point test are employed in this study. Suitable parameter settings and the properties of the proposed tests are studied by simulations based on resampling methods borrowed from nonparametric smoothing. The aim of the analysis is to find a reliable technical solution which avoids any interaction from a human side.
C89|Area interpolation in presence of measurement error and an application to German administrative data|"""In many situations the applied researcher wants to combine different data sources without knowing the exact link and merging rule. This paper considers different interpolation methods for interpolating attributes from German labor office districts to German counties and vice versa. In particular, we apply dasymetric weighting as an alternative to simple area weighting both of which are based on estimated intersection areas. Since these estimates can be spurious, our theoretical framework extends the well-known Goodchild and Lam (1980) approach to the presence of measurement error in the underlying maps. We also present conditions under which the choice of interpolation method does not matter and confirm the theoretical results with a simulation study. Our application to German administrative data suggests robustness of estimation results of interpolated attributes with respect to the choice of interpolation method. We deliver weighting matrices for regional data sources of the two largest German data producers."" (Author's abstract, IAB-Doku) ((en)) Additional Information Anlage zum FDZ-Methodenreport Nr. 01/2006: Stata-Dateien mit den Gewichten: Gewichte.zip"
C89|Multiway data analysis for comparing time use in different countries - Application to timebudgets at different stages of life in six European countries|Important time-budget methodological issues are concerned with analysing time use tables, obtainable from time-budget diaries to face the multipurpose nature, the size and the complexity of time-budget data. After a brief introduction to the main time use analysis the paper focuses on the cross-sectional analysis using the explorative multidimensional data analysis. The paper deals with the multiway methods suitable for comparing statistical studies (i.e. countries) when each of them has many variables (i.e. activities) observed on many cases (i.e. categories of population). This article examines an example of application to cross-national differences in time use in six European countries at different stages of life. The results are exemplary of the applicational steps and statistical aspects of the methods proposed rather than definitive findings.
C89|Are finance, management, and marketing autonomous fields of scientific research? An analysis based on journal citations|Abstract Although there is considerable consensus that Finance, Management and Marketing are ‘science’, some debate remains with regard to whether these three areas comprise autonomous, organized and settled scientific fields of research. In this paper we aim to explore this issue by analyzing the occurrence of citations in the top-ranked journals in the areas of Finance, Management, and Marketing. We put forward a modified version of the model of science as a network, proposed by Klamer and Van Dalen (J Econ Methodol 9(2):289–315, 2002), and conclude that Finance is a ‘Relatively autonomous, organized and settled field of research’, whereas Management and (to a larger extent) Marketing are relatively non-autonomous and hybrid fields of research’. Complementary analysis based on sub-discipline rankings using the recursive methodology of Liebowitz and Palmer (J Econ Lit 22:77–88, 1984) confirms the results. In conclusions we briefly discuss the pertinence of Whitley’s (The intellectual and social organization of the sciences, 1984) theory for explaining cultural differences across these sub-disciplines based on its dimensions of scholarly practices, ‘mutual dependency’ and ‘task uncertainty’.
C89|Energy Demand and Supply Issues - Scenario 2020 and Implications for CDM in West African Economic and Monetary Union. Case Study: Benin, Burkina Faso, Niger and Togo|The present study discusses energy supply challenge and assesses renewable energy potential in the studied countries. Moreover, energy demand as well as demand projection is assessed until 2020. Resulting CO2-eq emissions are also projected. The study reveals that the countries under examination lack accurate information on their renewable energy potentials. Based on cautious assumptions, countries renewable energy potentials have been assessed. Solar sources and biomass are not assessed. The study shows that countries are endowed with low renewable energy potentials. Using GDP per capita and population grow as driving forces, countries' electricity demands are projected until 2020. As result, electricity demand in case study countries will not be very high, as economic development is projected to remain low. Consequently, despite an increase in CO2 emissions, emissions will remain at a low level. Hence, the countries studied cannot be as competitive as current competing CDM countries, i.e., China, India, Brazil, etc. Strengthening energy co-operation within West African Economic and Monetary Union may reduce transaction costs, making it possible to use the available energy potential.
C89|Holding Period Return-Risk Modeling :The Importance of Dividends|In this paper we explore the relevance of dividends in the total equity return over longer time horizons. In addition, we investigate the effects of different reinvestment assumptions of dividends. We use a unique set of revised and corrected US equity data series, comprising monthly prices and dividends based on consistent definitions over the period 1871-2002 (132 years). Our findings are relevant for performance evaluation, for estimating the historical equity risk premium, and for investment simulation. En este trabajo se estudia la relevancia de los dividendos como componente del rendimiento de los activos financiero en el horizonte del largo plazo. Adicionalmente, se estudian varias alternativas de reinversión para estos dividendos. Se usaran series de datos procedentes del mercado americano con información sobre precios y dividendos para el periodo comprendido entre 1871 y 2002. Los resultados son relevantes de cara al estudio de la rentabilidad, de la estimación de la prima de riesgo así como para la simulación de distintas alternativas de inversión.
C89|Map Intersection Based Merging Schemes for Administrative Data Sources and an Application to Germany|In many situations the applied researcher wants to combine different data sources without knowing the exact link and merging rule. This paper introduces a theoretical framework how two different regional administrative data sources can be merged. It presents different merging schemes based on the area size of intersections between both regional entities. Estimates of intersection areas are derived from a digital map intersection. The theoretical framework derives conditions for the unbiasedness of estimated intersections and merging rules. The paper also presents conditions under which the choice of merging rule does not matter and illustrates the theoretical results with a simulation study. An application to German counties and federal employment office districts illustrates the applicability of the approach. It delivers merging schemes for regional data sources of the federal German statistical office and of the federal German employment office.
C89|Structural Change, Capital’s Contribution, and Economic Efficiency: Sources of China’s Economic Growth Between 1952-1998|This paper examines the effects of structural change, long-term TFP trend and marginal return to capital on China’s economic growth, comparing such effects with those in the other East Asian economies. Our empirical results show that China’s TFP converges to a higher level, and that the marginal return to capital declines dramatically in the late 1990s. Capital contributes much less, while labor contributes more to China’s post-reform growth. China is catching up via technology adoption from the developed economies, and this in turn results in higher TFP growth. Future growth hinges on improving efficiency in the capital allocation system, whose distortions cause the declining marginal return to capital.
C89|Benchmarking of corporate social responsibility : Methodological problems and robustness|This paper investigates the possibilities and problems of benchmarking Corporate Social Responsibility (CSR). After a methodological analysis of the advantages and problems of benchmarking, we develop a benchmark method that includes economic, social and environmental aspects as well as national and international aspects of CSR. The overall benchmark is based on a weighted average of these aspects. The weights are based on the opinions of companies and NGO’s. Using different methods of weighting, we find that the outcome of the benchmark is rather robust for a sample of more than 50 large Dutch companies.<br><small>(This abstract was borrowed from another version of this item.)</small>
C89|Benchmarking of corporate social responsibility: Methodological problems and robustness|This paper investigates the possibilities and problems of benchmarking Corporate Social Responsibility (CSR). After a methodological analysis of the advantages and problems of benchmarking, we develop a benchmark method that includes economic, social and environmental aspects as well as national and international aspects of CSR. The overall benchmark is based on a weighted average of these aspects. The weights are based on the opinions of companies and NGO’s. Using different methods of weighting, we find that the outcome of the benchmark is rather robust for a sample of more than 50 large Dutch companies.
C89|An assessment of the data quality for live births and infant deaths for the 1998-birth cohort, city of São Paulo, using information from SINASC and SIM|In this article we use data from the 1998 birth-cohort from the City of São Paulo for live births and data on deaths from the same birth cohort that took place before the first year of life. Information on live birth came from the Information System of Live Births (SINASC) and on deaths came from the Information System on Mortality (SIM). Our aim was to evaluate two aspects of data quality, which are the percentage of missing information and consistency of the data based on empirical regularities observed in other populations or with the criterion of plausibility. Preference for digits, sex ratios at birth and at death and the Apgar score distribution were examples of quality indicators evaluated in this population. We concluded that information is much more frequently recorded for live births than for infant deaths (except for race/color of the infant) and that the internal consistency of the information can be considered satisfactory for the study population.
C89|Holding Period Return-Risk Modeling: Ambiguity in Estimation|In this paper we explore the theoretical and empirical problems of estimating average (excess) return and risk of US equities over various holding periods and sample periods. Our findings are relevant for performance evaluation, for estimating the historical equity risk premium, and for investment simulation. Using a unique set of US equity data series, comprising monthly prices and dividends based on consistent definitions over the 132 year period 1871-2002, we investigate the complex effect of temporal return aggregation and sample estimation error. Our major finding is that holding period risk and return statistics show an extraordinary sensitivity to the choice of the starting point in calendar time. For example, over the period 1926-2002 there is a difference of almost 140 basis points between the average annual total return starting in January compared to starting in July, and a difference of almost 7 (!) percentage points in estimated annual volatility. This is yet another way in which stock price seasonality manifests itself, but this ambiguity in the underlying estimation process seems completely neglected in the current literature.
C89|University admission marks in Catalonia: Some highlights from the empirical research|The results of the examinations taken by graduated high school students who want to enrol at a Catalan university are here studied. To do so, the authors address several issues related to the equity of the system: reliability of grading, difficulty and discrimination power of the exams. The general emphasis is put upon the concurrent research and empirical evidence about the properties of the examination items and scores. After a discussion about the limitations of the exams' format and appropriateness of the instruments used in the study, the article concludes with some suggestions to improve such examinations.
C89|Associationism and electoral participation: A multilevel study of 2000 Spanish general election|This work presents an application of the multilevel analysis techniques to the study of the abstention in the 2000 Spanish general election. The interest of the study is both, substantive and methodological. From the substantive point of view the article intends to explain the causes of abstention and analyze the impact of associationism on it. From the methodological point of view it is intended to analyze the interaction between individual and context with a modelisation that takes into account the hierarchical structure of data. The multilevel study of this paper validates the one level results obtained in previous analysis of the abstention and shows that only a fraction of the differences in abstention are explained by the individual characteristics of the electors. Another important fraction of these differences is due to the political and social characteristics of the context. Relating to associationism, the data suggest that individual participation in associations decrease the probability of abstention. However, better indicators are needed in order to catch more properly the effect of associationism in electoral behaviour.
C89|Saving in New Zealand: Measurement and Trends|This paper examines the trends in saving in New Zealand. It considers different sources of information about saving and highlights issues with the measurement of saving. Illustrations are provided of the impact of adjusting saving for both the effects of inflation and the inclusion of some items of expenditure, which are typically counted as consumption. The difficulty of drawing clear implications for policy on the basis of our existing knowledge and data on saving and wealth levels in New Zealand is highlighted. An appendix to the paper includes a comprehensive set of data on New Zealand saving and related variables.
C89|Pattern Matching in Multidimensional Time Series|No abstract is available for this item.
C89|A Short Note on the Numerical Approximation of the Standard Normal Cumulative Distribution and Its Inverse|We provide computer codes in ANSI-C and Python for a fast and accurate computation of the cumulative distribution function (cdf) of the standard normal distribution and the inverse cdf of the same function. For the cdf we use the 5th order Gauss-Legendre quadrature which gives more accurate results compared to Excel and Matlab. The Inverse cdf is computed using rational fraction approximations and gives a result that is seven-decimal place accurate.
C89|Computer code for: A Short Note on the Numerical Approximation of the Standard Normal Cumulative Distribution and Its Inverse|Content: (cdf.c)->Is ANSI-C code to compute the cdf of standard normal dist. using a composite fifth-order Gauss-Legendre quadrature (cdf- GL.py)->same as cdf.c except the code is written in Python (cdf.py)- >Python code to compute the cdf using rational fraction approximations (invcdf.py)->Python code to compute the inverse cdf using rational fraction approximations
C89|Partnerships Technology Transfer-Based: Theory and Methodology for Analysing the Process|This article examines the technology transfer-based partnerships between public research organisations (sources of knowledge, innovation and technology) and users (firms, public administrations, etc.) as dynamic processes for a mutual learning. This process can provide for the R&D organisations an increased capacity of technology transfer and self-financing, while for firms an enhancing in competitiveness.This paper makes suggestions to researchers for studying strategy process and describes some methodologies, called longitudinal studies, that show as the patterns evolve over time.A theoretical framework and a case study in biomedical innovation (from Van de Ven and Garud, 1993) are presented
C89|Pattern-Based Target Selection Applied to Fund Raising|This paper proposes a new algorithm for target selection. This algorithm collects all frequent patterns (equivalent to frequent item sets) in a training set. These patterns are stored e?ciently using a compact data structure called a trie. For each pattern the relative frequency of the target class is determined. Target selection is achieved by matching the candidate records with the patterns in the trie. A score for each record results from this matching process, based upon the frequency values in the trie. The records with the best score values are selected. We have applied the new algorithm to a large data set containing the results of a number of mailing campaigns by a Dutch charity organization. Our algorithm turns out to be competitive with logistic regression and superior to CHAID.
C89|A recursive algorithm for solving SUR models|The main computational tool for solving SUR or simultaneous equations models is the generalized QR decomposition (GQRD) of an exogenous matrix A and the Cholesky factorization of a dispersion matrix C. Initially the GQRD computes the QRD of A and then the RQD of QC, where Q is an orthogonal matrix. Sequential and parallel strategies have been proposed for computing the GQRD by exploiting the block-diagonal and Kronecker structures of A and C, respectively. The RQD of QC is the most expensive of these operations. An algorithm is presented here that avoids the explicit computation of the RQD of QC. It is based on the strategies for solving augmented systems and updated SUR models. A modification to handle SUR models with unequal observation sizes is discussed.
C89|GAUSS™ Programs for the Estimation of State-Space Models with ARCH Errors: A User's Guide|State-space models have long been popular in explaining the evolution of various economic variables. This is mainly because they generally have more economic content than do others in their class of parsimonious models (for example, VARs). Yet, in spite of their advantages, use of these models until recently was limited by the assumption that all the innovations therein had to be conditionally normally distributed. Consequently, one could not model conditionally heteroskedastic series within that framework. The study by Harvey, Ruiz, and Sentana (1992) changed that. These authors showed how ARCH effects could be handled in a state-space framework, whether such innovations were in the measurement equations or in the transition ones. For these purposes, the authors modified the usual Kalman filter and developed an approximate (or quasi-optimal) filter to estimate these models. An application of the above framework was made recently by Kichian (1999) to estimate Canadian potential output. Because no code was publicly available at that time to perform this task, GAUSS programs were developed at the Bank of Canada. In fact, the code allows for the estimation of a wide variety of state-space models with or without ARCH errors. This paper explains how to use this Bank code. We show, step-by-step, how to use the programs and give several examples. Also included is additional code for calculating out-of-sample forecast errors on the observable variables in order to assess the goodness of fit of the estimated models.
C89|Mining frequent intemsets in memory-resident databases|Due to the present-day memory sizes, a memory-resident database has become a practical option. Consequently, new methods designed to mining in such databases are desirable. In the case of disk-resident databases, breadth-first search methods are commonly used. We propose a new algorithm, based upon depth-first search in a set-enumeration tree. For memory-resident databases, this method turns out to be superior to breadth-first search.
C89|Modelos estadísticos y evaluación: tres estudios en educación|"The educational system in Spain is undergoing a reorganization. At present, high-school graduates who want to enroll at a public university must take a set of examinations Pruebas de Aptitud para el Acceso a la Universidad (PAAU). A ""new formula"" (components, weights, type of exam,...) for university admission is been discussed. The present paper summarizes part of the research done by the author in her PhD. The context for this thesis is the evaluation of large-scale and complex systems of assessment. The main objectives were: to achieve a deep knowledge of the entire university admissions process in Spain, to discover the main sources of uncertainty and to promote empirical research in a continual improvement of the entire process. Focusing in the suitable statistical models and strategies which allow to high-light the imperfections of the system and reduce them, the paper develops, among other approaches, some applications of multilevel modeling."
C89|Algunos factores que inciden en el rendimiento y en la evaluación de los alumnos en las PAAU|The context where the university admissions exams are performed is presented and the main concerns about this exams are outlined and discussed from a statistical point of view. The paper offers an illustration of the use of random coefficient models in the study of educational data. The association between two individual scores (one internal and the other external to the school) and the effect of the school in the external exam is analized by a regression model with random intercept and fixed slope. A variance component model for the analysis of the grading process is also presented. The paper ends with an outline of the main findings and the presentation of some specific proposals to improve and control the equity of the system. Some pedagogic reflections are also included.
C89|"On Using a ""Patched"" Data Base: An Illustration of the Conundrum"|"This paper discusses the problem of using a data base whose missing data points have been filled, based upon those that do exist. By use of an actual case-in-point, the author points out the pitfalls and dangers of using such a data base, and places a ""flashing signal"" before every data base."
C89|Youth Joblessness and Race: Evidence from the 1980 Census|This paper includes a brief review of the economic litera- ture on unemployment, with implications for empirical work on youth unemployment and participation; original empirical work using linear probability and logit models on 1980 Cen- sus microdata; and suggestions for structural models to be used in future work with microdata on youth labor force be- havior. On Census Day in 1980, 41.4% of black male teenage school- leavers, but only 15.9% of white male teenage school-leav- ers, were out of the labor force as well as out of school. Among the labor force participants, the white male unemploy- ment rate was 18.5%, while the black male rate was 30.5%. The behavior of young women was quite similar, except for worse labor force participation among white school leavers. For student male teenagers, the racial differential in la- bor force nonparticipation was only half as bad as for non- students, but the unemployment differential was 22% more unfavorable to blacks. The female student differential in unemployment rates was 14% more unfavorable to blacks. Among both students and nonstudents, and among both young men and young women, there was no significant or large racial differential in the ratio of unemployment to popu- lation. The large racial differential in unemployment is counterbalanced by a large racial differential in labor force participation. There are two very different struc- tural interpretations of these findings: higher black reser- vation wages and discouraged worker effects. As previous researchers have found using other data, sim- ple statistical models do not explain much of the individ- ual variation in youth labor force behavior. Structural models of youth unemployment are proposed for estimation with microdata. These models are designed to ameliorate biases in the simple models from ignoring simultaneity and ecological correlation. These models for microdata have added worker and discouraged worker effects exactly anal- ogous to those in macroeconomic models.
