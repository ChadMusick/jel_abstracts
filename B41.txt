B41|Measuring Success: Clio and the Value of Database Creation|In a recent article Stefano Fenoaltea (2018) bemoaned the loss of respect and focus on the importance of creating databases, or “measurement” as he referred to it. Cliometrics has made and continues to make valuable contributions not just to the field of economic history, but economics in general. In particular, we focus on the contribution of cliometrics to the creation of datasets. We highlight several important cases in both the past and present, of recognized important contributions of new datasets to the economics discipline. We argue that Clio has continually focused on, and valued, the creation of new data sets and the clever and novel ways they have been exploited to further the frontiers of knowledge, and that these efforts are both appreciated and recognized.
B41|Publish and Perish: Creative Destruction and Macroeconomic Theory|A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (DSGE) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by ‘nature’. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence.
B41|Text Mining for Economic Analysis (in Korean)|We provide detailed description of how text data analysis is done and review series of studies done through text mining. Natural language can be characterized with ambiguity and obscurity compared to structured data. It is hard to retrieve useful information from text data as it carries natural language itself. Text mining or natural language processing is a multi-discipline area of modern technic in which we can distill and obtain just what we need from text. With the development of AI and machine learning, text mining is becoming one of the high-end technology in various fields of research even in economics. We expect there will be more demand for text data analysis as it will be complementary to traditional structured data and also as a new source of information.
B41|A Performance Analysis of Some New Meta-Analysis Estimators Designed to Correct Publication Bias|Publication selection bias is widely recognized as a serious challenge to the validity of meta-analyses. This study analyses the performance of three new estimators designed to correct publication bias: the weighted average of the adequately powered (WAAP) estimator of Stanley et al. (2017), and two estimators proposed by Andrews & Kasy (2019), which we call AK1 and AK2. With respect to bias, we find that none of these is consistently superior to the commonly used PET-PEESE estimator. With respect to mean squared error, we find that Andrews & Kasey’s AK1 estimator does consistently better than other estimators except when publication bias is focused solely on the sign, as opposed to the significance, of an effect. With respect to coverage rates, we find that all the estimators perform consistently poorly, so that hypothesis tests about the mean true effect are unreliable. We also find that effect heterogeneity generally worsens estimator performance, and that its adverse impact compounds with greater heterogeneity. This is particularly of concern for meta-analyses in business and economics, where I2 values, a measure of heterogeneity, are often 90 percent or higher. Finally, we find that the type of simulation environment used in the Monte Carlo experiments significantly impacts estimator performance. A better understanding of what makes an “appropriate” simulation environment for analysing meta-analysis estimators would be a potentially productive subject for future research.
B41|How economics forgot power|The article discusses a recent book publication by Philip Pilkington, in which an interesting and novel reconceptualizing of the investment (accumulation) process and economic growth is proposed. The gaze and critique through which the book is examined underlines certain theoretical similarities found in the Latin American economic discourse during the 1950´s, denominated as “Latin American structuralism”, in Anglo Saxon or European academia. Central to its perspective is the examination of economic formations and its agents as a configuration of power asymmetries.
B41|Keynes's Investment Theory as a Micro-foundation for his Grandchildren|In contrast with the ‘missing micro-foundations’ argument against Keynes’s macroeconomics, the paper argues that it is the present state of microeconomics that needs more solid ‘Keynesian foundations’. It is in particular Keynes’s understanding of investors’ behaviour that can be fruitfully extended to consumption theory, in a context in which consumers are considered as entrepreneurs, buying goods and services to engage in time-consuming activities. The paper emphasizes that the outcome in terms of enjoyment is particularly uncertain for those innovative and path-breaking activities, which Keynes discussed in his 1930 prophetic essay about us, the grandchildren of his contemporaries. Moreover, the Keynes-inspired microeconomics suggested in the paper provides an explanation of why Keynes’s prophecy about his grandchildren possibly expanding leisure did not materialize yet. The paper finally points at the need for appropriate economic policies supporting consumers’ propensity to enforce innovative forms of time use.
B41|The Cowles Commission and Foundation for Research in Economics: Bringing Mathematical Economics and Econometrics from the Fringes of Economics to the Mainstream|Founded in 1932 by a newspaper heir disillusioned by the failure of forecasters to predict the Great Crash, the Cowles Commission promoted the use of formal mathematical and statistical methods in economics, initially through summer research conferences in Colorado and through support of the Econometric Society (of which Alfred Cowles was secretary-treasurer for decades). After moving to the University of Chicago in 1939, the Cowles Commission sponsored works, many later honored with Nobel Prizes but at the time out of the mainstream of economics, by Haavelmo, Hurwicz and Koopmans on econometrics, Arrow and Debreu on general equilibrium, Yntema and Mosak on general equilibrium in international trade theory, Arrow on social choice, Koopmans on activity analysis, Klein on macroeconometric modelling, Lange, Marschak and Patinkin on macroeconomic theory, and Markowitz on portfolio choice, but came into intense methodological, ideological and personal conflict with the emerging “Chicago school.” This conflict led the Cowles Commission to move to Yale in 1955 as the Cowles Foundation, directed by James Tobin (who had declined to move to Chicago to direct it). The Cowles Foundation remained a leader in the more technical areas of economics, notably with Tobin’s “Yale school” of monetary theory, Scarf’s computable general equilibrium, Shubik in game theory, and later Phillips and Andrews in econometric theory but as formal methods in economic theory and econometrics pervaded the discipline of economics, Cowles (like the Econometric Society) became less distinct from the rest of economics.
B41|Lies, damned lies, and RCT : une expérience de J-PAL sur le microcrédit rural au Maroc|"Comment expliquer le succès académique d’une étude randomisée dont la validité, tant interne qu’externe, est pourtant très problématique ? Prenant l’exemple d’une étude menée par le laboratoire J-PAL sur le microcrédit rural marocain, cet article mobilise les outils analytiques de la statistique, de l’économie politique et de la sociologie des sciences pour répondre à cette question. Il décrit l’ensemble de la chaîne de production de l’étude, depuis l’échantillonnage jusqu’à la publication et la dissémination des résultats, en passant par la collecte de données, la saisie et le recodage, les estimations et les interprétations. Il met en évidence une stratégie particulièrement offensive qui permet aux chercheurs de J-PAL de faire table rase du passé, y compris en s’affranchissant d’une « culture de la donnée », de refuser la critique et de contourner les règles de base de l’exercice scientifique tout au long du processus de recherche. Bien au-delà de J-PAL, nos analyses questionnent la supposée supériorité des méthodes randomisées tout en reflétant un malaise grandissant au sein du champ académique, qui parvient de moins en moins à faire respecter les règles de base de l’éthique et de la déontologie scientifique._______english_______How can we explain the academic success of a randomized study whose validity, both internal and external, is very problematic? Drawing on a study conducted on Moroccan rural microcredit by J-PAL, this article uses analytical tools from statistics, political economy and sociology of science to answer this question. It describes the entire study production chain, from sampling, data collection, data entry and recoding, estimates and interpretations to publication and dissemination of results. It highlights a particularly aggressive strategy carried out throughout the study process and in the field of research. This allows J-PAL researchers to put the past behind them, including by freeing themselves from a ""data culture"", rejecting criticism and bypassing the basic rules of scientific exercise throughout the research process. Well beyond J-PAL, our analyses question the supposed superiority of randomized methods while reflecting a growing unease within the academic field, which is less and less successful in enforcing the basic rules of ethics and scientific deontology."
B41|"""Positional Views"" as the Cornerstone of Sen's Idea of Justice"|Our paper offers a novel reading of Sen’s idea of justice, beyond the standard prisms imposed by theories of justice – resting on external normative criteria – and formal welfarism – involving the definition of individual welfare and its aggregation. Instead we take seriously Sen’s emphasis on personal agency and focus on his original contribution to the issue of objectivity. Firstly, we demonstrate that Sen’s idea of justice, with at its core “positional views”, is more respectful of persons’ agency than would be a theory based on individual preference or capability. Secondly, we argue that Sen’s conception of objectivity considers that both information and sentiments are relative to a position. Such an alternative approach to subjectivity allows the formation of more impartial views through collective deliberation and a better consideration of justice by agents themselves.
B41|Note sur quelques limites de la méthodologie de Pareto et ses interprétations|: L'article évalue les limites de la méthodologie que Pareto applique à l'économie et à la sociologie. La première partie revisite les fondements sur lesquels repose la méthode logico-expérimentale et des approximations successives que Pareto propose pour les deux disciplines. La deuxième partie explicite les étapes qui définissent l'expérimentalisme de Pareto en sociologie. La troisième montre que les résultats que Pareto met en évidence impliquent qu'il n'applique pas la même méthodologie à l'économie et à la sociologie. La quatrième partie explique pourquoi les formes méthodologiques auxquelles Pareto recourt ne permettent pas la synthèse des résultats qu'il prêtant réaliser.
B41|Models as Speech Acts: A Restatement and a new Case Study|The goal of this paper is to provide a methodological perspective on economic models that accounts for some sociological dimensions of economics, in two senses. Firstly, we are interested in how modeling is an activity that is constrained by the (implicit and explicit) rules underlying the accumulation of academic prestige within economics and at the same time can be a means to change these rules. Secondly, we are interested in how, for a given model, this dynamic can be influenced by the use(s) of that model outside of economics. We first provide a restatement of Brisset’s (2018) original contribution. We then put this clarified methodological perspective to work on a new case study, i.e., on the dual models at the frontier between behavioral and standard economics.
B41|Peregrinations of an Economist: Perroux's Grand Tour of Fascist Europe|This article examines Perroux's intellectual career, from the interwar period to the Vichy period, in the light of his Grand Tour of European authoritarian regimes. By assessing Perroux's singular analysis of the Italian, German, Austrian and Portuguese regimes, we will illuminate how Perroux used foreign fascist experi-ences to speak about France and the organization of Europe as a whole. Ultimate-ly, by analysis Perroux's thoughts it will enable us to develop our understanding of how the Vichy regime perceived itself, and can, thus, contribute to recent debates concerning the ideological nature—fascist or not—of the Vichy regime.
B41|Evaluative judgments between positive and normative: For an axiological economy|This article argues that the distinction between positive and normative, which is the basis of much of economics, is not relevant. By inserting the distinction between norms and values, the article makes it possible to insert a new perspective between the two parts of the dichotomy: that of value judgments that are not necessarily normative. The article then supports the idea of an axiological economy that enriches evaluative judgments and provides a broader informational base for policy decisions.
B41|Measuring multivariate risk preferences in the health domain|We investigate univariate and multivariate risk preferences for health (longevity) and wealth. We measure attitudes toward correlation and attitudes toward higher order dependence structures such as cross-prudence and cross-temperance, making use of the risk apportionment technique proposed by Eeckhoudt et al. (2007). For multivariate gains, we find correlation aversion and cross-prudence in longevity and wealth. For losses, we observe correlation seeking and cross-imprudence. We do not find clear evidence for cross-temperance. Our results indicate that longevity and wealth are considered to be substitutes for gains, but not for losses. Second, univariate (higher order) risk preferences are comparable for longevity and wealth, although somewhat closer to linearity for wealth. Third, we find evidence that attitudes toward dependence structures in the health domain are sign-dependent.
B41|All that Glitters is not Gold. The Political Economy of Randomized Evaluations in Development|Randomized control trials (RCTs) have a narrow scope, restricted to basic intervention schemes. Experimental designs also display specific biases and political uses when implemented in the real world. Despite these limitations, the method has been advertised as the gold standard to evaluate development policies. This article adopts a political economy approach to explore this paradox. It argues that the success of RCTs is driven mainly by a new scientific business model based on a mix of simplicity and mathematical rigour, media and donor appeal, and academic and financial returns. This in turn meets current interests and preferences in the academic world and the donor community.
B41|世代内・世代間の受益・負担構造に関する研究 : 全国消費実態調査を用いた世代会計モデルを軸に|本研究では、政府を通じた個人の生涯にわたる受益と負担を所得階層・年齢階級別のコーホートに分けて推計し、受益と負担が、世代間のみならず、世代内の所得階層の違いによってどの程度異なるのかを明らかにした。その結果、我が国の現在世代及び将来世代が直面する世代内及び世代間の生涯純負担率は、（１）同一世代内で見ると高所得層ほど生涯純負担率が大きく、所得再分配機能が機能していること、（２）世代間では総じてみれば若年世代ほど負担が大きくなっており世代間格差は22～25ポイント（０歳世代と90歳世代との比較）となっていること、（３）現在世代（０歳世代）と将来世代間の格差は16～60ポイントとなっており現在世代内の格差の３倍弱にのぼる、つまり、現在世代内の世代間格差よりも将来性世代と現在世代との間の世代間格差の方が大きいこと、が明らかになった。また、消費増税と所得増税による財政再建シミュレーションの結果からは、消費増税は、相対的に高所得の若年世代に有利であるものの、その他の世代では不利であることが分かった。
B41|Brexit: Everyone Loses, but Britain Loses the Most|This paper examines 12 economic simulation models that estimate the impact of Brexit. We provide their range of results and explain their associated assumptions and methodologies (macroeconometric models, computable general equilibrium [CGE] models, or mixed approaches). CGE models simulate the operation of market economies, solving for changes in equilibrium prices and quantities (production, employment, demand, and international trade) for all sectors in the economy. Macroeconometric models focus on economic aggregates and macro shocks, such as interest rates, the exchange rate, inflation, risk, uncertainty, and government expenditure/revenue. Most of the studies find adverse effects for the UK and the EU-27. The UK's GDP losses from a hard Brexit (reversion to World Trade Organization rules due to a lack of UK-EU agreement) range from –1.2 to –4.5 percent in most of the models analyzed. A soft Brexit (e.g., Norway arrangement, which seems in line with the nonbinding text of the political declaration of November 14, 2018 on the future EU-UK relationship) has about half the negative impact of a hard Brexit. Only two of the models derive gains for the UK after Brexit because they are based on unrealistic assumptions. We analyze more deeply a CGE model that includes productivity and firms' selection effects within manufacturing sectors à la Melitz (2003) and the operations of foreign multinationals in services. Based on this latest model, we provide a complete overview and explanation of the likely economic impact of Brexit on a wide range of macroeconomic variables, namely GDP, wages, private consumption, capital remuneration, aggregate exports, aggregate imports, and the consumer price index. The data underlying this analysis are available at https://piie.com/system/files/documents/wp19-5.zip.
B41|A missing touch of Adam Smith in Amartya Sen’s account of Public Reasoning: the Man Within for the Man Without|Sen claims that his 2009 theory of justice is based in part upon Smith’s idea of the “impartial spectator”. His claim has received criticism: some authors have responded that his interpretation of Smith’s concept is unfaithful to the original (e.g., Ege, Igersheim and Le Chapelain 2012); others, focusing on internal features of Sen’s analysis, critique his use of the Smithian impartial spectator, arguing that it is a weak point in his comparative theory of justice (e.g., Shapiro 2011). In this paper we address both sets of criticisms. While agreeing with commentators that Sen’s reading of Smith is somewhat unfaithful, we reiterate that his aim in The Idea of Justice is not to provide an exegesis of Smith but rather to build his own comparative theory of justice by “extending Adam Smith’s idea of the impartial spectator” (IJ: 134) to his own project. After clarifying their distinct approaches to the concept of the impartial spectator, we draw upon our account of these differences to evaluate Sen’s own use of the concept. Despite significant divergences, we show that Sen’s version of the impartial spectator is not inconsistent with Smith’s analysis. Though it does not correspond to Smith’s concept, i.e. to what the Scottish philosopher sometimes calls the “man within”, it is reminiscent of another figure from Smith’s moral philosophy: the “man without”. Beyond this analogy, there are further connections between Smith’s imaginary figure of the “man within” and Sen’s account of “common beliefs”—both notions are ways of representing our beliefs regarding what is moral or just. But whereas Smith’s moral philosophy offers an analysis of the process by which the “man without” influences the “man within”, nothing of that kind is to be found in Sen’s conception of public reasoning. And it is here that Smith’s famous concept of “sympathy” can supplement Sen’s theory, in a way which furnishes an answer to Shapiro’s (2011) criticism regarding the possibility of the spontaneous change of beliefs toward greater impartiality.
B41|Macroeconomic simulation comparison with a multivariate extension of the Markov Information Criterion|Comparison of macroeconomic simulation models, particularly agent-based models (ABMs), with more traditional approaches such as VAR and DSGE models has long been identified as an important yet problematic issue in the literature. This is due to the fact that many such simulations have been developed following the great recession with a clear aim to inform policy, yet the methodological tools required for validating these models on empirical data are still in their infancy. The paper aims to address this issue by developing and testing a comparison framework for macroeconomic simulation models based on a multivariate extension of the Markov Information Criterion (MIC) originally developed in Barde (2017). The MIC is designed to measure the informational distance between a set of models and some empirical data by mapping the simulated data to the markov transition matrix of the underlying data generating process, and is proven to perform optimally (i.e. the measurement is unbiased in expectation) for all models reducible to a markov process. As a result, not only can the MIC provide an accurate measure of distance solely on the basis of simulated data, but it can do it for a very wide class of data generating processes. The paper first presents the strategies adopted to address the computational challenges that arise from extending the methodology to multivariate settings and validates the extension on VAR and DGSE models. The paper then carries out a comparison of the benchmark ABM of Caiani et al. (2016) and the DGSE framework of Smets and Wouters (2007), which to our knowledge, is the first direct comparison between a macroeconomic ABM and a DGSE model.
B41|The Smithian Market of Religions and its Legacy: Another Great Schism between Economics and Sociology?|Adam Smith (1776) is the first to introduce religions into a market. Our article studies Smith’s neglected contribution to secularization theories and sociological market of religions then distinguishes it from his contribution to the economic market of religions. The objective of this article is to show that sociology and economics of religion both rely on Smith. Our issue analyzes if the markets of religions in the two disciplines evolve contradictory or complementary. Our results show an interdisciplinary dissemination of Smith’s ideas between sociology and economics of religion, a (unknown/neglected) Smithian background for sociology of religion and a demand-side market of religions in sociology. We demonstrate that there is no opposition between the two disciplines, but a methodological difference between demand and supply mechanisms. Our historical work remarks a methodological schism in the markets of religion with the introduction of Becker’s rational choice into sociology. We trace a historical tree to distinguish the demand mechanism (Marx, Durkheim, Weber and traditional sociological market) from the supply mechanism (Tocqueville, Blau and Homans, Becker, and rational choice theory in sociology and economics of religion) in the evolution of Smith’s market.
B41|Measuring Success: Clio and the Value of Database Creation|In a recent article Stefano Fenoaltea (2018) bemoaned the loss of respect and focus on the importance of creating databases, or “measurement” as he referred to it. Cliometrics has made and continues to make valuable contributions not just to the field of economic history, but economics in general. In particular, we focus on the contribution of cliometrics to the creation of datasets. We highlight several important cases in both the past and present, of recognized important contributions of new datasets to the economics discipline. We argue that Clio has continually focused on, and valued, the creation of new data sets and the clever and novel ways they have been exploited to further the frontiers of knowledge, and that these efforts are both appreciated and recognized.<br><small>(This abstract was borrowed from another version of this item.)</small>
B41|Un héritage des Annales, la cliométrie à Strasbourg|C’est par sa volonté de combiner la rigueur des modèles théoriques et mathématiques avec la prise en compte, de la façon la plus exhaustive possible, de la complexité de toutes les données (qualitatives et quantitatives) que l’Ecole cliométrique strasbourgeoise reste fidèle à l’esprit des Annales et prolonge le mouvement initié en 1929 par Marc Bloch et Lucien Febvre.
B41|Die Illusion der Identität und die Krise der Wissenschaften|Das Eingangszitat von George Forster aus dem Jahre 1793 gibt einen ersten Hinweis auf das, was nachfolgend zu entfalten ist. Als These formuliert: Die Begriffe der modernen Wissenschaften sind auf innere Weise mit dem Rechnen in einer Geldökonomie verbunden. Die vielfältig zu beobachtenden Krisenphänomene in zahlreichen Wissenschaften lassen sich auf einen gemeinsamen Grund zurückführen. Ich werde zunächst von einer spezifischen Blickweise ausgehen, die charakteristisch ist für die modernen Wissenschaften, um in dieser Perspektive die stillschweigenden kategorialen Voraussetzungen näher zu beschreiben. Daraus lassen sich dann Krisenphänomene, die in Mathematik, Physik und Ökonomie zu beobachten sind, verständlich machen.
B41|The anti-democratic logic of right-wing populism and neoliberal market-fundamentalism|The paper compares neoliberal market-fundamentalism and right-wing populism on the basis of its core patterns of thinking and reasoning. Based on an analysis of the work of important founders of market fundamental economic thinking (particularly Mises, and Hayek) and the arguments brought forward by leading right-wing populist we find highlight conceptual resemblances of these two approaches: Both show a world that is split into only two countervailing parts. Right-wing populism shows a society split into two groups, fighting against each other. In a similar vein, neoliberal market-fundamentalism shows only two possible countervailing economic and societal orders. Thus, we develop a scheme of the similar dual social worlds of right-wing-populism and market-fundamentalism and offer some examples in the history of the Republican Party, where these concepts mutually reinforced each other or served as a gateway for each other. The main conclusion of the paper is that neoliberal market-fundamentalism and right-wing populism can be perceived as two mutually reinforcing and radicalizing threats to democracy in the 21st century.
B41|Corruption in Tax and Taxing the Corruption|Most of the countries in the world face corruption and struggling against to it in many aspects. Due to various loopholes and institutional inefficiencies it continues to be pressing issues which affects public in various dimensions. The long existence of corruption around the world made an illusion to the policy makers and public as it is unavoidable and adjustable. This creates an intuition to esquire into what makes the corruption market successful all over the world for many centuries and what Economic theory is operate behind it. In this paper an inquiry is made into how the corruption market works effectively without any intervention. It also explore the possibility of the Ronald Coase theory’s to control the corruption and justifies what intervention is needed to achieve optimal amount of corruption. It concludes that to achieve the optimal amount of corruption in the society all farms of corruptions has to be internalized by introducing a permit and tax for corruption.
B41|Potential economic effects of a global trade conflict: Projecting the medium-run effects with the WTO global trade model|The WTO Global Trade Model is employed to project the medium-run economic effects of a global trade conflict. The trade conflict scenario is based on recent estimates in the literature of the difference between cooperative and non-cooperative tariffs. The study provides three main insights. First, the projected macroeconomic effects in the medium run are considerable. A global trade conflict started in 2019 would lead to a reduction in global GDP in 2022 of about 1.96% and a reduction in global trade of about 17% compared to the baseline. For context global GDP fell about 2.1% and global trade 12.4% in the global financial crisis of 2009. Second, behind the single-digit aggregate production effects there are much larger, double-digit sectoral production effects in many countries, leading to a painful adjustment process. In general, a global trade conflict leads to a reallocation of resources away from the most efficient allocation based on comparative advantage. Third, the large swings in sectoral production lead to substantial labour displacement. On average 1.15% and 1.74% of high-skilled and low-skilled workers respectively would leave their initial sector of employment.
B41|Collective Actions: a Network Approach|This paper contributes to the issue of collective action by advancing an epistemology of agency based on the idea that individuals' propensity to act (attitudes) depends on relevant features of their social context. To this purpose, we develop a network model that links the probability that an agent joins collective action to the characteristics of the social structure, which is, in turn, shaped by the activation of collective actions within it. Our underlying assumption is that preferences for collective action are not only an individual endowment, but crucially depend on collective processes, that affect preference formation and characterize rationality as ecological.
B41|Постинституционализм: Программа Исследований За Пределами Институционального Мейнстрима<BR>[Post-institutionalism: research program beyond the institutional mainstream]|The paper examines the internal dualism of modern institutional economics manifested in division of orthodox or mainstream institutionalism (its axiomatics and dogmatics is represented by the Standard Model) and its opposition – post-institutionalism. It discusses the post-institutional agenda, covering a wide range of discussion issues beyond Standard Model – from the analysis of institutional complexity to introduction of the Evo-Devo paradigm into evolutionary research of institutions. It demonstrates that in the focus of post-institutionalism there are super-complicated institutional systems (assemblages) and related phenomena and processes (bricolage, kludges, anomalies, configurations), which can only be comprehended by overcoming unilateral and dichotomous approaches of the institutional mainstream.
B41|An attitude of complexity: thirteen essays on the nature and construction of reality under the challenge of Zeno's Paradox|This book is about the construction of reality. The central aim of this study is to understand how gravity works and how it may be focused and manipulated. While I do not have an answer to this question, the discoveries along the way have been worth collecting into a single volume for future reference.
B41|Sharia banking standard law|Abstract The adoption of a standard agreement from the beginning of its birth has caused controversy both concerning the existence and validity of standard contracts. The Civil Code does not specifically regulate standard agreements. This writing focuses on two issues, namely the validity of the agreement with the standard clause related to sharia principles and the consequences of the law lacking the principle of freedom of contract. This research is normative research that refers to legislation and jurisprudence using legal materials both primary and secondary. The legal material was collected through library studies and then analyzed qualitatively. This study concludes: first, the agreement with conventional standard clauses is no longer questioned whether the agreement is valid or not, but more importantly, the fairness of the contents of the standard clause and in the standard sharia contract tend to result in injustice. Second, normatively there are no legal consequences due to the absence of freedom of contract in the agreement.
B41|From institutions to extitutions to the post-institutional theory of institutional anomalies|The paper proposes to abandon the one-sidedly negative interpretation of institutional anomalies (non-optimal, inefficient, dysfunctional institutions) and rethink them as the main products and manifestations of institutional complexity. The concept of extitutions is introduced, which are understood as models of social order that go beyond the bounds of institutions and are based on variations of norms. The extitutional interpretation of the nature of institutional anomalies allows a critical review of the traditionally associated dichotomies (e.g. opposition of ideal and dysfunctional, inclusive and extractive institutions), analytical approaches (functionalist, mechanistic, isolationist, static, etc.) and stereotypes (e.g. assessment of institutions from the standpoint of public interests, “presumption of guilt” of interest groups, stigmatization of hybrid institutional trajectories, etc.). The article proposed a set of conceptual shifts towards increasing the objectivity and realism of the analysis of institutional anomalies in line with the research program of post-institutionalism.
B41|Постинституциональная Теория Блокчейна: Трансакционная Ценность И Ассамбляжи<BR>[Post-Institutional Theory of Blockchain: Transaction Value and Assemblages]|The paper on the example of blockchain demonstrates the possibilities of post-institutionalism – a new generation of institutional methodologies and theories, alternative to the new institutional economics. Based on the theory of transaction value, it has been proved that radical reduction of transaction costs by blockchain technologies will not lead to the elimination of intermediaries, but will redirect them to improving the quality of transactions and expanding the offer of additional (including hyperrelevant) transaction services. Using the theory of institutional assemblages, it is argued that it is impossible to form a homogeneous system of blockchain institutions based solely on the principles of decentralization, transparency and openness. The institutional system of blockchain will be organically hybrid, combining elements of opposing institutional logics – regulatory and algorithmic law, Ricardian and smart contracts, private and public systems, uncontrollability and arbitration. Thus, the conclusions of the neoinstitutional theory of blockchain (Davidson, De Filippi, Potts, 2018) are refuted from post-institutional positions.
B41|Housing insecurity measure, a development of a validated scale using household data|Based on the literature analysis, housing insecurity does not have a universally validated measure or scale that can be used across societies and contexts to measure housing insecurity. The literature on housing and housing insecurity is marred with individualised preferences of what individual researchers or organisations appropriate to measure housing insecurity. This paper takes the first step of proposing a scale of measuring housing insecurity that can be adopted for any context be it in developed countries or developing societies. The paper recognises the economic thinking that claims that the tools of mathematics are not always appropriate in the analysis of social reality (Lawson 2015) hence cognisance of the fact that functions and calculus are not always the best, this paper still makes use of mathematical calculations involving weights and still relies on the development of constructs that can be useful in explaining the reality of housing insecurity. We ask the question, to what extent is the ontology of housing so abstract that the numbers can be misleading? It is argued in this paper that the conception of reality and hence housing insecurity can still depend on the mathematical tools to understand the ontology of housing insecurity. Going deeper this paper does not claim to belong to the pluralism, or neoclassical thought, but as anticipated, devoid of that discourse and make use and hence benefit from both mainstream economic theory and aspects utilised by the pluralist school of thought and hence makes reference to the ontology of economics.
B41|Post-Keynesian Controversy About Uncertainty: Methodological Perspective, Part II|In this paper, the author follows a discussion of two post-Keynesian economists, Paul Davidson and Rod O?Donnell, about the nature of uncertainty in economics. The author focuses on two points of this discussion: a controversy about possibility/impossibility of such a proof and a criticism of Davidson?s allegedly split definition of ergodicity. In a controversy about possibility/impossibility, the author puts O?Donnell to criticism for the latter?s reduction of proving to providing empirical evidence and, in effect, omission of extra-empirical cognition. The author accepts O?Donnell?s argument of Davidson?s split definition and infers his own conclusion: the reason why Davidson keeps ignoring the incompatibility of both definitions of ergodicity is that he does not distinguish cumulative and theoretical probability. The author contends that Davidson?s claim about predetermination of long-run outcomes in ergodic processes draws its persuasiveness from the ambiguity of the concept ?long run?: according to the author, Davidson perceives ?long-run? in the meaning of ?finitely long? while O?Donnell perceives ?long-run? in the meaning of ?limit infinity?.
B41|Methods used in economic research. An empirical study of trends and levels|The methodological approaches used in economic research are analyzed on a sample of all 3,415 regular research papers published in 10 general interest journals every 5th year from 1997 to 2017. The number of papers published increases by 3.3% p.a. The papers are classified into three main groups with eight sub-groups: The main groups of theory and empirics are almost equally large. Most empiric papers use the classic method, which derives an operational model from theory and run regressions. Two main trends are highly significant: The fraction of theoretical papers has fallen by 26 pp (percentage points), while the fraction of papers using the classic method has increased by 15 pp. Almost 10% papers using the classic method have been analyzed using meta-analysis, which show that the results reported in the typical paper are exaggerated. There is little reason to believe that other methods have smaller problems.
B41|Ethics of Randomized Controlled Trials: Should Economists Care about Equipoise?|"Equipoise is defined by Freedman (1987, p.141) as a ""state of genuine uncertainty on the part of the clinical investigator regarding the comparative therapeutic merits of each arm in a trial."" This principle is grounded in the ethical motivation that any ex-ante preference for a given option would undermine the interests of those who are offered another. Randomized controlled trials (RCTs) in development economics disregard the equipoise requirement by typically disadvantaging the control group. This paper investigates how the equipoise principle is formalized in the medical literature and discusses whether and how it should be taken into consideration by economists. It argues that equipoise is especially relevant when double (or even single) blindness is excluded and when the control group includes already vulnerable individuals. More generally, this paper advocates for developing a vibrant ethics conversation on the design and fairness of RCTs in social sciences."
B41|More is different ... and complex! the case for agent-based macroeconomics|Abstract This work nests the Agent-Based macroeconomic perspective into the earlier history of macroeconomics. We discuss how the discipline in the 70’s took a perverse path relying on models grounded on fictitious rational representative agent in order to try to pathetically circumvent aggregation and coordination problems. The Great Recession was a natural experiment for macroeconomics, showing the inadequacy of the predominant theoretical framework grounded on DSGE models. After discussing the pathological fallacies of the DSGE-based approach, we claim that macroeconomics should consider the economy as a complex evolving system, i.e. as an ecology populated by heterogenous agents, whose far-from-equilibrium interactions continuously change the structure of the system. This in turn implies that more is different: macroeconomics cannot be shrink to representative-agent micro, but agents’ complex interactions lead to emergence of new phenomena and hierarchical structure at the macro level. This is what is taken into account by agent-based models, which provide a novel way to model complex economies from the bottom-up, with sound empirically-based microfoundations. We present the foundations of Agent-Based macroeconomics and we discuss how the contributions of this special issue push its frontier forward. Finally, we conclude by discussing the ways ahead for the fully acknowledgement of agent-based models as the standard way of theorizing in macroeconomics.
B41|ARDL model as a remedy for spurious regression: problems, performance and prospectus|Spurious regression have performed a vital role in the construction of contemporary time series econometrics and have developed many tools employed in applied macroeconomics. The conventional Econometrics has limitations in the treatment of spurious regression in non-stationary time series. While reviewing a well-established study of Granger and Newbold (1974) we realized that the experiments constituted in this paper lacked Lag Dynamics thus leading to spurious regression. As a result of this paper, in conventional Econometrics, the Unit root and Cointegration analysis have become the only ways to circumvent the spurious regression. These procedures are also equally capricious because of some specification decisions like, choice of the deterministic part, structural breaks, autoregressive lag length choice and innovation process distribution. This study explores an alternative treatment for spurious regression. We concluded that it is the missing variable (lag values) that are the major cause of spurious regression therefore an alternative way to look at the problem of spurious regression takes us back to the missing variable which further leads to ARDL Model. The study mainly focus on Monte Carlo simulations. The results are providing justification, that ARDL model can be used as an alternative tool to avoid the spurious regression problem.
B41|On the question of the relevance of Economics as a science: Postmodern filosofia critique|This article has adopted an open discourse in addressing pertinent concerns about the scientific existence of economics as a discipline. In doing so, some (critical) Filosofia arguments have been provided in ensuring that a well balanced approach is taken on the subject. Obviously, the approach of Popperian falsification used by economic science to address scientific justification through its varied scientific platform of technology applications like EVIEWS, STATA, MatLab and many more, have been applauded. Albeit such advances, the views of modern and postmodern critics have also come out saliently in a bid to ensuring open discourses are brought to the fore as a way of adding scientific value to the subject matter. In concluding, it was acknowledged that more is needed in ensuring that economic science as practiced by economists takes an open approach to critical discourse(s), reflecting reality about its pursed scientific ventures, given the persistence of economic volatility manifested across the global community.
B41|Economics of Information Biasing: A Unified Economic Theory That Leads to New Sustainability Concepts|The author believes that his concept “Biased Equilibrium” based on information sharing strategies of individual economic agents brings two scientific paradigms of economics, neoclassical economics and institutional economics together from the origin of general equilibrium to provide holistic view of real world economic and social structures. In this article he goes deep into the concept of dynamics of rational behaviors with respect to diverse self-interests of individual economic agents. Our social or economic institutions can be subjectively modeled as an information biasing chain where individuals are positioned in different abstract coalitions according to interdependence of their payoff functions. The upper layer coalitions virtually control the institutions and they have greater influences on our economy that provokes growth by exhausting energy and other natural resources and causes climate change. His model also provides guidelines for transiting from a growth based economy to a sustainable economy, while solving macro and micro-economic challenges in real time.
B41|Pay Level Comparisons in Job Satisfaction Research and Mainstream Economic Methodology|Although social scientists have been investigating the nature and impact of job satisfaction for many decades, economists only started to investigate job satisfaction systematically in the late 1980’s. Almost from the first systematic studies of job satisfaction by economists, the research potential of the notion of pay level comparisons was realized. The idea of pay level comparisons in job satisfaction has proven particularly useful also because it has important implications for a number of standard theoretical and economic policy results. However, the inclusion of the variable of comparison wage in job satisfaction and the resulting supporting empirical findings, are in sharp contrast to the orthodox approach, given that in mainstream economic theory an individuals’ utility is assumed to be a function of absolute income only. Despite the important theoretical and policy implications, mainstream economic theory has not paid much heed to the job satisfaction conceptual formulations and empirical findings. The paper argues that there are methodological reasons for this state of affairs which seem to be linked to the subjective well-being research in general, and to the job satisfaction literature in particular. A strong mistrust against the method of stated preferences and the inherent methodological bias against the integration of psychological findings, are suggested as the two prime reasons. Although a few prominent figures in job satisfaction research have realized the mainstream methodological attitude, it is necessary that job satisfaction specialists should consider more seriously the basic components of mainstream economic methodology that relate to their research field.
B41|Yeni Parasalcılık: Bir Yazın Taraması<BR>[New Monetarism: A Survey Of The Literature]|Parasal iktisat literatüründeki modeller genellikle paranın değerli olduğunu kabul ederek para miktarını ilgi odağına alan modellerdir. Yeni Parasalcı İktisat akımının görüşüne göre ise parasal teori ve politika analizinde gelişme sağlanabilmesi için karşılıksız paraya değişim aracı rolü veren - yani aslen değersiz bir varlık olan karşılıksız paranın değişim işlemlerinde nasıl değişim aracı rolü üstlendiğini gösteren, açık modeller kurulması gerekmektedir. Bunun için dağınık piyasada değişim sürecinin nasıl geliştiğini, oyuncuların faydalarını maksimize etmeleri sürecinde neler olduğunu modelleyebilmek gerekir. Bu modelleme için en uygun araç arama ve eşleştirme yaklaşımıdır. Bu çalışmada; değişim sürecinin ve özellikle paranın değişim aracı rolünün modellenebilmesini sağlayan denge arama modelleri incelenmiştir.
B41|A Modest Proposal For Augmenting The Gross Domestic Product Of Italy, Allowing Greater Public Spending, Employment, And Graft|Italy’s economy is stagnating, but a fiscal stimulus is ruled out by the Maastricht-limited deficit/GDP ratio. This paper presents a modest proposal for loosening the constraint on public spending by augmenting Italy’s female labor-force participation rate and therewith Italy’s GDP. Additional public spending would be popular, as it would increase employment; it would also be politically viable, as Italy’s elected and appointed officials would welcome the opportunity for increased graft.
B41|Эво-Дево: Парадигмальный Вызов Для Институционально-Эволюционного Анализа<BR>[Evo-Devo: Paradigmal Challenge for Institutional-Evolutionary Analysis]|In modern biological science there is a change in the paradigm of evolutionary research associated with the rejection of neo-Darwinism principles. The article discusses the prospect of using the conceptual ideas of evolutionary developmental biology (evo-devo) as the new dominant metaphors of institutional-evolutionary analysis. For example, metaphors of niche construction and developmental system stimulate the rejection of externalism (securing the key role in selection for the environment) and dichotomous thinking (opposition of actors and the environment, micro- and macro-analysis). The concept of institutional configurations developed in this vein makes it possible to analytically combine institutional, agential and environmental factors in their interaction into a single framework. The metaphor of bricolage actualizes the importance of abandoning the optimization concepts of evolution and one-sidedly negative interpretation of institutional anomalies (dysfunctions, failures, traps, etc.) in favor of studying institutional kludges as quasi-optimal persistent institutions created by non-professional actors, and positively rethinking anomalous institutions as a main output of institutional complexity. The metaphor of modularity is associated with the abandonment of thinking in the spirit of traditional totally integrated systems and the transition to the research of assemblages – super-complex institutional systems based on multiple logics and orders for which heterogeneity, fragmentation and hybridity are organic properties and evolutionary advantages.
B41|Эво-Дево: Парадигмальный Вызов Для Институционально-Эволюционного Анализа (Версия 2.0)<BR>[Evo-Devo: Paradigmal Challenge for Institutional-Evolutionary Analysis (version 2.0)]|In modern biological science there is a change in the paradigm of evolutionary research associated with the rejection of neo-Darwinism principles. The article discusses the prospect of using the conceptual ideas of evolutionary developmental biology (evo-devo) as the new dominant metaphors of institutional-evolutionary analysis. For example, metaphors of niche construction and developmental system stimulate the rejection of externalism (securing the key role in selection for the environment) and dichotomous thinking (opposition of actors and the environment, micro- and macro-analysis). The concept of institutional configurations developed in this vein makes it possible to analytically combine institutional, agential and environmental factors in their interaction into a single framework. The metaphor of bricolage actualizes the importance of abandoning the optimization concepts of evolution and one-sidedly negative interpretation of institutional anomalies (dysfunctions, failures, traps, etc.) in favor of studying institutional kludges as quasi-optimal persistent institutions created by non-professional actors, and positively rethinking anomalous institutions as a main output of institutional complexity. The metaphor of modularity is associated with the abandonment of thinking in the spirit of traditional totally integrated systems and the transition to the research of assemblages – super-complex institutional systems based on multiple logics and orders for which heterogeneity, fragmentation and hybridity are organic properties and evolutionary advantages
B41|От Институтов К Экститутам И Далее - К Теории Институциональных Аномалий<BR>[From Institutions to Extitutions to the Theory of Institutional Anomalies]|"The article suggests rethinking institutional anomalies (bad, inefficient, destructive institutions and related processes and effects) in a positive way. The term ‘extitutions’ is introduced as transcending institutions of (beyond-institutional) models of social order, based on variations of norms. The extitutional interpretation of the nature of institutional anomalies allows us to critically reconsider associated dichotomies (such as ‘bad / good institutions’ like North-Wallis-Weingast or Acemoglu-Robinson), approaches (eg, functionalism and evaluative ‘something wrong’-approach) and stereotypes (including one-sided negative interpretation of ‘bad’ institutions, ""presumption of guilt"" of interest groups, etc.). The author's position is to understand institutional anomalies as the main product of institutional complexity. The article also substantiates the expediency of taking into account the role of institutional configurations and small institutional entrepreneurship in the formation of ‘anomalous’ institutions. An agenda is proposed for future research in the field of the theory of institutional anomalies"
B41|Постинституционализм: За Пределами Институционального Мейнстрима<BR>[Post-institutionalism: Beyond the Institutional Mainstream]|The paper examines the internal dualism of modern institutional economics manifested in division of orthodox or mainstream institutionalism (its axiomatics and dogmatics is represented by the Standard Model) and its opposition – post-institutionalism. It discusses the post-institutional agenda, covering a wide range of discussion issues beyond Standard Model – from the analysis of institutional complexity to introduction of the Evo-Devo paradigm into evolutionary research of institutions. It demonstrates that in the focus of post-institutionalism there are super-complicated institutional systems (assemblages) and related phenomena and processes (bricolage, kludges, anomalies, configurations), which can only be comprehended by overcoming unilateral and dichotomous approaches of the institutional mainstream
B41|Контент-Аналіз Дисертацій З Економічної Безпеки Підприємства, Захищених В Україні За 2000-2018 Рр<BR>[Content analysis of doctoral dissertations on enterprise economic security, defended in Ukraine in 2000-2018]|Актуальність. Актуальність проблеми забезпечення економічної безпеки підприємства у сучасних умовах господарювання постає особливо гостро через зростаючу кількість збиткових та збанкрутілих суб’єктів, брак ресурсів для ефективної діяльності, ризиками, загрозами та небезпеками внутрішнього та невизначеністю зовнішнього середовища тощо. Практична діяльність компаній із гарантування економічної безпеки потребує науково-методичного забезпечення, яке б розкривало кращі практики, узагальнювало наявні теоретичні напрацювання, методичні положення та прикладні розробки. Хоча первинною ланкою наукової комунікації є стаття, для аналізу обрано дисертаційні роботи з економічної безпеки підприємства як найбільш уніфікована форма представлення результатів наукового дослідження у цій галузі знань. Мета та завдання. Метою статті є проведення контент-аналізу захищених дисертацій з економічної безпеки підприємства задля визначення загального стану дослідницької галузі, ступеню координації наукових зусиль та основних тенденцій оприлюднених досліджень. Результати. Обрано дисертаційні роботи виключно з економічної безпеки підприємства, вибірка за 2000-2018 рр. склала 205 робіт. Подальший аналіз проведено за критеріями методу оброблення масивів даних LATCH - Location (розташування); Alphabet (алфавіт); Time (час); Category (категорія); Hierarchy (ієрархія). Визначено низку наукових спеціальностей, кількість кандидатських та докторських дисертацій, основну категорію в тематиці дисертацій, динаміку захистів, провідні установи, географічні центри та галузі. Виявлено певні закономірності масиву робіт, також що сталої динаміки у дослідженнях економічної безпеки підприємства за різними спеціальностями не спостерігається, є періоди зростання та спаду, є п’ять закладів вищої освіти України, де захищено найбільше робіт; виділяються сім географічних центрів дослідження економічної безпеки підприємства. Висновки. Існує певна повторюваність тем та напрямів досліджень у різних спеціальностях щодо вивчення економічної безпеки підприємства. При підрахунку частотності понять у темах дисертаційних робіт визначається відмінність спеціальностей і відповідно досліджень в їхніх рамках: 21.04.02 орієнтована на комплексне вивчення системотворення, міжнародних стандартів з економічної безпеки, взаємовпливу національної безпеки та економічної безпеки підприємств тощо. Маємо узгодити напрями досліджень в рамках різних наукових спеціальностей з теми економічної безпеки підприємства, гармонізувати термінологію (у т.ч. з іншомовними відповідниками), розробити ефективні теоретико-методичні положення та прикладні рекомендації для практичної діяльності фахівців чи менеджерів сфери економічної безпеки суб’єктів господарської діяльності.
B41|Islamic Financial Institutions and Participatory Finance Constraints: The Case of Pakistan|Islamic financial contracts are designed to facilitate financing according to Islamic norms. Islamic financing in its first stages used only the partnership modes of Musharakah and Mudarabah. Later it is realized that, to avoid moral hazards, yet compete successfully with conventional banks, it is necessary to use all permissible Islamic modes and consequently, trade and leasing techniques were developed. This paper aims to identify the constraints faced by Islamic financial institutions in the adoption of participatory finance i.e., Musharakah and Mudarabah financing. The two basic categories of financing are: 1) profit-and-loss-sharing (PLS), also called participatory finance, i.e. Musharakah and Mudarabah and 2) purchase and hire of goods or assets and services on a fixed-return basis, i.e., Murabahah, Istisna', Salam and Ijarah also called non-participatory finance. This paper suggests that innovation and creativity is necessitated more than ever to promote participatory modes of financing and to make it the preferred choice for meeting the increasingly sophisticated and diversified financial needs.
B41|Edmond MalinvaudÂ´s Criticisms of the New Classical Economics: Restoring the Nature and the Rationale of the Old KeynesiansÂ´ Opposition|Contrarily to standard accounts of the history of macroeconomics, recent research has increasingly paid attention to the Old Keynesiansâ€™ criticisms of the New Classical Economics. In this paper, I study another study case through Edmond Malinvaudâ€™s criticisms of the New Classical Economics from the 1980s onwards. I argue that his opposition was radical in the sense that it was both multi-dimensional and systematic. I show, then, that the way he opposed reveals his own conception of macroeconomics, which owed much to the methodology and the practice of macroeconometric modeling. Finally, I suggest that the study of Malinvaudâ€™s opposition to the New Classical Economics shed light on both the nature and rationale of the Old Keynesiansâ€™.
B41|A Bottom-up Approach to Environmental Cost-Benefit Analysis|Cost-Benefit Analysis is a method to assess the effects of policies and projects on social welfare. CBAs are usually applied in a top-down approach, in the sense that a decision-making body first decides on which policies or projects are to be considered, and then applies a set of uniform criteria to identifying and valuing relevant cost and benefit flows. This paper investigates the possible advantages, prerequisites and limitations of applying CBA in what may be considered an alternative, “bottom-up” manner. Instead of starting out with a pre-defined policy option, the suggested approach begins with the underlying environmental problem, and then assesses costs and benefits of strategies and solutions as identified by local and directly affected stakeholders. For empirical case studies concerning two river catchments in Sweden and Latvia, the bottom-up CBA approach utilises local knowledge, assesses plans which are not only developed for local conditions but are also likely to be more acceptable to local society, and sheds additional light on possible distributional effects. By not only benefitting from, but also supporting participatory environmental planning, bottom-up CBA is in line with the growing trend of embedding stakeholder participation within environmental policy and decision-making.
B41|Media based sentiment indices as an alternative measure of consumer confidence|The world is currently generating data at an uprecedented rate. Embracing the data revolution, case studies on the construction of alternative consumer confidence indices using large text datasets have started to make its way into the academic literature. These 'sentiment indices' are constructed using text-based analysis. A subfield within computational linguistics. In this paper we consider the feasibility of constructing online sentiment indices using large amounts of media data as an alternative for the conventional survey method in South Africa. A clustering framework is adopted to provide an indication of feasible cadidate sentiment indices that best reflect the traditional survey based confidence consumer index conducted by the BER. The results indicate that the best candidate indices are linked to a single data source with a focus on using specialised financial dictionaries. Finally, composite indices for consumer confidence is constructed using Principle Component Analysis. The resulting indices' high correlation with the traditional consumer confidence index provide motivation for using media data sources to track consumer confidence within an emerging market such as South Africa using sentiment based techniques
B41|Best practices for the risk based approach assessment of the anti-money laundering program within a financial institutionBest practices for the risk based approach assessment of the anti-money laundering program within a financial institution|The Anti-Money Laundering („AML”) internal controls of financial institutions are no longer implemented to satisfy the supervision authorities, but precisely to prevent risks from materializing, risks which are much higher than just a fine, such as legal, reputational or substantial financial risks. Thus, we are welcoming institutional changes on the mentality and organizational culture, with the purpose of preventing the use of the financial institutions as means for money laundering, terrorist financing or other fraud schemes.This paper will firstly approach the „need” evolution with respect to AML measures, continuing by detailing the trends for assessing these measures. Basically, we would like to highlight that the Compliance function, especially from the AML point of view,should represent a business actual support and not an encumbrance. In this way, compliance and business should go in the same direction, whichis business development in a safe and legal environment.
B41|What does “we” want? Team Reasoning, Game Theory, and Unselfish Behaviours|this editorial presents the main contributions of the theory of team reasoning in game theory, and the issues that remain to be solved before this theory could become a credible alternative to ?orthodox? game theory. I argue in particular that an approach based on collective agency rather than rational choice theory and social preferences offer a scientifically preferable theory of unselfish behaviours, both in terms of parsimony and empirical validation. I review the economic literature on team reasoning, and highlight the contributions of the papers of the present volume to tackle the open issues of the theory of team reasoning.
B41|Choosing in a Large World: The Role of Focal Points as a Mindshaping Device|The aim of this paper is to offer a theory of coordination that considers the role of the context within which the individuals interact, and to develop a rigorous analysis of salience and focal points. This requires dealing with how agents choose in ‘large worlds’ (in Savage’s sense). We highlight the role of mindshaping in the formation of individual preferences and beliefs and show how social focal points can generate prior beliefs. We conclude by discussing normative implications of our analysis, since it suggests that agents are socially-embedded entities, whose preferences and beliefs are shaped by social dynamics and norms.<br><small>(This abstract was borrowed from another version of this item.)</small>
B41|Anthropology and Economics: The Argument for a Microeconomic Anthropology|The rapprochement between anthropology and economics is not a new subject of debate. Economic anthropology, whose very survival has largely been attributed to Marxism, remains a minor field of interest within anthropology and perhaps even more so within economics. Over recent years, researchers have argued that anthropology and economics should be interwoven, but few conceptual and empirical analyses have taken up the cause. The aim of this article is to promote a microeconomic anthropology. We discuss a contextual methodology and illustrate its advantages by way of interpersonal transfers.
B41|The role of natural resources in production: Georgescu-Roegen/Daly versus Solow/Stiglitz|This paper proposes a historical and epistemological account of one of the key controversy between natural resources economics and ecological economics, lasting from early 1970s to the end of 1990s. It shows that the theoretical disagreement on the scope of the economy's dependence to natural resources, such as energy and minerals, has deep methodological roots. On one hand, Solow's and Stiglitz's works are built on a “model-based methodology”, where the model precedes and supports the conceptual foundations of the theory and in particular the assumption of “unbounded resources productivity”. On the other hand, Georgescu-Roegen's counter-assumption of “thermodynamic limits to production”, later revived by Daly, rest on a methodology of “interdisciplinary consistency” which considers thermodynamics as a relevant scientific referent for economic theory. While antagonistic, these two methodologies face similar issues regarding the conceptual foundations that arise from them, which is a source of confusion and of the difficult dialogue between paradigms
B41|From Methodology to Practice (and Back): Georgescu-Roegen's Philosophy of Economics and the Flow-Fund Model|Despite his early contribution to the rise of mathematics in economics, Georgescu-Roegen's later methodological criticism of models has received little attention from historians and philosophers of economics. This paper attempts to fill this gap following two lines. First, I examine his explicitly methodological claims and connect them with related topics in economic methodology. Building on the distinction between dialectical and arithmomorphic concepts, I characterise his approach to theory-making as a three steps process of idealisation, isolation and arithmetisation. In this framework, models perform two functions, checking for logical consistency and facilitating understanding, which can be related to the idea of modelling as theorising. I then confront these general principles with Georgescu-Roegen's flow-fund model of production. I use the methodology as a reading grid of this theory, while examining its limits and complementary principles in practice. This shows a great deal of consistency, where idealisation provides conceptual foundations, isolation determines the relevant problems, and models are built according to structural consistency. The two functions of models are then illustrated by the logical derivation of older principles formulated by Babbage and Smith, and the understanding of the different organisational patterns of production. But some slightly different functions also appear when specific configurations of the model enable to check the conceptual consistency of other theories, or the understanding provided by the model contributes to the formation of new concepts. Hence, the consistency and the complementarity between Georgescu-Roegen's methodology and practice of theory-making provide interesting insights and a useful background for further investigations
B41|Turgot, Smith and Steuart on Stadial Histories|The theory of the stages of society appeared in the mid-18th century. Following a successful reception over the course of the second half of the century, the four-stage theory was finally adopted by Classical Economics, holding that the exchange economy is the final outcome of a long period of economic development. This paper carries out a comparative analysis of the stadial histories of Turgot, Smith and Steuart. We found theories which were similar, but which were identical in the pre-eminence of the productive forces and economic organisation. Firstly, a number of dynamic principles are noted?i.e., a natural tendency to improve their conditions, a series of shocks that change the historical stage and the innovative capacity of some individuals. Secondly, the necessary conditions for the movement from the agricultural stage to commercial society do not coincide. Turgot requires an accumulation of capital, Smith uses the market and Steuart points to the artificial institutions created by merchants. This is the central point in order to understand the differences between their economic theories.
B41|Sustainable regional development policy formation: role of industrial ecology and logistics|"The impossibility to define the clear and uniform operational guidelines for the implementation of sustainable development policy globally proves the necessity to consider the regional level as the key in terms of developing and implementing modern models of sustainable development, in particular, eco-industrial parks and circular economy projects. It substantiates the need to develop and use the modern innovative methodological approaches to the formation of the relevant regional policy. The circular economy proceeds from the flow-based understanding of the character of the production, distribution, exchange, and consumption of goods in the socio-economic system and, consequently, the turnover of resources and energy within this system. It determines the need for complex analysis and regulation of material and energy flows. These issues constitute the scope of research of industrial ecology and, at the same time, logistics. This causes the question of the integration of these disciplines within the system of scientific and methodological support of the processes of formation and implementation of the policy of sustainable region's development that is as yet little investigated. The article studies the theoretical and methodological foundations of the industrial ecology and logistics, such as objects, goals, methodological principles and approaches, methods, organizational forms, etc. On this basis the ontological unity of these disciplines is brought to light: they simultaneously study the different, mutually reinforcing aspects of the industrial system's performance through the accentuation of the flow form of the organization of the movement of resources, information, and energy as an object of regulation in such system. The integration of the ""environmental"" vision of material flows of the regional system, as is characteristic of the industrial ecology, with their ""economic"" content, which characterizes the structure of the regional economic system and constitutes the object of the logistics studies, should be considered as the basis for the formation and implementation of the policy aimed to achieve the region's sustainable development goals."
B41|Amartya Sen : un allié pour l’économie de la personne contre la métrique des capabilités. Deux arguments pour une lecture non fonctionnelle de la liberté chez Sen|Dans cet article, nous voulons montrer que l’usage du concept de capabilité comme une simple « métrique » du développement humain est une vision réductrice de la proposition intellectuelle de Sen. Contrairement à certaines idées reçues, Sen partage l’idée des tenants d’une économie de la personne (Ballet et al 2014) selon laquelle une théorie de la justice en termes de droits à certaines capabilités resterait prisonnière d’une vision purement fonctionnelle de la liberté. Notre démonstration passe par deux types d’arguments : 1) en reprenant l’hypothèse standard et originelle de la capabilité comme ensemble de vecteurs de fonctionnements accessibles (e.g., Sen 1987), nous mettons en évidence quatre implications théoriques de l’approche de Sen que la perspective standard en termes de « welfarisme formel » (D’Aspremont 2011, Baujard 2016) ne permet pas de saisir ; 2) nous confortons cette lecture en examinant l’hypothèse – passée inaperçue jusque là – de la capabilité comme « pouvoir effectif » d’agir dans le sens de résultats que l’on valorise (Sen 2008, 2010 [2009]). Dans les deux cas, il s’agit de montrer que la capabilité pour Sen est bien autre chose qu’une « métrique » de l’avantage personnel. De surcroît, la seconde hypothèse amène à intégrer d’emblée la question de l’obligation morale dans le concept de capabilité. Dès lors, la capabilité non seulement n’est pas une métrique de l’avantage personnel, mais elle n’est même plus une représentation de l’avantage personnel. C’est ici qu’apparaît la véritable révolution conceptuelle de Sen qui, contrairement à ce que Ricœur (2004) avait cru lire, ne se trouve pas dans le couple droit-capabilité, mais dans le couple responsabilité-capabilité nous obligeant à repenser le cadre standard des théories de la justice.
B41|The biological hypothesis in cliometrics of growth: a methodological critique of Fogel (post 1982) and Ashraf & Galor (2013)|Abstract The resort to biological “analogies”, “metaphors” and “concepts” is an important aspect of the history of the relationships between economics and biology and has long been greatly controversial. This controversy continues today in the most recent work of three cliometricians, i.e. Fogel (post 1982) and Ashraf and Galor (2013). We focus on the theories of historical growth relying on biological explanations which have been formulated by these economists, from the specific angle of biological reductionism. We propose a methodological critique of their use of biological variables as determinants of the historical dynamics of economic growth. Based upon the transposition to the field of economics of Ernst Mayr’s distinction between functional and evolutionary biology and his definitions of reductionism, we argue that despite some similarities, the questions raised by Fogel’s and Ashraf & Galor’s theories are of distinct nature. Nonetheless, we stress the need for a careful examination of the biological mechanisms supporting these researches.
B41|The gold standard for randomized evaluations: from discussion of method to political economy|(english) This last decade has seen the emergence of a new field of research in development economics: randomised control trials. This paper explores the contrast between the (many) limitations and (very narrow) real scope of these methods and their success in sheer number and media coverage. Our analysis suggests that the paradox is due to a particular economic and political mix driven by the innovative strategies used by this new school’s researchers and by specific interests and preferences in the academic world and the donor community. _________________________________ (français) La dernière décennie a vu l'émergence d'un nouveau champ de recherche en économie du développement : les méthodes expérimentales d'évaluation d'impacts par assignation aléatoire. Cet article explore le contraste entre d’une part les limites (nombreuses) et la circonscription (très étroite) du champ réel d'application de ces méthodes et d’autre part leur succès, attesté à la fois par leur nombre et leur forte médiatisation. L’analyse suggère que ce contraste est le fruit d’une conjonction économique et politique particulière, émanant de stratégies novatrices de la part des chercheurs de cette nouvelle école, et d’intérêts et de préférences spécifiques provenant à la fois du monde académique et de la communauté des donateurs.
B41|The Allais Paradox: What It Became, What It Really Was, What It Now Suggests to Us|"Whereas many others have scrutinized the Allais paradox from a theoretical angle, we study the paradox from an historical perspective and link our findings to a suggestion as to how decision theory could make use of it today. We emphasize that Allais proposed the paradox as a normative argument, concerned with ""the rational man"" and not the ""real man"", to use his words. Moreover, and more subtly, we argue that Allais had an unusual sense of the normative, being concerned not so much with the rationality of choices as with the rationality of the agent as a person. These two claims are buttressed by a detailed investigation – the first of its kind – of the 1952 Paris conference on risk, which set the context for the invention of the paradox, and a detailed reconstruction – also the first of its kind – of Allais's specific normative argument from his numerous but allusive writings. The paper contrasts these interpretations of what the paradox historically represented, with how it generally came to function within decision theory from the late 1970s onwards: that is, as an empirical refutation of the expected utility hypothesis, and more specifically of the condition of von Neumann-Morgenstern independence that underlies that hypothesis. While not denying that this use of the paradox was fruitful in many ways, we propose another use that turns out also to be compatible with an experimental perspective. Following Allais's hints on ""the experimental definition of rationality"", this new use consists in letting the experiment itself speak of the rationality or otherwise of the subjects. In the 1970s, a short sequence of papers inspired by Allais implemented original ways of eliciting the reasons guiding the subjects' choices, and claimed to be able to draw relevant normative consequences from this information. We end by reviewing this forgotten experimental avenue not simply historically, but with a view to recommending it for possible use by decision theorists today."
B41|LES ORIGINES DE LA DISTINCTION ENTRE POSITIF ET NORMATIF EN ECONOMIE (The Origin of the Positive-normative Distinction in Economics)|French Abstract: Les économistes ont coutume de distinguer entre une composante positive et une composante normative de leurs travaux, ce qui est une singularité de leur discipline, car cette distinction n'a pas de répondant exact dans les autres sciences sociales. Elle a fortement évolué au cours du temps et les différentes manières de la concevoir aujourd'hui en reflètent l'histoire. On se propose ici d'en retracer les origines et les premières formes, de l'économie politique classique anglaise de la première moitié du XIXe siècle jusqu'à l'apparition de l'économie du bien-être dans la première moitié du XXe siècle. Ce parcours séquentiel vise aussi à identifier les positions les plus représentatives et les arguments invoqués pour les soutenir, en préparant ainsi une discussion qui serait moins historique et plus strictement conceptuelle. English Abstract: Economists are accustomed to distinguishing between a positive and a normative component of their work, a distinction that is peculiar to their field, having no exact counterpart in the other social sciences. The distinction has substantially changed over time, and the different ways of understanding it today are reflective of its history. Our objective is to trace the origins and initial forms of the distinction, from the English classical political economy of the first half of the 19th century to the emergence of welfare economics in the first half of the 20th century. This sequential account will also serve to identify the main representative positions along with the arguments used to support them, and it thus prepares the ground for a discussion that will be less historical and more strictly conceptual.
B41|Choosing in a Large World: The Role of Focal Points as a Mindshaping Device|The aim of this paper is to offer a theory of coordination that considers the role of the context within which the individuals interact, and to develop a rigorous analysis of salience and focal points. This requires dealing with how agents choose in ‘large worlds’ (in Savage’s sense). We highlight the role of mindshaping in the formation of individual preferences and beliefs and show how social focal points can generate prior beliefs. We conclude by discussing normative implications of our analysis, since it suggests that agents are socially-embedded entities, whose preferences and beliefs are shaped by social dynamics and norms.
B41|The Geography and Concentration of Authorship in the Top Five: Implications For European Economics|We study to what degree authors who publish in the five most prestigious journals in economics have previously published there and in which world region they are based. Although still high, the concentration of United States‐based and previously published top‐five authors has decreased. This trend is driven by increased co‐authorship between USA and non‐USA scholars and between scholars with and without previous top‐five articles. Only around 5% of all articles each year are written solely by first‐time authors from outside the United States, and this share has not increased since the mid‐1990s. Against this background, we argue that European institutions should be wary of putting too much emphasis on publishing in these five journals. Both the advancement and diversity of the economics discipline may otherwise suffer.
B41|所得階層別一般均衡型世代重複シミュレーションモデルの開発|本稿の目的は、財政健全化や社会保障制度改革等の政策変更により家計が被る影響が、世代間のみならず世代内でどのような点で異なり、どのような点で類似しているのかなどについて分析を行うために資するよう、家計を生年だけではなく所得階層に区分し、同一世代内における家計の異質性を明示的に考慮した一般均衡型世代重複シミュレーションモデルの開発を行うことにある。あわせて、現在の財政スタンスが持続可能か否かについてシミュレーションし、世代別・所得階層別生涯純税負担率の推計を行った。その結果、現在の財政スタンスを継続した場合、2040年に政府債務残高比率が457％に達したところで限界が訪れ、2041年には消費税率の抜本的な引上げが必要になること、また、政府債務残高比率を457％に維持するだけにしても、現在の歳出構造が続くならば、長期的に30％の消費税率が必要なこと、さらに、世代別では高齢層ほど、世代内では所得階層の低いほど、生涯純税負担率が小さいことが明らかになった。, This paper primarily aims at explaining the structure and properties of the newly developed overlapping generation model with four types of households grouped by income levels based on the latest Japanese data. Along with detailed account of the model structure and data, the sensitivity analysis on the key parameters, which are not fully supported by empirical studies, are conducted. Regarding policy simulations, we examine the fiscal sustainability of Japan under the current levels of debt and fiscal policy. Key findings are as follows. First, the financial collapse defined as a convergence limit, appears in 2040 when the debt-GDP ratio reaches 457%, implying that a significant tax hike is required to sustain the economy. Second, 30% of the consumption tax rate is necessary to restrain levels of the debt-GDP ratio from exceeding 457%, if the current structure of government spending lasts in the long run. Third, the lifetime net tax burden rate varies among households. The rate tends to be higher as they are born later (younger), and as they are richer.
B41|消費増税を望むのは誰か？|本稿では、世代内の異質性を組み込んだ一般均衡型世代重複シミュレーションモデルを用いて、我が国財政の持続可能性を維持するために必要な財政再建について、消費増税か累進労働所得増税かという二択問題を想定し、効用基準と現行の投票制度を前提とした投票によって決定する場合の分析を行った。その結果、消費税増税への賛成者は、中年より若い世代の高所得層だけであり、財政当局が目論む財政再建策は実現不可能である。そこで、ベンサム型政府を想定し、財政再建開始年に生存するすべての国民の効用変化の総和を考慮した場合には、消費税が選択されると確認された。しかし、この結果は、もっぱら高所得層の利益のため他の所得階層に犠牲を強いるに等しい選択であり、公平性に適う選択であるかは疑問の余地が大きい。最後に、将来世代のなかでも、消費増税による財政再建のメリットが帰属する生年・所得階層を特定化するシミュレーションによれば、より高い所得階層に属する者ほど、また、より後に生まれる者ほど消費税の増税から得られる恩恵が大きいことが分かった。投票によっては、2137年生まれまでの将来世代を投票対象者に考慮しなければ消費増税による財政再建を実現できず、実質的に不可能であることが示された。, We calculate welfare changes to reveal Japan’s preferred tax hike option to achieve fiscal sustainability by an overlapping generation model with four types of households grouped by income levels based on the latest Japanese data. Households vote on preferred taxation, i.e. the consumption tax or the progressive income tax, according to respective welfare changes under the current election system. Following implications are delivered. First, the consumption tax option is chosen when voters consider temporary welfare changes alone, i.e. myopic, while the progressive income tax is chosen when voters consider life-long welfare changes, i.e. rational. Second, the consumption tax option is chosen under the Utilitarian-type government setting even when life-long welfare changes are considered. However, this choice results in net benefits among higher income households at the cost of lower income households, giving rise to worsening income distribution and unfairness. Third, the fiscal consolidation by the consumption tax option tends to bring net benefits to those with higher income, and to those born later. Finally, the government intention to raise the consumption tax further for fiscal consolidation will not be achieved by the current voting system with rational voters. To realize it through voting, it is necessary to give the right of voting to those who will be born before 2137.
B41|Distribution-led growth through methodological lenses|"This paper presents a methodological discussion of two recent ""endogeneity"" critiques of the Kaleckian model and the concept of distribution-led growth. From a neo-Keynesian perspective, it is criticized because it treats distribution as quasi-exogenous, while in Skott (2017), distribution is viewed as endogenously determined by a series of (exogenous) institutional factors and social norms, and therefore one should focus on these instead of the functional distribution of income per se. The paper discusses how abstraction is used in science and economics, and uses the criteria proposed by Lawson (1989) for what constitutes an appropriate abstraction. Based on this discussion, it concludes that the criticisms are weak, although the issues raised by Skott provide some interesting directions for future work within the Kaleckian framework."
B41|Methods Matter: P-Hacking and Causal Inference in Economics|The economics 'credibility revolution' has promoted the identification of causal relationships using difference-in-differences (DID), instrumental variables (IV), randomized control trials (RCT) and regression discontinuity design (RDD) methods. The extent to which a reader should trust claims about the statistical significance of results proves very sensitive to method. Applying multiple methods to 13,440 hypothesis tests reported in 25 top economics journals in 2015, we show that selective publication and p-hacking is a substantial problem in research employing DID and (in particular) IV. RCT and RDD are much less problematic. Almost 25% of claims of marginally significant results in IV papers are misleading.
B41|The Relativity Theory of General Economic Equilibrium|"Abstract Purpose. The purpose of this paper is to propose a new approach to the understanding of self-regulation mechanism of decentralized economic system. Design/methodology/approach. As a result of the dialectical analysis of fundamental economic categories of market economy it appears as the form of a complex, non-linear, functionally closed and causally open system of economic actions. These systems have a number of unique properties that are well studied by second-order cybernetics. This allows in the study of economic processes the unique research and development of this science to be involved in the interdisciplinary format. Findings. The self-organization of a market economy is carried out through the recursive processes. Recursive processes in the economic system, as well as in other complex nonlinear dynamical systems, generate ""eigenvalues"" (""fixed points""). These ""eigenvalues"" are the equilibrium prices to which through the recursive processes tend the actual market prices, thus providing a tendency of the system to the general equilibrium. However, due to constant influence on the system of random external factors, the general equilibrium is never achieved. Research limitations/implications. On the base of the created model the hidden relationships among the gross profit, gross saving, gross investment and gross consumption in debt, as well as the relationships among the other economic parameters are revealed. This is important for adequate understanding of economic reproduction, tendency to general equilibrium, genesis of economic cycles, etc. Practical implications. The proposed understanding of self-regulation mechanism of decentralized economic system will help to improve the applied economic models and to develop the effective economic policy. Originality/value. The original interpretation of economic self-regulation mechanism of market economy is given. The ―Symmetrical model‖ of general economic equilibrium, which shows how economic forces arise, where they are directed and how interact with each other, which provide the homeostasis of a decentralized economic system, is proposed. This model shows the attractor of a real disequilibrium economy."
B41|Searching for a theory that fits the data: A personal research odyssey|"This survey paper discusses the Cointegrated VAR methodology and how it has evolved over the last 30 years. The first section is a description of major steps in the econometric development of the CVAR model that facilitated serious real world applications. The next three sections are primarily methodological and discuss (i) difficulties and puzzles when confronting theory with the data, (ii) the formulation of a viable link between theory and the data, a so called theory-consistent CVAR scenario, and (iii) how all this was inspired by Trygve Haavelmo and his Nobel prize winning monograph ""The Probability Approach to Economics"". The next two sections discuss early applications of the Cointegrated VAR model to monetary transmission mechanisms, international transmission mechanisms and wage, price and unemployment dynamics. They report puzzling evidence, discuss the need for new theory, and propose a method for combining partial CVAR analyses into a larger macroeconomic model. The following sections propose a new, empirically-based, approach to macroeconomics in which imperfect knowledge based expectations replace so called rational expectations and in which the financial sector plays a key role for understanding the long persistent movements in the data. The last section argues that the CVAR can act as a ""design of experiment for passive observations"" and illustrates with several applications including unemployment dynamics under crises periods and aid effectiveness in South Saharan African countries."
B41|Positional goods and legal orderings|People consume because others consume, maintained Veblen in 1899. More recently, theoretical, empirical and experimental articles have argued that people constantly compare themselves to their environments and care greatly about their relative positions. Given that competition for positions may produce social costs, we adopt a Law and Economics approach (i) to suggest legal remedies for positional competition, and (ii) to argue that, because legal relations are characterized in turn by positional characteristics, such legal remedies do not represent ‘free lunches’
B41|Ethics and Economics: A Complex Systems Approach| This chapter examines the nature of ethics and economics as a single subject of investigation, and uses a complex systems approach to characterize the nature of that subject. It then distinguishes mainstream economic and social economic visions of it, where the former assumes that market processes encompass social processes, and the latter assumes that market processes are embedded in social processes. For each vision, string and weak theses are compared. Both visions are first explained in terms of their respective views of the positive-normative distinction, then in terms of a central normative principle, and then in terms of their policy strategies. The chapter closes with comments on the future status of ethics and economics as a single subject of investigation.
B41|Economics and Economic Methodology in a Core-Periphery Economic World| This paper uses a core-periphery distinction to characterize contemporary economics, economic methodology, and also today's world economy. First, it applies the distinction to the organization of contemporary economics through an examination of the problem of explaining economics' relations to and boundaries with other disciplines. Second, it argues that economics' core-periphery organization is replicated in a similar organization of the use and practice of contemporary economic methodology in economics. Third, it draws on the use of the core-periphery thinking in economics itself and the uneven development of the world economy to provide possible foundations for economics and economic methodology being organized in core-periphery terms. Fourth, the paper briefly discusses three as a potential countervailing forces operating on the development of contemporary economics that might work against its core-periphery organization.
B41|The role of natural resources in production: Georgescu-Roegen/ Daly versus Solow/ Stiglitz|"This paper proposes a historical and epistemological account of one of the key controversy between natural resources economics and ecological economics, lasting from early 1970s to the end of 1990s. It shows that the theoretical disagreement on the scope of the economy's dependence to natural resources, such as energy and minerals, has deep methodological roots. On one hand, Solow's and Stiglitz's works are built on a ""model-based methodology"", where the model precedes and supports the conceptual foundations of the theory and in particular the assumption of ""unbounded resources productivity"". On the other hand, Georgescu-Roegen's counter-assumption of ""thermodynamic limits to production"", later revived by Daly, rest on a methodology of ""interdisciplinary consistency"" which considers thermodynamics as a relevant scientific referent for economic theory. While antagonistic, these two methodologies face similar issues regarding the conceptual foundations that arise from them, which is a source of confusion and of the difficult dialogue between paradigms."
B41|From Methodology to Practice (and Back): Georgescu-Roegen's Philosophy of Economics and the Flow-Fund Model|Despite his early contribution to the rise of mathematics in economics, Georgescu-Roegen's later methodological criticism of models has received little attention from historians and philosophers of economics. This paper attempts to fill this gap following two lines. First, I examine his explicitly methodological claims and connect them with related topics in economic methodology. Building on the distinction between dialectical and arithmomorphic concepts, I characterise his approach to theory-making as a three steps process of idealisation, isolation and arithmetisation. In this framework, models perform two functions, checking for logical consistency and facilitating understanding, which can be related to the idea of modelling as theorising. I then confront these general principles with Georgescu-Roegen's flow-fund model of production. I use the methodology as a reading grid of this theory, while examining its limits and complementary principles in practice. This shows a great deal of consistency, where idealisation provides conceptual foundations, isolation determines the relevant problems, and models are built according to structural consistency. The two functions of models are then illustrated by the logical derivation of older principles formulated by Babbage and Smith, and the understanding of the different organisational patterns of production. But some slightly different functions also appear when specific configurations of the model enable to check the conceptual consistency of other theories, or the understanding provided by the model contributes to the formation of new concepts. Hence, the consistency and the complementarity between Georgescu-Roegen's methodology and practice of theory-making provide interesting insights and a useful background for further investigations.
B41|Non-linear Real Arithmetic Benchmarks derived from Automated Reasoning in Economics|We consider problems originating in economics that may be solved automatically using mathematical software. We present and make freely available a new benchmark set of such problems. The problems have been shown to fall within the framework of non-linear real arithmetic, and so are in theory soluble via Quantifier Elimination (QE) technology as usually implemented in computer algebra systems. Further, they all can be phrased in prenex normal form with only existential quantifiers and so are also admissible to those Satisfiability Module Theory (SMT) solvers that support the QF_NRA logic. There is a great body of work considering QE and SMT application in science and engineering, but we demonstrate here that there is potential for this technology also in the social sciences.
B41|Testing the Waters: Behavior across Participant Pools|We leverage a large-scale incentivized survey eliciting behaviors from (almost) an entire university student population, a representative sample of the U.S. population, and Amazon Mechanical Turk (MTurk) to address concerns about the external validity of experiments with student participants. Behavior in the student population offers bounds on behaviors in other populations, and correlations between behaviors are largely similar across samples. Furthermore, non-student samples exhibit higher measurement error. Adding historical lab participation data, we find a small set of attributes over which lab participants differ from non-lab participants. Using an additional set of lab experiments, we see no evidence of observer effects.
B41|Sniff Tests in Economics: Aggregate Distribution of Their Probability Values and Implications for Publication Bias|"The increasing demand for rigor in empirical economics has led to the growing use of auxiliary tests (balance, specification, over-identification, placebo, etc.) supporting the credibility of a paper's main results. We dub these ""sniff tests"" because standards for passing are subjective and rejection is bad news for the author. Sniff tests offer a new window into publication bias since authors prefer them to be insignificant, the reverse of standard statistical tests. Collecting a sample of nearly 30,000 sniff tests across 60 economics journals, we provide the first estimate of their aggregate probability-value (p-value) distribution. For the subsample of balance tests in randomized controlled trials (for which the distribution of p-values is known to be uniform absent publication bias, allowing reduced-form methods to be employed) estimates suggest that 45% of failed tests remain in the ""file drawer"" rather than being published. For the remaining sample with an unknown distribution of p-values, structural estimates suggest an even larger file-drawer problem, as high as 91%. Fewer significant sniff tests show up in top-tier journals, smaller tables, and more recent articles. We find no evidence of author manipulation other than a tendency to overly attribute significant sniff tests to bad luck."
B41|Methods Matter: P-Hacking and Causal Inference in Economics|The economics 'credibility revolution' has promoted the identification of causal relationships using difference-in-differences (DID), instrumental variables (IV), randomized control trials (RCT) and regression discontinuity design (RDD) methods. The extent to which a reader should trust claims about the statistical significance of results proves very sensitive to method. Applying multiple methods to 13,440 hypothesis tests reported in 25 top economics journals in 2015, we show that selective publication and p-hacking is a substantial problem in research employing DID and (in particular) IV. RCT and RDD are much less problematic. Almost 25% of claims of marginally significant results in IV papers are misleading.
B41|The strategies of economic research - An empirical study|The paper analyzes the structure of strategies of economic research on a sample of all regular research papers in 10 general interest journals every 5th year from 1997 to 2017. It is 3,415 papers, with an annual upward trend of 3.3%. I have classified the papers into eight categories: The fraction in theory and empirics are almost equal large. Most empiric papers use the classic strategy, which derives an operational model from theory and run regressions. Several trends are highly significant - notably two main ones: The fraction of theoretical papers has fallen by 26 pp (percentage points), while the fraction of papers using the classic strategy has increased by 15 pp. Many papers using the classic strategy have been analyzed using meta-analysis, which show that the typical paper exaggerate the results reported substantially. There is no reason to believe that other strategies have smaller problems.
B41|Cliometrics|"Cliometrics has been defined and summarized in numerous scholarly articles. They all pretty much start with the obvious, that cliometrics is the application of economic theory and quantitative techniques to study history; and then move on to the origin of the name, the joining of Clio (the muse of history), with metrics (""to measure,"" or ""the art of measurement""), allegedly coined by economist Stanley Reiter while collaborating with economic historians Lance Davis and Jonathan Hughes."
B41|Evaluating regulatory reform of network industries: a survey of empirical models based on categorical proxies|Proxies for regulatory reforms based on categorical variables are increasingly used in empirical evaluation models. We surveyed 63 studies that rely on such indices to analyze the effects of entry liberalization, privatization, unbundling, and independent regulation of the electricity, natural gas, and telecommunications sectors. We highlight methodological issues related to the use of these proxies. Next, taking stock of the literature, we provide practical advice for the design of the empirical strategy and discuss the selection of control and instrumental variables to attenuate endogeneity problems undermining identification of the effects of regulatory reforms.
B41|Testing the Waters: Behavior across Participant Pools|We leverage a large-scale incentivized survey eliciting behaviors from (almost) an entire university student population, a representative sample of the U.S. population, and Amazon Mechanical Turk (MTurk) to address concerns about the external validity of experiments with student participants. Behavior in the student population offers bounds on behaviors in other populations, and correlations between behaviors are largely similar across samples. Furthermore, non-student samples exhibit higher measurement error. Adding historical lab participation data, we find a small set of attributes over which lab participants differ from non-lab participants. Using an additional set of lab experiments, we see no evidence of observer effects.
B41|Place-specific Determinants of Income Gaps: New Sub-National Evidence from Chiapas, Mexico|The literature on income gaps between Chiapas and the rest of Mexico revolves around individual factors, such as education and ethnicity. Yet, twenty years after the Zapatista rebellion, the schooling gap between Chiapas and the other Mexican entities has shrunk while the income gap has widened, and we find no evidence indicating that Chiapas indigenes are worse-off than their likes elsewhere in Mexico. We explore a different hypothesis. Based on census data, we calculate the economic complexity index, a measure of the knowledge agglomeration embedded in the economic activities at a municipal level in Mexico. Economic complexity explains a larger fraction of the income gap than any individual factor. Our results suggest that chiapanecos are not the problem, the problem is Chiapas. These results hold when we extend our analysis to Mexico’s thirty-one federal entities, suggesting that place-specific determinants that have been overlooked in both the literature and policy, have a key role in the determination of income gaps.
B41|Growth Accelerations Strategies|Setting a country’s structural growth rate on a higher path, i.e. sparking and sustaining a growth acceleration can have quantitatively huge implications for national income and, more broadly, for people’s wellbeing. We develop a novel statistical framework to identify systematically the set of binding constraints that were unlocked before the 135 growth acceleration episodes that took place between 1962 and 2002 worldwide. We employ this information to characterise the acceleration process, which tends to be preceded by a deep recession and major economic policy changes. Once we combined this information with a set of counterfactual analyses, we find however that successful acceleration strategies should not contain off-the-shelf approaches or necessarily all-encompassing “shock therapy” solutions. On the other hand, they call for a careful tailoring to local conditions. Richer countries tend to experience fewer accelerations, but once these have been ignited, they are better positioned to make the most out of them. Despite standard growth determinants doing a fairly good job at characterising successful accelerations, we note how take-offs remain extremely hard to engineer with a high degree of certainty.
B41|Lawrence R. Klein and the making of large-scale macro-econometric modeling, 1938-1955|Lawrence R. Klein was the father of macro-econometric modeling, the scientific practice that dominated macroeconomics throughout the second half of the twentieth century. Therefore, understanding how Klein developed his identity as a macro-econometrician and how he conceived and forged macro-econometric modeling at the same time, is essential to draw a clear picture of the origins and subsequent development of this scientific practice in the United States. To this aim, I focus on Klein’s early trajectory as a student of economics and as an economist (from 1938-1955), and I particularly examine the extent to which the people and institutions Klein encountered helped him shape his professional identity. Klein’s experience at places like Berkeley, MIT, Cowles, and the University of Michigan, as well as his early acquaintance with people such as Griffith Evans, Paul Samuelson, and Trygve Haavelmo were decisive in the formation of his idea on how econometrics, expert knowledge, mathematical rigor, and a specific institutional configuration should enter macro-econometric modeling. Although Klein’s identity defined some of the most important characteristics of this practice, by the end of the 1950s, macro-econometric modeling became a scientific practice independent of Klein’s enthusiasm and with a “life of its own,” ready to be further developed and adapted to specific contexts by the community of macroeconomists.
B41|Contribución de la Operación de Bavaria S.A. a la Economía Colombiana|El estudio cuantifica la contribución de la operación de Bavaria S.A. a la economía colombiana de una manera integral a través de la metodología insumo-producto. El análisis considera no sólo los efectos directos de la producción de Bavaria S.A. sino también los impactos indirectos, e inducidos de forma tal que pueda capturarse el aporte a la economía a nivel agregado. Para esto, el análisis tiene en cuenta las interrelaciones económicas de Bavaria S.A. con el resto de sectores de la economía, así como con otros agentes como los hogares y el Gobierno plasmadas en una Matriz de Contabilidad Social (SAM). Se encuentra que los efectos indirectos en producción, valor agregado, empleo, salarios y pago de impuestos son importantes, incluso en muchos casos superiores a la contribución directa de la compañía.
B41|Testing the Waters: Behavior across Participant Pools|We leverage a large-scale incentivized survey eliciting behaviors from (almost) an entire university student population, a representative sample of the U.S. population, and Amazon Mechanical Turk (MTurk) to address concerns about the external validity of experiments with student participants. Behavior in the student population offers bounds on behaviors in other populations, and correlations between behaviors are largely similar across samples. Furthermore, non-student samples exhibit higher measurement error. Adding historical lab participation data, we find a small set of attributes over which lab participants differ from non-lab participants. Using an additional set of lab experiments, we see no evidence of observer effects.
B41|LES ORIGINES DE LA DISTINCTION ENTRE POSITIF ET NORMATIF EN ECONOMIE (The Origin of the Positive-normative Distinction in Economics)|Economists are accustomed to distinguishing between a positive and a normative component of their work, a distinction that is peculiar to their field, having no exact counterpart in the other social sciences. The distinction has substantially changed over time, and the different ways of understanding it today are reflective of its history. Our objective is to trace the origins and initial forms of the distinction, from the English classical political economy of the first half of the 19th century to the emergence of welfare economics in the first half of the 20th century. This sequential account will also serve to identify the main representative positions along with the arguments used to support them, and it thus prepares the ground for a discussion that will be less historical and more strictly conceptual.
B41|The Allais Paradox: What It Became, What It Really Was, What It Now Suggests to Us|"Whereas many others have scrutinized the Allais paradox from a theoretical angle, we study the paradox from an historical perspective and link our findings to a suggestion as to how decision theory could make use of it today. We emphasize that Allais proposed the paradox as a normative argument, concerned with ""the rational man"" and not the ""real man"", to use his words. Moreover, and more subtly, we argue that Allais had an unusual sense of the normative, being concerned not so much with the rationality of choices as with the rationality of the agent as a person. These two claims are buttressed by a detailed investigation – the first of its kind – of the 1952 Paris conference on risk, which set the context for the invention of the paradox, and a detailed reconstruction – also the first of its kind – of Allais's specific normative argument from his numerous but allusive writings. The paper contrasts these interpretations of what the paradox historically represented, with how it generally came to function within decision theory from the late 1970s onwards: that is, as an empirical refutation of the expected utility hypothesis, and more specifically of the condition of von Neumann-Morgenstern independence that underlies that hypothesis. While not denying that this use of the paradox was fruitful in many ways, we propose another use that turns out also to be compatible with an experimental perspective. Following Allais's hints on ""the experimental definition of rationality"", this new use consists in letting the experiment itself speak of the rationality or otherwise of the subjects. In the 1970s, a short sequence of papers inspired by Allais implemented original ways of eliciting the reasons guiding the subjects' choices, and claimed to be able to draw relevant normative consequences from this information. We end by reviewing this forgotten experimental avenue not simply historically, but with a view to recommending it for possible use by decision theorists today."
B41|Nominal wage rigidity in the EU countries before and after the Great Recession: evidence from the WDN surveys|This paper studies the recent trends in nominal wage rigidity in a large group of EU countries, using survey data. We analyse two forms of nominal wage rigidity: downward nominal wage rigidity (DNWR) and the lagged response of wages to shocks. The frequency of wage changes, which is an indicator of lagged wage setting, slowed down in the aftermath of the Great Recession. We assess the possible reasons for this and show that it was at least partially caused by a combination of a decline in average wage growth and persistent DNWR. In countries where wage growth slowed down more after the Great Recession, the frequency of wage changes declined more steeply as well. Our data allows evaluating the prevalence of DNWR in diverse economic circumstances. Like earlier research on this topic, we find that DNWR tends to be strongly prevalent, even in periods of slow economic growth and low wage inflation. DNWR declines during severe recessions but even then wage setting does not become completely flexible as the proportion of observed wage cuts is still below the level that would correspond to a flexible regime. JEL Classification: B41, D22
B41|Nominal wage rigidity in the EU countries before and after the Great Recession: evidence from the WDN surveys|This paper studies the recent trends in nominal wage rigidity in a large group of EU countries, using survey data. We analyse two forms of nominal wage rigidity: downward nominal wage rigidity (DNWR) and the lagged response of wages to shocks. The frequency of wage changes, which is an indicator of lagged wage setting, slowed down in the aftermath of the Great Recession. We assess the possible reasons for this, and show that it was at least partially caused by a combination of a decline in average wage growth and persistent DNWR. In countries where wage growth slowed down more after the Great Recession, the frequency of wage changes declined more steeply as well. Our data allows evaluating the prevalence of DNWR in diverse economic circumstances. Like earlier research on this topic, we find that DNWR tends to be strongly prevalent, even in periods of slow economic growth and low wage inflation. DNWR declines during severe recessions but even then wage setting does not become completely flexible as the proportion of observed wage cuts is still below the level that would correspond to a flexible regime.
B41|The influence of Sen’s applied economics on his “social choice” approach to justice: agency at the core of public action to remove injustice|Our paper shows that Sen’s (2009) alternative theory of justice is greatly influenced by 1) his work on famines ; 2) his empirical work on gender inequalities, specifically within the Indian society, that helped him to refine his approach to hunger ; and 3) his involvement in the creation of the human development approach. All these engagements — seemingly completely separate from his contribution to the theories of justice — have, in fact, fostered the formulation of a novel approach in which agency and public reasoning are the core elements.
B41|Cliometrics|"Cliometrics has been defined and summarized in numerous scholarly articles. They all pretty much start with the obvious, that cliometrics is the application of economic theory and quantitative techniques to study history; and then move on to the origin of the name, the joining of Clio (the muse of history), with metrics (""to measure,"" or ""the art of measurement""), allegedly coined by economist Stanley Reiter while collaborating with economic historians Lance Davis and Jonathan Hughes.<br><small>(This abstract was borrowed from another version of this item.)</small>"
B41|Postkeynesianismus: Ein heterodoxer Ansatz auf der Suche nach einer Fundierung|In diesem Beitrag geht es darum, den Postkeynesianismus als paradigmatische Alternative zum herrschenden neoklassischen Mainstream etwas näher kennenzulernen. Es zeigt sich sehr schnell, dass der Postkeynesianismus keine einheitliche Denkschule darstellt, sondern vielmehr eine Vielzahl von theoretischen Ansätzen darunter zu verstehen ist, die eine Reihe von methodologischen und epistemologischen Gemeinsamkeiten aufweist und die einige identitätsstiftende Postulate verbindet. Zum konkreten Nachvollzug dieser Postulate aus dem axiomatischen Kern des Postkeynesianismus wird dann darauf verzichtet, dass Kaleidoskop postkeynesinaischer Theorie mit kaleckianischer, kaldorianischer oder gar sraffianischer Grundlage aufzuzeigen, sondern es wird vielmehr nur ein Postkeynesianismus - die monetäre Theorie der Produktion - in seiner paradigmatischen und formalen Struktur beleuchtet und die darauf aufbauende Theorie der Marktteilnahme als alternative Theorie der Wirtschaftspolitik dargelegt.
B41|On the question of the relevance of Economics as a science: Postmodern filosofia critique|This article has adopted an open discourse in addressing pertinent concerns about the scientific existence of economics as a discipline. In doing so, some (critical) Filosofia arguments have been provided in ensuring that a well balanced approach is taken on the subject. Obviously, the approach of Popperian falsification used by economic science to address scientific justification through its varied scientific platform of technology applications like EVIEWS, STATA, MatLab and many more, have been applauded. Albeit such advances, the views of modern and postmodern critics have also come out saliently in a bid to ensuring open discourses are brought to the fore as a way of adding scientific value to the subject matter. In concluding, it was acknowledged that more is needed in ensuring that economic science as practiced by economists takes an open approach to critical discourse(s), reflecting reality about its pursed scientific ventures, given the persistence of economic volatility manifested across the global community.
B41|Das Experteninterview als Datenerhebungsmethode in Prüfungsarbeiten|No abstract is available for this item.
B41|Die Verantwortung von Wirtschaftswissenschaftlern für Wirtschaftskrisen und die Wirtschaft allgemein|Die jüngste globale Wirtschafts- und Finanzkrise sowie die Eurokrise werden kurz skizziert und analysiert. Wirtschaftswissenschaftler waren an diesen Krisen und ihrer Überwindung beteiligt. Ihr Anteil sollte jedoch nicht überschätzt werden. Mehr Forschung zu relevanten Problemen und eine bessere Vermittlung der Forschungsergebnisse wären wünschenswert, wozu jedoch die Anreizstrukturen in den Wirtschaftswissenschaften verbessert werden sollten.
B41|Wider die Zahlengläubigkeit: Sind Befragungsergebnisse eine gute Grundlage für wirtschaftspolitische Entscheidungen?|Befragungen von Konsumenten, Steuerzahlern und Wählern werden in Wirtschaft und Politik häufig als Entscheidungsgrundlage herangezogen. Die Ergebnisse dieser Befragungen können somit großen Einfluss auf politische Entscheidungen und damit auf den Alltag vieler Menschen haben. Befragungen sind besonders dann wichtig und notwendig, wenn noch keine entsprechenden Verhaltensdaten oder Erfahrungswerte vorliegen. Helga Fehr-Duda und Robin Schimmelpfennig gehen der Frage nach, ob Angaben zur Zahlungsbereitschaft, die in hypothetischen Entscheidungssituationen gemacht werden, glaubwürdig und zuverlässig genug sind, um als Grundlage für unternehmerische und wirtschaftspolitische Entscheidungen zu dienen. Die Autoren zeigen anhand zweier neuer Studien, dass Ergebnisse hypothetischer Befragungen, wie beispielsweise einer Stated preference Befragung, signifikant vom Kontext der Entscheidungssituation abhängen. Es ist daher nicht möglich, allgemeine kontextunabhängige Aussagen zum Ausmaß der möglichen Fehleinschätzung von Zahlungsbereitschaften zu treffen. Die Autoren empfehlen, wann immer möglich Labor- oder Feldexperimente im relevanten Kontext mit realen monetären Anreizen durchzuführen. In jenen Fällen, in denen hypothetische Befragungen die einzige Möglichkeit der Datengewinnung darstellen, ist es unabdingbar, das Befragungsdesign möglichst anreizverträglich, realitätsnah und dem Anwendungskontext angemessen zu gestalten. Auftraggeber sollten auf die Einhaltung dieser Grundsätze bestehen, um möglichst valide Befragungsergebnisse zu erhalten.
B41|A Tourism Financial Conditions Index for Tourism Finance|The paper uses monthly data on tourism related factors from April 2005–June 2016 for Taiwan that applies factor analysis and Chang’s (2015) novel approach for constructing a tourism financial indicator, namely the Tourism Financial Conditions Index (TFCI). The TFCI is an adaptation and extension of the widely-used Monetary Conditions Index (MCI) and Financial Conditions Index (FCI) to tourism stock data. However, the method of calculation of the TFCI is different from existing methods of constructing the MCI and FCI in that the weights are estimated empirically. The empirical findings show that TFCI is statistically significant using the estimated conditional mean of the tourism stock index returns (RTS). Granger Causality tests show that TFCI shows strong feedback on RTS. An interesting insight is that the empirical results show a significant negative correlation between F1_visitors (Foreign Visitor Arrivals) and RTS, implying that tourism authorities might promote travel by the “rich”, and not only on inbound visitor growth. The use of market returns on the tourism stock sub-index as the sole indicator of the tourism sector, as compared with the general activity of economic variables on tourism stocks, is shown to provide an exaggerated and excessively volatile explanation of tourism financial conditions.
B41|A cliometric counterfactual: what if there had been neither Fogel nor North?|Abstract 1993 Nobel laureates Robert Fogel and Douglass North were pioneers in the “new” economic history, or cliometrics. Their impact on the economic history discipline is great, though not without its critics. In this essay, we use both the “old” narrative form of economic history, and the “new” cliometric form to analyze the impact each had on the evolution of economic history.
B41|Some “unexpected proximities” between Schultz and Galbraith on human capital|This contribution highlights some unexpected proximities between Galbraith and Schultz’s thoughts on human capital. Despite apparently strong methodological divergences, both authors analyze the issue of human capital investment in the light of the dynamics of the economic development process. This issue is formulated in Galbraith’s vocabulary in terms of the requirements of the planning system, and in terms of the needs of production activities deriving from the dynamics of growth in Schultz’s. But the logic underlying their analysis is of the same order. The emphasis on the needs of production leads the two authors to address the issue of student sovereignty in making allocative decisions regarding education. By highlighting these proximities, our study shows that Schultz’s thought on human capital must not be conflated, from a methodological point of view, with Becker’s and Mincer’s. We thus question the idea that the human capital research program is characterized by strong methodological unity, in particular that it is characterized by methodological individualism. That Becker and Mincer’s works rely on methodological individualism is not called into question; the idea that Schultz’s thought is grounded on it deserves more careful examination.
B41|J.S. Mill And The Universality Of The “Desire Of Wealth”|This paper deals with a debate about the universality of the “desire of wealth” in John Stuart Mill’s thought. The debate occurred in the literature about fifteen years ago, when Samuel Hollander and Sandra Peart published in 1999 a criticism of Abraham Hirsch and Neil De Marchi’s interpretation of Mill’s methodology. This article constitutes an attempt to solve the debate by providing a rationale for the disagreement between both sets of scholars. In particular, we show that the divergence between them comes from the fact that they ground their respective arguments using different texts, while neglecting that Mill gradually changed his mind in his writings subsequent to the 1836 essay entitled “On the Definition of Political Economy...”. First, in accordance with the development of his ethology, Mill deprived the maximizing behavior of its universal validity; then, Mill focused more and more on “competition” as economics’ basic axiom in order to stress its historical relevance; and finally Mill strengthened the relativity of the behavioral axiom with the introduction of the concept of “custom”.
B41|Positional goods and social welfare: a note on George Pendleton Watkins’ neglected contribution| Watkins's analysis of adventitious utility contains many aspects that are connected to the contemporary debate on positional goods. First, Watkins adventitious utility emerges from a process of social exclusion and can create negative externalities, in the sense that positive consumption of one individual implies negative consumption by another individual. Not only it creates negative externalities on other individuals, but it can initiate a race-to-the-bottom, where individuals waste an increasing amount of money on goods which do not possess any real utility.
B41|Meta-Analysis and Publication Bias: How Well Does the FAT-PET-PEESE Procedure Work?|This paper studies the performance of the FAT-PET-PEESE (FPP) procedure, a commonly employed approach for addressing publication bias in the economics and business meta-analysis literature. The FPP procedure is generally used for three purposes: (i) to test whether a sample of estimates suffers from publication bias, (ii) to test whether the estimates indicate that the effect of interest is statistically different from zero, and (iii) to obtain an estimate of the overall mean effect. Our findings indicate that the FPP procedure performs well in the basic but unrealistic environment of “fixed effects”, where all estimates are assumed to derive from a single population value and sampling error is the only reason for why studies produce different estimates. However, when we study its performance in more realistic data environments, where there is heterogeneity in the population effects across and within studies, the FPP procedure becomes unreliable for the first two purposes, and is less efficient than other estimators when estimating overall mean effect. Further, hypothesis tests about the overall, mean effect cannot be trusted.
B41|Die ökonomische Lehrbuchwissenschaft: Zum interdisziplinären Selbstverständnis der Volkswirtschaftslehre|Die moderne Volkswirtschaftslehre wirkt auf andere Wissenschaften, auf die Gesellschaft und die Politik ein. Im Kontext dazu wird in dem Paper das disziplinäre Selbstverständnis von Ökonominnen und Ökonomen herausgearbeitet, wie es den wichtigsten Lehrbüchern des Faches inhärent ist. Anhand von Thomas S. Kuhns Konzept der Lehrbuchwissenschaft wird die zentrale Bedeutung des Lehrbuches für die moderne Volkswirtschaftslehre aufgezeigt und dann im Rückgriff auf einschlägige Lehrbuchliteratur des Faches untersucht, welche wissenschaftshistorischen, methodologischen und didaktischen Grundpositionen darin festgehalten sind und im Rahmen akademischer ökonomischer Bildung vermittelt werden.
B41|Embedding as a pitfall for survey‐based welfare indicators: evidence from an experiment|Welfare measurement using multiple indicators requires knowledge about how individuals weight different aspects of wellbeing. The better life index provides a way of resolving this individual level weighting issue. It invites people to weight 11 dimensions, embedding measurable indicators. Ideally, the specific embedding of the same indicators should not change their weights in a welfare function. Our experiment shows, however, that varying the embedding structure decisively affects people's weightings, i.e. we observe strong embedding effects. The better life index hence fails to measure citizens’ true preferences. Embedding thus opens a gateway to manipulating survey‐based welfare measures.
B41|Addressing the malaise in neoclassical economics: A call for partial models|Economics is currently experiencing a climate of uncertainty regarding the soundness of its theoretical framework and even its status as a science. Much of the criticism is within the discipline, and emphasizes the alleged failure of the neoclassical viewpoint. This article proposes the deployment of partial modeling, utilizing Boolean networks (BNs), as an inductive discovery procedure for the development of economic theory. The method is presented in detail and then linked to the Semantic View of Theories (SVT), closely identified with Bas van Fraassen and Patrick Suppes, in which models are construed as mediators creatively negotiating between theory and reality. It is suggested that this approach may be appropriate for economics and, by implication, for any science in which there is no consensus theory, and a wide range of viewpoints compete for acceptance.
B41|A replication recipe: List your ingredients before you start cooking|"The author argues that researchers should do replications using preanalysis plans. These plans should specify at least three characteristics: (1) how much flowtime the researchers will spend, (2) how much money and effort (working hours) the researchers will spend, and (3) the intended results and the precision of the replication necessary for ""success"". A researcher's replication will be ""successful"" according to context-specific criteria in the preanalysis plan. The author also argues that the two biggest drawbacks of preanalysis plans-(1) that they discount unexpected but extraordinary findings and (2) that they make it difficult for researchers to prespecify all possible actions in their decision trees-are less relevant for replications compared with new research. The author concludes with describing a preanalysis plan for replicating a paper on housing demand and household formation."
B41|"A proposal for replicating Evanschitzky, Baumgarth, Hubbard, and Armstrong's ""Replication research's disturbing trend"" (Journal of Business Research, 2007)"|"This paper is about how the author proposes to replicate Evanschitzky, Baumgarth, Hubbard, and Armstrong's ""Replication research's disturbing trend"" (Journal of Business Research, 2007). This is because estimating the incidence of published replication research and its outcomes must be continued."
B41|Which tests not witch hunts: A diagnostic approach for conducting replication research|Replication research can be used to explore original study results that researchers consider questionable, but it should also be a tool for reinforcing the credibility of results that are important to policies and programs. The challenge is to design a replication plan open to both supporting the original findings and uncovering potential problems. The purpose of this paper is to provide replication researchers with an objective list of checks or tests to consider when planning a replication study. The authors present tips for diagnostic replication exercises in four groups: validity of assumptions, data transformations, estimation methods, and heterogeneous impacts. For each group, the authors present an introduction to the issues, a list of replication tests and checks, some examples of how these checks are employed in replication studies of development impact evaluations, and a set of resources that provide statistical and econometric details. The authors also provide a list of don'ts for how to conduct and report replication research.
B41|Should you choose to do so...: A replication paradigm|"This note introduces the concept of the replication paradigm, a framework that can (and should) be followed in every replication attempt. The paradigm expands, in part, on Bruce McCullough's well-known paraphrase of Berkeley computer scientist Jon Claerbout's insight - ""An applied economics article is only the advertising for the data and code that produced the results"" - and on the view that the primary social and scientific value of replication is to measure the scientific contribution of the inferences in an empirical study. The paradigm has four steps. First, in the ""candidate study,"" identify and state clearly the hypotheses advanced by the study's authors. Second, provide a clear statement of the authors' econometric methods. Third, discuss the data. Fourth, discuss the authors' statistical inference. The author's purpose in this ordering is to reverse the too-frequent focus in the replication literature on ""data."" The correct data, of course, are critical to the replication. But ""replication"" as a scientific endeavor will never achieve respectability unless and until it abandons a narrow focus on data and expands its focus to the underlying scientific inferences."
B41|Global Integration and World Migration|This paper explores a theory of migration based upon a number of conjectures about the role of digital media. It proposes that a number of factors including rising use of the internet providing widespread access to global information and an intensified communication between regions and countries brought about, for example, by intensified trade links bring about expansion of peopleâ€™s social space. This also expands the factors through which they compare their own living standards and social life with others. This expansion increases peopleâ€™s stress and strengthens their inclination to resort to migration as a means of reducing this heightened stress. Other things held constant, the expansion of peopleâ€™s social space intensifies their inclination to move across geographical space.
B41|Embedding Effects in the OECD Better Life Index|The OECD aims to foster ‘better policies for better lives'. To this end, the OECD invites people to evaluate quality-of-life indicators according to their individual preferences, using the web-based Better Life Index. These indicators are embedded in 11 broader well-being dimensions. Our experiment shows that this procedure yields strong embedding effects, casting serious doubts on the reliability of the Better Life Index as well as its usefulness in providing meaningful policy recommendations.
B41|Back to Buchanan? Explorations of welfare and subjectivism in behavioral economics| In light of behavioral findings regarding inconsistent individual decision-making, economists have begun to re-conceptualize the notion of welfare. One prominent account is the preference purification approach (PP), which attempts to reconstruct preferences from choice data based on a normative understanding of neoclassical rationality. Using Buchanan’s notion of creative choice, this paper criticizes PP’s epistemic, ontological, and psychological assumptions. It identifies PP as a static position that assumes the satisfaction of given ‘true preferences’ as the normative standard for welfare. However, following Buchanan, choice should be understood dynamically as a process whereby preferences constantly regenerate. Accordingly, the meaning of welfare emerges from an ongoing quest for individual self-constitution. If this holds true, then rationality axioms cannot serve as a priori normative standards. Instead, creative imagination and learning processes must remain central to any understanding of welfare in economics.
B41|The Empirics of Regulatory Reforms Proxied by Categorical Variables: Recent Findings and Methodological Issues| Some regulatory reforms do not change just a specific signal that can be represented by a quantitative continuous variable, such as a tax rate, a price cap, or an emission threshold. The standard theory of reform in applied welfare economics (going back to contributions by e.g. Ramsey, Samuelson and Guesnerie) asks the question: What is the marginal effect on social welfare of changing a policy signal? However, reforms such as privatization, unbundling or liberalization of network industries are often described by ‘packages’ shifting a policy framework. It is increasingly frequent in the empirical evaluation of such reforms to use categorical variables, often in polytomous form, for instance describing unbundling steps (vertical integration, accounting, functional, legal, ownership separation) on a discrete numerical scale, such as those proposed by the OECD and other international bodies. We review recent econometric literature evaluating regulatory reforms using such variables (40 papers) and we discuss some methodological issues arising in this context.
B41|Mindreading and endogenous beliefs in games| We argue that a Bayesian explanation of strategic choices in games requires introducing a psychological theory of belief formation. We highlight that beliefs in epistemic game theory are derived from the actual choice of the players, and cannot therefore explain why Bayesian rational players should play the strategy they actually chose. We introduce the players’ capacity of mindreading in a game theoretical framework with the simulation theory, and characterise the beliefs that Bayes rational players could endogenously form in games. We show in particular that those beliefs need not be ratifiable, and therefore that rational players can form action-dependent beliefs.
B41|What Do We Learn from Market Design?|In this paper we try to show how the social and political acceptance of Roth's market design for kidney exchange provides some explanation of the rejection of market logic. We address three hypotheses generally cited as potential causes of the market rejection of certain goods: (I) the corrupting nature of money, (II) the idea that the market as such would be rejected, and (III) the assumption that the basis for market rejection would be the dominance it implied between seller and buyer. The example of the device developed by Roth, Ünver and Sönmez (2004, 2005) regarding the matching of organs from living donors suggests a fourth hypothesis: the market rejection of organs appears to be based not on the existence of potential domination but on the fact that this market presupposes such domination. In other words, economic domination appears to be a prerequisite for the organ trade: no domination, no market.
B41|Models as Speech Acts: The Telling Case of Financial Models|This paper intends to bring Austinian themes into methodological discussion about models. Using Austinian vocabulary, I argue that models perform actions in and outside of the academic field. This multiplicity of fields induces a variety of felicity conditions and types of performed actions. If for example, an inference from a model is judged according to some epistemological criteria in the scientific field, the representation of the world which the model carries, will not be judged by the same criteria outside the scientific field. A model can be considered as a standard in a strict scientific framework, while not being used as part of public policies, or vice versa. However, we focus on the dynamics between different fields.
B41|Effects of eliciting long-run price forecasts on market dynamics in asset market experiments|In this study, we investigate (a) whether eliciting future price forecasts influences market outcomes and (b) whether differences in the way in which subjects are incentivized to submit ``accurate'' price forecasts influence market outcomes as well as the forecasts in an experimental asset market. We consider four treatments: one without forecast elicitation and three with forecast elicitation. In two of the treatments with forecast elicitation, subjects are paid based on their performance in both forecasting and trading, while in the other treatment with forecast elicitations, they are paid based on only one of those factors, which is chosen randomly at the end of the experiment. We found no significant effect of forecast elicitation on market outcomes in the latter case. Thus, to avoid influencing the behavior of subjects and market outcomes by eliciting price forecasts, paying subjects based on either forecasting or trading performance is better than paying them based on both.
B41|A Short Walk on the Wild Side: Agent-Based Models and their Implications for Macroeconomic Analysis|I discuss recent advances in agent-based modelling applied to macroeconomic analysis. I first present the building blocks of agent- based models. Furthermore, by relying on examples taken from recent works, I argue that agent-based models provide complementary or new lights with respect to more standard models on key macroeconomic issues like endogenous business cycles, the interactions between business cycles and long-run growth, and the role of price vs. quantity adjustments in the return to full employment. Finally, I discuss some limits of agentbased models and how they are currently addressed in the literature.
B41|Reacting to the Lucas Critique: The Keynesians' Pragmatic Replies|We illustrate how the Lucas Critique was called into question by Keynesian macroeconomists during the 1970s and 1980s. Our claim is that Keynesians' reactions were carried out from a pragmatic approach, which addressed the empirical and practical relevance of the Critique. Keynesians rejected the Critique as a general principle with no relevance for concrete macroeconometric practice; their rejection relied on econometric investigations and contextual analysis of the U.S. 1970s stagflation and its aftermath. Keynesians argued that the parameters of their models remained stable across this period, and that simpler ways to account for stagflation (such as the introduction of supply shocks into their models) provided better alternatives to improve policy evaluation
B41|Cheating in the Lab Predicts Fraud in the Field An Experiment in Public Transportations|We conduct an artefactual field experiment using a diversified sample of passengers of public transportations to study attitudes towards dishonesty. We find that the diversity of behavior in terms of dis/honesty in laboratory tasks and in the field correlate. Moreover, individuals who have just been fined in the field behave more honestly in the lab than the other fare-dodgers, except when context is introduced. Overall, we show that simple tests of dishonesty in the lab can predict moral firmness in life, although frauders who care about social image cheat less when behavior can be verified ex post by the experimenter.
B41|Under Risk, Over Time, Regarding Other People: Language and Rationality Within Three Dimensions<BR>[Face au risque, dans le temps, par rapport aux autres : langage et rationalité dans trois dimensions]|This paper conducts a systematic comparison of behavioral economics's challenges to the standard accounts of economic behaviors within three dimensions: under risk, over time and regarding other people. A new perspective on two underlying methodological issues, i.e., interdisciplinarity and the positive/normative distinction, is proposed by following the entanglement thesis of Hilary Putnam, Vivian Walsh and Amartya Sen. This thesis holds that facts, values and conventions have interdependent meanings in science which can be understood by scrutinizing formal and ordinary language uses. The goal is to provide a broad and self-contained picture of how behavioral economics is changing the mainstream of economics.
B41|Sen is not a capability theorist| This paper aims to clarify the status of capability in Sen’s idea of justice. Sen’s name is so widely associated with the concept of capability that commentators often assume that his contribution to the study of justice amounts to a capability theory, albeit underdeveloped. We argue that such a reading is misleading. Taking Sen’s reticence about operationalization seriously, we show that his contribution is inconsistent with a capability theory. Instead, we defend the idea that the capability approach plays a heuristic role: capability is a step in his argument against alternative materials, but is not meant as a definitive end. Sen defends a critical perspective primarily to encourage public reasoning and respect for agency as regards the definition of what should count in the evaluation of social states.
B41|Social-scienciation of Economics and its Consequences: On a Relative Convergence between Economics and Sociology|We are currently in times in which an increased discussion on interdisciplinarity is on the agenda. Economics tends to go into directions of sociology, history, and psychology, taking on topics of their domains. Questions of convergencies and divergencies between the academic subjects are a result. This observation goes parallel with sociological debate on the status of sociology. Major questions remaining are: (1.) Has the field of sociology changed since Emilé Durkheim or Max Weber? (2.) Which domain can sociology claim as being its exclusive ground? Answers to these questions have to identify a broader landscape of academic division: Economics is moving increasingly in the direction of social topics and sociological ground. The “imperialism of economics” (Granovetter) is increasingly approaching traditional academic fields of history, psychology, and sociology. However, at least two psychologists (H. Simon, D. Kahneman) and an economic historian (R. Fogel) have received Nobel prizes in economics. How can sociology map with this trend, how can this challenge be converted into an academic opportunity? The paper will explore observed trends in detail in order to conclude that the public image of sociology may have declined during recent decades, but the strategic use and importance of (economic) sociology has never been greater. Economic sociology seems to have become an upgraded discipline since social networks, communication processes, institutions and culture are increasingly considered as core dimensions. Of course, the conclusion follows exactly the script of earlier instructions provided by Max Weber or Joseph Schumpeter.
B41|Dimensions of Quality of Life in Germany: Measured by Plain Text Responses in a Representative Survey (SOEP)|This paper demonstrates how quality of life can be measured by plain text in a representative survey, the German Socio Economic Panel study (SOEP). Furthermore, the paper shows that problems that are difficult to monitor, especially problems like the state of the European Union, long-term climate change but also the national debt or problems with the quality of consumer goods (like food) and services (like medical treatment), are not issues of particular importance to the majority of people. Developments and risks that are difficult to monitor and only have long-term effects should be left primarily to the discourse conducted by experts and the politically-minded “elites”, the avant garde. And in representative democracies it is ultimately the parliamentarians who must decide. Parliamentarians are likely able to make somewhat better decisions using modern representative surveys and national dialogues than they would be without these instruments of civic participation. Nevertheless, improved civic participation cannot replace parliaments. In diesem Beitrag wird gezeigt, dass es heutzutage gut möglich ist, die Wichtigkeitgesellschaftlicher Ziele und dem Stand der Lebensqualität in der Bevölkerung mit Hilfe einesrepräsentativen Surveys (hier: dem Sozio-oekonomischen Panel, SOEP) mit offenen Fragenund Klartextantworten zu erheben und sinnvoll auszuwerten. Dabei zeigt sich, dasslangfristig wichtige, aber zugleich aktuell wenig spürbare Themen wie Klimawandel,Staatsverschuldung oder die Europäische Unionkaum genannt werden. Wir ziehen dieSchlussfolgerung, dass langfristig wirkende Entwicklungen und Gefahren auch weiterhinvorwiegend dem Diskurs der Fachleute und der politisch denkenden „Avantgarde“zugewiesen werden sollten. Undam Ende müssen in einer repräsentativen Demokratie dieParlamente entscheiden. Auf Basis von modernen repräsentativen Erhebungen undBürgerdialogen können Parlamente vermutlich etwas besser entscheiden als ohne dieseInstrumente der Bürgerbeteiligung. Aber auch eine noch so effektive Bürgerbeteiligung kannParlamente nicht ersetzen.
B41|Macroeconomic Policy in DSGE and Agent-Based Models Redux: New Developments and Challenges Ahead|The Great Recession seems to be a natural experiment for economic analysis, in that it has shown the inadequacy of the predominant theoretical framework - the New Neoclassical Synthesis (NNS) - grounded on the DSGE model. In this paper, we present a critical discussion of the theoretical, empirical and political-economy pitfalls of the DSGE-based approach to policy analysis. We suggest that a more fruitful research avenue should escape the strong theoretical requirements of NNS models (e.g., equilibrium, rationality, representative agent, etc.) and consider the economy as a complex evolving system, i.e. as an ecology populated by heterogenous agents, whose far-from-equilibrium interactions continuously change the structure of the system. This is indeed the methodological core of agent-based computational economics (ACE), which is presented in this paper. We also discuss how ACE has been applied to policy analysis issues, and we provide a survey of macroeconomic policy applications (fiscal and monetary policy, bank regulation, labor market structural reforms and climate change interventions). Finally, we conclude by discussing the methodological status of ACE, as well as the problems it raises.
B41|Exploring Links between FDI Inflows, Energy Consumption, and Economic Growth: Further Evidence from MENA Countries|This study aims to examine the nexus between economic growth, FDI inflows and energy consumption on a panel of 17 countries using a ¡®growth model¡¯ framework and simultaneous-equation models estimated by the generalized method of moments (GMM) over the 1990-2012 period. We also implement these empirical models for 17 countries selected on the basis of data availability. They include: (a) 12 Middle Eastern countries, namely: Saudi Arabia, Qatar, Oman, Kuwait, Lebanon, United Arab Emirates, Iraq, Turkey, Iran, Syria, Jordan and Yemen, (b) 5 North African countries, namely: Egypt, Morocco, Tunisia, Algeria and Libya. Our results indicate that there is a bidirectional causal relationship between FDI inflows and economic growth, as between well as energy consumption and economic growth. Besides, there is a unidirectional causal relationship between energy consumption to FDI inflows for the global panel. This implies that the increase of energy consumption increases the FDI inflows for individual and collective countries.
B41|Gordon Tullock’s ill-fated appendix: “Flatland Revisited”|Abstract In an unpublished appendix to his Organization of Inquiry (“Flatland Revisited”) Gordon Tullock develops and extends ideas from both Ludwig von Mises and Karl Popper. We first discuss these commonalities and extensions, which center on the notions of necessary truth and reciprocity. Then we recover the manuscript history as well as comments from James Buchanan and provide an answer to the question of why the manuscript was never published.
B41|Understanding Social Market Economy, Francesco Forte and His Interpretation|Abstract The social thought which emerges from Francesco Forte’s economic writings proves to be mainly inspired by methodological individualism, though interpreted through a peculiar “personalistic” key. We will analyze the peculiar traits of his thought and the specific contribution that Forte gave to the understanding of a specific economic theory based on the doctrine of “Ordoliberalism” or the “Freiburg School.” In our work, we will show how Forte proposes an interpretation of that doctrine, according to two of his main points of reference in economic and philosophical thought: Luigi Einaudi and Antonio Rosmini Serbati. Finally, we will present an important aspect of Forte’s work: his institutional analysis in the light of the particular civil philosophy expressed by Christian social teaching.
B41|Dynamic coordinating non-equilibrium|Abstract Neo-Walrasian conceptualizations and DSGE models are incompatible with the emergence of coordination and discoordination in economic activity. While many conceptualizations stemming from the Austrian tradition are generally consistent with these fundamental problems, their process driven approach is hampered by the use of equilibrium constructs. This paper argues for the adoption of formal models that avoid this problem by addressing the following questions. Why should Austrian macroeconomists model? Where do models fit in with respect to pure and applied theory? How to model without equilibrium? To answer this final question I present a structure that aids in the construction and communication of such models.
B41|Max Weber és a modern makroökonómia újraértelmezése. Elméleti keret a kortárs makroökonómia módszertani elemzéséhez<BR>[Max Weber and reinterpretation of modern macroeconomics. A theoretical framework for a contemporary methodological analysis]|A tanulmány bekapcsolódva a főáramú közgazdaságtant övező erőteljes vitába, egyes módszertani-gazdaságfilozófiai szempontokra kívánja felhívni a felek figyelmét. Olyan értelmezést szándékozik körvonalazni, amely Weber hagyományos neoklasszikus közgazdasági módszertana alapján jelöli ki az absztrakt-idealizált főáramú modellek adekvát helyét. Kitér a modellek és a valóság közötti viszonynak a hagyományos leegyszerűsítő empirikus ellenőrzésen túlmutató kritikájára is. Az értékelés egyben egy érzékeny szempontrendszert is rendelkezésre bocsát, amelynek a kortárs makroökonómiára való alkalmazása révén kidomborodnak a jelenleg széleskörűen elfogadott lineáris fejlődési modell által elfedett módszertani törések is.* Journal of Economic Literature (JEL) kód: B22, B41, E32.
B41|States of Nature and States of Mind: A Generalised Theory of Decision-Making, evaluated by application to Human Capital Development|Canonical economic agents act so as to maximise a single, representative, utility function. However there is accumulating evidence that heterogeneity in thought-processes may be an important determinant of individual behaviour. This paper investigates the implications of a vector-valued generalisation of the Expected Utility paradigm, which permits agents either to deliberate as per Homo-economics, or to act impulsively. That generalised decision theory is applied to explain irrational educational investment decisions, persistent social inequalities, the crowding-out effect, the pervasive influence of non-cognitive ability on socio-economic outcomes, and the dynamic relationships between non-cognitive ability, cognitive ability, and behavioural biases. These results suggest that the generalised decision theory warrants further investigation.
B41|Infinite Idealizations and Approximate Explanations in Economics|If we take it that, at least in the social sciences, “realistic” implies “finite”, then countless economic models involving infinitary assumptions must obviously be classified as unrealistic—for example, models with infinitely divisible goods, a continuum of traders, consumers optimizing over an infinite time horizon, or players optimizing over an infinite number of interactions. We argue that unrealistic models involving infinities can, in principle, supply explanations in economics. We develop a concept of approximate explanation based on the “method of decreasing abstraction”, that is, the practice of approximating complex situations through a sequence of increasingly realistic models. Our account of approximate explanation renders the testing view of economic science compatible with scientific realism. However, compatibility does not extend to the folk theorems for infinitely repeated games, which are used widely in applied economics (e.g., in industrial economics) and beyond (e.g., spontaneous emergence of social order). Explanations based on these theorems are rejected by our criterion.
B41|Preferences: Neither Behavioural nor Mental|Recent debates on the nature of preferences in economics have typically assumed that they are to be interpreted either as behavioural regularities or as mental states. In this paper I challenge this dichotomy and argue that neither interpretation is consistent with scientific practice in choice theory and behavioural economics. Preferences are dispositions with a multiply realizable causal basis, which explains why economists are reluctant to make a commitment about their interpretation.
B41|The Continuing Relevance of Keynes's Philosophical Thinking: Reflexivity, Complexity and Uncertainty|This paper explains the continuing relevance of Keynes’s philosophical thinking in terms of his anticipation of complexity thinking in economics. It argues that that reflexivity is a central feature of the philosophical foundations of complexity theory, and shows that Keynes employed an understanding of reflexivity in both his philosophical and economic thinking. This argument is first developed in terms of his moral science conception of economics and General Theory beauty contest analysis. The paper advances a causal model that distinguishes direct causal relationships and reflexive feedback channels, uses this to distinguish Say’s Law economics and Keynes’s economics, and explains the economy as non-ergodic in these terms. Keynes’s policy activism is explained as a complexity view of economic policy that works like self-fulfilling and self-defeating prophecies. The paper closes with a discussion of the ontological foundations of uncertainty in Keynes’s thinking, and comments briefly on what a complexity-reflexivity framework implies regarding his thinking about time.
B41|Agent-Based Modelingâ€™s Open Methodology Approach: Simulation, Reflexivity, and Abduction| This paper argues that agent-based modelingâ€™s innovations in method developed in terms of simulation techniques also involve an innovation in economic methodology. It shows how Epsteinâ€™s generative science conception departs from conventional methodological reasoning, and employs what I term an open rather than closed approach to economic methodology associated with the roles that reflexivity, counterfactual reasoning, and abduction play in ABM. Central to this idea is that improvements in how we know something, a matter of method, determine whether we know something, a matter of methodology. The paper links this alternative view of economics and economic methodology to a social science model of economics and contrasts this with standard economicsâ€™ natural science model of economics. The paper discusses what this methodological understanding implies about the concept of emergence.
B41|Reacting to the Lucas Critique: The Keynesians' Pragmatic Replies|We illustrate how the Lucas Critique was called into question by Keynesian macroeconomists during the 1970s and 1980s. Our claim is that Keynesians' reactions were carried out from a pragmatic approach, which addressed the empirical and practical relevance of the Critique. Keynesians rejected the Critique as a general principle with no relevance for concrete macroeconometric practice; their rejection relied on econometric investigations and contextual analysis of the U.S. 1970s stagflation and its aftermath. Keynesians argued that the parameters of their models remained stable across this period, and that simpler ways to account for stagflation (such as the introduction of supply shocks into their models) provided better alternatives to improve policy evaluation.
B41|Stagflation and the crossroad in macroeconomics: the struggle between structural and New Classical macroeconometrics|The article studies the 1978 macroeconomics conference titled “After the Phillips Curve”, where Lucas and Sargent presented their fierce attack against structural macroeconometric models, “After Keynesian Macroeconomics”. The article aims at enlarging the comprehension of changes in macroeconomics in the 1970s. It shows: 1) that Lucas and Sargent dit not tackle directly the issue of the explanation of stagflation; 2) but that the struggle between different methodological stances in the conference cannot be separated from the way macroeconomists interpreted stagflation; 3) that it was not an opposition between being in favor or against microfounded models, but rather on the way we build microfoundations; 4) finally that the study of the 1978 conference opens the doors for scrutinizing the evolution of institution macroeconometric models of the 1970s which were not totally overthrown by Lucas and Sargent's arguments
B41|Dampening General Equilibrium: From Micro to Macro|We argue that standard modeling practices often overstate the potency of general-equilibrium (GE) mechanisms. We formalize the notion that GE adjustment is weak, or that it takes time, by modifying an elementary Walrasian economy in two alternative manners. In one, we replace Rational Expectations Equilibrium with solution concepts that mimic Tâtonnement or Cobweb dynamics, Level-k Thinking, Reflective Equilibrium, and certain kinds of cognitive discounting. In the other, we maintain rational expectations but remove common knowledge of aggregate shocks and accommodate higher-order uncertainty. This permits us, not only to illustrate the broader plausibility of the notion that the GE adjustment may be weak or slow, but also to illustrate the sense in which our preferred approach—the one based on lack of common knowledge—can be seen as a disciplined substitute to certain kinds of bounded rationality. We finally discuss possible applications, including how our results may help reduce the gap between the macroeconomic effects of interest and the micro or local effects estimated in a growing empirical literature.
B41|Co-authorship in economic history and economics: Are we any different?|Over the last six decades there has been less co-authorship in leading economic history journals than in leading general economics journals. There has also been a strong, monotonic increase in co-authorship in economic history journals that roughly parallels general economics journals but sharply differs from leading history journals. Increased co-authorship cannot be explained by increasing use of econometrics or large data sets; rather, it is likely due to common changes in incentives facing economic historians and economists. Finally, co-authorships in economic history are more likely to be formed of individuals of different seniority compared to economics generally.
B41|Measuring and Bounding Experimenter Demand|We propose a technique for assessing robustness of behavioral measures and treatment effects to experimenter demand effects. The premise is that by deliberately inducing demand in a structured way we can measure its influence and construct plausible bounds on demand-free behavior. We provide formal restrictions on choice that validate our method, and a Bayesian model that microfounds them. Seven pre-registered experiments with eleven canonical laboratory games and around 19,000 participants demonstrate the technique. We also illustrate how demand sensitivity varies by task, participant pool, gender, real versus hypothetical incentives, and participant attentiveness, and provide both reduced-form and structural analyses of demand effects.
B41|Inside Job or Deep Impact? Using Extramural Citations to Assess Economic Scholarship|Does academic economic research produce material of scientific value, or are academic economists writing only for clients and peers? Is economics scholarship uniquely insular? We address these questions by quantifying interactions between economics and other disciplines. Changes in the impact of economic scholarship are measured here by the way other disciplines cite us. We document a clear rise in the extramural influence of economic research, while also showing that economics is increasingly likely to reference other social sciences. A breakdown of extramural citations by economics fields shows broad field impact. Differentiating between theoretical and empirical papers classified using machine learning, we see that much of the rise in economics’ extramural influence reflects growth in citations to empirical work. This parallels a growing share of empirical cites within economics. At the same time, the disciplines of computer science and operations research are mostly influenced by economic theory.
B41|A Keynesian Dynamic Stochastic Disequilibrium model for business cycle analysis|A Dynamic Stochastic Disequilibrium (DSDE) model is proposed for business cycle analysis. Unemployment arises from job rationing due to insucient aggregate spending. The nominal wage is taken as a policy variable subject to a collective Nash bargaining process between workers and rms with the state of the labor market a ecting the relative bargaining power. A precautionary saving motive arising from an uninsurable risk of permanent income loss implies an equilibrium relation between consumption, income and wealth. The DSDE model di ers from the corresponding Dynamic Stochastic General Equilibrium (DSGE) model with labor market clearing in important respects: (i) Output is determined from the demand side and not from the supply side; (ii) The steady-state interest rate cannot be interpreted as a natural rate; (iii) It has to be smaller than the rate of economic growth in order for a steady state to exist; (iv) Determinacy of the solution requires the monetary policy response to in ation to be high (low) at low (high) steady-state interest rates; (v) Fighting in ation is stabilizing in the active monetary policy regime but destabilizing in the passive monetary policy regime; (vi) Macroeconomic responses to monetary policy and productivity shocks are similar to those of the DSGE model but give more weight to quantity adjustment and predict the real wage to increase with productivity.
B41|The strategy of Russia’s economic development: From reference to referent|(On the book by L. P. Evstigneeva and R. N. Evstigneev “The strategy of Russia’s economic development: A theoretical aspect”) Based on a brief review of the book “The strategy of Russia’s economic development: A theoretical aspect” by L. P. Evstigneeva and R. N. Evstigneev, the author introduces the reader to its basic ideas and shares with him/her his thoughts. The key idea is the economic synergy (or symbol in the language of semiotics), the essence of which (reference) is disclosed in detail in the book; the emphasis is not just on the new paradigm, adequate to humanitarian civilization (referent), but also on the ability to ensure the transition from the reference to the referent.
B41|The Rural Economics of René de Girardin: Landscapes at the Service of l’Idéologie Nobiliaire|René-Louis de Girardin is remembered for having invited Rousseau at Ermenonville estate. Girardin believed it was necessary to further the debate on gardens on the basis of a principle of continuity that rejects any idea of enclosure. This made it possible to establish an agricultural model that increased production, and finally allowed the monopoly in grain sales to be broken. At the service of l’idéologie nobiliaire, his analysis shows the existence of a form of economic thinking in the second half of the 18th century that, giving primacy to agriculture, nevertheless cannot fall within the paths of physiocrats and agronomes.
B41|Productivity of work and land: a comparison between three dissimilar countries|Research background: Analysis of economic and agricultural indicators are important tools to evaluate the performance of agriculture and describe scientific and technical progress (Agol et al., 2014, pp. 1-9; Archibugi and Coco, 2004, pp. 629–654). They also enable comparisons between the performances of different countries. In the comprehensive review by McConnell and Bockstael (2005, pp. 621-669), the measures of development show that competitiveness, both in the international and domestic arena, should be evaluated by two main indexes: the work productivity index and the land productivity index. Purpose of the article: The objective of this paper is to analyse social and economic factors that influence the efficiency of agriculture in three dissimilar countries: Poland, Unites States of America and China. The analysed countries have characteristic features that influence development of specific branches of agriculture including the level of social and economic growth, structural features of agriculture, agricultural policy, and market situations, thus shaping the level and structure of production. To our knowledge, this is the first study that discusses work and land productivity in these three countries. Methodology/methods: For calculation of final indexes of work and land productivity for the analysed countries, basic control and economic characteristics are necessary. These were calculated using the Eurostat database (2014) and the Yearbook of International Statistics CSO (2012; 2013a, 2013b) and include the area of agricultural land, number of farms and the average size of farms, the number of people active in agriculture, and gross national production in total and in agriculture. Findings & Value added: We found that Poland has not yet reached optimal land or work force productivity. The indicators suggest Poland is agriculturally closer to developing countries than developed. In particular, we indicate a low agricultural efficiency compared with Western countries. We conclude that to realise the full potential of Polish agriculture, considerable changes, such as farm consolidation and alternative employment options for farm workers, are necessary. According to the analysed data, Poland in comparison to China and the USA is at the last position in the ranking achieving 4% of the GNP in agriculture. Moreover, the structure of small farms in Poland with the average surface area of 10.38 is considerably lower than in the USA (190 ha) which causes that Poland is a less-competitive country. However, one should remember that not all experiences of leading countries may be directly translated into Polish conditions, where agriculture was shaping in completely different conditions and its present level has its historical preconditions.
B41|Agent-based modelling. History, essence, future|The currently fashionable modelling tool agent-based simulation is characterized. The first part concerns the past. It presents a selection of the major intellectual roots from which this new tool emerged. It is important for social scientists, in particular for economists, to see that two relevant impacts came from neighbouring disciplines: biology and network theory. The second part concerns the present of ABM. It aims at highlighting the essential features which are characteristic for an agent-based model. Since there are currently several different opinions on this topic, the one presented here also includes some more epistemologically oriented ideas to support its plausibility. In particular the notion of emergence is scrutinized and extended. This part ends with a short recipe stating how to build an agent-based model. In the last part some ideas on the future of agent based modelling are presented. This part follows the sequence of syntax, semantics, and pragmatics. The syntactic challenges, like operators for pattern recognition, will be meat by a continuing variety of software packages and programming languages tailored to support ABM. The semantic aspect of future agent-based modelling hinges on the close relationship between the tool ABM and its object of investigation, e.g. evolutionary political economy. The need to model institutional change or communication processes will imply adaptive evolution of ABM. The pragmatics of future agent-based modelling are finally characterized as the most demanding – but also as the most influential – element that the new tool will bring about.
B41|Informal and formal meaning of the norm and the institution|In this article the problem of estimation the performance of formal norm is examined. To this purpose the existing definitions of the notion “norm” are analyzed and summarized, their insufficient formalization is noted, whereupon with the approach, using the apparatus of theory of sets and Boolean algebra, a strict definition of the norm, which includes static and dynamic components, is proposed. The description of the norm is extended by the definition of the space of the norm – a group of notions related to the norm. It’s substantiated that these notions shouldn’t be regarded as component parts of the norm. The methods of estimation the endogenous performance of formal norm (rule), basing on an analysis of its internal characteristics, but not on the results of its application is proposed. It’s suggested to determine the quality of the norm at three ways: norm as itself; accordance of the new norm to current ones; easiness of its compliance and easiness of its control. This approach allows identifying potential problematic points of the norm that can lead to difficulties in the future. Using the proposed methods of estimation of formal norm in areas, where such norms are developed actively (e.g. jurisprudence), can increase the quality of projectable norms, thus reducing costs for their future support. For the already existing norms those methods allow determining their weaknesses. In the theoretical-economic research the apparatus of formalization of norms may be useful in examination of institutional dynamics – namely, the process of institutional change.
B41|Piyasa ekonomisine geçiş süreci ve sonrasında Türkiye'de GINI katsayılarının analizi: Alternatif GINI formülü yaklaşımı<BR>[During and after the process of transition to market economy, an analysis of income distribution in Turkey: An alternative GINI formula approach]|This study considers the Gini 1 and alternative Gini 2 coefficients for households’ % income shares from 1963 to 2015 in Turkey. Throughout regarding calibrations, one might see that, despite the existence of some deviations from trend and some Gini 1 and Gini 2 coefficients’ differences, (a) there exists an improvement in the distribution of income until 2011, except for the year 2009 when the global crisis was experienced, but an average deterioration in the distribution for 2011-2015 period is experienced, (b) the geographical regions of the Turkish economy reveal different outcomes. For the period 2006-2015, it is observed that in the regions of Istanbul, West Marmara, Central Anatolia and North East Anatolia, the Lorenz curve has moved away from full equilibrium line, but in the regions of Aegean, Eastern Marmara and Eastern Black Sea, on the average, a convergence towards the equilibrium from the Lorenz curve has appeared. In other three regions, the Gini coefficients improve on average in Western Anatolia, Mediterranean and Western Black Sea regions. The Gini coefficients are increasing in the period 2006-2011 in the Middle East Anatolia and falling in 2015. In the South East Anatolia Region, there is no progress in the period 2006-2011, but, there happens to be a recovery in income distribution in 2015.
B41|Communism - A survival analysis|Human generation try to fit into a 4 dimensional survival concepts comprising the Environment, Geography, Economic and Social dimensions, over centuries and their pedigree too progressed under these guidelines. Because of the divergent level of survival targets in the economic and social strata by each human being, wealth accumulation flows unequally among the people. Industrial revolution mechanised the human work, with cost reduction and quality/volume optimization and planted Capitalism in the world, creating a wedge in the wealth accumulation process. This inducted a class war between the owners of wealth versus the workers, who are hired and fired by them. Competition made the capitalist to realise the importance of labour and diluted their concept as “Socialism”. The disproportionate wealth accumulation among people seeded the concept of communism in the world. Communism originated by Marx in Germany, spread to Russia and was promoted by Lenin. Both assumed that the large volume of people in the world belong to the low wealth possessing worker class, will revolt towards equal wealth share, and Communism shall dominate the whole world soon. But both Marx and Lenin were “Social revolutionists” and lacked “futuristic management thoughts” on how the shared wealth will be recycled to grow more, and result in prosperity among the equally shared population ? With this limited thought, the USSR (1922) and the East Germany (GDR-1961) and were created, with the entire wealth of the nation pooled on the apex “State”, representing the entire population. The state became a monopoly and all the people were simple labourers, without any self possessions. The state utilised the labour like a commodity, without any motivation to use their original ideas and any incentive to improve the productive contribution spirit. As a result, the GDR collapsed in 1989 and the USSR dwindled in 1991, bringing an end to the 69 year old Communist concept. Also both started promoting the diametrically opposite Capitalist approach and established cooperation with the (imperialist) USA. Communism could have survived and continued as a guide for wealth and prosperity for all the nations and their people in the world, if the domestic population was considered as “superior” to the “state”. The national wealth owned by the “State” should have been invested in sectorial projects and entrusted to optimum group of people to work, manage and encouraged to meet a targeted quality volume. State should have met all needs of these groups of people. A reasonable share of the net gains should have been distributed in equal proportion to all the people involved, as an incentive. Below targets and loss should have been questioned and corrective action should have been taken. In addition, the productivity and management decision should have been oriented towards ‘socio-economic Development units”. The domestic investment should be made from domestic savings and domestic technology should be manned by the domestic labour.
B41|Yes we can! Teaching DSGE models to undergraduate students|Dynamic stochastic general equilibrium (DSGE) models have become the workhorse of modern macroeconomics and the standard way to communicate ideas among applied macroeconomists. Undergraduate students, however, often remain unaware of their existence. The lack of specialized knowledge can hurt them if they decide to attend graduate school. Indeed, many first-year PhD students discover that the material they are currently learning differs significantly from what they mastered in college. But this can change. In this essay, I describe how to teach a full-fledged macroeconomics course where DSGE models take center stage. I discuss how to arrange such a course within a one-semester time frame, detail the main components of instruction, and finish with some thoughts based on my teaching experience at Macalester College.
B41|Institutional Quality and Economic Performance in West Africa|This study empirically accessed the impact of institutional quality on economic performance in West Africa. The study employed the control of corruption, government effectiveness, regulatory quality and rule of law as institutional quality indicators as provided by the World Governance Indicators, WGI (2017). A panel data set of 12 West African countries from 1996 to 2015 was estimated using the fixed effect model, the random effect model and the panel two-stage least square technique. The result showed that all the indicators of institutional quality employed in the study have positive and significant impact on economic performance in West Africa when the fixed and random effect model estimation technique was employed but only government effectiveness was significant after taking account of endogeneity using the panel two-stage least square technique. The study concludes that economic performance in West Africa would be enhanced in the presence of improved institutions with more consideration to government effectiveness.
B41|China's QE in the Context of Economic Long-Wave Theory|Soft system methodology was 'rationally reconstrusted'(as Marcuzzo (2008) recommended) to suit the research of history of economic thought.The paper constitutes a ‘meaningful narrative' and 'coherent colligation' as Walsh(1970) guilded.According to the soft system analysis map of China's QE below,The new form of China's QE is aimed at Easing Monetary Policy,small-scale living-related Fiscal Policy and revival of estate industry.
B41|Economic philosophy of al-Mawardi: Review of economic behaviour in Islamic economic|Economic behaviour in the study of Islamic economics is the basis for the government to portray political ethics and ethical economic functions of individuals in functioning as a member of society. Secular ethics and religious ethics, according to al-Mawardi, as the code of conduct in conducting economic practices by the government and every member of society to uphold the principle of goodness. In the context of economic behaviour, the world ethics (adab al-dunya) and the religious ethics (adab al-din) became guidelines for economic actors in conducting business activities including other forms of cooperation or other muamalah practice.
B41|Gross Domestic Product – National Income of Romania 1862 – 2010. Secular statistical series and methodological foundations|Starting from the importance and need to investigate one of the most relevant issues regarding the structure and dynamics of the economic and social development of all countries in the world, the book focuses on Romania, from the perspective of certain synthetic indicators, aggregated at macroeconomic level, i.e. the Gross Domestic Product and the National Income, on long data series over the past 150 years, also taking into account the comparative international context, in terms of purchasing power parity. The Part One contains a synthesis, developed and completed, of GDP data for each year of the period 1862 – 2010 and also indicators resulting from the GDP, as Net Domestic Product, Net National Product and National Income. The historical research has adopted and applied, with maximum attention, criteria that substantiated the calculations, through rigorous techniques and methods of data aggregation, in order to remove certain errors that would lead to distorted results, focusing on the accuracy of evaluations, so that they would express, in the most genuine manner, the real dimension of the statistical indicators, allowing for a correct interpretation of the economic phenomena. The operations for compiling the indicators are accompanied by comments regarding the criteria and calculation methods, as well as by methodological explanations, so that the data would be able to be rebuilt in a better format, by the interested authors, should they have a more reliable and relevant statistical information about Romania. The Part Two of the book focuses on the international literature, dedicated to criticisms theoretical and methodological opinions regarding the GDP, as well as a comparative analysis of the GDP evolution in Romania, in various hypotheses, compared to other countries.
B41|Economics in the Interdisciplinary Discourse|Structural functionalism sees society or other social objects as a system, as a structurally dissected integrity, in which each system unit performs a specific function, creating conditions for the normal functioning of all subsystems and of the system as a whole. The main problem that sociologists try to explain on the basis of functionalism - How does the social order under conditions of free activity of individuals, pursuing their own interests? How does a social mechanism operate that leads to mutual coordination of their actions in the public interest? As we see, sociologists of this direction see for themselves the basic scientific problem the same as, beginning from Adam Smith, economists see it in relation to the decentralized economic system. Economic theory can discover for itself many valuable ideas in very interesting scientific developments of sociologists.
B41|Harrodian Instability: a Misleading Concept|The concept of Harrodian instability is reexamined taking into due consideration the fact that growth occurs through irregular fluctuations. This undermines the cornerstone of Harrodian instability, namely the way in which investment is assumed to react to a degree of utilization differing from its desired level. The methodo-logical consequence of Harrodian instability is reconsidered: the assumption that only theoretical positions in which capacity and demand are perfectly adjusted can be regarded as theoretically acceptable appears to be based on weak foundations. The relevance of the cumulative tendencies toward expansion and recession is greatly re-duced. Different ways of addressing these hypothetical phenomena are suggested.
B41|The advantages of using Best-Worst Model for hybrid products|Purpose-the aim of this paper is to highlight the advantages of using Best-Worst Model to find out the importance of country of origin of hybrid products for specialistsDesign/Methodology/Approach-quantitative methods: questionnaires. SPSS was used for computing the scores and to check out if the gender or age has an influence on the scores.Findings- for specialists or consumers familiar with products, country of origin is of low importance, it is less important comparing to price or quality and it doesn?t have a significant effect on buying intention.Practical implications-the paper is very for researchers, it was proved that Best-Worst Model is more objective than other types of survey.Originality/Value-the application of the Best-Worst Model on specific categories of goods.
B41|Evolutions and Contradictions in Mainstream Macroeconomics: The Case of Olivier Blanchard| This article traces the complex intellectual path of Olivier Blanchard, a personification of the controversial evolution of macroeconomic research over the last three decades. After contributing to consolidation of the core of mainstream macroeconomics, Blanchard recently suggested ‘rethinking’ some of its key aspects to take stock of the lessons of the 2008 Great Recession, which he witnessed as the International Monetary Fund’s Chief Economist. This welcome discussion, which according to Blanchard should open mainstream macroeconomics to heterodox thinking, has so far produced a certainly interesting albeit theoretically contradictory synthesis and limited policy consequences. The most paradigmatic aspect of this rethinking of macroeconomics is represented by the abandonment in teaching of aggregate supply and demand in favor of a revival of the IS–LM model complemented by the Phillips curve. While this change of perspective does allow for the instability of ‘natural’ equilibrium to be emphasized, a deeper reading may prove incompatible with the neoclassical foundations of the mainstream approach.
B41|A Practical, Accurate, Information Criterion for Nth Order Markov Processes|Abstract The recent increase in the breath of computational methodologies has been matched with a corresponding increase in the difficulty of comparing the relative explanatory power of models from different methodological lineages. In order to help address this problem a Markovian information criterion (MIC) is developed that is analogous to the Akaike information criterion (AIC) in its theoretical derivation and yet can be applied to any model able to generate simulated or predicted data, regardless of its methodology. Both the AIC and proposed MIC rely on the Kullback–Leibler (KL) distance between model predictions and real data as a measure of prediction accuracy. Instead of using the maximum likelihood approach like the AIC, the proposed MIC relies instead on the literal interpretation of the KL distance as the inefficiency of compressing real data using modelled probabilities, and therefore uses the output of a universal compression algorithm to obtain an estimate of the KL distance. Several Monte Carlo tests are carried out in order to (a) confirm the performance of the algorithm and (b) evaluate the ability of the MIC to identify the true data-generating process from a set of alternative models.
B41|A co-utility approach to the mesh economy: the crowd-based business model|Abstract We explore the mesh economy applications of co-utility, a new concept describing self-enforcing and mutually beneficial interactions among self-interested agents. We show that the crowdsourcing market is naturally co-utile (without additional incentives). Furthermore, we analyze the investment crowdfunding industry and propose solutions that can neutralize the fear and mistrust effects underlying its market in order to make it strictly co-utile. Up on our analysis under the co-utility framework, we corroborate that collaboration is always rationally sustainable, as long as the system is co-utile and that all co-utile outcomes are Pareto-optimal; but not all Pareto-optimal outcomes are co-utile. In addition, reciprocity and hybridity equilibrium are compatible with co-utility in specific cases at which they provide Pareto-optimal outcomes. This methodology of analysis within the framework of co-utility can be extended beyond the crowd-based business models and promises to significantly contribute to economic theory.
B41|The External Validity of Consequential Stated Preference Studies: a comment|Mounting evidence suggests that Consequential Discrete Choice Experiments (CDCEs) are internally valid i.e. they elicit a de-facto revealed preference. This comment asks whether CDCEs are always externally valid. For instance, when it comes to existence values, policy makers require a valuation of the benefit that derives from passively experiencing the continued existence of a good, whereas CDCEs measure the value that derives from actively intervening to maintain or increase the supply of a good. We show that CDCEs will recommend suboptimal levels of Pigovian taxes and public goods provision. We suggest potential alternatives to CDCEs that future research should consider.
B41|The Empirics of Regulatory Reforms Proxied by Categorical Variables: Recent Findings and Methodological Issues|Some regulatory reforms do not change just a specific signal that can be represented by a quantitative continuous variable, such as a tax rate, a price cap, or an emission threshold. The standard theory of reform in applied welfare economics (going back to contributions by e.g. Ramsey, Samuelson and Guesnerie) asks the question: What is the marginal effect on social welfare of changing a policy signal? However, reforms such as privatization, unbundling or liberalization of network industries are often described by ‘packages’ shifting a policy framework. It is increasingly frequent in the empirical evaluation of such reforms to use categorical variables, often in polytomous form, for instance describing unbundling steps (vertical integration, accounting, functional, legal, ownership separation) on a discrete numerical scale, such as those proposed by the OECD and other international bodies. We review recent econometric literature evaluating regulatory reforms using such variables (40 papers) and we discuss some methodological issues arising in this context.
B41|Historia Global vs. Eurocentrismo: revisión historiográfica, análisis de consumo y un caso de estudio comparativo entre China y Europa (1730-1808)|This paper focuses on the impact of the discipline of Global History in recent decades, paying particular attention to studies on consumption and circulation of new goods in European and Asian markets. The main objective of this article is, therefore, to present a historiographical review on the impact of Global History, in which it can be observed that, in the case of studies on consumption, in particular, has had an obvious Eurocentric focus. The analysis of the British world, and its colonies, as engine of the first industrialisation, has been one of the main causes that have led towards such Eurocentric focus. This approach began to change with the growing interest in the study of China and its role in the world economy. Thus, this essay presents a historiographical review of both spaces, concluding with a comparative case study between Macau and Marseille as trans-national ports. This project is in its preliminary phases; therefore, it is only showing the principal lines. KEY Classification-JEL: B41. N20. N33. N35
B41|Classifications of innovations: Survey and future directions|The purpose of this paper is to focus on similarity and/or heterogeneity of taxonomies of innovation present in the economic fields to show as the economic literature uses different names to indicate the same type of technical change and innovation, and the same name for different types of innovation. This ambiguity of classification makes it impossible to compare the various studies; moreover the numerous typologies existing in the economics of innovation, technometrics, economics of technical change, management of technology, etc., have hindered the development of knowledge in these fields. The research presents also new directions on the classification of innovation that try to overcome these problems.
B41|A methodological note for the development of integrated aquaculture production models|Aquaculture production can yield significant economic, social and environmental effects. These exceed the financial costs and benefits aquaculture producers are faced with. We propose a methodology for the development of integrated production models that allow for the inclusion of the socio-economic and environmental effects of aquaculture into the production management. The methodology develops on a Social Cost-Benefit Analysis context and it includes three parts: i) environmental, that captures the interactions of aquaculture with the environment, ii) economic, that makes provision for the incorporation of economic determinants in the production models and iii) social, that introduces the social preferences to the production and management process. Alternatives to address data availability issues are also discussed. The methodology extends the assessment of the costs and benefits of aquaculture beyond pure financial metrics and beyond the quantification of private costs and benefits. It can also support the development of integrated models of aquaculture production that take into consideration both the private and the social costs and benefits associated with externalities and effects not appropriately captured by market mechanisms. The methodology can support aquaculture management and policies targeting sustainable and efficient aquaculture production and financing from an economic, financial, social and environmental point of view.
B41|A Primer on the “Reproducibility Crisis” and Ways to Fix It|This article uses the framework of Ioannidis (2005) to organize a discussion of issues related to the “reproducibility crisis.” It then goes on to use that framework to evaluate various proposals to fix the problem. Of particular interest is the “post-study probability”, the probability that a reported research finding represents a true relationship. This probability is inherently unknowable. However, a number of insightful results emerge if we are willing to make some conjectures about reasonable parameter values. Among other things, this analysis demonstrates the important role that replication can play in improving the signal value of empirical research.
B41|Economists, social scientists, and the reconstruction of the world order in interwar britain|The early decades of the 20th century in Europe witnessed a wealth of discussion on the epistemology of the social sciences. Not only were the boundaries between different disciplinary fields being redrawn, but also the nature of scientific knowledge about human and social affairs came under careful scrutiny. One prominent issue in debate was the separation between positive and normative analysis, and the legitimacy of the prescriptive claims often advanced by social scientists. The paper attempts to investigate this process through the lenses of contemporary debates on international politics. During the interwar years, the reconstruction of the world order provided a topic over which social analysts of different backgrounds and persuasions could debate and interact, thus exploring the limits of the knowledge they produced. In England, authors as diverse as Bertrand Russell, Graham Wallas, Harold Laski, Karl Mannheim, John Hobson, and Lionel Robbins were all part of this conversation, which transgressed most disciplinary boundaries. As a pressing issue in the European agenda at the time, however, international politics also made it more difficult to sustain a clear distinction between positive analysis and policy prescription. In the works of Robbins, one can see the topic treated as part of the applied domain of political economy.
B41|Measuring and Bounding Experimenter Demand|We propose a technique for assessing robustness of behavioral measures and treatment effects to experimenter demand effects. The premise is that by deliberately inducing demand in a structured way we can measure its influence and construct plausible bounds on demand-free behavior. We provide formal restrictions on choice that validate our method, and a Bayesian model that microfounds them. Seven pre-registered experiments with eleven canonical laboratory games and around 19,000 participants demonstrate the technique. We also illustrate how demand sensitivity varies by task, participant pool, gender, real versus hypothetical incentives, and participant attentiveness, and provide both reduced-form and structural analyses of demand effects.
B41|Policy relevance of applied economist: Examining sensitivity and inferences|It is assumed that research based on empirical data produces factual insight that can be used to guide evidence based policies. However, researchers may tend to specify models based on prior beliefs and construe results accordingly. In this paper, we argue that greater scrutiny is needed along the research process to acknowledge and communicate the limitations of research findings. To illustrate, we review two empirical papers from applied economists aimed at influencing policy. Each paper is analysed to identify how inferences based on prior beliefs are used to specify models and how this impacts the result. Additionally, consideration is given to the sensitivity of results under alternative assumptions. While we do find that the considered papers provide valuable knowledge to the field of agriculture economics, they fail in disclosing the limitations of their results to decision makers, thus undermining considerably their policy relevance. Finally, approaches to increase objectivity in empirical research are considered. Il est d’avis général que la recherche empirique produit des résultats factuels qui peuvent servir à l’élaboration de politiques publiques. Par contre, le chercheur est sujet à spécifier ses modèles, ainsi qu’à faire des hypothèses susceptibles de refléter ses a priori, influençant potentiellement, du fait, les résultats obtenus. Dans ce papier, nous suggérons qu’une plus grande rigueur tout au long du processus de recherche serait nécessaire afin de communiquer les faiblesses et limitations des résultats. Pour démontrer ce propos, nous considérons deux papiers publiés qui visaient à influencer des politiques agricoles. Pour chacun des papiers, nous identifions des hypothèses associées aux a priori des auteurs et comment ces derniers peuvent influencer les résultats. Par la suite, nous vérifions ces mêmes résultats sous des hypothèses alternatives. Bien que les deux papiers considérés apportent une certaine contribution, la non-divulgation d’hypothèses fortes susceptibles d’affecter les résultats réduit considérablement leur relevance pour les preneurs de décisions. Pour terminer, des suggestions pour améliorer l’objectivité des recherches empiriques sont brièvement discutées.
B41|Dimensions of Quality of Life in Germany: Measured by Plain Text Responses in a Representative Survey (SOEP)|"This paper demonstrates how quality of life can be measured by plain text in a representative survey, the German Socio Economic Panel Study (SOEP). Furthermore, the paper shows that problems that are difficult to monitor, especially problems like the state of the European Union, long-term climate change but also the national debt or problems with the quality of consumer goods (like food) and services (like medical treatment), are not issues of particular importance to the majority of people. Developments and risks that are difficult to monitor and only have long-term effects should be left primarily to the discourse conducted by experts and the politically-minded ""elites"", the avant garde. And in representative democracies it is ultimately the parliamentarians who must decide. Parliamentarians are likely able to make somewhat better decisions using modern representative surveys and national dialogues than they would be without these instruments of civic participation. Nevertheless, improved civic participation cannot replace parliaments."
B41|Jumping the queue: An experiment on procedural preferences|We present a three-player queuing game to study procedural preferences in a laboratory experiment. Together with markets, queues and waiting lists are universal procedures for allocating goods and services. We designed our queuing game to disentangle motivations of outcome-oriented egoistic preferences, outcome-oriented distributional (inequality aversion) preferences and outcome-independent procedural preferences. In a series of treatments, we introduce a market element and allow two of the three players to bargain over a queue jump, thus violating the queuing procedure. A third player is able to engage in peer punishment to sanction queue jumping. We provide evidence that a simple model of procedural preferences is able to explain the behavior of a share of the subjects in our experiment.
B41|Are Dynamic Stochastic Disequilibrium models Keynesian or neoclassical?|Dynamic Stochastic Disequilibrium (DSDE) models share the micro-foundations of Dynamic Stochastic General Equilibrium (DSGE) models based on inter-temporal optimization and rational expectations. Yet, it features the principle of effective demand which is at the core of Traditional Post-Keynesian (TPK) models and follows from the perception that the wage inflation is a policy variable rather than a labor-market clearing variable. In order to locate the DSDE model among the traditions of economic thought, the paper compares DSDE first-order conditions of optimal behavior with TPK rule-of-thumb behavior. It further compares the economic propagation of a DSDE model to those of a DSGE and TPK model as well as a Synthetic Neoclassical (SNC) model which features TPK behavioral assumptions and labor-market clearing. We arrive at two core conclusions: First, apart from assumptions regarding expectation formation, orthodox micro-foundation is, to a considerable extent, consistent with the behavioral hypotheses underlying TPK models. Second, the economy characterized by the DSDE model is essentially post-Keynesian rather than neoclassical because it features the principle of effective demand.
B41|The WHO warns of outbreak of virulent new â€˜Economic Realityâ€™ virus|A new virus, known as â€˜Realityâ€™, has started to afflict Mainstream Economists, causing them to reject the â€˜as ifâ€™ arguments they used to use to justify their models. There is no known cure for the virus, and complete avoidance of â€˜Realityâ€™ is the only effective strategy to prevent infection.
B41|Beliefs Aggregation and Return Predictability|We study return predictability using a dynamic model of speculative trading among relatively overconfident competitive traders who agree to disagree about the precision of their private information. The return process depends on both parameter values used by traders and empirically correct parameter values. Although traders apply Bayes Law consistently, equilibrium returns are predictable based on current and past dividends and prices. We derive specific conditions under which excess returns exhibit realistic patterns of short-run momentum and long-run mean-reversion. We clarify the concepts of rational expectations and market efficiency in a setting with differences in beliefs.
B41|As Críticas de Amartya Sen à Teoria da Escolha Social de Kenneth Arrow|Este artigo visa a sistematizar as críticas que Amartya Sen dirige à estrutura teórica adotada por Arrow e a mostrar como, para fugir aos resultados devastadores do teorema da Impossibilidade, Sen defende a ampliação do universo de informações a serem utilizadas para embasar a escolha social. Inicialmente é apresentado um breve apanhado da teoria da Escolha Social de Arrow com o objetivo de fornecer o pano de fundo para a compreensão das críticas que Sen dirige a esse sistema teórico. Em seguida são expostas as interpretações de Sen sobre as razões que levaram ao resultado da impossibilidade e as críticas que este autor dirige aos fundamentos da teoria de Arrow. Por fim, são tecidas algumas considerações sobre a natureza desta reflexão crítica e suas consequências para a visão de Bem-Estar posteriormente adotada por Sen.
B41|NEW ECONOMIC WINDOWS ON INCOME AND WEALTH: THE k-GENERALIZED FAMILY OF DISTRIBUTIONS|Over the last decades, the distribution of income and wealth has been deteriorating in many countries, leading to increased inequalities within and between societies. This tendency has revived the interest in the subject greatly, yet it still receives very little attention within the realm of mainstream economic thinking. One reason for this is that the basic paradigm of “standard economics”, the representative-agent General Equilibrium framework, is badly equipped to cope with distributional issues. Here we argue that when the economy is treated as a complex system composed of many heterogeneous interacting agents who give rise to emergent phenomena, to address the main stylized facts of income/wealth distribution requires leaving the toolbox of mainstream economics in favour of alternative approaches. The “?-generalized” family of income/wealth distributions, building on the categories of complexity, is an example of how advances in the field can be achieved within new interdisciplinary research contexts.
B41|Stock Market Cycles and Supply Side Dynamics: Two Worlds, One Vision?|The paper compares two state-of-art but very dinstinct methods used in macroeconomics: rational-expectations DSGE and bounded rationality behavioural models. Both models are extended to include a financial friction on the supply side.The result in both models is that production, supply of credit and the front payment to capital producers depend heavily on the stock market cycles. During phases of optimism, credit is abundant, access to production capital is easy, the cash-in-advance constraint is lax, the risks are undervalued, and production is booming. But upon reversal in market sentiment, the contraction in all these parameters is deeper and asymmetric. This is even more evident in the behavioural model, where cognitive limitations of economic agents result in exacerbation of the contraction. While both models capture the empirical regularities very well, the validation exercise is even more favourable to the behavioural model.
B41|Ekonomija Vlada (Prikaz Knjige Denija Rodrika: Economics Rules - Why Economics Works, When It Fails, And How To Tell The Difference)|No abstract is available for this item.
B41|The Global Consumption and Income Project (GCIP): An Overview|We introduce two separate datasets [The Global Consumption Dataset (GCD) and The Global Income Dataset (GID)] making possible an unprecedented portrait of consumption and income of persons over time, within and across countries, around the world. The current benchmark version of the dataset presents estimates of monthly real consumption and income for every percentile of the population (a “consumption/income profile”) for more than 160 countries and more than half a century (1960–2015). We describe the construction of the datasets and demonstrate possible uses by presenting some sample results concerning the distribution of consumption, poverty and inequality in the world.
B41|Economic Aspects Of Fossil Fuel Social Costs. Why Do We Subsidize And Mediate The Cliamte Change Process?|Nowadays, humanity is in a position to choose carefully every step it makes in order to ensure economic development without compromising the welfare of future generations who will need a social and ecological climate as favorable it could be. On the other hand, the conventional energy production is achieved taking the risks of the Earth overheating and its aggregate economic consequences, actually this climatic changes already appear in a more and more aggressive way, including on global economies. Over the past few years international organizations such as OECD, the IMF, the IEA, the World Bank are focusing their attention on the fossil fuel subsidies impacts over the energy production and consumption, quantifying the economic and social impacts of fossil fuel reform. The reason this study had to be done is the disadvantageous position of renewable energy industry compared with the fossil fuel’s industry situation which lies actually in the adopted subsidy strategy and the lack of measures for internalizing externalities on the sector, which are considered by IMF also a type of fossil fuel subsidy. So, this study presents an updated overlook on the fossil fuel externality problem, revises the identified literature linked to the”externality” notion, outlines the identified trends and polices of internalizing the fossil fuels externalities, and tries to review the estimations of the potential costs of the global warming as a consequence of too high social costs of the fossil fuel installed technologies. In this purpose there are on their way of implementation different systemic methods of research, including scientific abstraction, deduction, analysis and synthesis and quantitative analysis in order to outline the current situation of fossil fuel externality problem and its potential impact over the economic welfare.
B41|Une approche transactionnelle des démarches d’élaboration participative d’indicateurs sociétaux. La méthode du Conseil de l’Europe|This article is dedicated to innovative approaches regarding association of citizens in the production of alternative indicators. It is based on an experimentation of the methodology proposed by the Council of Europe which is aimed at developing well-being indicators in a participatory way to qualify well-being and societal progress. The article proposes an analytical shaping of this approach, and more generally of the efforts to involve citizens in indicators production processes. Our framework, which can be described as transactional, is based on American pragmatism, especially on J. Dewey?s works. Such an approach invites to pay attention on the communicative processes which underlie the formation of values. This implies to reconsider the nature of the data used to understand well-being and to develop indicators. The article also focuses on structuring phenomena that can affect the participatory processes. JEL Codes?: A13, B41, B52, I31, Z13
B41|L’analyse axiomatique et l’attitude par rapport au risque|This epistemological note examines the status of risk attitude concepts in decision theory.?At first sight, axiomatic analysis does not rely on those concepts, which illustrates a certain neutrality of decision models regarding risk attitudes.?Further analysis, however, highlights the importance of the conditional variation and the strengthening of risk attitudes, which establishes the axiomatic significance of risk attitude concepts. Classification JEL?: B41, D81.
B41|Religion et marché : du réductionnisme économique à l’intégration du rôle des croyances|The economics of religion was developed on the base, on one hand of Hume?s assumption of the motivational neutrality of beliefs, and on the other hand on the work of Adam Smith on religious goods as standard goods. This article aims to go beyond the standard economic approach of religion in rehabilitating the role of beliefs via interpretative rationality and identity of the person. It then follows an analysis of embedded market in religion. Classification JEL?: B41, N00
B41|Beliefs Aggregation and Return Predictability|We study return predictability using a dynamic model of speculative trading among relatively overconfident competitive traders who agree to disagree about the precision of their private information. The return process depends on both parameter values used by traders and empirically correct parameter values. Although traders apply Bayes Law consistently, equilibrium returns are predictable based on current and past dividends and prices. We derive specific conditions under which excess returns exhibit realistic patterns of short-run momentum and long-run mean-reversion. We clarify the concepts of rational expectations and market efficiency in a setting with differences in beliefs.
B41|El Plan de Ordenamiento Territorial (POT) de Cali, una aproximación|En este documento se describe, analiza y evalúa la política pública de desarrollo urbanístico del Plan de Ordenamiento Territorial en la ciudad de Cali (POT, 2000). La incidencia de dicha política pública dentro de la transformación física de la urbe se puede evidenciar a través de un indicador tan elemental como es el precio del suelo urbano -en relación con el mercado de los precios de la tierra urbana, debido a que este factor señalizador de mercado determina las reglas del juego en una sociedad-. Es decir, se tiene una herramienta metodológica en términos de evaluación de estas políticas públicas específicas.
B41|Desempeño académico y diferencias de género en Colombia: un análisis con base en las pruebas TIMSS 2007|Este artículo analiza las características que inciden en el desempeño de los estudiantes colombianos en el área de matemáticas. Con base en la información de la prueba TIMSS 2007, evalúa el impacto sobre las brechas en el desempeño entre hombres y mujeres en los grados cuarto y octavo. El estudio evidencia que, además de las condiciones innatas, las características que inciden en mayor proporción sobre el desempeño académico son, en primer lugar, el entorno familiar del estudiante, que en buena parte determina el comportamiento individual y su interacción dentro de la sociedad, y segundo, las creencias y/o confianza que el estudiante tiene en su capacidad y su esfuerzo en las actividades matemáticas.
B41|Desigualdad inicial y trayectorias de acumulación del capital humano bajo dos regímenes de financiamiento educativo: simulaciones para Colombia|Este trabajo estudia la relación dinámica entre el entorno socioeconómico local, la desigualdad inicial en los ingresos de las familias y los impactos en las trayectorias de acumulación de capital humano en Colombia. El estudio compara las trayectorias dinámicas de un régimen centralizado en el financiamiento de los servicios educativos, frente a un régimen descentralizado en el que los gastos educativos se financian en ámbitos locales o con recursos propios de las familias. Los resultados del estudio sugieren que cuando existe heterogeneidad inicial severa en la dotación de recursos de las familias, a largo plazo es más eficiente un sistema económico y social con gobierno central vigoroso en la financiación del gasto educativo que otro en el que los recursos para el suministro de los servicios educativos provienen predominantemente de los recursos propios de las familias o de las tasas impositivas a las rentas locales.
B41|Mentalism Versus Behaviourism In Economics: A Philosophy-Of-Science Perspective|Behaviourism is the view that preferences, beliefs, and other mental states in social-scientific theories are nothing but constructs re-describing people’s behaviour. Mentalism is the view that they capture real phenomena, on a par with the unobservables in science, such as electrons and electromagnetic fields. While behaviourism has gone out of fashion in psychology, it remains influential in economics, especially in ‘revealed preference’ theory. We defend mentalism in economics, construed as a positive science, and show that it fits best scientific practice. We distinguish mentalism from, and reject, the radical neuroeconomic view that behaviour should be explained in terms of brain processes, as distinct from mental states.<br><small>(This abstract was borrowed from another version of this item.)</small>
B41|Agent-based computational models– a formal heuristic for institutionalist pattern modelling?|"Institutionalist economists have always been criticizing the neoclassical way of studying the economy, especially because of its obsession to a very strict and flawed formalism. This formalism receives critique also from advocates of agent-based computational economic (ACE) models. The criticism seems to be similar to that of institutional economists. Although some authors consider ACE models to belong to a completely new way of thinking about economics, many concepts of ACE have been anticipated by institutionalists: Although using a different vocabulary, ACE proponents speak about cumulative causation, realistic agents, explanatory models, dynamic relations among individuals and the necessity to see the economy as an systemic whole rather than from an atomistic perspective. Consequently, the emergence of the ACE framework may not be left unconsidered by institutionalist economists. This paper investigates the consistency of ACE models with the institutionalist research program as defined by Myrdal, Wilber and Harrison and other original institutionalists and discusses whether ACE models can be a useful heuristic for institutionalist ""pattern modelling"". I study the ability of ACE models to provide a holistic, systemic and evolutionary picture of the economy, the conception of agents in ACE models, and ask whether they can help to understand the social stratification of a society with its power relations. I also compare ACE models with earlier attempts to formalize institutionalist analysis, e.g. by Bush and Elsner (Theory of Institutional Change), Hayden (Social-­Fabric-Matrix) or Radzicki (System Dynamics).<br><small>(This abstract was borrowed from another version of this item.)</small>"
B41|Economics: Between Prediction And Criticism|We suggest that one way in which economic analysis is useful is by offering a critique of reasoning. According to this view, economic theory may be useful not only by providing predictions, but also by pointing out weaknesses of arguments. It is argued that when a theory requires a nontrivial act of interpretation, its roles in producing predictions and offering critiques vary in a substantial way. We offer a formal model in which these different roles can be captured.
